(window["webpackJsonp"] = window["webpackJsonp"] || []).push([[0],{

/***/ "./node_modules/@dr/drc-audio-player/dist/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/@dr/drc-audio-player/dist/index.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nmodule.exports = __webpack_require__(/*! ./player */ \"./node_modules/@dr/drc-audio-player/dist/player.js\");\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-audio-player/dist/index.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-audio-player/dist/lib/EventTarget.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@dr/drc-audio-player/dist/lib/EventTarget.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\n\nvar _eventtarget = __webpack_require__(/*! @dr/drc-util/object/eventtarget */ \"./node_modules/@dr/drc-util/object/eventtarget.js\");\n\nvar _eventtarget2 = _interopRequireDefault(_eventtarget);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar EventTarget = function EventTarget() {\n    _classCallCheck(this, EventTarget);\n\n    (0, _eventtarget2.default)(this);\n};\n\nexports.default = EventTarget;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-audio-player/dist/lib/EventTarget.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-audio-player/dist/lib/Player.js":
/*!**************************************************************!*\
  !*** ./node_modules/@dr/drc-audio-player/dist/lib/Player.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nvar _EventTarget2 = __webpack_require__(/*! ./EventTarget */ \"./node_modules/@dr/drc-audio-player/dist/lib/EventTarget.js\");\n\nvar _EventTarget3 = _interopRequireDefault(_EventTarget2);\n\nvar _Tracking = __webpack_require__(/*! ./Tracking */ \"./node_modules/@dr/drc-audio-player/dist/lib/Tracking.js\");\n\nvar _Tracking2 = _interopRequireDefault(_Tracking);\n\nvar _extend = __webpack_require__(/*! @dr/drc-util/object/extend */ \"./node_modules/@dr/drc-util/object/extend.js\");\n\nvar _extend2 = _interopRequireDefault(_extend);\n\nvar _create = __webpack_require__(/*! @dr/drc-util/dom/create */ \"./node_modules/@dr/drc-util/dom/create.js\");\n\nvar _create2 = _interopRequireDefault(_create);\n\nvar _PsdbClient = __webpack_require__(/*! ./PsdbClient */ \"./node_modules/@dr/drc-audio-player/dist/lib/PsdbClient.js\");\n\nvar _PsdbClient2 = _interopRequireDefault(_PsdbClient);\n\nvar _hls = __webpack_require__(/*! hls.js */ \"./node_modules/hls.js/dist/hls.js\");\n\nvar _hls2 = _interopRequireDefault(_hls);\n\nvar _drcMediaDecryption = __webpack_require__(/*! @dr/drc-media-decryption */ \"./node_modules/@dr/drc-media-decryption/js/index.js\");\n\nvar _drcMediaDecryption2 = _interopRequireDefault(_drcMediaDecryption);\n\nvar _config = __webpack_require__(/*! ./config.options */ \"./node_modules/@dr/drc-audio-player/dist/lib/config.options.js\");\n\nvar _config2 = _interopRequireDefault(_config);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } // Import dependencies.\n\n\n// Import local config.\n\n\n// Import consts from package.\nvar name = \"@dr/drc-audio-player\";\nvar version = \"1.5.3\";\n\n/**\n * Class for player SDK.\n * @extends EventTarget\n */\n\nvar Player = function (_EventTarget) {\n  _inherits(Player, _EventTarget);\n\n  _createClass(Player, [{\n    key: \"options\",\n\n    /**\n     * Get options.\n     * @return {object} Object with applied options.\n     */\n    get: function get() {\n      return this._options;\n    }\n    /**\n     * Set options.\n     * @param  {Object} obj   Options object.\n     * @return {Class}        Player class\n     */\n    ,\n    set: function set(obj) {\n      this._options = obj;\n      return this;\n    }\n\n    /**\n     * Get attached audio element.\n     * @return {Element} HTML <audio> element\n     */\n\n  }, {\n    key: \"element\",\n    get: function get() {\n      return this._element;\n    }\n    /**\n     * Set audio element.\n     * @param  {Element} element  HTML <audio> element\n     * @return {Class}            Player class\n     */\n    ,\n    set: function set(element) {\n      this._element = element;\n      return this;\n    }\n\n    /**\n     * Get loaded programcard or channel object.\n     * @return {Object}           ProgramCard or Channel object\n     */\n\n  }, {\n    key: \"resource\",\n    get: function get() {\n      return this._resource;\n    }\n    /**\n     * Set loaded programcard or channel object.\n     * @param  {Object} obj       ProgramCard or Channel object\n     * @return {Class}            Player class\n     */\n    ,\n    set: function set(obj) {\n      this._resource = obj;\n      return this;\n    }\n\n    /**\n     * Get loaded programcard object.\n     * @return {Object}           Programcard object\n     */\n\n  }, {\n    key: \"program\",\n    get: function get() {\n      return this._program;\n    }\n    /**\n     * Set loaded programcard object.\n     * @param  {Object} obj       Programcard object\n     * @return {Class}            Player class\n     */\n    ,\n    set: function set(obj) {\n      this._program = obj;\n      return this;\n    }\n\n    /**\n     * Get loaded channel object.\n     * @return {Object}           Channel object\n     */\n\n  }, {\n    key: \"channel\",\n    get: function get() {\n      return this._channel;\n    }\n    /**\n     * Set loaded channel object.\n     * @param  {Object} obj       Channel object\n     * @return {Class}            Player class\n     */\n    ,\n    set: function set(obj) {\n      this._channel = obj;\n      return this;\n    }\n\n    /**\n     * Get available channels.\n     * @return {Array}            List of radio channels\n     */\n\n  }, {\n    key: \"channels\",\n    get: function get() {\n      return this.hasOwnProperty('_channels') ? this._channels : null;\n    }\n    /**\n     * Set available channels.\n     * @param  {Array} arr        List of radio channels\n     * @return {Class}            Player class\n     */\n    ,\n    set: function set(arr) {\n      this._channels = arr;\n      return this;\n    }\n\n    /**\n     * Get current broadcast object.\n     * @return {Object}           Broadcast object\n     */\n\n  }, {\n    key: \"broadcast\",\n    get: function get() {\n      return this._broadcast;\n    }\n    /**\n     * Set current broadcast object.\n     * @param  {Object} obj       Channel object\n     * @return {Class}            Player class\n     */\n    ,\n    set: function set(obj) {\n      this._broadcast = obj;\n      return this;\n    }\n\n    /**\n     * Get player audio sources.\n     * @return {Array}            Array of available sources\n     */\n\n  }, {\n    key: \"sources\",\n    get: function get() {\n      return this._sources;\n    }\n    /**\n     * Set player audio sources.\n     * @param  {Array} arr        Array of available sources\n     * @return {Class}            Player class\n     */\n    ,\n    set: function set(arr) {\n      this._sources = arr;\n      return this;\n    }\n\n    /**\n     * Get list of supported features.\n     * @return {Object}           Object with features as key and boolean state as value.\n     */\n\n  }, {\n    key: \"features\",\n    get: function get() {\n      return {\n        MP3: this._supportsMP3,\n        ICY: this._supportsICY,\n        MP4: this._supportsMP4,\n        NativeHLS: this._supportsNativeHLS,\n        MSE: this._supportsMSE,\n        HLS: this._supportsHLS\n      };\n    }\n\n    /**\n     * Get player version. Extracted from package.json.\n     * @return {String}           Version string, e.g. '1.0.0'\n     */\n\n  }, {\n    key: \"version\",\n    get: function get() {\n      return version;\n    }\n\n    /**\n     * Get player name. Extracted from package.json.\n     * @return {String}           Name string, e.g. '@dr/drc-audio-player-sdk'\n     */\n\n  }, {\n    key: \"name\",\n    get: function get() {\n      return name;\n    }\n\n    /**\n     * Create player.\n     * @param {Object} settings   Setup settings for player.\n     */\n\n  }]);\n\n  function Player(settings) {\n    _classCallCheck(this, Player);\n\n    var _this = _possibleConstructorReturn(this, (Player.__proto__ || Object.getPrototypeOf(Player)).call(this));\n\n    _this.options = (0, _extend2.default)({}, _config2.default, settings.options || {});\n    _this.DEBUG = _this.options.debug;\n\n    if (!settings.element) {\n      var _ret;\n\n      return _ret = _this.DEBUG ? console.debug('Element is undefined.') : false, _possibleConstructorReturn(_this, _ret);\n    } else {\n      _this.element = settings.element;\n    }\n\n    _this.DEBUG && console.debug(_this.name, 'version:', _this.version);\n\n    _this._idstring = _this.name.replace('@dr/', 'dr.') + '.' + _this.version; // e.g. dr.drc-audio-player.1.4.0\n\n    _this._psdb = new _PsdbClient2.default((0, _extend2.default)({}, settings.psdbClientOptions || {}, {\n      subscriberId: _this._idstring\n    }));\n    _this._tracker = new _Tracking2.default(_this.element, _this);\n\n    _this._detectFeatures();\n    _this._attachEvents();\n    _this._attachToElement();\n    _this._updateChannelList();\n    return _this;\n  }\n\n  /**\n   * Detect features supported by browser.\n   * @return {Class}            Player class\n   */\n\n\n  _createClass(Player, [{\n    key: \"_detectFeatures\",\n    value: function _detectFeatures() {\n      this._supportsMP3 = !!(this.element.canPlayType && this.element.canPlayType('audio/mpeg;').replace(/no/, ''));\n      this._supportsICY = this._supportsMP3;\n      this._supportsMP4 = !!(this.element.canPlayType && this.element.canPlayType('audio/mp4').replace(/no/, ''));\n      this._supportsNativeHLS = !!(this.element.canPlayType && this.element.canPlayType('application/vnd.apple.mpegURL').replace(/no/, ''));\n      this._supportsMSE = 'MediaSource' in window;\n      this._supportsHLS = this._supportsNativeHLS || this._supportsMSE;\n      if (this.DEBUG) {\n        console.debug('Features:', this.features);\n      }\n      return this;\n    }\n\n    /**\n     * Setup HLS.js if native HLS is unavailbale but Media Source Extension is.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_setupHls\",\n    value: function _setupHls() {\n      var _this2 = this,\n          _arguments = arguments;\n\n      if (!this._supportsNativeHLS && this._supportsMSE) {\n        this._hls = new _hls2.default({\n          debug: this.DEBUG\n        });\n        this._hls.attachMedia(this.element);\n        this._hls.on(_hls2.default.Events.MEDIA_ATTACHED, function () {\n          _this2.dispatchEvent('HLSJS_MEDIA_ATTACHED', _arguments);\n        });\n        this._hls.on(_hls2.default.Events.FRAG_BUFFERED, function () {\n          _this2.dispatchEvent('HLSJS_FRAG_BUFFERED', _arguments);\n        });\n        this._hls.on(_hls2.default.Events.ERROR, function (evt, data) {\n          return _this2._onHLSJSError;\n        });\n        this._onHLSJSError = function (evt, data) {\n          this.dispatchEvent('HLSJS_ERROR', arguments);\n          if (data.fatal) {\n            console.debug(evt, data);\n            switch (data.type) {\n              case _hls2.default.ErrorTypes.NETWORK_ERROR:\n                // try to recover network error\n                console.debug(\"Fatal network error encountered, trying to recover.\");\n                this._hls.startLoad();\n                break;\n              case _hls2.default.ErrorTypes.MEDIA_ERROR:\n                // try to recover media error\n                console.debug(\"Fatal media error encountered, trying to recover.\");\n                this._hls.recoverMediaError();\n                break;\n              default:\n                // cannot recover\n                console.debug(\"Fatal error, cannot recover.\", evt, data);\n                this._hls.destroy();\n                break;\n            }\n          }\n        };\n      }\n      return this;\n    }\n\n    /**\n     * Attach events.\n     * @return {Class}            Player class\n     **/\n\n  }, {\n    key: \"_attachEvents\",\n    value: function _attachEvents() {\n      var _this3 = this;\n\n      // Log events if debug is active.\n      if (this.DEBUG) {\n        this.options.debugEvents.forEach(function (event) {\n          _this3.element.addEventListener(event, function (e) {\n            console.debug(event, e);\n          });\n        });\n      }\n\n      // Hack for MEDIA_ERR_DECODE errors in Chrome 64+ (see: https://github.com/video-dev/hls.js/blob/b80a20d095ea4b7d92ba58e0b966a87c51727986/demo/main.js)\n      var chrome64plus = /chrome\\/((\\d{3})|([7-9]\\d)|(6[4-9]))\\./;\n      var userAgent = navigator.userAgent.toLowerCase();\n      if (chrome64plus.test(userAgent)) {\n        this.element.addEventListener('error', function (event) {\n          var mediaError = event.currentTarget.error;\n          if (mediaError.code === mediaError.MEDIA_ERR_DECODE) {\n            _this3._hls.recoverMediaError();\n          }\n        });\n      }\n\n      return this;\n    }\n\n    /**\n     * Attach methods to audio element.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_attachToElement\",\n    value: function _attachToElement() {\n      var _this4 = this;\n\n      // Unified loading method.\n      this.element.loadResource = function (obj) {\n        _this4.loadResource(obj);\n        return _this4;\n      };\n      // Load a program (OD material).\n      this.element.loadProgram = function (uri) {\n        _this4.loadProgram(uri);\n        return _this4;\n      };\n      // Load a live channel.\n      this.element.loadChannel = function (id) {\n        _this4.loadChannel(id);\n        return _this4;\n      };\n      // Returns the loaded program or live channel info.\n      this.element.getResource = function () {\n        return _this4.resource;\n      };\n      // Returns programcard for the current program.\n      this.element.getProgramCard = function () {\n        return _this4.program;\n      };\n      // Returns the current broadcast object.\n      this.element.getBroadcast = function () {\n        return _this4.broadcast;\n      };\n      // Returns duration of current program.\n      this.element.getDuration = function () {\n        return _this4.getDuration();\n      };\n      // Return this player class.\n      this.element.getPlayerClass = function () {\n        return _this4;\n      };\n      return this;\n    }\n\n    /**\n     * Update list of active radio channels.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_updateChannelList\",\n    value: function _updateChannelList() {\n      var _this5 = this;\n\n      this._psdb.getChannels('radio').then(function (channels) {\n        _this5.channels = channels;\n      });\n      return this;\n    }\n\n    /**\n     * Load program / ondemand resource. Using promises.\n     * @param {String} id         Production number, url, urn or slug\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"loadProgram\",\n    value: function loadProgram(id) {\n      var _this6 = this;\n\n      this._psdb.getProgramCard(id).then(function (programcard) {\n        // Extract timestamp.\n        _this6._timestamp = id.match(/#+[\\/\\&\\?\\!]*((?:(\\d{1,3}):)?([0-5]?\\d{1}):([0-5]{1}\\d{1}))$/);\n        _this6.resource = _this6.program = programcard;\n        _this6.dispatchEvent('programcardReady', _this6.programcard);\n        _this6.channel = _this6.broadcast = null;\n        return _this6._psdb.getPrimaryAsset(programcard);\n      }).then(function (asset) {\n        // If previous resource was a live channel, cancel timer.\n        clearTimeout(_this6._id);\n        return _this6._psdb.getAsset(asset.Uri);\n      }).then(function (manifest) {\n        _this6._resolveManifest(manifest);\n        _this6._addSources();\n      }).catch(function (error) {\n        if (_this6.DEBUG) console.error(error);\n      });\n      return this;\n    }\n\n    /**\n     * Load live channel. Using promises.\n     * @param {String} uri        Channel slug, urn or url\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"loadChannel\",\n    value: function loadChannel(uri) {\n      var _this7 = this;\n\n      this._psdb.getChannel(uri).then(function (channel) {\n        _this7._timestamp = false;\n        _this7.resource = _this7.channel = channel;\n        return _this7._psdb.getLiveServers(_this7.channel);\n      }).then(function (servers) {\n        _this7._resolveLiveServers(servers);\n        _this7._addSources();\n        return _this7._psdb.getCurrentBroadcast(_this7.channel.Slug);\n      }).then(function (broadcast) {\n        _this7.broadcast = broadcast;\n        return _this7._psdb.getProgramCard(broadcast.ProductionNumber);\n      }).then(function (programcard) {\n        _this7.program = programcard;\n        _this7.dispatchEvent('programcardReady', _this7.programcard);\n        clearTimeout(_this7._id);\n        _this7._setTimerForBroadcastUpdate();\n      }).catch(function (error) {\n        if (_this7.DEBUG) console.error(error);\n      });\n      return this;\n    }\n\n    /**\n     * Load program or live channel.\n     * @param {Object} obj        Object with 'resource' or 'channel' key.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"loadResource\",\n    value: function loadResource(obj) {\n      try {\n        if (obj.hasOwnProperty('resource') && obj.resource) {\n          this.loadProgram(obj.resource);\n        } else if (obj.hasOwnProperty('channel') && obj.channel) {\n          this.loadChannel(obj.channel);\n        } else {\n          return this.DEBUG ? console.debug('No valid source found.') : false;\n        }\n      } catch (error) {\n        if (this.DEBUG) console.error(error);\n      }\n      return this;\n    }\n\n    /**\n     * If timestamp is available, attach a temporary event then seeks to timestamp when playback is ready.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_attachTimestampEvent\",\n    value: function _attachTimestampEvent() {\n      var _this8 = this;\n\n      var applyTimestamp = function applyTimestamp() {\n        // Remove event to prevent endless cycle.\n        _this8.element.removeEventListener('canplay', applyTimestamp);\n        if (_this8._timestamp) {\n          // Extract hours, minutes and seconds from regex match.\n          var time = _this8._timestamp.slice(2, 5);\n          // Convert to seconds.\n          var seconds = parseInt(time[0] || 0) * 3600 + parseInt(time[1]) * 60 + parseInt(time[2]);\n          // Apply timestamp.\n          _this8.element.currentTime = seconds;\n        }\n      };\n      // If timestamp found in loaded resource, attach event.\n      if (this._timestamp) {\n        this.element.addEventListener('canplay', applyTimestamp);\n      }\n      return this;\n    }\n\n    /**\n     * Compare function that sorts by highest bitrate. Bitrate \"-1\" is dynamic and should be first.\n     * @param {Object} a          First value to compare\n     * @param {Object} b          Second object to compare\n     * @return {Number}           Positive or negative number\n     */\n\n  }, {\n    key: \"_sortByHighestQuality\",\n    value: function _sortByHighestQuality(a, b) {\n      // Bitrate with value of -1 gets highest priority.\n      if (a.Bitrate < 0) {\n        return -1;\n      } else if (b.Bitrate < 0) {\n        return 1;\n      } else {\n        return b.Bitrate - a.Bitrate;\n      }\n    }\n\n    /**\n     * Creates an object from live stream link. Relies on 'this' being the server array. See _resolveLiveServers().\n     * @param {Object}            Object with current quality\n     * @this {Object}             Object with server path etc\n     * @return {Object}           Object with selected properties and values\n     */\n\n  }, {\n    key: \"_transformLink\",\n    value: function _transformLink(stream) {\n      var source = {\n        Bitrate: stream.Kbps,\n        Target: this.LinkType\n      };\n      if (this.hasOwnProperty('EncryptedServer')) {\n        Object.defineProperties(source, {\n          'EncryptedServer': {\n            value: this.EncryptedServer\n          },\n          'EncryptedStream': {\n            value: stream.Streams[0].EncryptedStream\n          }\n        });\n      } else if (this.hasOwnProperty('Server')) {\n        Object.defineProperties(source, {\n          'Server': {\n            value: this.Server\n          },\n          'Stream': {\n            value: stream.Streams[0].Stream\n          }\n        });\n      }\n      return source;\n    }\n\n    /**\n     * Get resources from programcard manifest, sorted by priority.\n     * Streams are sorted by link types / file format and iterated, selecting best available and supported quality.\n     * @param {Object} manifest   Asset manifest from programcard\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_resolveManifest\",\n    value: function _resolveManifest(manifest) {\n      if (!manifest) {\n        throw \"No manifest received\";\n      }\n      var priority = this.options.sourcePriority;\n      var formats = {};\n      // Filter and sort available link types or file formats.\n      priority.forEach(function (format) {\n        formats[format] = manifest.Links.filter(function (link) {\n          var pattern = new RegExp(format, 'i');\n          return pattern.test(link.Target) || /download/i.test(link.Target) && pattern.test(link.FileFormat);\n        });\n      });\n      // Step through sources and select the best available and supported quality.\n      for (var i = 0, l = priority.length, format = priority[i]; i < l; i++, format = priority[i]) {\n        if (formats.hasOwnProperty(format)) {\n          if (this.features[format] && formats[format].length) {\n            this.DEBUG && console.debug('Manifest => ' + format);\n            this.sources = formats[format].sort(this._sortByHighestQuality);\n            break;\n          }\n        }\n      }\n      return this;\n    }\n\n    /**\n     * Get resources from live channel, sorted by priority.\n     * Streams are sorted by link types / file format and iterated, selecting best available and supported quality.\n     * @param {Object} servers    Object with available streaming servers\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_resolveLiveServers\",\n    value: function _resolveLiveServers(servers) {\n      var priority = this.options.sourcePriority;\n      var formats = {};\n      // Filter and sort available link types.\n      priority.forEach(function (format) {\n        formats[format] = servers.filter(function (link) {\n          var pattern = new RegExp(format, 'i');\n          return pattern.test(link.LinkType);\n        });\n      });\n      // Step through sources and select the best available and supported quality.\n      for (var i = 0, l = priority.length, format = priority[i]; i < l; i++, format = priority[i]) {\n        if (formats.hasOwnProperty(format)) {\n          if (this.features[format] && formats[format].length) {\n            this.DEBUG && console.debug('Manifest => ' + format);\n            formats[format] = formats[format][0];\n            this.sources = formats[format].Qualities.map(this._transformLink, formats[format]).sort(this._sortByHighestQuality);\n            break;\n          }\n        }\n      }\n      return this;\n    }\n\n    /**\n     * Remove all <source> elements from <audio> element.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_clearSources\",\n    value: function _clearSources() {\n      var sources = this.element.querySelectorAll('source');\n      for (var i = 0, l = sources.length; i < l; i++) {\n        this.element.removeChild(sources[i]);\n      }\n      return this;\n    }\n\n    /**\n     * Add sources to <audio> element.\n     * If browser has native HLS support, all available streams are added, letting the browser handle quality switching.\n     * If browser doesn't have HLS support the HLS.js library is attached or re-attached to re-initialize stream.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_addSources\",\n    value: function _addSources() {\n      if (!this.element.paused) {\n        this.element.pause();\n      }\n      this._clearSources();\n      this._attachTimestampEvent();\n      for (var uri, i = 0, l = this.sources.length, s = this.sources[i]; i < l; i++, s = this.sources[i]) {\n        // Decrypt source URI.\n        if (s.hasOwnProperty('EncryptedUri')) {\n          uri = (0, _drcMediaDecryption2.default)(s.EncryptedUri);\n        } else if (s.hasOwnProperty('EncryptedServer') && s.hasOwnProperty('EncryptedStream')) {\n          uri = (0, _drcMediaDecryption2.default)(s.EncryptedServer).replace(/\\/+$/, '') + '/' + (0, _drcMediaDecryption2.default)(s.EncryptedStream);\n        } else if (s.hasOwnProperty('Uri')) {\n          uri = s.Uri;\n        } else if (s.hasOwnProperty('Server') && s.hasOwnProperty('Stream')) {\n          uri = s.Server.replace(/\\/+$/, '') + '/' + s.Stream;\n        } else {\n          throw 'No source path found.';\n        }\n        // Load source URI.\n        if (/HLS/i.test(s.Target) && !this.features.NativeHLS) {\n          if (this._hls) {\n            this.DEBUG && console.debug('Re-attaching HLS.js');\n            // Re-initialize HLSJS when switching source.\n            this._hls.destroy();\n          } else {\n            this.DEBUG && console.debug('Attaching HLS.js');\n          }\n          this._setupHls();\n          this._hls.loadSource(uri);\n          // Load only one HLS source.\n          break;\n        } else {\n          this.DEBUG && console.debug('Using native source element(s).');\n          this.element.appendChild((0, _create2.default)('source', {\n            src: uri,\n            type: s.hasOwnProperty('FileFormat') ? 'audio/' + s.FileFormat.toLowerCase().replace(/mp3/i, 'mpeg') : ''\n          }));\n          this.element.load();\n        }\n      }\n      return this;\n    }\n\n    /**\n     * Get duration of current program.\n     * Returns the elements duration in case of on demand resource, otherwise duration extracted from broadcast.\n     * @return {Number}           Duration length\n     */\n\n  }, {\n    key: \"getDuration\",\n    value: function getDuration() {\n      if (!this.broadcast) {\n        return this.element.duration;\n      }\n      var startTime = new Date(this.broadcast.StartTime);\n      var endTime = new Date(this.broadcast.EndTime);\n      return (endTime - startTime) / 1000;\n    }\n\n    /**\n     * Setup a timer that will update the broadcast object when the current (live) program ends.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"_setTimerForBroadcastUpdate\",\n    value: function _setTimerForBroadcastUpdate() {\n      var _this9 = this;\n\n      if (!this.options.autoUpdate || !this.broadcast) {\n        return;\n      }\n      // Get current broadcast end-time and fetch new broadcast object 1 sec. after.\n      var endTime = new Date(this.broadcast.EndTime);\n      var timeout = endTime - Date.now() + 1000;\n      // In case of outdated broadcast object, timeout will be negative.\n      // Increase timer to 20 sec. and fetch again.\n      if (timeout < 0) {\n        timeout = 20000;\n      }\n      // Set timer function.\n      this._id = setTimeout(function () {\n        _this9._psdb.getCurrentBroadcast(_this9.channel.Slug).then(function (broadcast) {\n          _this9.broadcast = broadcast;\n          _this9.program = broadcast.ProgramCard;\n          _this9._setTimerForBroadcastUpdate();\n        });\n      }, timeout);\n      return this;\n    }\n  }]);\n\n  return Player;\n}(_EventTarget3.default);\n\nexports.default = Player;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-audio-player/dist/lib/Player.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-audio-player/dist/lib/PsdbClient.js":
/*!******************************************************************!*\
  !*** ./node_modules/@dr/drc-audio-player/dist/lib/PsdbClient.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nvar _EventTarget2 = __webpack_require__(/*! ./EventTarget */ \"./node_modules/@dr/drc-audio-player/dist/lib/EventTarget.js\");\n\nvar _EventTarget3 = _interopRequireDefault(_EventTarget2);\n\nvar _configPsdb = __webpack_require__(/*! ./config.psdb.js */ \"./node_modules/@dr/drc-audio-player/dist/lib/config.psdb.js\");\n\nvar _configPsdb2 = _interopRequireDefault(_configPsdb);\n\nvar _extend = __webpack_require__(/*! @dr/drc-util/object/extend */ \"./node_modules/@dr/drc-util/object/extend.js\");\n\nvar _extend2 = _interopRequireDefault(_extend);\n\nvar _get = __webpack_require__(/*! @dr/drc-util/url/get */ \"./node_modules/@dr/drc-util/url/get.js\");\n\nvar _get2 = _interopRequireDefault(_get);\n\nvar _es6Promise = __webpack_require__(/*! es6-promise */ \"./node_modules/es6-promise/dist/es6-promise.js\");\n\nvar _es6Promise2 = _interopRequireDefault(_es6Promise);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\nvar Promise = _es6Promise2.default.Promise;\n\n/**\n * Class for PSDB client.\n * Uses Promises.\n */\n\nvar PsdbClient = function (_EventTarget) {\n  _inherits(PsdbClient, _EventTarget);\n\n  _createClass(PsdbClient, [{\n    key: \"options\",\n\n    /**\n     * Get options.\n     * @return {object} Object with applied options.\n     */\n    get: function get() {\n      return this._options;\n    }\n    /**\n     * Set options.\n     * @param  {Object} obj   Options object.\n     * @return {Class}        Player class\n     */\n    ,\n    set: function set(obj) {\n      this._options = obj;\n      return this;\n    }\n\n    /**\n     * Create PSDB Client class.\n     */\n\n  }]);\n\n  function PsdbClient(options) {\n    _classCallCheck(this, PsdbClient);\n\n    var _this = _possibleConstructorReturn(this, (PsdbClient.__proto__ || Object.getPrototypeOf(PsdbClient)).call(this));\n\n    _this.options = (0, _extend2.default)({}, _configPsdb2.default, options || {});\n    return _this;\n  }\n\n  /**\n   * Extract production nnumber, URN or slug.\n   * @param {String} input      Production number, URL, URN or slug\n   * @return {Mixed}            Matched string or null.\n   */\n\n\n  _createClass(PsdbClient, [{\n    key: \"_extractPnUrnOrSlug\",\n    value: function _extractPnUrnOrSlug(input) {\n      // Clean and match production number, URN or slug.\n      return input.replace(/[\\/#\\&\\?\\!]+[0-9:]*$/, '').match(/(^\\d{11}$|urn:dr:mu:\\w+:[0-9a-f]+|[^\\/][a-z0-9\\-]+$)/i)[0] || null;\n    }\n\n    /**\n     * Get programcard for program.\n     * @param {String} id         Production number, URL, URN or slug\n     * @return {Function}         Function that requests the programcard from API.\n     */\n\n  }, {\n    key: \"getProgramCard\",\n    value: function getProgramCard(id) {\n      var url = void 0;\n      // Extract production nember, URN or slug.\n      var match = this._extractPnUrnOrSlug(id);\n      if (/^\\d{11}$/.test(match)) {\n        url = this.options.endpoint + 'programcard/get-by-productionnumber/' + match;\n      } else if (match) {\n        url = this.options.endpoint + 'programcard/' + match;\n      }\n      return this._makeRequest(url);\n    }\n\n    /**\n     * Get object for channel.\n     * @param {String} uri        URL, URN or slug\n     * @return {Function}         Function that requests the channel from API.\n     */\n\n  }, {\n    key: \"getChannel\",\n    value: function getChannel(uri) {\n      var url = void 0;\n      // Extract URN or slug.\n      var match = this._extractPnUrnOrSlug(uri);\n      if (match) {\n        url = this.options.endpoint + 'channels/' + match;\n      }\n      return this._makeRequest(url);\n    }\n\n    /**\n     * Get asset.\n     * @param {String} uri        Asset uri\n     * @return {Function}         Function that requests the asset from API.\n     */\n\n  }, {\n    key: \"getAsset\",\n    value: function getAsset(uri) {\n      return this._makeRequest(uri);\n    }\n\n    /**\n     * Get list of active channels.\n     * @param {String} type       Device type, 'tv' or 'radio'\n     * @return {Function}         Function that requests the list from API.\n     */\n\n  }, {\n    key: \"getChannels\",\n    value: function getChannels() {\n      var url = this.options.endpoint + 'channels/all-active-dr-channels';\n      return this._makeRequest(url, {\n        data: {\n          includeNowNext: false\n        }\n      });\n    }\n\n    /**\n     * Get broadcast object for current live program.\n     * @param {String} channel    Channel id (slug)\n     * @return {Promise}          Promise with resolve and reject callbacks\n     */\n\n  }, {\n    key: \"getCurrentBroadcast\",\n    value: function getCurrentBroadcast(channel) {\n      var _this2 = this;\n\n      var url = this.options.endpoint + 'schedule/now-next/' + channel;\n      return new Promise(function (resolve, reject) {\n        _this2._makeRequest(url).then(function (schedule) {\n          resolve(schedule.Now);\n        }).catch(function (err) {\n          reject(err);\n        });\n      });\n    }\n\n    /**\n     * Request function.\n     * @param {Object} options    Object with 'url', 'params' (optional) and 'method' (optional)\n     * @return {Promise}          Promise with resolve and reject callbacks\n     */\n\n  }, {\n    key: \"_makeRequest\",\n    value: function _makeRequest(url, options) {\n      if (!url) throw \"No url to fetch.\";\n      options = (0, _extend2.default)({\n        headers: {\n          \"x-dr-mu-subscriber-id\": this.options.subscriberId\n        }\n      }, options || {});\n      return new Promise(function (resolve, reject) {\n        (0, _get2.default)(url, function (error, response) {\n          if (error) {\n            reject(error);\n          } else {\n            response = JSON.parse(response);\n            resolve(response);\n          }\n        }, options);\n      });\n    }\n\n    /**\n     * Extracts primary asset from programcard.\n     * @param {Object} programcard  Programcard object from API.\n     * @return {Promise}            Promise with resolve and reject callbacks\n     */\n\n  }, {\n    key: \"getPrimaryAsset\",\n    value: function getPrimaryAsset(programcard) {\n      return new Promise(function (resolve, reject) {\n        if (programcard.hasOwnProperty('PrimaryAsset')) {\n          resolve(programcard.PrimaryAsset);\n        } else {\n          reject('No asset found.');\n        }\n      });\n    }\n\n    /**\n    * Extracts servers from live channel.\n    * @param {Object} channel       Channel object from API.\n    * @return {Promise}             Promise with resolve and reject callbacks\n     */\n\n  }, {\n    key: \"getLiveServers\",\n    value: function getLiveServers(channel) {\n      return new Promise(function (resolve, reject) {\n        if (channel.hasOwnProperty('StreamingServers') && channel.StreamingServers.length > 0) {\n          resolve(channel.StreamingServers);\n        } else {\n          reject('No servers found.');\n        }\n      });\n    }\n  }]);\n\n  return PsdbClient;\n}(_EventTarget3.default);\n\nexports.default = PsdbClient;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-audio-player/dist/lib/PsdbClient.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-audio-player/dist/lib/Tracking.js":
/*!****************************************************************!*\
  !*** ./node_modules/@dr/drc-audio-player/dist/lib/Tracking.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nvar _EventTarget2 = __webpack_require__(/*! ./EventTarget */ \"./node_modules/@dr/drc-audio-player/dist/lib/EventTarget.js\");\n\nvar _EventTarget3 = _interopRequireDefault(_EventTarget2);\n\nvar _drcMediaStatistics = __webpack_require__(/*! @dr/drc-media-statistics */ \"./node_modules/@dr/drc-media-statistics/js/stats_base.js\");\n\nvar _drcMediaStatistics2 = _interopRequireDefault(_drcMediaStatistics);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /* global akamaiSetStreamURL: true, akamaiPlaybackCompleted: true, akamaiHandleError: true */\n\nvar Tracking = function (_EventTarget) {\n  _inherits(Tracking, _EventTarget);\n\n  _createClass(Tracking, [{\n    key: \"element\",\n\n    /**\n     * Get attached audio element.\n     * @return {Element}          HTML <audio> element\n     */\n    get: function get() {\n      return this._element;\n    }\n    /**\n     * Set audio element.\n     * @param  {Element} element  HTML <audio> element\n     * @return {Class}            Player class\n     */\n    ,\n    set: function set(element) {\n      this._element = element;\n      return this;\n    }\n\n    /**\n     * Get attached audio player class.\n     * @return {Class}            Player class\n     */\n\n  }, {\n    key: \"player\",\n    get: function get() {\n      return this._player;\n    }\n    /**\n     * Set audio player class.\n     * @param  {Class} player     Player class\n     * @return {Class}            Tracking class\n     */\n    ,\n    set: function set(player) {\n      this._player = player;\n      return this;\n    }\n  }]);\n\n  function Tracking(element, player) {\n    _classCallCheck(this, Tracking);\n\n    var _this = _possibleConstructorReturn(this, (Tracking.__proto__ || Object.getPrototypeOf(Tracking)).call(this));\n\n    if (!element || !player) return _possibleConstructorReturn(_this);\n    _this.element = element;\n    _this.player = player;\n\n    _this.addEvent = _this.addEventListener;\n    _this.removeEvent = _this.removeEventListener;\n    _this.fireEvent = _this.dispatchEvent;\n\n    _this._setupEvents();\n\n    _this._setupAkamaiTracking();\n    _this._setupPSDBTracking();\n    _this._setupEnsightenTracking();\n    return _this;\n  }\n\n  _createClass(Tracking, [{\n    key: \"_setupEvents\",\n    value: function _setupEvents() {\n      var _this2 = this;\n\n      this.element.addEventListener('loadeddata', function (e) {\n        _this2.onResourceReady(e);\n      });\n      this.addEventListener('akamaiReady', function (e) {\n        _this2.onAkamaiReady(e);\n      });\n      this.element.addEventListener('play', function (e) {\n        _this2.onPlay(e);\n      });\n      this.element.addEventListener('playing', function (e) {\n        _this2.onPlaying(e);\n      });\n      this.element.addEventListener('pause', function (e) {\n        _this2.onPause(e);\n      });\n      this.element.addEventListener('ended', function (e) {\n        _this2.onEnded(e);\n      });\n      this.element.addEventListener('seeking', function (e) {\n        _this2.onSeeking(e);\n      });\n      this.element.addEventListener('seeked', function (e) {\n        _this2.onSeeked(e);\n      });\n      this.element.addEventListener('waiting', function (e) {\n        _this2.onWaiting(e);\n      });\n      this.element.addEventListener('canplay', function (e) {\n        _this2.onCanplay(e);\n      });\n      this.element.addEventListener('error', function (e) {\n        _this2.onError(e);\n      });\n      this.player.addEventListener('HLSJS_ERROR', function (e) {\n        _this2.onError(e);\n      });\n    }\n  }, {\n    key: \"_setupAkamaiTracking\",\n    value: function _setupAkamaiTracking() {\n      _drcMediaStatistics2.default.initAkamaiHtml5Tracker(this, {\n        playerId: this.player._idstring\n      });\n    }\n  }, {\n    key: \"_setupPSDBTracking\",\n    value: function _setupPSDBTracking() {\n      _drcMediaStatistics2.default.initPsdbRadioTracker(this, {\n        version: this.player._idstring\n      });\n    }\n  }, {\n    key: \"_setupEnsightenTracking\",\n    value: function _setupEnsightenTracking() {\n      _drcMediaStatistics2.default.initEnsightenTracker(this);\n    }\n  }, {\n    key: \"_getMetadataObject\",\n    value: function _getMetadataObject() {\n      var src = this.player.resource,\n          obj = {};\n      if (/programcard/i.test(src.Type)) {\n        obj = this._getProgramCardObject(src);\n      } else if (/bundle/i.test(src.Type) && /channel/i.test(src.BundleType)) {\n        obj = this._getChannelObject(src);\n      }\n      return obj;\n    }\n  }, {\n    key: \"_getProgramCardObject\",\n    value: function _getProgramCardObject(program) {\n      return {\n        channelId: program.PrimaryChannelSlug,\n        genre: null,\n        mediaType: \"audio\",\n        primaryChannel: program.PrimaryBroadcastChannel,\n        productionNumber: program.ProductionNumber || null,\n        programSerieSlug: program.SeriesSlug,\n        publishStartTimeCode: program.PrimaryBroadcastStartTime,\n        slug: program.Slug,\n        title: program.Title,\n        urn: program.Urn,\n        videoType: \"ondemand\"\n      };\n    }\n  }, {\n    key: \"_getChannelObject\",\n    value: function _getChannelObject(src) {\n      var broadcast = this.player.broadcast;\n      var program = this.player.program;\n      return {\n        channelId: src.Slug,\n        channels: this.player.channels,\n        duration: this.player.getDuration(),\n        mediaType: \"audio\",\n        productionNumber: broadcast.ProductionNumber,\n        programSerieSlug: program.SeriesSlug,\n        publishStartTimeCode: broadcast.StartTime,\n        slug: program.Slug,\n        title: program.Title || broadcast.Title,\n        urn: program.Urn,\n        videoType: \"live\"\n      };\n    }\n  }, {\n    key: \"_getStreamUrl\",\n    value: function _getStreamUrl() {\n      var source = this.element.currentSrc;\n      if (/blob:/i.test(source)) {\n        // HLS.js transform current source url and must be circumvented.\n        return this.player._hls.url;\n      } else {\n        return source;\n      }\n    }\n  }, {\n    key: \"position\",\n    value: function position() {\n      return this.element.currentTime;\n    }\n  }, {\n    key: \"onResourceReady\",\n    value: function onResourceReady(eventData) {\n      this.dispatchEvent('resourceReady', this._getMetadataObject());\n    }\n  }, {\n    key: \"onAkamaiReady\",\n    value: function onAkamaiReady() {\n      var url = this._getStreamUrl();\n      var manifest = /\\.m3u8/i.test(url);\n      akamaiSetStreamURL(url, manifest);\n    }\n  }, {\n    key: \"onPlay\",\n    value: function onPlay(eventData) {\n      this.dispatchEvent('play', eventData);\n    }\n  }, {\n    key: \"onPlaying\",\n    value: function onPlaying(eventData) {\n      this.dispatchEvent('playing', eventData);\n    }\n  }, {\n    key: \"onPause\",\n    value: function onPause(eventData) {\n      // pause : Playback is paused (used for OD streams)\n      // stop  : Playback has stopped (used for live streams)\n      if (this.player.broadcast) {\n        this.dispatchEvent('stop', eventData);\n      } else {\n        this.dispatchEvent('pause', eventData);\n      }\n    }\n  }, {\n    key: \"onWaiting\",\n    value: function onWaiting(eventData) {\n      this._bufferUnderrun = true;\n      // buffering : Playback is stopped while the player is reading more buffer data\n      this.dispatchEvent('buffering', eventData);\n    }\n  }, {\n    key: \"onCanplay\",\n    value: function onCanplay(eventData) {\n      if (this._bufferUnderrun) {\n        // bufferingComplete : Reading buffer data is now complete\n        this.dispatchEvent('bufferingComplete', eventData);\n      }\n      this._bufferUnderrun = false;\n    }\n  }, {\n    key: \"onSeeking\",\n    value: function onSeeking(eventData) {\n      this.dispatchEvent('beforeSeek', this.element.currentTime, eventData);\n    }\n  }, {\n    key: \"onSeeked\",\n    value: function onSeeked(eventData) {\n      this.dispatchEvent('afterSeek', this.element.currentTime, eventData);\n    }\n  }, {\n    key: \"onEnded\",\n    value: function onEnded(eventData) {\n      akamaiPlaybackCompleted();\n      this.dispatchEvent('ended', eventData);\n      this.dispatchEvent('complete', eventData);\n    }\n  }, {\n    key: \"onError\",\n    value: function onError(eventData) {\n      if ('akamaiHandleError' in window) {\n        akamaiHandleError(eventData);\n      }\n    }\n  }]);\n\n  return Tracking;\n}(_EventTarget3.default);\n\nexports.default = Tracking;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-audio-player/dist/lib/Tracking.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-audio-player/dist/lib/config.options.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@dr/drc-audio-player/dist/lib/config.options.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nvar options = {\n  debug: false,\n  autoUpdate: true, // Enable timer for broadcast update during live streaming;\n  sourcePriority: ['HLS', // HTTP Live Streaming for Live and OD, AAC format.\n  'ICY', // Icecast server, MP3 format.\n  'MP4', // AAC format.\n  'MP3' // MP3 format.\n  ],\n  debugEvents: [\"abort\", // playback is aborted; for example, if the media is playing and is restarted from the beginning, this event is sent.\n  \"canplay\", // can play the media, but estimates that not enough data has been loaded to play the media up to its end without having to stop for further buffering of content.\n  \"durationchange\", // the duration attribute has been updated.\n  \"ended\", // end of the media was reached or because no further data is available.\n  \"error\", // when an error occurs.  The element's error attribute contains more information.\n  \"loadeddata\", // the first frame of the media has finished loading.\n  \"loadedmetadata\", // the metadata has been loaded.\n  \"loadend\", // progression has stopped (after \"error\", \"abort\" or \"load\" have been dispatched).\n  \"pause\", // playback has been paused.\n  \"play\", // playback has begun\n  \"playing\", // playback is ready to start after having been paused or delayed due to lack of data.\n  \"progress\", // indication that an operation is in progress.\n  \"seeked\", // a seek operation completed.\n  \"seeking\", // a seek operation began.\n  \"timeupdate\", // the time indicated by the currentTime attribute has been updated.\n  \"volumechange\", // the volume has changed.\n  \"waiting\" // playback has stopped because of a temporary lack of data.\n  ]\n};\n\nexports.default = options;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-audio-player/dist/lib/config.options.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-audio-player/dist/lib/config.psdb.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@dr/drc-audio-player/dist/lib/config.psdb.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nvar config = {\n  endpoint: '//www.dr.dk/mu-online-radio/api/1.0/',\n  subscriberId: ''\n};\n\nexports.default = config;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-audio-player/dist/lib/config.psdb.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-audio-player/dist/player.js":
/*!**********************************************************!*\
  !*** ./node_modules/@dr/drc-audio-player/dist/player.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar _Player = __webpack_require__(/*! ./lib/Player */ \"./node_modules/@dr/drc-audio-player/dist/lib/Player.js\");\n\nvar _Player2 = _interopRequireDefault(_Player);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nmodule.exports = function (settings) {\n    return new _Player2.default(settings);\n};\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-audio-player/dist/player.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-decryption/js/index.js":
/*!***********************************************************!*\
  !*** ./node_modules/@dr/drc-media-decryption/js/index.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var forge = __webpack_require__(/*! ../lib/forge */ \"./node_modules/@dr/drc-media-decryption/lib/forge/index.js\");\n\nfunction generateCipher(seed) {\n\tvar secret = \"sRBzYNXBzkKgnjj8pGtkACch\";\n\n\tvar md = forge.md.sha256.create();\n\tmd.update(seed + \":\" + secret);\n\n\tvar cipher = md.digest();\n\n\treturn cipher;\n}\n\nfunction decrypt(encryptedString) {\n\tvar payloadHeader = encryptedString.substring(2, 10);\n\tvar payloadLength = parseInt(payloadHeader, 16);\n\n\tvar payloadHex = encryptedString.substring(10, 10 + payloadLength);\n\tvar initialVectorHex = encryptedString.substring(10 + payloadLength);\n\n\tvar cipher = generateCipher(initialVectorHex);\n\n\tvar initialVector = forge.util.hexToBytes(initialVectorHex);\n\tvar encryptedDataBytes = forge.util.hexToBytes(payloadHex);\n\tvar encryptedDataBuffer = forge.util.createBuffer(encryptedDataBytes);\n\n\tvar decipher = forge.cipher.createDecipher(\"AES-CBC\", cipher);\n\n\tdecipher.start({iv: initialVector});\n\tdecipher.update(encryptedDataBuffer);\n\tdecipher.finish();\n\n\treturn decipher.output.data;\n}\n\nmodule.exports = decrypt;\n\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-decryption/js/index.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-decryption/lib/forge/aes.js":
/*!****************************************************************!*\
  !*** ./node_modules/@dr/drc-media-decryption/lib/forge/aes.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/**\n * Advanced Encryption Standard (AES) implementation.\n *\n * This implementation is based on the public domain library 'jscrypto' which\n * was written by:\n *\n * Emily Stark (estark@stanford.edu)\n * Mike Hamburg (mhamburg@stanford.edu)\n * Dan Boneh (dabo@cs.stanford.edu)\n *\n * Parts of this code are based on the OpenSSL implementation of AES:\n * http://www.openssl.org\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\nmodule.exports = function(forge) {\n\n/* AES API */\nforge.aes = forge.aes || {};\n\n/**\n * Creates a new AES cipher algorithm object.\n *\n * @param name the name of the algorithm.\n * @param mode the mode factory function.\n *\n * @return the AES algorithm object.\n */\nforge.aes.Algorithm = function(name, mode) {\n  if(!init) {\n    initialize();\n  }\n  var self = this;\n  self.name = name;\n  self.mode = new mode({\n    blockSize: 16,\n    cipher: {\n      encrypt: function(inBlock, outBlock) {\n        return _updateBlock(self._w, inBlock, outBlock, false);\n      },\n      decrypt: function(inBlock, outBlock) {\n        return _updateBlock(self._w, inBlock, outBlock, true);\n      }\n    }\n  });\n  self._init = false;\n};\n\n/**\n * Initializes this AES algorithm by expanding its key.\n *\n * @param options the options to use.\n *          key the key to use with this algorithm.\n *          decrypt true if the algorithm should be initialized for decryption,\n *            false for encryption.\n */\nforge.aes.Algorithm.prototype.initialize = function(options) {\n  if(this._init) {\n    return;\n  }\n\n  var key = options.key;\n  var tmp;\n\n  /* Note: The key may be a string of bytes, an array of bytes, a byte\n    buffer, or an array of 32-bit integers. If the key is in bytes, then\n    it must be 16, 24, or 32 bytes in length. If it is in 32-bit\n    integers, it must be 4, 6, or 8 integers long. */\n\n  if(typeof key === 'string' &&\n    (key.length === 16 || key.length === 24 || key.length === 32)) {\n    // convert key string into byte buffer\n    key = forge.util.createBuffer(key);\n  } else if(forge.util.isArray(key) &&\n    (key.length === 16 || key.length === 24 || key.length === 32)) {\n    // convert key integer array into byte buffer\n    tmp = key;\n    key = forge.util.createBuffer();\n    for(var i = 0; i < tmp.length; ++i) {\n      key.putByte(tmp[i]);\n    }\n  }\n\n  // convert key byte buffer into 32-bit integer array\n  if(!forge.util.isArray(key)) {\n    tmp = key;\n    key = [];\n\n    // key lengths of 16, 24, 32 bytes allowed\n    var len = tmp.length();\n    if(len === 16 || len === 24 || len === 32) {\n      len = len >>> 2;\n      for(var i = 0; i < len; ++i) {\n        key.push(tmp.getInt32());\n      }\n    }\n  }\n\n  // key must be an array of 32-bit integers by now\n  if(!forge.util.isArray(key) ||\n    !(key.length === 4 || key.length === 6 || key.length === 8)) {\n    throw new Error('Invalid key parameter.');\n  }\n\n  // encryption operation is always used for these modes\n  var mode = this.mode.name;\n  var encryptOp = (['CFB', 'OFB', 'CTR', 'GCM'].indexOf(mode) !== -1);\n\n  // do key expansion\n  this._w = _expandKey(key, options.decrypt && !encryptOp);\n  this._init = true;\n};\n\n/**\n * Expands a key. Typically only used for testing.\n *\n * @param key the symmetric key to expand, as an array of 32-bit words.\n * @param decrypt true to expand for decryption, false for encryption.\n *\n * @return the expanded key.\n */\nforge.aes._expandKey = function(key, decrypt) {\n  if(!init) {\n    initialize();\n  }\n  return _expandKey(key, decrypt);\n};\n\n/**\n * Updates a single block. Typically only used for testing.\n *\n * @param w the expanded key to use.\n * @param input an array of block-size 32-bit words.\n * @param output an array of block-size 32-bit words.\n * @param decrypt true to decrypt, false to encrypt.\n */\nforge.aes._updateBlock = _updateBlock;\n\n\n/** Register AES algorithms **/\n\nregisterAlgorithm('AES-CBC', forge.cipher.modes.cbc);\n\nfunction registerAlgorithm(name, mode) {\n  var factory = function() {\n    return new forge.aes.Algorithm(name, mode);\n  };\n  forge.cipher.registerAlgorithm(name, factory);\n}\n\n\n/** AES implementation **/\n\nvar init = false; // not yet initialized\nvar Nb = 4;       // number of words comprising the state (AES = 4)\nvar sbox;         // non-linear substitution table used in key expansion\nvar isbox;        // inversion of sbox\nvar rcon;         // round constant word array\nvar mix;          // mix-columns table\nvar imix;         // inverse mix-columns table\n\n/**\n * Performs initialization, ie: precomputes tables to optimize for speed.\n *\n * One way to understand how AES works is to imagine that 'addition' and\n * 'multiplication' are interfaces that require certain mathematical\n * properties to hold true (ie: they are associative) but they might have\n * different implementations and produce different kinds of results ...\n * provided that their mathematical properties remain true. AES defines\n * its own methods of addition and multiplication but keeps some important\n * properties the same, ie: associativity and distributivity. The\n * explanation below tries to shed some light on how AES defines addition\n * and multiplication of bytes and 32-bit words in order to perform its\n * encryption and decryption algorithms.\n *\n * The basics:\n *\n * The AES algorithm views bytes as binary representations of polynomials\n * that have either 1 or 0 as the coefficients. It defines the addition\n * or subtraction of two bytes as the XOR operation. It also defines the\n * multiplication of two bytes as a finite field referred to as GF(2^8)\n * (Note: 'GF' means \"Galois Field\" which is a field that contains a finite\n * number of elements so GF(2^8) has 256 elements).\n *\n * This means that any two bytes can be represented as binary polynomials;\n * when they multiplied together and modularly reduced by an irreducible\n * polynomial of the 8th degree, the results are the field GF(2^8). The\n * specific irreducible polynomial that AES uses in hexadecimal is 0x11b.\n * This multiplication is associative with 0x01 as the identity:\n *\n * (b * 0x01 = GF(b, 0x01) = b).\n *\n * The operation GF(b, 0x02) can be performed at the byte level by left\n * shifting b once and then XOR'ing it (to perform the modular reduction)\n * with 0x11b if b is >= 128. Repeated application of the multiplication\n * of 0x02 can be used to implement the multiplication of any two bytes.\n *\n * For instance, multiplying 0x57 and 0x13, denoted as GF(0x57, 0x13), can\n * be performed by factoring 0x13 into 0x01, 0x02, and 0x10. Then these\n * factors can each be multiplied by 0x57 and then added together. To do\n * the multiplication, values for 0x57 multiplied by each of these 3 factors\n * can be precomputed and stored in a table. To add them, the values from\n * the table are XOR'd together.\n *\n * AES also defines addition and multiplication of words, that is 4-byte\n * numbers represented as polynomials of 3 degrees where the coefficients\n * are the values of the bytes.\n *\n * The word [a0, a1, a2, a3] is a polynomial a3x^3 + a2x^2 + a1x + a0.\n *\n * Addition is performed by XOR'ing like powers of x. Multiplication\n * is performed in two steps, the first is an algebriac expansion as\n * you would do normally (where addition is XOR). But the result is\n * a polynomial larger than 3 degrees and thus it cannot fit in a word. So\n * next the result is modularly reduced by an AES-specific polynomial of\n * degree 4 which will always produce a polynomial of less than 4 degrees\n * such that it will fit in a word. In AES, this polynomial is x^4 + 1.\n *\n * The modular product of two polynomials 'a' and 'b' is thus:\n *\n * d(x) = d3x^3 + d2x^2 + d1x + d0\n * with\n * d0 = GF(a0, b0) ^ GF(a3, b1) ^ GF(a2, b2) ^ GF(a1, b3)\n * d1 = GF(a1, b0) ^ GF(a0, b1) ^ GF(a3, b2) ^ GF(a2, b3)\n * d2 = GF(a2, b0) ^ GF(a1, b1) ^ GF(a0, b2) ^ GF(a3, b3)\n * d3 = GF(a3, b0) ^ GF(a2, b1) ^ GF(a1, b2) ^ GF(a0, b3)\n *\n * As a matrix:\n *\n * [d0] = [a0 a3 a2 a1][b0]\n * [d1]   [a1 a0 a3 a2][b1]\n * [d2]   [a2 a1 a0 a3][b2]\n * [d3]   [a3 a2 a1 a0][b3]\n *\n * Special polynomials defined by AES (0x02 == {02}):\n * a(x)    = {03}x^3 + {01}x^2 + {01}x + {02}\n * a^-1(x) = {0b}x^3 + {0d}x^2 + {09}x + {0e}.\n *\n * These polynomials are used in the MixColumns() and InverseMixColumns()\n * operations, respectively, to cause each element in the state to affect\n * the output (referred to as diffusing).\n *\n * RotWord() uses: a0 = a1 = a2 = {00} and a3 = {01}, which is the\n * polynomial x3.\n *\n * The ShiftRows() method modifies the last 3 rows in the state (where\n * the state is 4 words with 4 bytes per word) by shifting bytes cyclically.\n * The 1st byte in the second row is moved to the end of the row. The 1st\n * and 2nd bytes in the third row are moved to the end of the row. The 1st,\n * 2nd, and 3rd bytes are moved in the fourth row.\n *\n * More details on how AES arithmetic works:\n *\n * In the polynomial representation of binary numbers, XOR performs addition\n * and subtraction and multiplication in GF(2^8) denoted as GF(a, b)\n * corresponds with the multiplication of polynomials modulo an irreducible\n * polynomial of degree 8. In other words, for AES, GF(a, b) will multiply\n * polynomial 'a' with polynomial 'b' and then do a modular reduction by\n * an AES-specific irreducible polynomial of degree 8.\n *\n * A polynomial is irreducible if its only divisors are one and itself. For\n * the AES algorithm, this irreducible polynomial is:\n *\n * m(x) = x^8 + x^4 + x^3 + x + 1,\n *\n * or {01}{1b} in hexadecimal notation, where each coefficient is a bit:\n * 100011011 = 283 = 0x11b.\n *\n * For example, GF(0x57, 0x83) = 0xc1 because\n *\n * 0x57 = 87  = 01010111 = x^6 + x^4 + x^2 + x + 1\n * 0x85 = 131 = 10000101 = x^7 + x + 1\n *\n * (x^6 + x^4 + x^2 + x + 1) * (x^7 + x + 1)\n * =  x^13 + x^11 + x^9 + x^8 + x^7 +\n *    x^7 + x^5 + x^3 + x^2 + x +\n *    x^6 + x^4 + x^2 + x + 1\n * =  x^13 + x^11 + x^9 + x^8 + x^6 + x^5 + x^4 + x^3 + 1 = y\n *    y modulo (x^8 + x^4 + x^3 + x + 1)\n * =  x^7 + x^6 + 1.\n *\n * The modular reduction by m(x) guarantees the result will be a binary\n * polynomial of less than degree 8, so that it can fit in a byte.\n *\n * The operation to multiply a binary polynomial b with x (the polynomial\n * x in binary representation is 00000010) is:\n *\n * b_7x^8 + b_6x^7 + b_5x^6 + b_4x^5 + b_3x^4 + b_2x^3 + b_1x^2 + b_0x^1\n *\n * To get GF(b, x) we must reduce that by m(x). If b_7 is 0 (that is the\n * most significant bit is 0 in b) then the result is already reduced. If\n * it is 1, then we can reduce it by subtracting m(x) via an XOR.\n *\n * It follows that multiplication by x (00000010 or 0x02) can be implemented\n * by performing a left shift followed by a conditional bitwise XOR with\n * 0x1b. This operation on bytes is denoted by xtime(). Multiplication by\n * higher powers of x can be implemented by repeated application of xtime().\n *\n * By adding intermediate results, multiplication by any constant can be\n * implemented. For instance:\n *\n * GF(0x57, 0x13) = 0xfe because:\n *\n * xtime(b) = (b & 128) ? (b << 1 ^ 0x11b) : (b << 1)\n *\n * Note: We XOR with 0x11b instead of 0x1b because in javascript our\n * datatype for b can be larger than 1 byte, so a left shift will not\n * automatically eliminate bits that overflow a byte ... by XOR'ing the\n * overflow bit with 1 (the extra one from 0x11b) we zero it out.\n *\n * GF(0x57, 0x02) = xtime(0x57) = 0xae\n * GF(0x57, 0x04) = xtime(0xae) = 0x47\n * GF(0x57, 0x08) = xtime(0x47) = 0x8e\n * GF(0x57, 0x10) = xtime(0x8e) = 0x07\n *\n * GF(0x57, 0x13) = GF(0x57, (0x01 ^ 0x02 ^ 0x10))\n *\n * And by the distributive property (since XOR is addition and GF() is\n * multiplication):\n *\n * = GF(0x57, 0x01) ^ GF(0x57, 0x02) ^ GF(0x57, 0x10)\n * = 0x57 ^ 0xae ^ 0x07\n * = 0xfe.\n */\nfunction initialize() {\n  init = true;\n\n  /* Populate the Rcon table. These are the values given by\n    [x^(i-1),{00},{00},{00}] where x^(i-1) are powers of x (and x = 0x02)\n    in the field of GF(2^8), where i starts at 1.\n\n    rcon[0] = [0x00, 0x00, 0x00, 0x00]\n    rcon[1] = [0x01, 0x00, 0x00, 0x00] 2^(1-1) = 2^0 = 1\n    rcon[2] = [0x02, 0x00, 0x00, 0x00] 2^(2-1) = 2^1 = 2\n    ...\n    rcon[9]  = [0x1B, 0x00, 0x00, 0x00] 2^(9-1)  = 2^8 = 0x1B\n    rcon[10] = [0x36, 0x00, 0x00, 0x00] 2^(10-1) = 2^9 = 0x36\n\n    We only store the first byte because it is the only one used.\n  */\n  rcon = [0x00, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1B, 0x36];\n\n  // compute xtime table which maps i onto GF(i, 0x02)\n  var xtime = new Array(256);\n  for(var i = 0; i < 128; ++i) {\n    xtime[i] = i << 1;\n    xtime[i + 128] = (i + 128) << 1 ^ 0x11B;\n  }\n\n  // compute all other tables\n  sbox = new Array(256);\n  isbox = new Array(256);\n  mix = new Array(4);\n  imix = new Array(4);\n  for(var i = 0; i < 4; ++i) {\n    mix[i] = new Array(256);\n    imix[i] = new Array(256);\n  }\n  var e = 0, ei = 0, e2, e4, e8, sx, sx2, me, ime;\n  for(var i = 0; i < 256; ++i) {\n    /* We need to generate the SubBytes() sbox and isbox tables so that\n      we can perform byte substitutions. This requires us to traverse\n      all of the elements in GF, find their multiplicative inverses,\n      and apply to each the following affine transformation:\n\n      bi' = bi ^ b(i + 4) mod 8 ^ b(i + 5) mod 8 ^ b(i + 6) mod 8 ^\n            b(i + 7) mod 8 ^ ci\n      for 0 <= i < 8, where bi is the ith bit of the byte, and ci is the\n      ith bit of a byte c with the value {63} or {01100011}.\n\n      It is possible to traverse every possible value in a Galois field\n      using what is referred to as a 'generator'. There are many\n      generators (128 out of 256): 3,5,6,9,11,82 to name a few. To fully\n      traverse GF we iterate 255 times, multiplying by our generator\n      each time.\n\n      On each iteration we can determine the multiplicative inverse for\n      the current element.\n\n      Suppose there is an element in GF 'e'. For a given generator 'g',\n      e = g^x. The multiplicative inverse of e is g^(255 - x). It turns\n      out that if use the inverse of a generator as another generator\n      it will produce all of the corresponding multiplicative inverses\n      at the same time. For this reason, we choose 5 as our inverse\n      generator because it only requires 2 multiplies and 1 add and its\n      inverse, 82, requires relatively few operations as well.\n\n      In order to apply the affine transformation, the multiplicative\n      inverse 'ei' of 'e' can be repeatedly XOR'd (4 times) with a\n      bit-cycling of 'ei'. To do this 'ei' is first stored in 's' and\n      'x'. Then 's' is left shifted and the high bit of 's' is made the\n      low bit. The resulting value is stored in 's'. Then 'x' is XOR'd\n      with 's' and stored in 'x'. On each subsequent iteration the same\n      operation is performed. When 4 iterations are complete, 'x' is\n      XOR'd with 'c' (0x63) and the transformed value is stored in 'x'.\n      For example:\n\n      s = 01000001\n      x = 01000001\n\n      iteration 1: s = 10000010, x ^= s\n      iteration 2: s = 00000101, x ^= s\n      iteration 3: s = 00001010, x ^= s\n      iteration 4: s = 00010100, x ^= s\n      x ^= 0x63\n\n      This can be done with a loop where s = (s << 1) | (s >> 7). However,\n      it can also be done by using a single 16-bit (in this case 32-bit)\n      number 'sx'. Since XOR is an associative operation, we can set 'sx'\n      to 'ei' and then XOR it with 'sx' left-shifted 1,2,3, and 4 times.\n      The most significant bits will flow into the high 8 bit positions\n      and be correctly XOR'd with one another. All that remains will be\n      to cycle the high 8 bits by XOR'ing them all with the lower 8 bits\n      afterwards.\n\n      At the same time we're populating sbox and isbox we can precompute\n      the multiplication we'll need to do to do MixColumns() later.\n    */\n\n    // apply affine transformation\n    sx = ei ^ (ei << 1) ^ (ei << 2) ^ (ei << 3) ^ (ei << 4);\n    sx = (sx >> 8) ^ (sx & 255) ^ 0x63;\n\n    // update tables\n    sbox[e] = sx;\n    isbox[sx] = e;\n\n    /* Mixing columns is done using matrix multiplication. The columns\n      that are to be mixed are each a single word in the current state.\n      The state has Nb columns (4 columns). Therefore each column is a\n      4 byte word. So to mix the columns in a single column 'c' where\n      its rows are r0, r1, r2, and r3, we use the following matrix\n      multiplication:\n\n      [2 3 1 1]*[r0,c]=[r'0,c]\n      [1 2 3 1] [r1,c] [r'1,c]\n      [1 1 2 3] [r2,c] [r'2,c]\n      [3 1 1 2] [r3,c] [r'3,c]\n\n      r0, r1, r2, and r3 are each 1 byte of one of the words in the\n      state (a column). To do matrix multiplication for each mixed\n      column c' we multiply the corresponding row from the left matrix\n      with the corresponding column from the right matrix. In total, we\n      get 4 equations:\n\n      r0,c' = 2*r0,c + 3*r1,c + 1*r2,c + 1*r3,c\n      r1,c' = 1*r0,c + 2*r1,c + 3*r2,c + 1*r3,c\n      r2,c' = 1*r0,c + 1*r1,c + 2*r2,c + 3*r3,c\n      r3,c' = 3*r0,c + 1*r1,c + 1*r2,c + 2*r3,c\n\n      As usual, the multiplication is as previously defined and the\n      addition is XOR. In order to optimize mixing columns we can store\n      the multiplication results in tables. If you think of the whole\n      column as a word (it might help to visualize by mentally rotating\n      the equations above by counterclockwise 90 degrees) then you can\n      see that it would be useful to map the multiplications performed on\n      each byte (r0, r1, r2, r3) onto a word as well. For instance, we\n      could map 2*r0,1*r0,1*r0,3*r0 onto a word by storing 2*r0 in the\n      highest 8 bits and 3*r0 in the lowest 8 bits (with the other two\n      respectively in the middle). This means that a table can be\n      constructed that uses r0 as an index to the word. We can do the\n      same with r1, r2, and r3, creating a total of 4 tables.\n\n      To construct a full c', we can just look up each byte of c in\n      their respective tables and XOR the results together.\n\n      Also, to build each table we only have to calculate the word\n      for 2,1,1,3 for every byte ... which we can do on each iteration\n      of this loop since we will iterate over every byte. After we have\n      calculated 2,1,1,3 we can get the results for the other tables\n      by cycling the byte at the end to the beginning. For instance\n      we can take the result of table 2,1,1,3 and produce table 3,2,1,1\n      by moving the right most byte to the left most position just like\n      how you can imagine the 3 moved out of 2,1,1,3 and to the front\n      to produce 3,2,1,1.\n\n      There is another optimization in that the same multiples of\n      the current element we need in order to advance our generator\n      to the next iteration can be reused in performing the 2,1,1,3\n      calculation. We also calculate the inverse mix column tables,\n      with e,9,d,b being the inverse of 2,1,1,3.\n\n      When we're done, and we need to actually mix columns, the first\n      byte of each state word should be put through mix[0] (2,1,1,3),\n      the second through mix[1] (3,2,1,1) and so forth. Then they should\n      be XOR'd together to produce the fully mixed column.\n    */\n\n    // calculate mix and imix table values\n    sx2 = xtime[sx];\n    e2 = xtime[e];\n    e4 = xtime[e2];\n    e8 = xtime[e4];\n    me =\n      (sx2 << 24) ^  // 2\n      (sx << 16) ^   // 1\n      (sx << 8) ^    // 1\n      (sx ^ sx2);    // 3\n    ime =\n      (e2 ^ e4 ^ e8) << 24 ^  // E (14)\n      (e ^ e8) << 16 ^        // 9\n      (e ^ e4 ^ e8) << 8 ^    // D (13)\n      (e ^ e2 ^ e8);          // B (11)\n    // produce each of the mix tables by rotating the 2,1,1,3 value\n    for(var n = 0; n < 4; ++n) {\n      mix[n][e] = me;\n      imix[n][sx] = ime;\n      // cycle the right most byte to the left most position\n      // ie: 2,1,1,3 becomes 3,2,1,1\n      me = me << 24 | me >>> 8;\n      ime = ime << 24 | ime >>> 8;\n    }\n\n    // get next element and inverse\n    if(e === 0) {\n      // 1 is the inverse of 1\n      e = ei = 1;\n    } else {\n      // e = 2e + 2*2*2*(10e)) = multiply e by 82 (chosen generator)\n      // ei = ei + 2*2*ei = multiply ei by 5 (inverse generator)\n      e = e2 ^ xtime[xtime[xtime[e2 ^ e8]]];\n      ei ^= xtime[xtime[ei]];\n    }\n  }\n}\n\n/**\n * Generates a key schedule using the AES key expansion algorithm.\n *\n * The AES algorithm takes the Cipher Key, K, and performs a Key Expansion\n * routine to generate a key schedule. The Key Expansion generates a total\n * of Nb*(Nr + 1) words: the algorithm requires an initial set of Nb words,\n * and each of the Nr rounds requires Nb words of key data. The resulting\n * key schedule consists of a linear array of 4-byte words, denoted [wi ],\n * with i in the range 0 ≤ i < Nb(Nr + 1).\n *\n * KeyExpansion(byte key[4*Nk], word w[Nb*(Nr+1)], Nk)\n * AES-128 (Nb=4, Nk=4, Nr=10)\n * AES-192 (Nb=4, Nk=6, Nr=12)\n * AES-256 (Nb=4, Nk=8, Nr=14)\n * Note: Nr=Nk+6.\n *\n * Nb is the number of columns (32-bit words) comprising the State (or\n * number of bytes in a block). For AES, Nb=4.\n *\n * @param key the key to schedule (as an array of 32-bit words).\n * @param decrypt true to modify the key schedule to decrypt, false not to.\n *\n * @return the generated key schedule.\n */\nfunction _expandKey(key, decrypt) {\n  // copy the key's words to initialize the key schedule\n  var w = key.slice(0);\n\n  /* RotWord() will rotate a word, moving the first byte to the last\n    byte's position (shifting the other bytes left).\n\n    We will be getting the value of Rcon at i / Nk. 'i' will iterate\n    from Nk to (Nb * Nr+1). Nk = 4 (4 byte key), Nb = 4 (4 words in\n    a block), Nr = Nk + 6 (10). Therefore 'i' will iterate from\n    4 to 44 (exclusive). Each time we iterate 4 times, i / Nk will\n    increase by 1. We use a counter iNk to keep track of this.\n   */\n\n  // go through the rounds expanding the key\n  var temp, iNk = 1;\n  var Nk = w.length;\n  var Nr1 = Nk + 6 + 1;\n  var end = Nb * Nr1;\n  for(var i = Nk; i < end; ++i) {\n    temp = w[i - 1];\n    if(i % Nk === 0) {\n      // temp = SubWord(RotWord(temp)) ^ Rcon[i / Nk]\n      temp =\n        sbox[temp >>> 16 & 255] << 24 ^\n        sbox[temp >>> 8 & 255] << 16 ^\n        sbox[temp & 255] << 8 ^\n        sbox[temp >>> 24] ^ (rcon[iNk] << 24);\n      iNk++;\n    } else if(Nk > 6 && (i % Nk === 4)) {\n      // temp = SubWord(temp)\n      temp =\n        sbox[temp >>> 24] << 24 ^\n        sbox[temp >>> 16 & 255] << 16 ^\n        sbox[temp >>> 8 & 255] << 8 ^\n        sbox[temp & 255];\n    }\n    w[i] = w[i - Nk] ^ temp;\n  }\n\n   /* When we are updating a cipher block we always use the code path for\n     encryption whether we are decrypting or not (to shorten code and\n     simplify the generation of look up tables). However, because there\n     are differences in the decryption algorithm, other than just swapping\n     in different look up tables, we must transform our key schedule to\n     account for these changes:\n\n     1. The decryption algorithm gets its key rounds in reverse order.\n     2. The decryption algorithm adds the round key before mixing columns\n       instead of afterwards.\n\n     We don't need to modify our key schedule to handle the first case,\n     we can just traverse the key schedule in reverse order when decrypting.\n\n     The second case requires a little work.\n\n     The tables we built for performing rounds will take an input and then\n     perform SubBytes() and MixColumns() or, for the decrypt version,\n     InvSubBytes() and InvMixColumns(). But the decrypt algorithm requires\n     us to AddRoundKey() before InvMixColumns(). This means we'll need to\n     apply some transformations to the round key to inverse-mix its columns\n     so they'll be correct for moving AddRoundKey() to after the state has\n     had its columns inverse-mixed.\n\n     To inverse-mix the columns of the state when we're decrypting we use a\n     lookup table that will apply InvSubBytes() and InvMixColumns() at the\n     same time. However, the round key's bytes are not inverse-substituted\n     in the decryption algorithm. To get around this problem, we can first\n     substitute the bytes in the round key so that when we apply the\n     transformation via the InvSubBytes()+InvMixColumns() table, it will\n     undo our substitution leaving us with the original value that we\n     want -- and then inverse-mix that value.\n\n     This change will correctly alter our key schedule so that we can XOR\n     each round key with our already transformed decryption state. This\n     allows us to use the same code path as the encryption algorithm.\n\n     We make one more change to the decryption key. Since the decryption\n     algorithm runs in reverse from the encryption algorithm, we reverse\n     the order of the round keys to avoid having to iterate over the key\n     schedule backwards when running the encryption algorithm later in\n     decryption mode. In addition to reversing the order of the round keys,\n     we also swap each round key's 2nd and 4th rows. See the comments\n     section where rounds are performed for more details about why this is\n     done. These changes are done inline with the other substitution\n     described above.\n  */\n  if(decrypt) {\n    var tmp;\n    var m0 = imix[0];\n    var m1 = imix[1];\n    var m2 = imix[2];\n    var m3 = imix[3];\n    var wnew = w.slice(0);\n    end = w.length;\n    for(var i = 0, wi = end - Nb; i < end; i += Nb, wi -= Nb) {\n      // do not sub the first or last round key (round keys are Nb\n      // words) as no column mixing is performed before they are added,\n      // but do change the key order\n      if(i === 0 || i === (end - Nb)) {\n        wnew[i] = w[wi];\n        wnew[i + 1] = w[wi + 3];\n        wnew[i + 2] = w[wi + 2];\n        wnew[i + 3] = w[wi + 1];\n      } else {\n        // substitute each round key byte because the inverse-mix\n        // table will inverse-substitute it (effectively cancel the\n        // substitution because round key bytes aren't sub'd in\n        // decryption mode) and swap indexes 3 and 1\n        for(var n = 0; n < Nb; ++n) {\n          tmp = w[wi + n];\n          wnew[i + (3&-n)] =\n            m0[sbox[tmp >>> 24]] ^\n            m1[sbox[tmp >>> 16 & 255]] ^\n            m2[sbox[tmp >>> 8 & 255]] ^\n            m3[sbox[tmp & 255]];\n        }\n      }\n    }\n    w = wnew;\n  }\n\n  return w;\n}\n\n/**\n * Updates a single block (16 bytes) using AES. The update will either\n * encrypt or decrypt the block.\n *\n * @param w the key schedule.\n * @param input the input block (an array of 32-bit words).\n * @param output the updated output block.\n * @param decrypt true to decrypt the block, false to encrypt it.\n */\nfunction _updateBlock(w, input, output, decrypt) {\n  /*\n  Cipher(byte in[4*Nb], byte out[4*Nb], word w[Nb*(Nr+1)])\n  begin\n    byte state[4,Nb]\n    state = in\n    AddRoundKey(state, w[0, Nb-1])\n    for round = 1 step 1 to Nr–1\n      SubBytes(state)\n      ShiftRows(state)\n      MixColumns(state)\n      AddRoundKey(state, w[round*Nb, (round+1)*Nb-1])\n    end for\n    SubBytes(state)\n    ShiftRows(state)\n    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])\n    out = state\n  end\n\n  InvCipher(byte in[4*Nb], byte out[4*Nb], word w[Nb*(Nr+1)])\n  begin\n    byte state[4,Nb]\n    state = in\n    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])\n    for round = Nr-1 step -1 downto 1\n      InvShiftRows(state)\n      InvSubBytes(state)\n      AddRoundKey(state, w[round*Nb, (round+1)*Nb-1])\n      InvMixColumns(state)\n    end for\n    InvShiftRows(state)\n    InvSubBytes(state)\n    AddRoundKey(state, w[0, Nb-1])\n    out = state\n  end\n  */\n\n  // Encrypt: AddRoundKey(state, w[0, Nb-1])\n  // Decrypt: AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])\n  var Nr = w.length / 4 - 1;\n  var m0, m1, m2, m3, sub;\n  if(decrypt) {\n    m0 = imix[0];\n    m1 = imix[1];\n    m2 = imix[2];\n    m3 = imix[3];\n    sub = isbox;\n  } else {\n    m0 = mix[0];\n    m1 = mix[1];\n    m2 = mix[2];\n    m3 = mix[3];\n    sub = sbox;\n  }\n  var a, b, c, d, a2, b2, c2;\n  a = input[0] ^ w[0];\n  b = input[decrypt ? 3 : 1] ^ w[1];\n  c = input[2] ^ w[2];\n  d = input[decrypt ? 1 : 3] ^ w[3];\n  var i = 3;\n\n  /* In order to share code we follow the encryption algorithm when both\n    encrypting and decrypting. To account for the changes required in the\n    decryption algorithm, we use different lookup tables when decrypting\n    and use a modified key schedule to account for the difference in the\n    order of transformations applied when performing rounds. We also get\n    key rounds in reverse order (relative to encryption). */\n  for(var round = 1; round < Nr; ++round) {\n    /* As described above, we'll be using table lookups to perform the\n      column mixing. Each column is stored as a word in the state (the\n      array 'input' has one column as a word at each index). In order to\n      mix a column, we perform these transformations on each row in c,\n      which is 1 byte in each word. The new column for c0 is c'0:\n\n               m0      m1      m2      m3\n      r0,c'0 = 2*r0,c0 + 3*r1,c0 + 1*r2,c0 + 1*r3,c0\n      r1,c'0 = 1*r0,c0 + 2*r1,c0 + 3*r2,c0 + 1*r3,c0\n      r2,c'0 = 1*r0,c0 + 1*r1,c0 + 2*r2,c0 + 3*r3,c0\n      r3,c'0 = 3*r0,c0 + 1*r1,c0 + 1*r2,c0 + 2*r3,c0\n\n      So using mix tables where c0 is a word with r0 being its upper\n      8 bits and r3 being its lower 8 bits:\n\n      m0[c0 >> 24] will yield this word: [2*r0,1*r0,1*r0,3*r0]\n      ...\n      m3[c0 & 255] will yield this word: [1*r3,1*r3,3*r3,2*r3]\n\n      Therefore to mix the columns in each word in the state we\n      do the following (& 255 omitted for brevity):\n      c'0,r0 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]\n      c'0,r1 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]\n      c'0,r2 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]\n      c'0,r3 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]\n\n      However, before mixing, the algorithm requires us to perform\n      ShiftRows(). The ShiftRows() transformation cyclically shifts the\n      last 3 rows of the state over different offsets. The first row\n      (r = 0) is not shifted.\n\n      s'_r,c = s_r,(c + shift(r, Nb) mod Nb\n      for 0 < r < 4 and 0 <= c < Nb and\n      shift(1, 4) = 1\n      shift(2, 4) = 2\n      shift(3, 4) = 3.\n\n      This causes the first byte in r = 1 to be moved to the end of\n      the row, the first 2 bytes in r = 2 to be moved to the end of\n      the row, the first 3 bytes in r = 3 to be moved to the end of\n      the row:\n\n      r1: [c0 c1 c2 c3] => [c1 c2 c3 c0]\n      r2: [c0 c1 c2 c3]    [c2 c3 c0 c1]\n      r3: [c0 c1 c2 c3]    [c3 c0 c1 c2]\n\n      We can make these substitutions inline with our column mixing to\n      generate an updated set of equations to produce each word in the\n      state (note the columns have changed positions):\n\n      c0 c1 c2 c3 => c0 c1 c2 c3\n      c0 c1 c2 c3    c1 c2 c3 c0  (cycled 1 byte)\n      c0 c1 c2 c3    c2 c3 c0 c1  (cycled 2 bytes)\n      c0 c1 c2 c3    c3 c0 c1 c2  (cycled 3 bytes)\n\n      Therefore:\n\n      c'0 = 2*r0,c0 + 3*r1,c1 + 1*r2,c2 + 1*r3,c3\n      c'0 = 1*r0,c0 + 2*r1,c1 + 3*r2,c2 + 1*r3,c3\n      c'0 = 1*r0,c0 + 1*r1,c1 + 2*r2,c2 + 3*r3,c3\n      c'0 = 3*r0,c0 + 1*r1,c1 + 1*r2,c2 + 2*r3,c3\n\n      c'1 = 2*r0,c1 + 3*r1,c2 + 1*r2,c3 + 1*r3,c0\n      c'1 = 1*r0,c1 + 2*r1,c2 + 3*r2,c3 + 1*r3,c0\n      c'1 = 1*r0,c1 + 1*r1,c2 + 2*r2,c3 + 3*r3,c0\n      c'1 = 3*r0,c1 + 1*r1,c2 + 1*r2,c3 + 2*r3,c0\n\n      ... and so forth for c'2 and c'3. The important distinction is\n      that the columns are cycling, with c0 being used with the m0\n      map when calculating c0, but c1 being used with the m0 map when\n      calculating c1 ... and so forth.\n\n      When performing the inverse we transform the mirror image and\n      skip the bottom row, instead of the top one, and move upwards:\n\n      c3 c2 c1 c0 => c0 c3 c2 c1  (cycled 3 bytes) *same as encryption\n      c3 c2 c1 c0    c1 c0 c3 c2  (cycled 2 bytes)\n      c3 c2 c1 c0    c2 c1 c0 c3  (cycled 1 byte)  *same as encryption\n      c3 c2 c1 c0    c3 c2 c1 c0\n\n      If you compare the resulting matrices for ShiftRows()+MixColumns()\n      and for InvShiftRows()+InvMixColumns() the 2nd and 4th columns are\n      different (in encrypt mode vs. decrypt mode). So in order to use\n      the same code to handle both encryption and decryption, we will\n      need to do some mapping.\n\n      If in encryption mode we let a=c0, b=c1, c=c2, d=c3, and r<N> be\n      a row number in the state, then the resulting matrix in encryption\n      mode for applying the above transformations would be:\n\n      r1: a b c d\n      r2: b c d a\n      r3: c d a b\n      r4: d a b c\n\n      If we did the same in decryption mode we would get:\n\n      r1: a d c b\n      r2: b a d c\n      r3: c b a d\n      r4: d c b a\n\n      If instead we swap d and b (set b=c3 and d=c1), then we get:\n\n      r1: a b c d\n      r2: d a b c\n      r3: c d a b\n      r4: b c d a\n\n      Now the 1st and 3rd rows are the same as the encryption matrix. All\n      we need to do then to make the mapping exactly the same is to swap\n      the 2nd and 4th rows when in decryption mode. To do this without\n      having to do it on each iteration, we swapped the 2nd and 4th rows\n      in the decryption key schedule. We also have to do the swap above\n      when we first pull in the input and when we set the final output. */\n    a2 =\n      m0[a >>> 24] ^\n      m1[b >>> 16 & 255] ^\n      m2[c >>> 8 & 255] ^\n      m3[d & 255] ^ w[++i];\n    b2 =\n      m0[b >>> 24] ^\n      m1[c >>> 16 & 255] ^\n      m2[d >>> 8 & 255] ^\n      m3[a & 255] ^ w[++i];\n    c2 =\n      m0[c >>> 24] ^\n      m1[d >>> 16 & 255] ^\n      m2[a >>> 8 & 255] ^\n      m3[b & 255] ^ w[++i];\n    d =\n      m0[d >>> 24] ^\n      m1[a >>> 16 & 255] ^\n      m2[b >>> 8 & 255] ^\n      m3[c & 255] ^ w[++i];\n    a = a2;\n    b = b2;\n    c = c2;\n  }\n\n  /*\n    Encrypt:\n    SubBytes(state)\n    ShiftRows(state)\n    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])\n\n    Decrypt:\n    InvShiftRows(state)\n    InvSubBytes(state)\n    AddRoundKey(state, w[0, Nb-1])\n   */\n   // Note: rows are shifted inline\n  output[0] =\n    (sub[a >>> 24] << 24) ^\n    (sub[b >>> 16 & 255] << 16) ^\n    (sub[c >>> 8 & 255] << 8) ^\n    (sub[d & 255]) ^ w[++i];\n  output[decrypt ? 3 : 1] =\n    (sub[b >>> 24] << 24) ^\n    (sub[c >>> 16 & 255] << 16) ^\n    (sub[d >>> 8 & 255] << 8) ^\n    (sub[a & 255]) ^ w[++i];\n  output[2] =\n    (sub[c >>> 24] << 24) ^\n    (sub[d >>> 16 & 255] << 16) ^\n    (sub[a >>> 8 & 255] << 8) ^\n    (sub[b & 255]) ^ w[++i];\n  output[decrypt ? 1 : 3] =\n    (sub[d >>> 24] << 24) ^\n    (sub[a >>> 16 & 255] << 16) ^\n    (sub[b >>> 8 & 255] << 8) ^\n    (sub[c & 255]) ^ w[++i];\n}\n\n/**\n * Deprecated. Instead, use:\n *\n * forge.cipher.createCipher('AES-<mode>', key);\n * forge.cipher.createDecipher('AES-<mode>', key);\n *\n * Creates a deprecated AES cipher object. This object's mode will default to\n * CBC (cipher-block-chaining).\n *\n * The key and iv may be given as a string of bytes, an array of bytes, a\n * byte buffer, or an array of 32-bit words.\n *\n * @param options the options to use.\n *          key the symmetric key to use.\n *          output the buffer to write to.\n *          decrypt true for decryption, false for encryption.\n *          mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nfunction _createCipher(options) {\n  options = options || {};\n  var mode = (options.mode || 'CBC').toUpperCase();\n  var algorithm = 'AES-' + mode;\n\n  var cipher;\n  if(options.decrypt) {\n    cipher = forge.cipher.createDecipher(algorithm, options.key);\n  } else {\n    cipher = forge.cipher.createCipher(algorithm, options.key);\n  }\n\n  // backwards compatible start API\n  var start = cipher.start;\n  cipher.start = function(iv, options) {\n    // backwards compatibility: support second arg as output buffer\n    var output = null;\n    if(options instanceof forge.util.ByteBuffer) {\n      output = options;\n      options = {};\n    }\n    options = options || {};\n    options.output = output;\n    options.iv = iv;\n    start.call(cipher, options);\n  };\n\n  return cipher;\n}\n\n};\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-decryption/lib/forge/aes.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-decryption/lib/forge/cipher.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@dr/drc-media-decryption/lib/forge/cipher.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/**\n * Cipher base API.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\nmodule.exports = function(forge) {\n\nforge.cipher = forge.cipher || {};\n\n// registered algorithms\nforge.cipher.algorithms = forge.cipher.algorithms || {};\n\n/**\n * Creates a cipher object that can be used to encrypt data using the given\n * algorithm and key. The algorithm may be provided as a string value for a\n * previously registered algorithm or it may be given as a cipher algorithm\n * API object.\n *\n * @param algorithm the algorithm to use, either a string or an algorithm API\n *          object.\n * @param key the key to use, as a binary-encoded string of bytes or a\n *          byte buffer.\n *\n * @return the cipher.\n */\nforge.cipher.createCipher = function(algorithm, key) {\n  var api = algorithm;\n  if(typeof api === 'string') {\n    api = forge.cipher.getAlgorithm(api);\n    if(api) {\n      api = api();\n    }\n  }\n  if(!api) {\n    throw new Error('Unsupported algorithm: ' + algorithm);\n  }\n\n  // assume block cipher\n  return new forge.cipher.BlockCipher({\n    algorithm: api,\n    key: key,\n    decrypt: false\n  });\n};\n\n/**\n * Creates a decipher object that can be used to decrypt data using the given\n * algorithm and key. The algorithm may be provided as a string value for a\n * previously registered algorithm or it may be given as a cipher algorithm\n * API object.\n *\n * @param algorithm the algorithm to use, either a string or an algorithm API\n *          object.\n * @param key the key to use, as a binary-encoded string of bytes or a\n *          byte buffer.\n *\n * @return the cipher.\n */\nforge.cipher.createDecipher = function(algorithm, key) {\n  var api = algorithm;\n  if(typeof api === 'string') {\n    api = forge.cipher.getAlgorithm(api);\n    if(api) {\n      api = api();\n    }\n  }\n  if(!api) {\n    throw new Error('Unsupported algorithm: ' + algorithm);\n  }\n\n  // assume block cipher\n  return new forge.cipher.BlockCipher({\n    algorithm: api,\n    key: key,\n    decrypt: true\n  });\n};\n\n/**\n * Registers an algorithm by name. If the name was already registered, the\n * algorithm API object will be overwritten.\n *\n * @param name the name of the algorithm.\n * @param algorithm the algorithm API object.\n */\nforge.cipher.registerAlgorithm = function(name, algorithm) {\n  name = name.toUpperCase();\n  forge.cipher.algorithms[name] = algorithm;\n};\n\n/**\n * Gets a registered algorithm by name.\n *\n * @param name the name of the algorithm.\n *\n * @return the algorithm, if found, null if not.\n */\nforge.cipher.getAlgorithm = function(name) {\n  name = name.toUpperCase();\n  if(name in forge.cipher.algorithms) {\n    return forge.cipher.algorithms[name];\n  }\n  return null;\n};\n\nvar BlockCipher = forge.cipher.BlockCipher = function(options) {\n  this.algorithm = options.algorithm;\n  this.mode = this.algorithm.mode;\n  this.blockSize = this.mode.blockSize;\n  this._finish = false;\n  this._input = null;\n  this.output = null;\n  this._op = options.decrypt ? this.mode.decrypt : this.mode.encrypt;\n  this._decrypt = options.decrypt;\n  this.algorithm.initialize(options);\n};\n\n/**\n * Starts or restarts the encryption or decryption process, whichever\n * was previously configured.\n *\n * For non-GCM mode, the IV may be a binary-encoded string of bytes, an array\n * of bytes, a byte buffer, or an array of 32-bit integers. If the IV is in\n * bytes, then it must be Nb (16) bytes in length. If the IV is given in as\n * 32-bit integers, then it must be 4 integers long.\n *\n * Note: an IV is not required or used in ECB mode.\n *\n * For GCM-mode, the IV must be given as a binary-encoded string of bytes or\n * a byte buffer. The number of bytes should be 12 (96 bits) as recommended\n * by NIST SP-800-38D but another length may be given.\n *\n * @param options the options to use:\n *          iv the initialization vector to use as a binary-encoded string of\n *            bytes, null to reuse the last ciphered block from a previous\n *            update() (this \"residue\" method is for legacy support only).\n *          additionalData additional authentication data as a binary-encoded\n *            string of bytes, for 'GCM' mode, (default: none).\n *          tagLength desired length of authentication tag, in bits, for\n *            'GCM' mode (0-128, default: 128).\n *          tag the authentication tag to check if decrypting, as a\n *             binary-encoded string of bytes.\n *          output the output the buffer to write to, null to create one.\n */\nBlockCipher.prototype.start = function(options) {\n  options = options || {};\n  var opts = {};\n  for(var key in options) {\n    opts[key] = options[key];\n  }\n  opts.decrypt = this._decrypt;\n  this._finish = false;\n  this._input = forge.util.createBuffer();\n  this.output = options.output || forge.util.createBuffer();\n  this.mode.start(opts);\n};\n\n/**\n * Updates the next block according to the cipher mode.\n *\n * @param input the buffer to read from.\n */\nBlockCipher.prototype.update = function(input) {\n  if(input) {\n    // input given, so empty it into the input buffer\n    this._input.putBuffer(input);\n  }\n\n  // do cipher operation until it needs more input and not finished\n  while(!this._op.call(this.mode, this._input, this.output, this._finish) &&\n    !this._finish) {}\n\n  // free consumed memory from input buffer\n  this._input.compact();\n};\n\n/**\n * Finishes encrypting or decrypting.\n *\n * @param pad a padding function to use in CBC mode, null for default,\n *          signature(blockSize, buffer, decrypt).\n *\n * @return true if successful, false on error.\n */\nBlockCipher.prototype.finish = function(pad) {\n  // backwards-compatibility w/deprecated padding API\n  // Note: will overwrite padding functions even after another start() call\n  if(pad && (this.mode.name === 'ECB' || this.mode.name === 'CBC')) {\n    this.mode.pad = function(input) {\n      return pad(this.blockSize, input, false);\n    };\n    this.mode.unpad = function(output) {\n      return pad(this.blockSize, output, true);\n    };\n  }\n\n  // build options for padding and afterFinish functions\n  var options = {};\n  options.decrypt = this._decrypt;\n\n  // get # of bytes that won't fill a block\n  options.overflow = this._input.length() % this.blockSize;\n\n  if(!this._decrypt && this.mode.pad) {\n    if(!this.mode.pad(this._input, options)) {\n      return false;\n    }\n  }\n\n  // do final update\n  this._finish = true;\n  this.update();\n\n  if(this._decrypt && this.mode.unpad) {\n    if(!this.mode.unpad(this.output, options)) {\n      return false;\n    }\n  }\n\n  if(this.mode.afterFinish) {\n    if(!this.mode.afterFinish(this.output, options)) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\n};\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-decryption/lib/forge/cipher.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-decryption/lib/forge/cipherModes.js":
/*!************************************************************************!*\
  !*** ./node_modules/@dr/drc-media-decryption/lib/forge/cipherModes.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/**\n * Supported cipher modes.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\nmodule.exports = function(forge) {\n\nforge.cipher = forge.cipher || {};\n\n// supported cipher modes\nvar modes = forge.cipher.modes = forge.cipher.modes || {};\n\n\n/** Electronic codebook (ECB) (Don't use this; it's not secure) **/\n\n\n/** Cipher-block Chaining (CBC) **/\n\nmodes.cbc = function(options) {\n  options = options || {};\n  this.name = 'CBC';\n  this.cipher = options.cipher;\n  this.blockSize = options.blockSize || 16;\n  this._ints = this.blockSize / 4;\n  this._inBlock = new Array(this._ints);\n  this._outBlock = new Array(this._ints);\n};\n\nmodes.cbc.prototype.start = function(options) {\n  // Note: legacy support for using IV residue (has security flaws)\n  // if IV is null, reuse block from previous processing\n  if(options.iv === null) {\n    // must have a previous block\n    if(!this._prev) {\n      throw new Error('Invalid IV parameter.');\n    }\n    this._iv = this._prev.slice(0);\n  } else if(!('iv' in options)) {\n    throw new Error('Invalid IV parameter.');\n  } else {\n    // save IV as \"previous\" block\n    this._iv = transformIV(options.iv);\n    this._prev = this._iv.slice(0);\n  }\n};\n\nmodes.cbc.prototype.encrypt = function(input, output, finish) {\n  // not enough input to encrypt\n  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {\n    return true;\n  }\n\n  // get next block\n  // CBC XOR's IV (or previous block) with plaintext\n  for(var i = 0; i < this._ints; ++i) {\n    this._inBlock[i] = this._prev[i] ^ input.getInt32();\n  }\n\n  // encrypt block\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // write output, save previous block\n  for(var i = 0; i < this._ints; ++i) {\n    output.putInt32(this._outBlock[i]);\n  }\n  this._prev = this._outBlock;\n};\n\nmodes.cbc.prototype.decrypt = function(input, output, finish) {\n  // not enough input to decrypt\n  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {\n    return true;\n  }\n\n  // get next block\n  for(var i = 0; i < this._ints; ++i) {\n    this._inBlock[i] = input.getInt32();\n  }\n\n  // decrypt block\n  this.cipher.decrypt(this._inBlock, this._outBlock);\n\n  // write output, save previous ciphered block\n  // CBC XOR's IV (or previous block) with ciphertext\n  for(var i = 0; i < this._ints; ++i) {\n    output.putInt32(this._prev[i] ^ this._outBlock[i]);\n  }\n  this._prev = this._inBlock.slice(0);\n};\n\nmodes.cbc.prototype.pad = function(input, options) {\n  // add PKCS#7 padding to block (each pad byte is the\n  // value of the number of pad bytes)\n  var padding = (input.length() === this.blockSize ?\n    this.blockSize : (this.blockSize - input.length()));\n  input.fillWithByte(padding, padding);\n  return true;\n};\n\nmodes.cbc.prototype.unpad = function(output, options) {\n  // check for error: input data not a multiple of blockSize\n  if(options.overflow > 0) {\n    return false;\n  }\n\n  // ensure padding byte count is valid\n  var len = output.length();\n  var count = output.at(len - 1);\n  if(count > (this.blockSize << 2)) {\n    return false;\n  }\n\n  // trim off padding bytes\n  output.truncate(count);\n  return true;\n};\n\n/** Utility functions */\n\nfunction transformIV(iv) {\n  if(typeof iv === 'string') {\n    // convert iv string into byte buffer\n    iv = forge.util.createBuffer(iv);\n  }\n\n  if(forge.util.isArray(iv) && iv.length > 4) {\n    // convert iv byte array into byte buffer\n    var tmp = iv;\n    iv = forge.util.createBuffer();\n    for(var i = 0; i < tmp.length; ++i) {\n      iv.putByte(tmp[i]);\n    }\n  }\n  if(!forge.util.isArray(iv)) {\n    // convert iv byte buffer into 32-bit integer array\n    iv = [iv.getInt32(), iv.getInt32(), iv.getInt32(), iv.getInt32()];\n  }\n\n  return iv;\n}\n\n};\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-decryption/lib/forge/cipherModes.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-decryption/lib/forge/index.js":
/*!******************************************************************!*\
  !*** ./node_modules/@dr/drc-media-decryption/lib/forge/index.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var forge = {};\r\n\r\n__webpack_require__(/*! ./util */ \"./node_modules/@dr/drc-media-decryption/lib/forge/util.js\")(forge);\r\n__webpack_require__(/*! ./sha256 */ \"./node_modules/@dr/drc-media-decryption/lib/forge/sha256.js\")(forge);\r\n__webpack_require__(/*! ./cipher */ \"./node_modules/@dr/drc-media-decryption/lib/forge/cipher.js\")(forge);\r\n__webpack_require__(/*! ./cipherModes */ \"./node_modules/@dr/drc-media-decryption/lib/forge/cipherModes.js\")(forge);\r\n__webpack_require__(/*! ./aes */ \"./node_modules/@dr/drc-media-decryption/lib/forge/aes.js\")(forge);\r\n\r\nmodule.exports = forge;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-decryption/lib/forge/index.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-decryption/lib/forge/sha256.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@dr/drc-media-decryption/lib/forge/sha256.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/**\n * Secure Hash Algorithm with 256-bit digest (SHA-256) implementation.\n *\n * See FIPS 180-2 for details.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\nmodule.exports = function(forge) {\n\nvar sha256 = forge.sha256 = forge.sha256 || {};\nforge.md = forge.md || {};\nforge.md.algorithms = forge.md.algorithms || {};\nforge.md.sha256 = forge.md.algorithms.sha256 = sha256;\n\n/**\n * Creates a SHA-256 message digest object.\n *\n * @return a message digest object.\n */\nsha256.create = function() {\n  // do initialization as necessary\n  if(!_initialized) {\n    _init();\n  }\n\n  // SHA-256 state contains eight 32-bit integers\n  var _state = null;\n\n  // input buffer\n  var _input = forge.util.createBuffer();\n\n  // used for word storage\n  var _w = new Array(64);\n\n  // message digest object\n  var md = {\n    algorithm: 'sha256',\n    blockLength: 64,\n    digestLength: 32,\n    // 56-bit length of message so far (does not including padding)\n    messageLength: 0,\n    // true 64-bit message length as two 32-bit ints\n    messageLength64: [0, 0]\n  };\n\n  /**\n   * Starts the digest.\n   *\n   * @return this digest object.\n   */\n  md.start = function() {\n    md.messageLength = 0;\n    md.messageLength64 = [0, 0];\n    _input = forge.util.createBuffer();\n    _state = {\n      h0: 0x6A09E667,\n      h1: 0xBB67AE85,\n      h2: 0x3C6EF372,\n      h3: 0xA54FF53A,\n      h4: 0x510E527F,\n      h5: 0x9B05688C,\n      h6: 0x1F83D9AB,\n      h7: 0x5BE0CD19\n    };\n    return md;\n  };\n  // start digest automatically for first time\n  md.start();\n\n  /**\n   * Updates the digest with the given message input. The given input can\n   * treated as raw input (no encoding will be applied) or an encoding of\n   * 'utf8' maybe given to encode the input using UTF-8.\n   *\n   * @param msg the message input to update with.\n   * @param encoding the encoding to use (default: 'raw', other: 'utf8').\n   *\n   * @return this digest object.\n   */\n  md.update = function(msg, encoding) {\n    if(encoding === 'utf8') {\n      msg = forge.util.encodeUtf8(msg);\n    }\n\n    // update message length\n    md.messageLength += msg.length;\n    md.messageLength64[0] += (msg.length / 0x100000000) >>> 0;\n    md.messageLength64[1] += msg.length >>> 0;\n\n    // add bytes to input buffer\n    _input.putBytes(msg);\n\n    // process bytes\n    _update(_state, _w, _input);\n\n    // compact input buffer every 2K or if empty\n    if(_input.read > 2048 || _input.length() === 0) {\n      _input.compact();\n    }\n\n    return md;\n  };\n\n  /**\n   * Produces the digest.\n   *\n   * @return a byte buffer containing the digest value.\n   */\n  md.digest = function() {\n    /* Note: Here we copy the remaining bytes in the input buffer and\n    add the appropriate SHA-256 padding. Then we do the final update\n    on a copy of the state so that if the user wants to get\n    intermediate digests they can do so. */\n\n    /* Determine the number of bytes that must be added to the message\n    to ensure its length is congruent to 448 mod 512. In other words,\n    the data to be digested must be a multiple of 512 bits (or 128 bytes).\n    This data includes the message, some padding, and the length of the\n    message. Since the length of the message will be encoded as 8 bytes (64\n    bits), that means that the last segment of the data must have 56 bytes\n    (448 bits) of message and padding. Therefore, the length of the message\n    plus the padding must be congruent to 448 mod 512 because\n    512 - 128 = 448.\n\n    In order to fill up the message length it must be filled with\n    padding that begins with 1 bit followed by all 0 bits. Padding\n    must *always* be present, so if the message length is already\n    congruent to 448 mod 512, then 512 padding bits must be added. */\n\n    // 512 bits == 64 bytes, 448 bits == 56 bytes, 64 bits = 8 bytes\n    // _padding starts with 1 byte with first bit is set in it which\n    // is byte value 128, then there may be up to 63 other pad bytes\n    var padBytes = forge.util.createBuffer();\n    padBytes.putBytes(_input.bytes());\n    // 64 - (remaining msg + 8 bytes msg length) mod 64\n    padBytes.putBytes(\n      _padding.substr(0, 64 - ((md.messageLength64[1] + 8) & 0x3F)));\n\n    /* Now append length of the message. The length is appended in bits\n    as a 64-bit number in big-endian order. Since we store the length in\n    bytes, we must multiply the 64-bit length by 8 (or left shift by 3). */\n    padBytes.putInt32(\n      (md.messageLength64[0] << 3) | (md.messageLength64[0] >>> 28));\n    padBytes.putInt32(md.messageLength64[1] << 3);\n    var s2 = {\n      h0: _state.h0,\n      h1: _state.h1,\n      h2: _state.h2,\n      h3: _state.h3,\n      h4: _state.h4,\n      h5: _state.h5,\n      h6: _state.h6,\n      h7: _state.h7\n    };\n    _update(s2, _w, padBytes);\n    var rval = forge.util.createBuffer();\n    rval.putInt32(s2.h0);\n    rval.putInt32(s2.h1);\n    rval.putInt32(s2.h2);\n    rval.putInt32(s2.h3);\n    rval.putInt32(s2.h4);\n    rval.putInt32(s2.h5);\n    rval.putInt32(s2.h6);\n    rval.putInt32(s2.h7);\n    return rval;\n  };\n\n  return md;\n};\n\n// sha-256 padding bytes not initialized yet\nvar _padding = null;\nvar _initialized = false;\n\n// table of constants\nvar _k = null;\n\n/**\n * Initializes the constant tables.\n */\nfunction _init() {\n  // create padding\n  _padding = String.fromCharCode(128);\n  _padding += forge.util.fillString(String.fromCharCode(0x00), 64);\n\n  // create K table for SHA-256\n  _k = [\n    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,\n    0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,\n    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,\n    0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,\n    0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,\n    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,\n    0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,\n    0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,\n    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2];\n\n  // now initialized\n  _initialized = true;\n}\n\n/**\n * Updates a SHA-256 state with the given byte buffer.\n *\n * @param s the SHA-256 state to update.\n * @param w the array to use to store words.\n * @param bytes the byte buffer to update with.\n */\nfunction _update(s, w, bytes) {\n  // consume 512 bit (64 byte) chunks\n  var t1, t2, s0, s1, ch, maj, i, a, b, c, d, e, f, g, h;\n  var len = bytes.length();\n  while(len >= 64) {\n    // the w array will be populated with sixteen 32-bit big-endian words\n    // and then extended into 64 32-bit words according to SHA-256\n    for(i = 0; i < 16; ++i) {\n      w[i] = bytes.getInt32();\n    }\n    for(; i < 64; ++i) {\n      // XOR word 2 words ago rot right 17, rot right 19, shft right 10\n      t1 = w[i - 2];\n      t1 =\n        ((t1 >>> 17) | (t1 << 15)) ^\n        ((t1 >>> 19) | (t1 << 13)) ^\n        (t1 >>> 10);\n      // XOR word 15 words ago rot right 7, rot right 18, shft right 3\n      t2 = w[i - 15];\n      t2 =\n        ((t2 >>> 7) | (t2 << 25)) ^\n        ((t2 >>> 18) | (t2 << 14)) ^\n        (t2 >>> 3);\n      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^32\n      w[i] = (t1 + w[i - 7] + t2 + w[i - 16]) | 0;\n    }\n\n    // initialize hash value for this chunk\n    a = s.h0;\n    b = s.h1;\n    c = s.h2;\n    d = s.h3;\n    e = s.h4;\n    f = s.h5;\n    g = s.h6;\n    h = s.h7;\n\n    // round function\n    for(i = 0; i < 64; ++i) {\n      // Sum1(e)\n      s1 =\n        ((e >>> 6) | (e << 26)) ^\n        ((e >>> 11) | (e << 21)) ^\n        ((e >>> 25) | (e << 7));\n      // Ch(e, f, g) (optimized the same way as SHA-1)\n      ch = g ^ (e & (f ^ g));\n      // Sum0(a)\n      s0 =\n        ((a >>> 2) | (a << 30)) ^\n        ((a >>> 13) | (a << 19)) ^\n        ((a >>> 22) | (a << 10));\n      // Maj(a, b, c) (optimized the same way as SHA-1)\n      maj = (a & b) | (c & (a ^ b));\n\n      // main algorithm\n      t1 = h + s1 + ch + _k[i] + w[i];\n      t2 = s0 + maj;\n      h = g;\n      g = f;\n      f = e;\n      e = (d + t1) | 0;\n      d = c;\n      c = b;\n      b = a;\n      a = (t1 + t2) | 0;\n    }\n\n    // update hash state\n    s.h0 = (s.h0 + a) | 0;\n    s.h1 = (s.h1 + b) | 0;\n    s.h2 = (s.h2 + c) | 0;\n    s.h3 = (s.h3 + d) | 0;\n    s.h4 = (s.h4 + e) | 0;\n    s.h5 = (s.h5 + f) | 0;\n    s.h6 = (s.h6 + g) | 0;\n    s.h7 = (s.h7 + h) | 0;\n    len -= 64;\n  }\n}\n\n};\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-decryption/lib/forge/sha256.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-decryption/lib/forge/util.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@dr/drc-media-decryption/lib/forge/util.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(process, setImmediate) {/**\n * Utility functions for web applications.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\n\nmodule.exports = function(forge) {\n\nvar util = forge.util = {};\n\n// define setImmediate and nextTick\n(function() {\n  // use native nextTick\n  if(typeof process !== 'undefined' && process.nextTick) {\n    util.nextTick = process.nextTick;\n    if(typeof setImmediate === 'function') {\n      util.setImmediate = setImmediate;\n    } else {\n      // polyfill setImmediate with nextTick, older versions of node\n      // (those w/o setImmediate) won't totally starve IO\n      util.setImmediate = util.nextTick;\n    }\n    return;\n  }\n\n  // polyfill nextTick with native setImmediate\n  if(typeof setImmediate === 'function') {\n    util.setImmediate = setImmediate;\n    util.nextTick = function(callback) {\n      return setImmediate(callback);\n    };\n    return;\n  }\n\n  /* Note: A polyfill upgrade pattern is used here to allow combining\n  polyfills. For example, MutationObserver is fast, but blocks UI updates,\n  so it needs to allow UI updates periodically, so it falls back on\n  postMessage or setTimeout. */\n\n  // polyfill with setTimeout\n  util.setImmediate = function(callback) {\n    setTimeout(callback, 0);\n  };\n\n  // upgrade polyfill to use postMessage\n  if(typeof window !== 'undefined' &&\n    typeof window.postMessage === 'function') {\n    var msg = 'forge.setImmediate';\n    var callbacks = [];\n    util.setImmediate = function(callback) {\n      callbacks.push(callback);\n      // only send message when one hasn't been sent in\n      // the current turn of the event loop\n      if(callbacks.length === 1) {\n        window.postMessage(msg, '*');\n      }\n    };\n    function handler(event) {\n      if(event.source === window && event.data === msg) {\n        event.stopPropagation();\n        var copy = callbacks.slice();\n        callbacks.length = 0;\n        copy.forEach(function(callback) {\n          callback();\n        });\n      }\n    }\n    window.addEventListener('message', handler, true);\n  }\n\n  // upgrade polyfill to use MutationObserver\n  if(typeof MutationObserver !== 'undefined') {\n    // polyfill with MutationObserver\n    var now = Date.now();\n    var attr = true;\n    var div = document.createElement('div');\n    var callbacks = [];\n    new MutationObserver(function() {\n      var copy = callbacks.slice();\n      callbacks.length = 0;\n      copy.forEach(function(callback) {\n        callback();\n      });\n    }).observe(div, {attributes: true});\n    var oldSetImmediate = util.setImmediate;\n    util.setImmediate = function(callback) {\n      if(Date.now() - now > 15) {\n        now = Date.now();\n        oldSetImmediate(callback);\n      } else {\n        callbacks.push(callback);\n        // only trigger observer when it hasn't been triggered in\n        // the current turn of the event loop\n        if(callbacks.length === 1) {\n          div.setAttribute('a', attr = !attr);\n        }\n      }\n    };\n  }\n\n  util.nextTick = util.setImmediate;\n})();\n\n// define isArray\nutil.isArray = Array.isArray || function(x) {\n  return Object.prototype.toString.call(x) === '[object Array]';\n};\n\n// define isArrayBuffer\nutil.isArrayBuffer = function(x) {\n  return typeof ArrayBuffer !== 'undefined' && x instanceof ArrayBuffer;\n};\n\n// define isArrayBufferView\nutil.isArrayBufferView = function(x) {\n  return x && util.isArrayBuffer(x.buffer) && x.byteLength !== undefined;\n};\n\n// TODO: set ByteBuffer to best available backing\nutil.ByteBuffer = ByteStringBuffer;\n\n/** Buffer w/BinaryString backing */\n\n/**\n * Constructor for a binary string backed byte buffer.\n *\n * @param [b] the bytes to wrap (either encoded as string, one byte per\n *          character, or as an ArrayBuffer or Typed Array).\n */\nfunction ByteStringBuffer(b) {\n  // TODO: update to match DataBuffer API\n\n  // the data in this buffer\n  this.data = '';\n  // the pointer for reading from this buffer\n  this.read = 0;\n\n  if(typeof b === 'string') {\n    this.data = b;\n  } else if(util.isArrayBuffer(b) || util.isArrayBufferView(b)) {\n    // convert native buffer to forge buffer\n    // FIXME: support native buffers internally instead\n    var arr = new Uint8Array(b);\n    try {\n      this.data = String.fromCharCode.apply(null, arr);\n    } catch(e) {\n      for(var i = 0; i < arr.length; ++i) {\n        this.putByte(arr[i]);\n      }\n    }\n  } else if(b instanceof ByteStringBuffer ||\n    (typeof b === 'object' && typeof b.data === 'string' &&\n    typeof b.read === 'number')) {\n    // copy existing buffer\n    this.data = b.data;\n    this.read = b.read;\n  }\n\n  // used for v8 optimization\n  this._constructedStringLength = 0;\n}\nutil.ByteStringBuffer = ByteStringBuffer;\n\n/* Note: This is an optimization for V8-based browsers. When V8 concatenates\n  a string, the strings are only joined logically using a \"cons string\" or\n  \"constructed/concatenated string\". These containers keep references to one\n  another and can result in very large memory usage. For example, if a 2MB\n  string is constructed by concatenating 4 bytes together at a time, the\n  memory usage will be ~44MB; so ~22x increase. The strings are only joined\n  together when an operation requiring their joining takes place, such as\n  substr(). This function is called when adding data to this buffer to ensure\n  these types of strings are periodically joined to reduce the memory\n  footprint. */\nvar _MAX_CONSTRUCTED_STRING_LENGTH = 4096;\nutil.ByteStringBuffer.prototype._optimizeConstructedString = function(x) {\n  this._constructedStringLength += x;\n  if(this._constructedStringLength > _MAX_CONSTRUCTED_STRING_LENGTH) {\n    // this substr() should cause the constructed string to join\n    this.data.substr(0, 1);\n    this._constructedStringLength = 0;\n  }\n};\n\n// used\n/**\n * Gets the number of bytes in this buffer.\n *\n * @return the number of bytes in this buffer.\n */\nutil.ByteStringBuffer.prototype.length = function() {\n  return this.data.length - this.read;\n};\n\n// used\n/**\n * Puts bytes in this buffer.\n *\n * @param bytes the bytes (as a UTF-8 encoded string) to put.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putBytes = function(bytes) {\n  this.data += bytes;\n  this._optimizeConstructedString(bytes.length);\n  return this;\n};\n\n// used\n/**\n * Puts a 32-bit integer in this buffer in big-endian order.\n *\n * @param i the 32-bit integer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putInt32 = function(i) {\n  return this.putBytes(\n    String.fromCharCode(i >> 24 & 0xFF) +\n    String.fromCharCode(i >> 16 & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i & 0xFF));\n};\n\n\n// used\n/**\n * Puts the given buffer into this buffer.\n *\n * @param buffer the buffer to put into this one.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putBuffer = function(buffer) {\n  return this.putBytes(buffer.getBytes());\n};\n\n// used\n/**\n * Gets a uint32 from this buffer in big-endian order and advances the read\n * pointer by 4.\n *\n * @return the word.\n */\nutil.ByteStringBuffer.prototype.getInt32 = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) << 24 ^\n    this.data.charCodeAt(this.read + 1) << 16 ^\n    this.data.charCodeAt(this.read + 2) << 8 ^\n    this.data.charCodeAt(this.read + 3));\n  this.read += 4;\n  return rval;\n};\n\n// used\n/**\n * Reads bytes out into a UTF-8 string and clears them from the buffer.\n *\n * @param count the number of bytes to read, undefined or null for all.\n *\n * @return a UTF-8 string of bytes.\n */\nutil.ByteStringBuffer.prototype.getBytes = function(count) {\n  var rval;\n  if(count) {\n    // read count bytes\n    count = Math.min(this.length(), count);\n    rval = this.data.slice(this.read, this.read + count);\n    this.read += count;\n  } else if(count === 0) {\n    rval = '';\n  } else {\n    // read all bytes, optimize to only copy when needed\n    rval = (this.read === 0) ? this.data : this.data.slice(this.read);\n    this.clear();\n  }\n  return rval;\n};\n\n// used\n/**\n * Gets a UTF-8 encoded string of the bytes from this buffer without modifying\n * the read pointer.\n *\n * @param count the number of bytes to get, omit to get all.\n *\n * @return a string full of UTF-8 encoded characters.\n */\nutil.ByteStringBuffer.prototype.bytes = function(count) {\n  return (typeof(count) === 'undefined' ?\n    this.data.slice(this.read) :\n    this.data.slice(this.read, this.read + count));\n};\n\n// used\n/**\n * Gets a byte at the given index without modifying the read pointer.\n *\n * @param i the byte index.\n *\n * @return the byte.\n */\nutil.ByteStringBuffer.prototype.at = function(i) {\n  return this.data.charCodeAt(this.read + i);\n};\n\n// used\n/**\n * Compacts this buffer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.compact = function() {\n  if(this.read > 0) {\n    this.data = this.data.slice(this.read);\n    this.read = 0;\n  }\n  return this;\n};\n\n// used\n/**\n * Clears this buffer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.clear = function() {\n  this.data = '';\n  this.read = 0;\n  return this;\n};\n\n// used\n/**\n * Shortens this buffer by triming bytes off of the end of this buffer.\n *\n * @param count the number of bytes to trim off.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.truncate = function(count) {\n  var len = Math.max(0, this.length() - count);\n  this.data = this.data.substr(this.read, len);\n  this.read = 0;\n  return this;\n};\n\n/** End Buffer w/BinaryString backing */\n\n// used\n/**\n * Creates a buffer that stores bytes. A value may be given to put into the\n * buffer that is either a string of bytes or a UTF-16 string that will\n * be encoded using UTF-8 (to do the latter, specify 'utf8' as the encoding).\n *\n * @param [input] the bytes to wrap (as a string) or a UTF-16 string to encode\n *          as UTF-8.\n * @param [encoding] (default: 'raw', other: 'utf8').\n */\nutil.createBuffer = function(input, encoding) {\n  // TODO: deprecate, use new ByteBuffer() instead\n  encoding = encoding || 'raw';\n  if(input !== undefined && encoding === 'utf8') {\n    input = util.encodeUtf8(input);\n  }\n  return new util.ByteBuffer(input);\n};\n\n// used\n/**\n * Fills a string with a particular value. If you want the string to be a byte\n * string, pass in String.fromCharCode(theByte).\n *\n * @param c the character to fill the string with, use String.fromCharCode\n *          to fill the string with a byte value.\n * @param n the number of characters of value c to fill with.\n *\n * @return the filled string.\n */\nutil.fillString = function(c, n) {\n  var s = '';\n  while(n > 0) {\n    if(n & 1) {\n      s += c;\n    }\n    n >>>= 1;\n    if(n > 0) {\n      c += c;\n    }\n  }\n  return s;\n};\n\n// used\n/**\n * Converts a hex string into a 'binary' encoded string of bytes.\n *\n * @param hex the hexadecimal string to convert.\n *\n * @return the binary-encoded string of bytes.\n */\nutil.hexToBytes = function(hex) {\n  // TODO: deprecate: \"Deprecated. Use util.binary.hex.decode instead.\"\n  var rval = '';\n  var i = 0;\n  if(hex.length & 1 == 1) {\n    // odd number of characters, convert first character alone\n    i = 1;\n    rval += String.fromCharCode(parseInt(hex[0], 16));\n  }\n  // convert 2 characters (1 byte) at a time\n  for(; i < hex.length; i += 2) {\n    rval += String.fromCharCode(parseInt(hex.substr(i, 2), 16));\n  }\n  return rval;\n};\n\n};\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../process/browser.js */ \"./node_modules/process/browser.js\"), __webpack_require__(/*! ./../../../../timers-browserify/main.js */ \"./node_modules/timers-browserify/main.js\").setImmediate))\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-decryption/lib/forge/util.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/js/dk_time.js":
/*!*************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/js/dk_time.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var timezoneJS = __webpack_require__(/*! timezone-js */ \"./node_modules/timezone-js/src/date.js\");\nvar _tz = timezoneJS.timezone;\n_tz.loadingScheme = _tz.loadingSchemes.MANUAL_LOAD;\n_tz.loadZoneDataFromObject({\"zones\":{\"Europe/Copenhagen\":[[\"-50.333333333333336\",\"-\",\"LMT\",\"-2493072000000\"],[\"-50.333333333333336\",\"-\",\"CMT\",\"-2398291200000\"],[\"-60\",\"Denmark\",\"CE%sT\",\"-857253600000\"],[\"-60\",\"C-Eur\",\"CE%sT\",\"-781048800000\"],[\"-60\",\"Denmark\",\"CE%sT\",\"347068800000\"],[\"-60\",\"EU\",\"CE%sT\",null]],\"Etc/UTC\":[[\"0\",\"-\",\"UTC\",null]]},\"rules\":{\"Denmark\":[[\"1916\",\"only\",\"-\",\"May\",\"14\",[\"23\",\"0\",\"0\",null],\"60\",\"S\"],[\"1916\",\"only\",\"-\",\"Sep\",\"30\",[\"23\",\"0\",\"0\",null],\"0\",\"-\"],[\"1940\",\"only\",\"-\",\"May\",\"15\",[\"0\",\"0\",\"0\",null],\"60\",\"S\"],[\"1945\",\"only\",\"-\",\"Apr\",\"2\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1945\",\"only\",\"-\",\"Aug\",\"15\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1946\",\"only\",\"-\",\"May\",\"1\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1946\",\"only\",\"-\",\"Sep\",\"1\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1947\",\"only\",\"-\",\"May\",\"4\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1947\",\"only\",\"-\",\"Aug\",\"10\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1948\",\"only\",\"-\",\"May\",\"9\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1948\",\"only\",\"-\",\"Aug\",\"8\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"]],\"C-Eur\":[[\"1916\",\"only\",\"-\",\"Apr\",\"30\",[\"23\",\"0\",\"0\",null],\"60\",\"S\"],[\"1916\",\"only\",\"-\",\"Oct\",\"1\",[\"1\",\"0\",\"0\",null],\"0\",\"-\"],[\"1917\",\"1918\",\"-\",\"Apr\",\"Mon>=15\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1917\",\"1918\",\"-\",\"Sep\",\"Mon>=15\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1940\",\"only\",\"-\",\"Apr\",\"1\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1942\",\"only\",\"-\",\"Nov\",\"2\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1943\",\"only\",\"-\",\"Mar\",\"29\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1943\",\"only\",\"-\",\"Oct\",\"4\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1944\",\"1945\",\"-\",\"Apr\",\"Mon>=1\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1944\",\"only\",\"-\",\"Oct\",\"2\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1945\",\"only\",\"-\",\"Sep\",\"16\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1977\",\"1980\",\"-\",\"Apr\",\"Sun>=1\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1977\",\"only\",\"-\",\"Sep\",\"lastSun\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1978\",\"only\",\"-\",\"Oct\",\"1\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1979\",\"1995\",\"-\",\"Sep\",\"lastSun\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"],[\"1981\",\"max\",\"-\",\"Mar\",\"lastSun\",[\"2\",\"0\",\"0\",\"s\"],\"60\",\"S\"],[\"1996\",\"max\",\"-\",\"Oct\",\"lastSun\",[\"2\",\"0\",\"0\",\"s\"],\"0\",\"-\"]],\"EU\":[[\"1977\",\"1980\",\"-\",\"Apr\",\"Sun>=1\",[\"1\",\"0\",\"0\",\"u\"],\"60\",\"S\"],[\"1977\",\"only\",\"-\",\"Sep\",\"lastSun\",[\"1\",\"0\",\"0\",\"u\"],\"0\",\"-\"],[\"1978\",\"only\",\"-\",\"Oct\",\"1\",[\"1\",\"0\",\"0\",\"u\"],\"0\",\"-\"],[\"1979\",\"1995\",\"-\",\"Sep\",\"lastSun\",[\"1\",\"0\",\"0\",\"u\"],\"0\",\"-\"],[\"1981\",\"max\",\"-\",\"Mar\",\"lastSun\",[\"1\",\"0\",\"0\",\"u\"],\"60\",\"S\"],[\"1996\",\"max\",\"-\",\"Oct\",\"lastSun\",[\"1\",\"0\",\"0\",\"u\"],\"0\",\"-\"]]}});\n\nfunction isoTzString() {\n\tvar tzo = -this.getTimezoneOffset(),\n\t\tdif = tzo >= 0 ? \"+\" : \"-\",\n\t\tpad = function(num) {\n\t\t\tvar norm = Math.abs(Math.floor(num));\n\t\t\treturn (norm < 10 ? \"0\" : \"\") + norm;\n\t\t};\n\treturn this.getFullYear() +\n\t\t\"-\" + pad(this.getMonth() + 1) +\n\t\t\"-\" + pad(this.getDate()) +\n\t\t\"T\" + pad(this.getHours()) +\n\t\t\":\" + pad(this.getMinutes()) +\n\t\t\":\" + pad(this.getSeconds()) +\n\t\tdif + pad(tzo / 60) +\n\t\t\":\" + pad(tzo % 60);\n}\n\nfunction dkTimeString(timeString) {\n\tvar d = new timezoneJS.Date(timeString);\n\td.setTimezone(\"Europe/Copenhagen\");\n\treturn isoTzString.call(d);\n}\n\nmodule.exports = { dkTimeString: dkTimeString };\n\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/dk_time.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/js/stats_base.js":
/*!****************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/js/stats_base.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("\nvar akamaiClass\t\t= __webpack_require__(/*! ./tracking/akamai/SolaImplementation */ \"./node_modules/@dr/drc-media-statistics/js/tracking/akamai/SolaImplementation.js\");\nvar gallupClass\t\t= __webpack_require__(/*! ./tracking/gallup/SpringstreamsImplementation */ \"./node_modules/@dr/drc-media-statistics/js/tracking/gallup/SpringstreamsImplementation.js\");\nvar psdbClass\t\t= __webpack_require__(/*! ./tracking/psdb/PsdbTracking */ \"./node_modules/@dr/drc-media-statistics/js/tracking/psdb/PsdbTracking.js\");\nvar psdbRadioClass = __webpack_require__(/*! ./tracking/psdb/PsdbRadioTracking */ \"./node_modules/@dr/drc-media-statistics/js/tracking/psdb/PsdbRadioTracking.js\");\nvar ensightenClass = __webpack_require__(/*! ./tracking/ensighten/EnsightenImplementation */ \"./node_modules/@dr/drc-media-statistics/js/tracking/ensighten/EnsightenImplementation.js\");\nvar tracker = {\n// removing akamai from media statistics to fix radio site\n// plan is to remove it permanently from media statistics and let \n// ensighten implement it\n\tinitAkamaiHtml5Tracker: function (player, options) {\n//\t\toptions = options || {};\n//\n//    \tnew akamaiClass(player, options);\n\t},\n\tinitGallupHtml5Tracker: function (player) {\n\t\tnew gallupClass(player);\n\t},\n\tinitPsdbTracker: function (player, options) {\n\t\toptions = options || {};\n\t\toptions.url = options.url || 'https://www.dr.dk/mu-online/api/1.2/reporting/viewed';\n\t\toptions.latestViewedUrl = options.latestViewedUrl || 'https://www.dr.dk/mu-online/api/1.2/user/add-last-viewed';\n\t\toptions.version = options.version || 'dr.ChromecastReceiver.1.0.0';\n\t\toptions.registerLatestViewed = true;\n\n\t\tnew psdbClass(player, options);\n\t},\n\tinitPsdbRadioTracker: function (player, options) {\n\t\toptions = options || {};\n\t\toptions.url = options.url || 'https://www.dr.dk/mu-online-radio/played';\n\t\toptions.version = options.version || 'dr.drc-media-statistics.3.4.0';\n\t\tnew psdbRadioClass(player, options);\n\t},\n\tinitEnsightenTracker: function (player, options) {\n\t\tnew ensightenClass(player, options);\n\t}\n};\n\n// Export module\nmodule.exports = tracker;\n\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/stats_base.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/js/tracking/akamai/SolaImplementation.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/js/tracking/akamai/SolaImplementation.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* jshint devel: true */\n/* global define: true, require: true, akamaiSetVideoObject: true, akamaiHandleStreamSwitch:true, setAkamaiMediaAnalyticsData: true */\nvar script = __webpack_require__(/*! scriptjs */ \"./node_modules/scriptjs/dist/script.js\");\n\nvar SolaImplementation = function (player, options) {\n    \n    var self = this;\n\n    self.player = player;\n    self.options = options || {};\n    self.metadata = null;\n\n    setTrackingSettings(options);\n\n    function setTrackingSettings(options) {\n        self.options.playerId = options.playerId || 'HTML5 player'\n    }\n\n    function onResourceReady(metadata) {\n        if (typeof metadata === \"undefined\") {\n            if (window.console) console.error('Error: metadata not defined! Aborting Akamai logging');\n            return;\n        }\n\n        self.player.addEvent('play', bootstrap);\n        \n        self.metadata = metadata;\n\n        // Needs to be set before loading the Akamai js script\n        window.AKAMAI_MEDIA_ANALYTICS_CONFIG_FILE_PATH = getBeaconPath();\n    }\n\n    function bootstrap() {\n        self.player.removeEvent('play', bootstrap);\n\n        if (self.metadata.mediaType === 'audio') {\n            self.mediaElement = self.player.audioElement;\n        } else {\n            self.mediaElement = self.player.videoElement;\n        }\n\n        script([getScriptPath()], function() {\n            buildAndSendSolaMetadata();\n            akamaiSetVideoObject(self.mediaElement);\n            akamaiHandleStreamSwitch();\n            self.player.fireEvent('akamaiReady');\n        }).bind(this);\n    }\n\n    function getScriptPath() {\n        if (isLocationSecure()) {\n            return 'https://79423.analytics.edgekey.net/html5/akamaihtml5-min.js';\n        }\n\n        return 'http://79423.analytics.edgesuite.net/html5/akamaihtml5-min.js';\n    }\n\n    function getBeaconPath() {\n        switch (self.metadata.mediaType) {\n            case 'audio':\n                if (isLocationSecure()) {\n                    return 'https://ma1121-r.analytics.edgekey.net/config/beacon-8741.xml';\n                } else {\n                    return 'http://ma403-r.analytics.edgesuite.net/config/beacon-5186.xml';\n                }\n            case 'video':\n                if (isLocationSecure()) {\n                    return 'https://ma1120-r.analytics.edgekey.net/config/beacon-8740.xml';\n                } else {\n                    return 'http://ma403-r.analytics.edgesuite.net/config/beacon-5118.xml';\n                }\n            default:\n                if (console) {\n                    console.log('Unsupported mediaType received by SolaImplementation: ' + self.metadata.mediaType);\n                }\n        }\n    }\n\n    function isLocationSecure() {\n        return window.location.protocol !== \"http:\";\n    }\n\n    function getDeviceType () {\n        var deviceType  = 'Other';\n        var userAgent = navigator.userAgent;\n        deviceType = userAgent;\n        if (userAgent === null)\n        {\n            return deviceType;\n        }\n        if (userAgent.toLowerCase().indexOf('android') > -1) \n        {\n            if (userAgent.toLowerCase() === 'Phone - Android') {    \n            } else {\n                deviceType = 'Tablet - Android';\n            }\n\n        } else if (userAgent.toLowerCase().indexOf('ipad') > -1) {\n            deviceType = 'Tablet - IOS';\n        } else if (userAgent.toLowerCase().indexOf('iphone') > -1) {\n            deviceType = 'Phone - IOS';\n        } else if (isWinTablet(userAgent)) {\n            deviceType = 'Tablet - Windows';\n        } else if (isWinPhone(userAgent)) {\n            deviceType = 'Phone - Windows';\n        } else if (userAgent.toLowerCase().indexOf('linux') > -1) {\n            deviceType = 'Computer - Linux';\n        } else if (userAgent.toLowerCase().indexOf('windows') > -1) {\n            deviceType = 'Computer - Windows';\n        } else if (userAgent.toLowerCase().indexOf('macintosh') > -1) {\n            deviceType = 'Computer - Mac';\n        }\n        return deviceType;\n    }\n\n    function getDeliveryType () {\n        if (self.metadata.videoType === 'live') {\n            var thisRef = self;\n            var channels = self.metadata.channels.filter(function(element){return element.slug === thisRef.metadata.channelId || element.Slug === thisRef.metadata.channelId});\n            if (channels.length > 0) {\n                var channel = channels[0];\n\n                if (channel.webChannel === true) {\n                    return 'L';\n                }\n\n                return 'T';\n            }\n\n            // Weird. Channel is not in channel list\n            return 'L';\n        }\n        \n        return 'O';\n    }\n\n    function isWinTablet (userAgent) {\n        return userAgent.toLowerCase().indexOf('windows nt') > -1 && userAgent.toLowerCase().indexOf('touch') > -1;\n    }\n    function isWinPhone (userAgent) {\n        return userAgent.toLowerCase().indexOf('windows phone') > -1;\n    }\n    function buildAndSendSolaMetadata () {\n        var eventName = '';\n        \n        if (self.metadata.videoType === 'live') {\n            eventName = self.metadata.channelId;\n        } else {\n            if (self.metadata.productionNumber !== null && self.metadata.productionNumber !== undefined) {\n                eventName = '[' + self.metadata.productionNumber + '] ' + self.metadata.slug;\n            } else {\n                eventName = '[] ' + self.metadata.slug;\n            }\n        }\n    \n        //var eventName = options.videoData.videoType === 'live' ? options.videoData.programSerieSlug :'[' + self.player.productionNumber() + '] ' + options.videoData.programmeName;\n        var playerId = self.options.playerId;\n        var device = getDeviceType();\n\n        var log = '';\n        log += 'sola data:';\n        log += '\\n\\teventName: ' + eventName;\n        log += '\\n\\tplayerId: ' + playerId;\n        log += '\\n\\tdevice: ' + device;\n\n        if (self.metadata.programSerieSlug !== undefined && self.metadata.programSerieSlug !== null) {\n            log += '\\n\\tshow: ' + self.metadata.programSerieSlug;\n            setAkamaiMediaAnalyticsData('show', self.metadata.programSerieSlug);\n        }\n\n        if (self.metadata.slug !== '') {\n            setAkamaiMediaAnalyticsData('title', self.metadata.slug);\n            log += '\\n\\ttitle: ' + self.metadata.slug;\n        }\n        \n        log += '\\n\\tdeliveryType: ' + getDeliveryType();\n      \n        setAkamaiMediaAnalyticsData('eventName', eventName);\n        \n        if (self.metadata.genre) {\n            setAkamaiMediaAnalyticsData('category', self.metadata.genre);\n            log += '\\n\\tcategory: ' + self.metadata.genre;\n        }\n\n        setAkamaiMediaAnalyticsData('device', device);\n        setAkamaiMediaAnalyticsData('deliveryType', getDeliveryType());\n        setAkamaiMediaAnalyticsData('playerId', playerId);\n        \n        if (self.metadata.videoType === 'live') {\n            setAkamaiMediaAnalyticsData('channel', self.metadata.channelId);\n            log += '\\n\\tchannel: ' + self.metadata.channelId;\n        } else {\n            setAkamaiMediaAnalyticsData('productionNumber', self.metadata.productionNumber);\n            log += '\\n\\tproductionNumber: ' + self.metadata.productionNumber;\n        }\n        \n        if (window.console) console.log(log);\n    }\n\n    self.player.addEvent('resourceReady', onResourceReady);\n};\n\nmodule.exports = SolaImplementation;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/tracking/akamai/SolaImplementation.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/js/tracking/ensighten/EnsightenImplementation.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/js/tracking/ensighten/EnsightenImplementation.js ***!
  \************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/*jshint browser:true, devel:false */\n/*Ensighten Implementation */\n\nvar EnsightenImplementation = function (player, options) {\n\n    try {\n        if (Bootstrapper) {\n            var self = this;\n\n            self.isSeeking = false;\n            self.isPlaying = false;\n            self.isBuffering = false;\n            self.metadata = null;\n            self.player = (player) ? player : null;\n            self.options = options;\n\n            // bind events\n            self.player.addEvent('play', onPlay);\n            self.player.addEvent('pause', onPause);\n            self.player.addEvent('stop', onStopped);\n            self.player.addEvent('buffering', onBuffering);\n            self.player.addEvent('bufferingComplete', onBufferingComplete);\n            self.player.addEvent('beforeSeek', onBeforeSeek);\n            self.player.addEvent('afterSeek', onAfterSeek);\n            self.player.addEvent('complete', onComplete);\n            self.player.addEvent('resourceReady', onResourceReady);\n\n            // on play, send how far into the program play is called.\n            function onPlay() {\n                self.isPlaying = true;\n                Bootstrapper.videoTracking(\"play\", self.metadata, self.player.position());\n            }\n            function onPause() {\n                self.isPlaying = false;\n                Bootstrapper.videoTracking(\"pause\", self.metadata);\n            }\n            function onStopped() {\n                self.isPlaying = false;\n                Bootstrapper.videoTracking(\"stopped\", self.metadata);\n            }\n            function onBuffering() {\n                self.isBuffering = true;\n                Bootstrapper.videoTracking(\"buffering\", self.metadata);\n            }\n            function onBufferingComplete() {\n                self.isBuffering = false;\n                Bootstrapper.videoTracking(\"bufferingComplete\", self.metadata);\n            }\n            function onBeforeSeek(seekToPosition) {\n                self.isSeeking = true;\n                Bootstrapper.videoTracking(\"beforeSeek\", self.metadata, seekToPosition);\n            }\n            function onAfterSeek(seekToPosition) {\n                self.isSeeking = false;\n                Bootstrapper.videoTracking(\"afterSeek\", self.metadata, seekToPosition);\n            }\n            function onComplete() {\n                self.isPlaying = false;\n                Bootstrapper.videoTracking(\"complete\", self.metadata);\n            }\n            function onResourceReady(metadata) {\n                self.metadata = metadata;\n                Bootstrapper.videoTracking(\"resourceReady\", self.metadata);\n            }\n        }\n    }\n    catch (e) {\n      console.log('No Bootstrapper available');\n    }\n};\n\nmodule.exports = EnsightenImplementation;\n\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/tracking/ensighten/EnsightenImplementation.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/js/tracking/gallup/SpringstreamsImplementation.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/js/tracking/gallup/SpringstreamsImplementation.js ***!
  \*************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* jshint devel: true */\n/* global define: true, SpringStreams: true */\nvar dkTime = __webpack_require__(/*! ../../dk_time */ \"./node_modules/@dr/drc-media-statistics/js/dk_time.js\");\n\n__webpack_require__(/*! script-loader!../../3rd_party/springstreams/2.0.0/springstreams */ \"./node_modules/@dr/drc-media-statistics/node_modules/script-loader/index.js!./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js\");\n\nvar SpringstreamsImplementation = function (player){\n    var self = this;\n    self.player = player;\n    self.metadata = {};\n\n    self.sensors = new SpringStreams('drstream');\n\n    function onResourceReady(metadata) {\n        if (typeof metadata === \"undefined\") {\n            if (window.console) console.error('Error: metadata not defined! Aborting SpringStreams logging');\n            return;\n        }\n\n        if (self.stream) {\n            self.stream.stop();\n            self.stream = null;\n        }\n\n        self.player.addEvent('play', bootstrap);\n\n        self.metadata = metadata;\n        self.metadata.publishStartTimeCode = dkTime.dkTimeString(\n            self.metadata.publishStartTimeCode || new Date().toISOString()\n        );\n    }\n\n    function bootstrap() {\n        self.player.removeEvent('play', bootstrap);\n\n        trackPlayEvent();\n    }\n\n    function nowNextUpdated(metadata) {\n        // check if program was actually changed.\n        if(metadata && metadata.urn !== self.metadata.urn || metadata && metadata.publishStartTimeCode !== self.metadata.publishStartTimeCode) {\n            // stop existing stream\n            if (self.stream) {\n                self.stream.stop();\n                self.stream = null;\n            }\n\n            // update and format metadata\n            self.metadata = metadata;\n            self.metadata.publishStartTimeCode = dkTime.dkTimeString(\n                self.metadata.publishStartTimeCode || new Date().toISOString()\n            );\n\n            // start a new track event for the new program.\n            trackPlayEvent();\n        }\n    }\n    function trackPlayEvent () {\n        var date, time, channelId;\n        var broadcastName = getBroadcastName();\n        var streamId = getStreamId();\n        var series = self.metadata.programSerieSlug;\n        var videoType = self.metadata.videoType == 'live' ? 'live' : 'OD';\n\n        if (videoType === 'OD') {\n            channelId = getODChannelId();\n            date = getODBroadcastDate();\n            time = getODBroadcastTime();\n        } else {\n            channelId = getLiveChannelId();\n            date = getLiveBroadcastDate();\n            time = getLiveBroadcastTime();\n        }\n\n        /**\n         * Tag order:\n         * BroadCaster_OD/Channel/Program/Season/Episode/DateBroadcast/TimeBroadcast/Streamid\n         * BroadCaster_Live/Channel/Program/Season/Episode/DateBroadcast/TimeBroadcast/Streamid\n         * (season og episode vil altid være NULL, da vi slet ikke er så avancerede)\n         */\n        var desc = {\n            'stream':'DR_' + videoType + '/' + channelId + '/' + broadcastName + '/NULL/NULL/' + date + '/' + time + '/' + streamId,\n            'duration': getDuration(videoType),\n            'cq': streamId\n        };\n        if (self.stream) {\n            self.stream.stop();\n            self.stream = null;\n        }\n        //if (window.console) console.log('SpringstreamsImplementation.trackPlayEvent', self.sensors, desc);\n        self.stream = self.sensors.track(self.player.videoElement, desc);\n    }\n\n    function getDuration(videoType) {\n        if (videoType === 'live') {\n            return 0;\n        }\n        return Math.round(self.player.duration());\n    }\n\n    function getBroadcastName() {\n        return self.metadata.slug && self.metadata.slug !== '' ? self.metadata.slug : 'NULL';\n    }\n\n    function getStreamId() {\n        if (self.metadata.urn) {\n            var urn = self.metadata.urn;\n            urn = urn.split(':').join('_');\n            urn = urn.split('programcard_')[1];\n            return urn;\n        }\n\n        return self.metadata.productionNumber;\n    }\n\n    function getODBroadcastDate() {\n        if (self.metadata.publishStartTimeCode) {\n            return self.metadata.publishStartTimeCode.split('T')[0];\n        }\n\n        return 'NULL';\n    }\n\n    function getODBroadcastTime() {\n        if (self.metadata.publishStartTimeCode) {\n            var time = self.metadata.publishStartTimeCode.split('T')[1].split('+')[0]\n            if (time)\n                time = time.split(':').join('.');\n\n            return time;\n        }\n\n        return 'NULL';\n    }\n\n    function getODChannelId() {\n        /**\n         *  A primary channel from the program card will be ie. \"dr.dk/mas/whatson/channel/DR1\".\n         *  That's why er're splitting the string and taking the last index of the array\n         */\n        var channels = getChannelList();\n        if (self.metadata.primaryChannel) {\n            var channelNameArr = self.metadata.primaryChannel.split('/');\n            var channelSourceName = channelNameArr[channelNameArr.length-1].toLowerCase();\n            return channels[channelSourceName] ? channels[channelSourceName] : channels['fallback'];\n        }\n\n        return channels['fallback'];\n    }\n\n    function getLiveChannelId() {\n        var channels = getChannelList();\n        var liveChannelId = self.metadata.channelId;\n        liveChannelId = liveChannelId.replace('-', '');\n\n        return channels[liveChannelId] ? channels[liveChannelId] : channels['fallback'];\n    }\n\n    function getLiveBroadcastTime() {\n            var dateObj = self.metadata.publishStartTimeCode;\n            if (dateObj !== null && dateObj !== undefined) {\n                var time = dateObj.split('T')[1].split('+')[0];\n                if (time)\n                    time = time.split(':').join('.')\n\n                return time;\n            }\n\n            return 'NULL';\n    }\n\n    function getLiveBroadcastDate() {\n            var dateObj = self.metadata.publishStartTimeCode;\n            if (dateObj !== null && dateObj !== undefined) {\n                return dateObj.split('T')[0];\n            }\n\n            return 'NULL';\n    }\n\n    function getChannelList() {\n        return {\n            dr1: 'DR1',\n            dr2: 'DR2',\n            dr3: 'DR3',\n            tvr: 'DRRamasjang',\n            tvl: 'DRUltra',\n            tvk: 'DRK',\n            drramasjang: 'DRRamasjang',\n            drultra: 'DRUltra',\n            drk: 'DRK',\n            fallback: 'drdk'\n        };\n    }\n\n    self.player.addEvent('resourceReady', onResourceReady);\n    self.player.addEvent('liveDataUpdated', nowNextUpdated);\n};\n\nmodule.exports = SpringstreamsImplementation;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/tracking/gallup/SpringstreamsImplementation.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/js/tracking/psdb/PsdbRadioTracking.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/js/tracking/psdb/PsdbRadioTracking.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("﻿var psdbUtilities = function (player, options) {\n    var self = this;\n    this.player = player;\n    this.options = options;\n    this.metadata = null;\n\n    function onResourceReady (metadata) {\n        if (typeof metadata === \"undefined\") {\n            if (window.console) console.error('Error: metadata not defined! Aborting PSDB logging');\n            return;\n        }\n\n        self.player.addEventListener('play', onPlay);\n\n        self.metadata = metadata;\n    }\n\n    function registerView () {\n        if (!self.metadata) {\n            if (window.console) console.error('Error: metadata not defined! Aborting PSDB logging');\n            return;\n        }\n\n        var requesturl = self.options.url;\n\n        if(requesturl && self.metadata.urn){\n            var httpRequest = new XMLHttpRequest();\n            httpRequest.open('POST', requesturl);\n            httpRequest.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');\n\n            var dateString = new Date().toISOString();\n            var paramString = 'Id=' + encodeURIComponent(self.metadata.urn) + '&PlayedTime=' + encodeURIComponent(dateString) + '&Client=' + self.options.version;\n\n            httpRequest.send(paramString);\n        }\n    }\n\n    function onPlay () {\n        self.player.removeEventListener('play', onPlay);\n        registerView();\n    }\n\n    self.player.addEventListener('resourceReady', onResourceReady);\n};\n\nmodule.exports = psdbUtilities;\n\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/tracking/psdb/PsdbRadioTracking.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/js/tracking/psdb/PsdbTracking.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/js/tracking/psdb/PsdbTracking.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("﻿var psdbUtilities = function(player, options) {\n    var self = this;\n    this.player = player;\n    this.options = options;\n    this.metadata = null;\n\n    function onResourceReady(metadata) {\n        if (typeof metadata === \"undefined\") {\n            if (window.console) console.error('Error: metadata not defined! Aborting PSDB logging');\n            return;\n        }\n\n        self.player.addEvent('play', onPlay);\n\n        self.metadata = metadata;\n    }\n\n    function registerView () {\n        if (!self.metadata) {\n            if (window.console) console.error('Error: metadata not defined! Aborting PSDB logging');\n            return;\n        }\n\n        var requesturl = self.options.url;\n\n        if (window.DR && typeof window.DR.proxyUrl === 'string' && window.DR.proxyUrl.length > 1) {\n            requesturl = window.DR.proxyUrl + encodeURIComponent(requesturl);\n        }\n\n        if(requesturl && self.metadata.urn){\n            var httpRequest = new XMLHttpRequest();\n            httpRequest.open('POST', requesturl);\n            httpRequest.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');\n\n            var paramString = 'Id=' + encodeURIComponent(self.metadata.urn) + '&client=' + self.options.version;\n\n            httpRequest.send(paramString);\n        }\n    }\n\n    function registerLatestViewed () {\n        if (!self.metadata) {\n            if (window.console) console.error('Error: metadata not defined! Aborting PSDB logging');\n            return;\n        }\n\n        if (!self.metadata.sharedKey || self.metadata.sharedKey === undefined)\n            return;\n\n        var requesturl = self.options.latestViewedUrl;\n\n        if (window.DR && typeof window.DR.proxyUrl === 'string' && window.DR.proxyUrl.length > 1) {\n            requesturl = window.DR.proxyUrl + encodeURIComponent(requesturl);\n        }\n\n        if(requesturl && self.metadata.urn){\n            var httpRequest = new XMLHttpRequest();\n            httpRequest.open('POST', requesturl);\n            httpRequest.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');\n\n            var paramString = 'Id=' + encodeURIComponent(self.metadata.urn) + '&Userkey=' + self.metadata.sharedKey;\n\n            httpRequest.send(paramString);\n        }\n    }\n\n    function onPlay () {\n        self.player.removeEvent('play', onPlay);\n\n        registerView();\n\n        if (self.options.registerLatestViewed && self.options.registerLatestViewed === true)\n            registerLatestViewed();\n    }\n\n\n    self.player.addEvent('resourceReady', onResourceReady);\n};\n\nmodule.exports = psdbUtilities;\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/tracking/psdb/PsdbTracking.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/node_modules/script-loader/addScript.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/node_modules/script-loader/addScript.js ***!
  \***************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/*\r\n\tMIT License http://www.opensource.org/licenses/mit-license.php\r\n\tAuthor Tobias Koppers @sokra\r\n*/\r\nmodule.exports = function(src) {\r\n\tif (typeof execScript === \"function\")\r\n\t\texecScript(src);\r\n\telse\r\n\t\teval.call(null, src);\r\n}\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/node_modules/script-loader/addScript.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-media-statistics/node_modules/script-loader/index.js!./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js":
/*!********************************************************************************************************************************************************************!*\
  !*** ./node_modules/@dr/drc-media-statistics/node_modules/script-loader!./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js ***!
  \********************************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("__webpack_require__(/*! !./node_modules/@dr/drc-media-statistics/node_modules/script-loader/addScript.js */ \"./node_modules/@dr/drc-media-statistics/node_modules/script-loader/addScript.js\")(__webpack_require__(/*! !./node_modules/raw-loader!./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js */ \"./node_modules/raw-loader/index.js!./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js\"))\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js?./node_modules/@dr/drc-media-statistics/node_modules/script-loader");

/***/ }),

/***/ "./node_modules/@dr/drc-util/dom/create.js":
/*!*************************************************!*\
  !*** ./node_modules/@dr/drc-util/dom/create.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar doc = document;\nvar selReg = /^([^.#\\[\\s]+|)(#[^.\\[\\s]+|)((?:\\.[^.]+)+|)$/;\nvar collapseReg = /\\./g;\n\nmodule.exports = function (selector, properties, children) {\n\tif (properties){\n\t\tif (Array.isArray(properties)) {\n\t\t\tchildren = properties;\n\t\t\tproperties = null;\n\t\t}\n\t}\n\n\tvar props = typeof selector === \"string\" && selector.match(selReg);\n\tvar element = doc.createElement(props && props[1] || \"div\");\n\tif (props) {\n\n\t\tvar id = props[2];\n\t\tif (id) {\n\t\t\telement.id = id.slice(1);\n\t\t}\n\n\t\tvar className = props[3];\n\t\tif (className) {\n\t\t\telement.className = className.slice(1).replace(collapseReg, \" \");\n\t\t}\n\n\t}\n\n\tif (properties) {\n\t\tfor (var key in properties) {\n\t\t\t// Is this a special case attribute? - deprecate at some point.\n\t\t\tif (key === \"text\") {\n\t\t\t\tif (children) {\n\t\t\t\t\tchildren.unshift(properties[key]);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tchildren = [properties[key]];\n\t\t\t\t}\n\t\t\t}\n\t\t\t// It's a bog standard attribute.\n\t\t\telse {\n\t\t\t\telement.setAttribute(key, properties[key]);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (children) {\n\t\tchildren.forEach(function (child) {\n\t\t\tif (typeof child === \"string\") {\n\t\t\t\tchild = doc.createTextNode(child);\n\t\t\t}\n\t\t\telement.appendChild(child);\n\t\t});\n\t}\n\n\treturn element;\n};\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-util/dom/create.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-util/object/eventtarget.js":
/*!*********************************************************!*\
  !*** ./node_modules/@dr/drc-util/object/eventtarget.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* eslint-env node, browser */\n\n\nmodule.exports = function (obj) {\n\tvar listeners = {};\n\n\tfunction addEventListener(type, listener) {\n\t\tif (!listeners[type]) {\n\t\t\tlisteners[type] = [];\n\t\t}\n\t\tif (listeners[type].indexOf(listener) === -1) {\n\t\t\tlisteners[type].push(listener);\n\t\t}\n\t}\n\n\tfunction removeEventListener(type, listener) {\n\t\tif (listeners[type]) {\n\t\t\tif (listener) {\n\t\t\t\tvar index = listeners[type].indexOf(listener);\n\t\t\t\tif (index > -1) {\n\t\t\t\t\tlisteners[type].splice(index, 1);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlisteners[type].length = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tfunction dispatchEvent(type, data) {\n\t\tif (listeners[type]) {\n\t\t\tvar handle = function(listener) {\n\t\t\t\ttry {\n\t\t\t\t\tlistener.call(obj, data);\n\t\t\t\t} catch(e) {\n\t\t\t\t\tif (console && console.error) {\n\t\t\t\t\t\tconsole.error(e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tlisteners[type].slice().forEach(handle);\n\t\t}\n\t}\n\n\tObject.defineProperties(obj, {\n\t\t\"addEventListener\": {\n\t\t\tvalue: addEventListener\n\t\t},\n\t\t\"removeEventListener\": {\n\t\t\tvalue: removeEventListener\n\t\t},\n\t\t\"dispatchEvent\": {\n\t\t\tvalue: dispatchEvent\n\t\t}\n\t});\n\treturn obj;\n};\n\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-util/object/eventtarget.js?");

/***/ }),

/***/ "./node_modules/@dr/drc-util/object/extend.js":
/*!****************************************************!*\
  !*** ./node_modules/@dr/drc-util/object/extend.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* eslint-env node, browser */\n\n\nmodule.exports = function (target /*, sources... */) {\n\tif (typeof target !== \"object\") {\n\t\tthrow new Error(\"target is not an object\");\n\t}\n\tfor (var i=1;i<arguments.length;i++) {\n\t\tvar source = arguments[i];\n\t\tif (typeof source !== \"object\") {\n\t\t\tthrow new Error(\"source is not an object\");\n\t\t}\n\t\tObject.keys(source).forEach(function(key) {\n\t\t\ttarget[key] = source[key];\n\t\t});\n\t}\n\treturn target;\n};\n\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-util/object/extend.js?");

/***/ }),

/***/ "./node_modules/es6-promise/dist/es6-promise.js":
/*!******************************************************!*\
  !*** ./node_modules/es6-promise/dist/es6-promise.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(process, global) {/*!\n * @overview es6-promise - a tiny implementation of Promises/A+.\n * @copyright Copyright (c) 2014 Yehuda Katz, Tom Dale, Stefan Penner and contributors (Conversion to ES6 API by Jake Archibald)\n * @license   Licensed under MIT license\n *            See https://raw.githubusercontent.com/stefanpenner/es6-promise/master/LICENSE\n * @version   v4.2.4+314e4831\n */\n\n(function (global, factory) {\n\t true ? module.exports = factory() :\n\tundefined;\n}(this, (function () { 'use strict';\n\nfunction objectOrFunction(x) {\n  var type = typeof x;\n  return x !== null && (type === 'object' || type === 'function');\n}\n\nfunction isFunction(x) {\n  return typeof x === 'function';\n}\n\n\n\nvar _isArray = void 0;\nif (Array.isArray) {\n  _isArray = Array.isArray;\n} else {\n  _isArray = function (x) {\n    return Object.prototype.toString.call(x) === '[object Array]';\n  };\n}\n\nvar isArray = _isArray;\n\nvar len = 0;\nvar vertxNext = void 0;\nvar customSchedulerFn = void 0;\n\nvar asap = function asap(callback, arg) {\n  queue[len] = callback;\n  queue[len + 1] = arg;\n  len += 2;\n  if (len === 2) {\n    // If len is 2, that means that we need to schedule an async flush.\n    // If additional callbacks are queued before the queue is flushed, they\n    // will be processed by this flush that we are scheduling.\n    if (customSchedulerFn) {\n      customSchedulerFn(flush);\n    } else {\n      scheduleFlush();\n    }\n  }\n};\n\nfunction setScheduler(scheduleFn) {\n  customSchedulerFn = scheduleFn;\n}\n\nfunction setAsap(asapFn) {\n  asap = asapFn;\n}\n\nvar browserWindow = typeof window !== 'undefined' ? window : undefined;\nvar browserGlobal = browserWindow || {};\nvar BrowserMutationObserver = browserGlobal.MutationObserver || browserGlobal.WebKitMutationObserver;\nvar isNode = typeof self === 'undefined' && typeof process !== 'undefined' && {}.toString.call(process) === '[object process]';\n\n// test for web worker but not in IE10\nvar isWorker = typeof Uint8ClampedArray !== 'undefined' && typeof importScripts !== 'undefined' && typeof MessageChannel !== 'undefined';\n\n// node\nfunction useNextTick() {\n  // node version 0.10.x displays a deprecation warning when nextTick is used recursively\n  // see https://github.com/cujojs/when/issues/410 for details\n  return function () {\n    return process.nextTick(flush);\n  };\n}\n\n// vertx\nfunction useVertxTimer() {\n  if (typeof vertxNext !== 'undefined') {\n    return function () {\n      vertxNext(flush);\n    };\n  }\n\n  return useSetTimeout();\n}\n\nfunction useMutationObserver() {\n  var iterations = 0;\n  var observer = new BrowserMutationObserver(flush);\n  var node = document.createTextNode('');\n  observer.observe(node, { characterData: true });\n\n  return function () {\n    node.data = iterations = ++iterations % 2;\n  };\n}\n\n// web worker\nfunction useMessageChannel() {\n  var channel = new MessageChannel();\n  channel.port1.onmessage = flush;\n  return function () {\n    return channel.port2.postMessage(0);\n  };\n}\n\nfunction useSetTimeout() {\n  // Store setTimeout reference so es6-promise will be unaffected by\n  // other code modifying setTimeout (like sinon.useFakeTimers())\n  var globalSetTimeout = setTimeout;\n  return function () {\n    return globalSetTimeout(flush, 1);\n  };\n}\n\nvar queue = new Array(1000);\nfunction flush() {\n  for (var i = 0; i < len; i += 2) {\n    var callback = queue[i];\n    var arg = queue[i + 1];\n\n    callback(arg);\n\n    queue[i] = undefined;\n    queue[i + 1] = undefined;\n  }\n\n  len = 0;\n}\n\nfunction attemptVertx() {\n  try {\n    var vertx = Function('return this')().require('vertx');\n    vertxNext = vertx.runOnLoop || vertx.runOnContext;\n    return useVertxTimer();\n  } catch (e) {\n    return useSetTimeout();\n  }\n}\n\nvar scheduleFlush = void 0;\n// Decide what async method to use to triggering processing of queued callbacks:\nif (isNode) {\n  scheduleFlush = useNextTick();\n} else if (BrowserMutationObserver) {\n  scheduleFlush = useMutationObserver();\n} else if (isWorker) {\n  scheduleFlush = useMessageChannel();\n} else if (browserWindow === undefined && \"function\" === 'function') {\n  scheduleFlush = attemptVertx();\n} else {\n  scheduleFlush = useSetTimeout();\n}\n\nfunction then(onFulfillment, onRejection) {\n  var parent = this;\n\n  var child = new this.constructor(noop);\n\n  if (child[PROMISE_ID] === undefined) {\n    makePromise(child);\n  }\n\n  var _state = parent._state;\n\n\n  if (_state) {\n    var callback = arguments[_state - 1];\n    asap(function () {\n      return invokeCallback(_state, child, callback, parent._result);\n    });\n  } else {\n    subscribe(parent, child, onFulfillment, onRejection);\n  }\n\n  return child;\n}\n\n/**\n  `Promise.resolve` returns a promise that will become resolved with the\n  passed `value`. It is shorthand for the following:\n\n  ```javascript\n  let promise = new Promise(function(resolve, reject){\n    resolve(1);\n  });\n\n  promise.then(function(value){\n    // value === 1\n  });\n  ```\n\n  Instead of writing the above, your code now simply becomes the following:\n\n  ```javascript\n  let promise = Promise.resolve(1);\n\n  promise.then(function(value){\n    // value === 1\n  });\n  ```\n\n  @method resolve\n  @static\n  @param {Any} value value that the returned promise will be resolved with\n  Useful for tooling.\n  @return {Promise} a promise that will become fulfilled with the given\n  `value`\n*/\nfunction resolve$1(object) {\n  /*jshint validthis:true */\n  var Constructor = this;\n\n  if (object && typeof object === 'object' && object.constructor === Constructor) {\n    return object;\n  }\n\n  var promise = new Constructor(noop);\n  resolve(promise, object);\n  return promise;\n}\n\nvar PROMISE_ID = Math.random().toString(36).substring(2);\n\nfunction noop() {}\n\nvar PENDING = void 0;\nvar FULFILLED = 1;\nvar REJECTED = 2;\n\nvar TRY_CATCH_ERROR = { error: null };\n\nfunction selfFulfillment() {\n  return new TypeError(\"You cannot resolve a promise with itself\");\n}\n\nfunction cannotReturnOwn() {\n  return new TypeError('A promises callback cannot return that same promise.');\n}\n\nfunction getThen(promise) {\n  try {\n    return promise.then;\n  } catch (error) {\n    TRY_CATCH_ERROR.error = error;\n    return TRY_CATCH_ERROR;\n  }\n}\n\nfunction tryThen(then$$1, value, fulfillmentHandler, rejectionHandler) {\n  try {\n    then$$1.call(value, fulfillmentHandler, rejectionHandler);\n  } catch (e) {\n    return e;\n  }\n}\n\nfunction handleForeignThenable(promise, thenable, then$$1) {\n  asap(function (promise) {\n    var sealed = false;\n    var error = tryThen(then$$1, thenable, function (value) {\n      if (sealed) {\n        return;\n      }\n      sealed = true;\n      if (thenable !== value) {\n        resolve(promise, value);\n      } else {\n        fulfill(promise, value);\n      }\n    }, function (reason) {\n      if (sealed) {\n        return;\n      }\n      sealed = true;\n\n      reject(promise, reason);\n    }, 'Settle: ' + (promise._label || ' unknown promise'));\n\n    if (!sealed && error) {\n      sealed = true;\n      reject(promise, error);\n    }\n  }, promise);\n}\n\nfunction handleOwnThenable(promise, thenable) {\n  if (thenable._state === FULFILLED) {\n    fulfill(promise, thenable._result);\n  } else if (thenable._state === REJECTED) {\n    reject(promise, thenable._result);\n  } else {\n    subscribe(thenable, undefined, function (value) {\n      return resolve(promise, value);\n    }, function (reason) {\n      return reject(promise, reason);\n    });\n  }\n}\n\nfunction handleMaybeThenable(promise, maybeThenable, then$$1) {\n  if (maybeThenable.constructor === promise.constructor && then$$1 === then && maybeThenable.constructor.resolve === resolve$1) {\n    handleOwnThenable(promise, maybeThenable);\n  } else {\n    if (then$$1 === TRY_CATCH_ERROR) {\n      reject(promise, TRY_CATCH_ERROR.error);\n      TRY_CATCH_ERROR.error = null;\n    } else if (then$$1 === undefined) {\n      fulfill(promise, maybeThenable);\n    } else if (isFunction(then$$1)) {\n      handleForeignThenable(promise, maybeThenable, then$$1);\n    } else {\n      fulfill(promise, maybeThenable);\n    }\n  }\n}\n\nfunction resolve(promise, value) {\n  if (promise === value) {\n    reject(promise, selfFulfillment());\n  } else if (objectOrFunction(value)) {\n    handleMaybeThenable(promise, value, getThen(value));\n  } else {\n    fulfill(promise, value);\n  }\n}\n\nfunction publishRejection(promise) {\n  if (promise._onerror) {\n    promise._onerror(promise._result);\n  }\n\n  publish(promise);\n}\n\nfunction fulfill(promise, value) {\n  if (promise._state !== PENDING) {\n    return;\n  }\n\n  promise._result = value;\n  promise._state = FULFILLED;\n\n  if (promise._subscribers.length !== 0) {\n    asap(publish, promise);\n  }\n}\n\nfunction reject(promise, reason) {\n  if (promise._state !== PENDING) {\n    return;\n  }\n  promise._state = REJECTED;\n  promise._result = reason;\n\n  asap(publishRejection, promise);\n}\n\nfunction subscribe(parent, child, onFulfillment, onRejection) {\n  var _subscribers = parent._subscribers;\n  var length = _subscribers.length;\n\n\n  parent._onerror = null;\n\n  _subscribers[length] = child;\n  _subscribers[length + FULFILLED] = onFulfillment;\n  _subscribers[length + REJECTED] = onRejection;\n\n  if (length === 0 && parent._state) {\n    asap(publish, parent);\n  }\n}\n\nfunction publish(promise) {\n  var subscribers = promise._subscribers;\n  var settled = promise._state;\n\n  if (subscribers.length === 0) {\n    return;\n  }\n\n  var child = void 0,\n      callback = void 0,\n      detail = promise._result;\n\n  for (var i = 0; i < subscribers.length; i += 3) {\n    child = subscribers[i];\n    callback = subscribers[i + settled];\n\n    if (child) {\n      invokeCallback(settled, child, callback, detail);\n    } else {\n      callback(detail);\n    }\n  }\n\n  promise._subscribers.length = 0;\n}\n\nfunction tryCatch(callback, detail) {\n  try {\n    return callback(detail);\n  } catch (e) {\n    TRY_CATCH_ERROR.error = e;\n    return TRY_CATCH_ERROR;\n  }\n}\n\nfunction invokeCallback(settled, promise, callback, detail) {\n  var hasCallback = isFunction(callback),\n      value = void 0,\n      error = void 0,\n      succeeded = void 0,\n      failed = void 0;\n\n  if (hasCallback) {\n    value = tryCatch(callback, detail);\n\n    if (value === TRY_CATCH_ERROR) {\n      failed = true;\n      error = value.error;\n      value.error = null;\n    } else {\n      succeeded = true;\n    }\n\n    if (promise === value) {\n      reject(promise, cannotReturnOwn());\n      return;\n    }\n  } else {\n    value = detail;\n    succeeded = true;\n  }\n\n  if (promise._state !== PENDING) {\n    // noop\n  } else if (hasCallback && succeeded) {\n    resolve(promise, value);\n  } else if (failed) {\n    reject(promise, error);\n  } else if (settled === FULFILLED) {\n    fulfill(promise, value);\n  } else if (settled === REJECTED) {\n    reject(promise, value);\n  }\n}\n\nfunction initializePromise(promise, resolver) {\n  try {\n    resolver(function resolvePromise(value) {\n      resolve(promise, value);\n    }, function rejectPromise(reason) {\n      reject(promise, reason);\n    });\n  } catch (e) {\n    reject(promise, e);\n  }\n}\n\nvar id = 0;\nfunction nextId() {\n  return id++;\n}\n\nfunction makePromise(promise) {\n  promise[PROMISE_ID] = id++;\n  promise._state = undefined;\n  promise._result = undefined;\n  promise._subscribers = [];\n}\n\nfunction validationError() {\n  return new Error('Array Methods must be provided an Array');\n}\n\nvar Enumerator = function () {\n  function Enumerator(Constructor, input) {\n    this._instanceConstructor = Constructor;\n    this.promise = new Constructor(noop);\n\n    if (!this.promise[PROMISE_ID]) {\n      makePromise(this.promise);\n    }\n\n    if (isArray(input)) {\n      this.length = input.length;\n      this._remaining = input.length;\n\n      this._result = new Array(this.length);\n\n      if (this.length === 0) {\n        fulfill(this.promise, this._result);\n      } else {\n        this.length = this.length || 0;\n        this._enumerate(input);\n        if (this._remaining === 0) {\n          fulfill(this.promise, this._result);\n        }\n      }\n    } else {\n      reject(this.promise, validationError());\n    }\n  }\n\n  Enumerator.prototype._enumerate = function _enumerate(input) {\n    for (var i = 0; this._state === PENDING && i < input.length; i++) {\n      this._eachEntry(input[i], i);\n    }\n  };\n\n  Enumerator.prototype._eachEntry = function _eachEntry(entry, i) {\n    var c = this._instanceConstructor;\n    var resolve$$1 = c.resolve;\n\n\n    if (resolve$$1 === resolve$1) {\n      var _then = getThen(entry);\n\n      if (_then === then && entry._state !== PENDING) {\n        this._settledAt(entry._state, i, entry._result);\n      } else if (typeof _then !== 'function') {\n        this._remaining--;\n        this._result[i] = entry;\n      } else if (c === Promise$1) {\n        var promise = new c(noop);\n        handleMaybeThenable(promise, entry, _then);\n        this._willSettleAt(promise, i);\n      } else {\n        this._willSettleAt(new c(function (resolve$$1) {\n          return resolve$$1(entry);\n        }), i);\n      }\n    } else {\n      this._willSettleAt(resolve$$1(entry), i);\n    }\n  };\n\n  Enumerator.prototype._settledAt = function _settledAt(state, i, value) {\n    var promise = this.promise;\n\n\n    if (promise._state === PENDING) {\n      this._remaining--;\n\n      if (state === REJECTED) {\n        reject(promise, value);\n      } else {\n        this._result[i] = value;\n      }\n    }\n\n    if (this._remaining === 0) {\n      fulfill(promise, this._result);\n    }\n  };\n\n  Enumerator.prototype._willSettleAt = function _willSettleAt(promise, i) {\n    var enumerator = this;\n\n    subscribe(promise, undefined, function (value) {\n      return enumerator._settledAt(FULFILLED, i, value);\n    }, function (reason) {\n      return enumerator._settledAt(REJECTED, i, reason);\n    });\n  };\n\n  return Enumerator;\n}();\n\n/**\n  `Promise.all` accepts an array of promises, and returns a new promise which\n  is fulfilled with an array of fulfillment values for the passed promises, or\n  rejected with the reason of the first passed promise to be rejected. It casts all\n  elements of the passed iterable to promises as it runs this algorithm.\n\n  Example:\n\n  ```javascript\n  let promise1 = resolve(1);\n  let promise2 = resolve(2);\n  let promise3 = resolve(3);\n  let promises = [ promise1, promise2, promise3 ];\n\n  Promise.all(promises).then(function(array){\n    // The array here would be [ 1, 2, 3 ];\n  });\n  ```\n\n  If any of the `promises` given to `all` are rejected, the first promise\n  that is rejected will be given as an argument to the returned promises's\n  rejection handler. For example:\n\n  Example:\n\n  ```javascript\n  let promise1 = resolve(1);\n  let promise2 = reject(new Error(\"2\"));\n  let promise3 = reject(new Error(\"3\"));\n  let promises = [ promise1, promise2, promise3 ];\n\n  Promise.all(promises).then(function(array){\n    // Code here never runs because there are rejected promises!\n  }, function(error) {\n    // error.message === \"2\"\n  });\n  ```\n\n  @method all\n  @static\n  @param {Array} entries array of promises\n  @param {String} label optional string for labeling the promise.\n  Useful for tooling.\n  @return {Promise} promise that is fulfilled when all `promises` have been\n  fulfilled, or rejected if any of them become rejected.\n  @static\n*/\nfunction all(entries) {\n  return new Enumerator(this, entries).promise;\n}\n\n/**\n  `Promise.race` returns a new promise which is settled in the same way as the\n  first passed promise to settle.\n\n  Example:\n\n  ```javascript\n  let promise1 = new Promise(function(resolve, reject){\n    setTimeout(function(){\n      resolve('promise 1');\n    }, 200);\n  });\n\n  let promise2 = new Promise(function(resolve, reject){\n    setTimeout(function(){\n      resolve('promise 2');\n    }, 100);\n  });\n\n  Promise.race([promise1, promise2]).then(function(result){\n    // result === 'promise 2' because it was resolved before promise1\n    // was resolved.\n  });\n  ```\n\n  `Promise.race` is deterministic in that only the state of the first\n  settled promise matters. For example, even if other promises given to the\n  `promises` array argument are resolved, but the first settled promise has\n  become rejected before the other promises became fulfilled, the returned\n  promise will become rejected:\n\n  ```javascript\n  let promise1 = new Promise(function(resolve, reject){\n    setTimeout(function(){\n      resolve('promise 1');\n    }, 200);\n  });\n\n  let promise2 = new Promise(function(resolve, reject){\n    setTimeout(function(){\n      reject(new Error('promise 2'));\n    }, 100);\n  });\n\n  Promise.race([promise1, promise2]).then(function(result){\n    // Code here never runs\n  }, function(reason){\n    // reason.message === 'promise 2' because promise 2 became rejected before\n    // promise 1 became fulfilled\n  });\n  ```\n\n  An example real-world use case is implementing timeouts:\n\n  ```javascript\n  Promise.race([ajax('foo.json'), timeout(5000)])\n  ```\n\n  @method race\n  @static\n  @param {Array} promises array of promises to observe\n  Useful for tooling.\n  @return {Promise} a promise which settles in the same way as the first passed\n  promise to settle.\n*/\nfunction race(entries) {\n  /*jshint validthis:true */\n  var Constructor = this;\n\n  if (!isArray(entries)) {\n    return new Constructor(function (_, reject) {\n      return reject(new TypeError('You must pass an array to race.'));\n    });\n  } else {\n    return new Constructor(function (resolve, reject) {\n      var length = entries.length;\n      for (var i = 0; i < length; i++) {\n        Constructor.resolve(entries[i]).then(resolve, reject);\n      }\n    });\n  }\n}\n\n/**\n  `Promise.reject` returns a promise rejected with the passed `reason`.\n  It is shorthand for the following:\n\n  ```javascript\n  let promise = new Promise(function(resolve, reject){\n    reject(new Error('WHOOPS'));\n  });\n\n  promise.then(function(value){\n    // Code here doesn't run because the promise is rejected!\n  }, function(reason){\n    // reason.message === 'WHOOPS'\n  });\n  ```\n\n  Instead of writing the above, your code now simply becomes the following:\n\n  ```javascript\n  let promise = Promise.reject(new Error('WHOOPS'));\n\n  promise.then(function(value){\n    // Code here doesn't run because the promise is rejected!\n  }, function(reason){\n    // reason.message === 'WHOOPS'\n  });\n  ```\n\n  @method reject\n  @static\n  @param {Any} reason value that the returned promise will be rejected with.\n  Useful for tooling.\n  @return {Promise} a promise rejected with the given `reason`.\n*/\nfunction reject$1(reason) {\n  /*jshint validthis:true */\n  var Constructor = this;\n  var promise = new Constructor(noop);\n  reject(promise, reason);\n  return promise;\n}\n\nfunction needsResolver() {\n  throw new TypeError('You must pass a resolver function as the first argument to the promise constructor');\n}\n\nfunction needsNew() {\n  throw new TypeError(\"Failed to construct 'Promise': Please use the 'new' operator, this object constructor cannot be called as a function.\");\n}\n\n/**\n  Promise objects represent the eventual result of an asynchronous operation. The\n  primary way of interacting with a promise is through its `then` method, which\n  registers callbacks to receive either a promise's eventual value or the reason\n  why the promise cannot be fulfilled.\n\n  Terminology\n  -----------\n\n  - `promise` is an object or function with a `then` method whose behavior conforms to this specification.\n  - `thenable` is an object or function that defines a `then` method.\n  - `value` is any legal JavaScript value (including undefined, a thenable, or a promise).\n  - `exception` is a value that is thrown using the throw statement.\n  - `reason` is a value that indicates why a promise was rejected.\n  - `settled` the final resting state of a promise, fulfilled or rejected.\n\n  A promise can be in one of three states: pending, fulfilled, or rejected.\n\n  Promises that are fulfilled have a fulfillment value and are in the fulfilled\n  state.  Promises that are rejected have a rejection reason and are in the\n  rejected state.  A fulfillment value is never a thenable.\n\n  Promises can also be said to *resolve* a value.  If this value is also a\n  promise, then the original promise's settled state will match the value's\n  settled state.  So a promise that *resolves* a promise that rejects will\n  itself reject, and a promise that *resolves* a promise that fulfills will\n  itself fulfill.\n\n\n  Basic Usage:\n  ------------\n\n  ```js\n  let promise = new Promise(function(resolve, reject) {\n    // on success\n    resolve(value);\n\n    // on failure\n    reject(reason);\n  });\n\n  promise.then(function(value) {\n    // on fulfillment\n  }, function(reason) {\n    // on rejection\n  });\n  ```\n\n  Advanced Usage:\n  ---------------\n\n  Promises shine when abstracting away asynchronous interactions such as\n  `XMLHttpRequest`s.\n\n  ```js\n  function getJSON(url) {\n    return new Promise(function(resolve, reject){\n      let xhr = new XMLHttpRequest();\n\n      xhr.open('GET', url);\n      xhr.onreadystatechange = handler;\n      xhr.responseType = 'json';\n      xhr.setRequestHeader('Accept', 'application/json');\n      xhr.send();\n\n      function handler() {\n        if (this.readyState === this.DONE) {\n          if (this.status === 200) {\n            resolve(this.response);\n          } else {\n            reject(new Error('getJSON: `' + url + '` failed with status: [' + this.status + ']'));\n          }\n        }\n      };\n    });\n  }\n\n  getJSON('/posts.json').then(function(json) {\n    // on fulfillment\n  }, function(reason) {\n    // on rejection\n  });\n  ```\n\n  Unlike callbacks, promises are great composable primitives.\n\n  ```js\n  Promise.all([\n    getJSON('/posts'),\n    getJSON('/comments')\n  ]).then(function(values){\n    values[0] // => postsJSON\n    values[1] // => commentsJSON\n\n    return values;\n  });\n  ```\n\n  @class Promise\n  @param {Function} resolver\n  Useful for tooling.\n  @constructor\n*/\n\nvar Promise$1 = function () {\n  function Promise(resolver) {\n    this[PROMISE_ID] = nextId();\n    this._result = this._state = undefined;\n    this._subscribers = [];\n\n    if (noop !== resolver) {\n      typeof resolver !== 'function' && needsResolver();\n      this instanceof Promise ? initializePromise(this, resolver) : needsNew();\n    }\n  }\n\n  /**\n  The primary way of interacting with a promise is through its `then` method,\n  which registers callbacks to receive either a promise's eventual value or the\n  reason why the promise cannot be fulfilled.\n   ```js\n  findUser().then(function(user){\n    // user is available\n  }, function(reason){\n    // user is unavailable, and you are given the reason why\n  });\n  ```\n   Chaining\n  --------\n   The return value of `then` is itself a promise.  This second, 'downstream'\n  promise is resolved with the return value of the first promise's fulfillment\n  or rejection handler, or rejected if the handler throws an exception.\n   ```js\n  findUser().then(function (user) {\n    return user.name;\n  }, function (reason) {\n    return 'default name';\n  }).then(function (userName) {\n    // If `findUser` fulfilled, `userName` will be the user's name, otherwise it\n    // will be `'default name'`\n  });\n   findUser().then(function (user) {\n    throw new Error('Found user, but still unhappy');\n  }, function (reason) {\n    throw new Error('`findUser` rejected and we're unhappy');\n  }).then(function (value) {\n    // never reached\n  }, function (reason) {\n    // if `findUser` fulfilled, `reason` will be 'Found user, but still unhappy'.\n    // If `findUser` rejected, `reason` will be '`findUser` rejected and we're unhappy'.\n  });\n  ```\n  If the downstream promise does not specify a rejection handler, rejection reasons will be propagated further downstream.\n   ```js\n  findUser().then(function (user) {\n    throw new PedagogicalException('Upstream error');\n  }).then(function (value) {\n    // never reached\n  }).then(function (value) {\n    // never reached\n  }, function (reason) {\n    // The `PedgagocialException` is propagated all the way down to here\n  });\n  ```\n   Assimilation\n  ------------\n   Sometimes the value you want to propagate to a downstream promise can only be\n  retrieved asynchronously. This can be achieved by returning a promise in the\n  fulfillment or rejection handler. The downstream promise will then be pending\n  until the returned promise is settled. This is called *assimilation*.\n   ```js\n  findUser().then(function (user) {\n    return findCommentsByAuthor(user);\n  }).then(function (comments) {\n    // The user's comments are now available\n  });\n  ```\n   If the assimliated promise rejects, then the downstream promise will also reject.\n   ```js\n  findUser().then(function (user) {\n    return findCommentsByAuthor(user);\n  }).then(function (comments) {\n    // If `findCommentsByAuthor` fulfills, we'll have the value here\n  }, function (reason) {\n    // If `findCommentsByAuthor` rejects, we'll have the reason here\n  });\n  ```\n   Simple Example\n  --------------\n   Synchronous Example\n   ```javascript\n  let result;\n   try {\n    result = findResult();\n    // success\n  } catch(reason) {\n    // failure\n  }\n  ```\n   Errback Example\n   ```js\n  findResult(function(result, err){\n    if (err) {\n      // failure\n    } else {\n      // success\n    }\n  });\n  ```\n   Promise Example;\n   ```javascript\n  findResult().then(function(result){\n    // success\n  }, function(reason){\n    // failure\n  });\n  ```\n   Advanced Example\n  --------------\n   Synchronous Example\n   ```javascript\n  let author, books;\n   try {\n    author = findAuthor();\n    books  = findBooksByAuthor(author);\n    // success\n  } catch(reason) {\n    // failure\n  }\n  ```\n   Errback Example\n   ```js\n   function foundBooks(books) {\n   }\n   function failure(reason) {\n   }\n   findAuthor(function(author, err){\n    if (err) {\n      failure(err);\n      // failure\n    } else {\n      try {\n        findBoooksByAuthor(author, function(books, err) {\n          if (err) {\n            failure(err);\n          } else {\n            try {\n              foundBooks(books);\n            } catch(reason) {\n              failure(reason);\n            }\n          }\n        });\n      } catch(error) {\n        failure(err);\n      }\n      // success\n    }\n  });\n  ```\n   Promise Example;\n   ```javascript\n  findAuthor().\n    then(findBooksByAuthor).\n    then(function(books){\n      // found books\n  }).catch(function(reason){\n    // something went wrong\n  });\n  ```\n   @method then\n  @param {Function} onFulfilled\n  @param {Function} onRejected\n  Useful for tooling.\n  @return {Promise}\n  */\n\n  /**\n  `catch` is simply sugar for `then(undefined, onRejection)` which makes it the same\n  as the catch block of a try/catch statement.\n  ```js\n  function findAuthor(){\n  throw new Error('couldn't find that author');\n  }\n  // synchronous\n  try {\n  findAuthor();\n  } catch(reason) {\n  // something went wrong\n  }\n  // async with promises\n  findAuthor().catch(function(reason){\n  // something went wrong\n  });\n  ```\n  @method catch\n  @param {Function} onRejection\n  Useful for tooling.\n  @return {Promise}\n  */\n\n\n  Promise.prototype.catch = function _catch(onRejection) {\n    return this.then(null, onRejection);\n  };\n\n  /**\n    `finally` will be invoked regardless of the promise's fate just as native\n    try/catch/finally behaves\n  \n    Synchronous example:\n  \n    ```js\n    findAuthor() {\n      if (Math.random() > 0.5) {\n        throw new Error();\n      }\n      return new Author();\n    }\n  \n    try {\n      return findAuthor(); // succeed or fail\n    } catch(error) {\n      return findOtherAuther();\n    } finally {\n      // always runs\n      // doesn't affect the return value\n    }\n    ```\n  \n    Asynchronous example:\n  \n    ```js\n    findAuthor().catch(function(reason){\n      return findOtherAuther();\n    }).finally(function(){\n      // author was either found, or not\n    });\n    ```\n  \n    @method finally\n    @param {Function} callback\n    @return {Promise}\n  */\n\n\n  Promise.prototype.finally = function _finally(callback) {\n    var promise = this;\n    var constructor = promise.constructor;\n\n    return promise.then(function (value) {\n      return constructor.resolve(callback()).then(function () {\n        return value;\n      });\n    }, function (reason) {\n      return constructor.resolve(callback()).then(function () {\n        throw reason;\n      });\n    });\n  };\n\n  return Promise;\n}();\n\nPromise$1.prototype.then = then;\nPromise$1.all = all;\nPromise$1.race = race;\nPromise$1.resolve = resolve$1;\nPromise$1.reject = reject$1;\nPromise$1._setScheduler = setScheduler;\nPromise$1._setAsap = setAsap;\nPromise$1._asap = asap;\n\n/*global self*/\nfunction polyfill() {\n  var local = void 0;\n\n  if (typeof global !== 'undefined') {\n    local = global;\n  } else if (typeof self !== 'undefined') {\n    local = self;\n  } else {\n    try {\n      local = Function('return this')();\n    } catch (e) {\n      throw new Error('polyfill failed because global object is unavailable in this environment');\n    }\n  }\n\n  var P = local.Promise;\n\n  if (P) {\n    var promiseToString = null;\n    try {\n      promiseToString = Object.prototype.toString.call(P.resolve());\n    } catch (e) {\n      // silently ignored\n    }\n\n    if (promiseToString === '[object Promise]' && !P.cast) {\n      return;\n    }\n  }\n\n  local.Promise = Promise$1;\n}\n\n// Strange compat..\nPromise$1.polyfill = polyfill;\nPromise$1.Promise = Promise$1;\n\nreturn Promise$1;\n\n})));\n\n\n\n//# sourceMappingURL=es6-promise.map\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\"), __webpack_require__(/*! ./../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/es6-promise/dist/es6-promise.js?");

/***/ }),

/***/ "./node_modules/hls.js/dist/hls.js":
/*!*****************************************!*\
  !*** ./node_modules/hls.js/dist/hls.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("(function webpackUniversalModuleDefinition(root, factory) {\n\tif(true)\n\t\tmodule.exports = factory();\n\telse {}\n})(typeof self !== 'undefined' ? self : this, function() {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"/dist/\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = 9);\n/******/ })\n/************************************************************************/\n/******/ ([\n/* 0 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return enableLogs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return logger; });\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\nfunction noop() {}\n\nvar fakeLogger = {\n  trace: noop,\n  debug: noop,\n  log: noop,\n  warn: noop,\n  info: noop,\n  error: noop\n};\n\nvar exportedLogger = fakeLogger;\n\n/* globals self: false */\n\n// let lastCallTime;\n// function formatMsgWithTimeInfo(type, msg) {\n//   const now = Date.now();\n//   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';\n//   lastCallTime = now;\n//   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';\n//   return msg;\n// }\n\nfunction formatMsg(type, msg) {\n  msg = '[' + type + '] > ' + msg;\n  return msg;\n}\n\nfunction consolePrintFn(type) {\n  var func = self.console[type];\n  if (func) {\n    return function () {\n      for (var _len = arguments.length, args = Array(_len), _key = 0; _key < _len; _key++) {\n        args[_key] = arguments[_key];\n      }\n\n      if (args[0]) args[0] = formatMsg(type, args[0]);\n\n      func.apply(self.console, args);\n    };\n  }\n  return noop;\n}\n\nfunction exportLoggerFunctions(debugConfig) {\n  for (var _len2 = arguments.length, functions = Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n    functions[_key2 - 1] = arguments[_key2];\n  }\n\n  functions.forEach(function (type) {\n    exportedLogger[type] = debugConfig[type] ? debugConfig[type].bind(debugConfig) : consolePrintFn(type);\n  });\n}\n\nvar enableLogs = function enableLogs(debugConfig) {\n  if (debugConfig === true || (typeof debugConfig === 'undefined' ? 'undefined' : _typeof(debugConfig)) === 'object') {\n    exportLoggerFunctions(debugConfig,\n    // Remove out from list here to hard-disable a log-level\n    // 'trace',\n    'debug', 'log', 'info', 'warn', 'error');\n    // Some browsers don't allow to use bind on console object anyway\n    // fallback to default if needed\n    try {\n      exportedLogger.log();\n    } catch (e) {\n      exportedLogger = fakeLogger;\n    }\n  } else {\n    exportedLogger = fakeLogger;\n  }\n};\n\nvar logger = exportedLogger;\n\n/***/ }),\n/* 1 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/**\n * @readonly\n * @enum {string}\n */\nvar HlsEvents = {\n  // fired before MediaSource is attaching to media element - data: { media }\n  MEDIA_ATTACHING: 'hlsMediaAttaching',\n  // fired when MediaSource has been succesfully attached to media element - data: { }\n  MEDIA_ATTACHED: 'hlsMediaAttached',\n  // fired before detaching MediaSource from media element - data: { }\n  MEDIA_DETACHING: 'hlsMediaDetaching',\n  // fired when MediaSource has been detached from media element - data: { }\n  MEDIA_DETACHED: 'hlsMediaDetached',\n  // fired when we buffer is going to be reset - data: { }\n  BUFFER_RESET: 'hlsBufferReset',\n  // fired when we know about the codecs that we need buffers for to push into - data: {tracks : { container, codec, levelCodec, initSegment, metadata }}\n  BUFFER_CODECS: 'hlsBufferCodecs',\n  // fired when sourcebuffers have been created - data: { tracks : tracks }\n  BUFFER_CREATED: 'hlsBufferCreated',\n  // fired when we append a segment to the buffer - data: { segment: segment object }\n  BUFFER_APPENDING: 'hlsBufferAppending',\n  // fired when we are done with appending a media segment to the buffer - data : { parent : segment parent that triggered BUFFER_APPENDING, pending : nb of segments waiting for appending for this segment parent}\n  BUFFER_APPENDED: 'hlsBufferAppended',\n  // fired when the stream is finished and we want to notify the media buffer that there will be no more data - data: { }\n  BUFFER_EOS: 'hlsBufferEos',\n  // fired when the media buffer should be flushed - data { startOffset, endOffset }\n  BUFFER_FLUSHING: 'hlsBufferFlushing',\n  // fired when the media buffer has been flushed - data: { }\n  BUFFER_FLUSHED: 'hlsBufferFlushed',\n  // fired to signal that a manifest loading starts - data: { url : manifestURL}\n  MANIFEST_LOADING: 'hlsManifestLoading',\n  // fired after manifest has been loaded - data: { levels : [available quality levels], audioTracks : [ available audio tracks], url : manifestURL, stats : { trequest, tfirst, tload, mtime}}\n  MANIFEST_LOADED: 'hlsManifestLoaded',\n  // fired after manifest has been parsed - data: { levels : [available quality levels], firstLevel : index of first quality level appearing in Manifest}\n  MANIFEST_PARSED: 'hlsManifestParsed',\n  // fired when a level switch is requested - data: { level : id of new level }\n  LEVEL_SWITCHING: 'hlsLevelSwitching',\n  // fired when a level switch is effective - data: { level : id of new level }\n  LEVEL_SWITCHED: 'hlsLevelSwitched',\n  // fired when a level playlist loading starts - data: { url : level URL, level : id of level being loaded}\n  LEVEL_LOADING: 'hlsLevelLoading',\n  // fired when a level playlist loading finishes - data: { details : levelDetails object, level : id of loaded level, stats : { trequest, tfirst, tload, mtime} }\n  LEVEL_LOADED: 'hlsLevelLoaded',\n  // fired when a level's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, level : id of updated level }\n  LEVEL_UPDATED: 'hlsLevelUpdated',\n  // fired when a level's PTS information has been updated after parsing a fragment - data: { details : levelDetails object, level : id of updated level, drift: PTS drift observed when parsing last fragment }\n  LEVEL_PTS_UPDATED: 'hlsLevelPtsUpdated',\n  // fired to notify that audio track lists has been updated - data: { audioTracks : audioTracks }\n  AUDIO_TRACKS_UPDATED: 'hlsAudioTracksUpdated',\n  // fired when an audio track switching is requested - data: { id : audio track id }\n  AUDIO_TRACK_SWITCHING: 'hlsAudioTrackSwitching',\n  // fired when an audio track switch actually occurs - data: { id : audio track id }\n  AUDIO_TRACK_SWITCHED: 'hlsAudioTrackSwitched',\n  // fired when an audio track loading starts - data: { url : audio track URL, id : audio track id }\n  AUDIO_TRACK_LOADING: 'hlsAudioTrackLoading',\n  // fired when an audio track loading finishes - data: { details : levelDetails object, id : audio track id, stats : { trequest, tfirst, tload, mtime } }\n  AUDIO_TRACK_LOADED: 'hlsAudioTrackLoaded',\n  // fired to notify that subtitle track lists has been updated - data: { subtitleTracks : subtitleTracks }\n  SUBTITLE_TRACKS_UPDATED: 'hlsSubtitleTracksUpdated',\n  // fired when an subtitle track switch occurs - data: { id : subtitle track id }\n  SUBTITLE_TRACK_SWITCH: 'hlsSubtitleTrackSwitch',\n  // fired when a subtitle track loading starts - data: { url : subtitle track URL, id : subtitle track id }\n  SUBTITLE_TRACK_LOADING: 'hlsSubtitleTrackLoading',\n  // fired when a subtitle track loading finishes - data: { details : levelDetails object, id : subtitle track id, stats : { trequest, tfirst, tload, mtime } }\n  SUBTITLE_TRACK_LOADED: 'hlsSubtitleTrackLoaded',\n  // fired when a subtitle fragment has been processed - data: { success : boolean, frag : the processed frag }\n  SUBTITLE_FRAG_PROCESSED: 'hlsSubtitleFragProcessed',\n  // fired when the first timestamp is found - data: { id : demuxer id, initPTS: initPTS, frag : fragment object }\n  INIT_PTS_FOUND: 'hlsInitPtsFound',\n  // fired when a fragment loading starts - data: { frag : fragment object }\n  FRAG_LOADING: 'hlsFragLoading',\n  // fired when a fragment loading is progressing - data: { frag : fragment object, { trequest, tfirst, loaded } }\n  FRAG_LOAD_PROGRESS: 'hlsFragLoadProgress',\n  // Identifier for fragment load aborting for emergency switch down - data: { frag : fragment object }\n  FRAG_LOAD_EMERGENCY_ABORTED: 'hlsFragLoadEmergencyAborted',\n  // fired when a fragment loading is completed - data: { frag : fragment object, payload : fragment payload, stats : { trequest, tfirst, tload, length } }\n  FRAG_LOADED: 'hlsFragLoaded',\n  // fired when a fragment has finished decrypting - data: { id : demuxer id, frag: fragment object, payload : fragment payload, stats : { tstart, tdecrypt } }\n  FRAG_DECRYPTED: 'hlsFragDecrypted',\n  // fired when Init Segment has been extracted from fragment - data: { id : demuxer id, frag: fragment object, moov : moov MP4 box, codecs : codecs found while parsing fragment }\n  FRAG_PARSING_INIT_SEGMENT: 'hlsFragParsingInitSegment',\n  // fired when parsing sei text is completed - data: { id : demuxer id, frag: fragment object, samples : [ sei samples pes ] }\n  FRAG_PARSING_USERDATA: 'hlsFragParsingUserdata',\n  // fired when parsing id3 is completed - data: { id : demuxer id, frag: fragment object, samples : [ id3 samples pes ] }\n  FRAG_PARSING_METADATA: 'hlsFragParsingMetadata',\n  // fired when data have been extracted from fragment - data: { id : demuxer id, frag: fragment object, data1 : moof MP4 box or TS fragments, data2 : mdat MP4 box or null}\n  FRAG_PARSING_DATA: 'hlsFragParsingData',\n  // fired when fragment parsing is completed - data: { id : demuxer id, frag: fragment object }\n  FRAG_PARSED: 'hlsFragParsed',\n  // fired when fragment remuxed MP4 boxes have all been appended into SourceBuffer - data: { id : demuxer id, frag : fragment object, stats : { trequest, tfirst, tload, tparsed, tbuffered, length, bwEstimate } }\n  FRAG_BUFFERED: 'hlsFragBuffered',\n  // fired when fragment matching with current media position is changing - data : { id : demuxer id, frag : fragment object }\n  FRAG_CHANGED: 'hlsFragChanged',\n  // Identifier for a FPS drop event - data: { curentDropped, currentDecoded, totalDroppedFrames }\n  FPS_DROP: 'hlsFpsDrop',\n  // triggered when FPS drop triggers auto level capping - data: { level, droppedlevel }\n  FPS_DROP_LEVEL_CAPPING: 'hlsFpsDropLevelCapping',\n  // Identifier for an error event - data: { type : error type, details : error details, fatal : if true, hls.js cannot/will not try to recover, if false, hls.js will try to recover,other error specific data }\n  ERROR: 'hlsError',\n  // fired when hls.js instance starts destroying. Different from MEDIA_DETACHED as one could want to detach and reattach a media to the instance of hls.js to handle mid-rolls for example - data: { }\n  DESTROYING: 'hlsDestroying',\n  // fired when a decrypt key loading starts - data: { frag : fragment object }\n  KEY_LOADING: 'hlsKeyLoading',\n  // fired when a decrypt key loading is completed - data: { frag : fragment object, payload : key payload, stats : { trequest, tfirst, tload, length } }\n  KEY_LOADED: 'hlsKeyLoaded',\n  // fired upon stream controller state transitions - data: { previousState, nextState }\n  STREAM_STATE_TRANSITION: 'hlsStreamStateTransition'\n};\n/* harmony default export */ __webpack_exports__[\"a\"] = (HlsEvents);\n\n/***/ }),\n/* 2 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return ErrorTypes; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return ErrorDetails; });\nvar ErrorTypes = {\n  // Identifier for a network error (loading error / timeout ...)\n  NETWORK_ERROR: 'networkError',\n  // Identifier for a media Error (video/parsing/mediasource error)\n  MEDIA_ERROR: 'mediaError',\n  // EME (encrypted media extensions) errors\n  KEY_SYSTEM_ERROR: 'keySystemError',\n  // Identifier for a mux Error (demuxing/remuxing)\n  MUX_ERROR: 'muxError',\n  // Identifier for all other errors\n  OTHER_ERROR: 'otherError'\n};\n\n/**\n * @enum {ErrorDetails}\n * @typedef {string} ErrorDetail\n */\nvar ErrorDetails = {\n  KEY_SYSTEM_NO_KEYS: 'keySystemNoKeys',\n  KEY_SYSTEM_NO_ACCESS: 'keySystemNoAccess',\n  KEY_SYSTEM_NO_SESSION: 'keySystemNoSession',\n  KEY_SYSTEM_LICENSE_REQUEST_FAILED: 'keySystemLicenseRequestFailed',\n  // Identifier for a manifest load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  MANIFEST_LOAD_ERROR: 'manifestLoadError',\n  // Identifier for a manifest load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  MANIFEST_LOAD_TIMEOUT: 'manifestLoadTimeOut',\n  // Identifier for a manifest parsing error - data: { url : faulty URL, reason : error reason}\n  MANIFEST_PARSING_ERROR: 'manifestParsingError',\n  // Identifier for a manifest with only incompatible codecs error - data: { url : faulty URL, reason : error reason}\n  MANIFEST_INCOMPATIBLE_CODECS_ERROR: 'manifestIncompatibleCodecsError',\n  // Identifier for a level load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  LEVEL_LOAD_ERROR: 'levelLoadError',\n  // Identifier for a level load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  LEVEL_LOAD_TIMEOUT: 'levelLoadTimeOut',\n  // Identifier for a level switch error - data: { level : faulty level Id, event : error description}\n  LEVEL_SWITCH_ERROR: 'levelSwitchError',\n  // Identifier for an audio track load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  AUDIO_TRACK_LOAD_ERROR: 'audioTrackLoadError',\n  // Identifier for an audio track load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  AUDIO_TRACK_LOAD_TIMEOUT: 'audioTrackLoadTimeOut',\n  // Identifier for fragment load error - data: { frag : fragment object, response : { code: error code, text: error text }}\n  FRAG_LOAD_ERROR: 'fragLoadError',\n  // Identifier for fragment load timeout error - data: { frag : fragment object}\n  FRAG_LOAD_TIMEOUT: 'fragLoadTimeOut',\n  // Identifier for a fragment decryption error event - data: {id : demuxer Id,frag: fragment object, reason : parsing error description }\n  FRAG_DECRYPT_ERROR: 'fragDecryptError',\n  // Identifier for a fragment parsing error event - data: { id : demuxer Id, reason : parsing error description }\n  // will be renamed DEMUX_PARSING_ERROR and switched to MUX_ERROR in the next major release\n  FRAG_PARSING_ERROR: 'fragParsingError',\n  // Identifier for a remux alloc error event - data: { id : demuxer Id, frag : fragment object, bytes : nb of bytes on which allocation failed , reason : error text }\n  REMUX_ALLOC_ERROR: 'remuxAllocError',\n  // Identifier for decrypt key load error - data: { frag : fragment object, response : { code: error code, text: error text }}\n  KEY_LOAD_ERROR: 'keyLoadError',\n  // Identifier for decrypt key load timeout error - data: { frag : fragment object}\n  KEY_LOAD_TIMEOUT: 'keyLoadTimeOut',\n  // Triggered when an exception occurs while adding a sourceBuffer to MediaSource - data : {  err : exception , mimeType : mimeType }\n  BUFFER_ADD_CODEC_ERROR: 'bufferAddCodecError',\n  // Identifier for a buffer append error - data: append error description\n  BUFFER_APPEND_ERROR: 'bufferAppendError',\n  // Identifier for a buffer appending error event - data: appending error description\n  BUFFER_APPENDING_ERROR: 'bufferAppendingError',\n  // Identifier for a buffer stalled error event\n  BUFFER_STALLED_ERROR: 'bufferStalledError',\n  // Identifier for a buffer full event\n  BUFFER_FULL_ERROR: 'bufferFullError',\n  // Identifier for a buffer seek over hole event\n  BUFFER_SEEK_OVER_HOLE: 'bufferSeekOverHole',\n  // Identifier for a buffer nudge on stall (playback is stuck although currentTime is in a buffered area)\n  BUFFER_NUDGE_ON_STALL: 'bufferNudgeOnStall',\n  // Identifier for an internal exception happening inside hls.js while handling an event\n  INTERNAL_EXCEPTION: 'internalException'\n};\n\n/***/ }),\n/* 3 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// see https://tools.ietf.org/html/rfc1808\r\n\r\n/* jshint ignore:start */\r\n(function(root) { \r\n/* jshint ignore:end */\r\n\r\n  var URL_REGEX = /^((?:[a-zA-Z0-9+\\-.]+:)?)(\\/\\/[^\\/\\;?#]*)?(.*?)??(;.*?)?(\\?.*?)?(#.*?)?$/;\r\n  var FIRST_SEGMENT_REGEX = /^([^\\/;?#]*)(.*)$/;\r\n  var SLASH_DOT_REGEX = /(?:\\/|^)\\.(?=\\/)/g;\r\n  var SLASH_DOT_DOT_REGEX = /(?:\\/|^)\\.\\.\\/(?!\\.\\.\\/).*?(?=\\/)/g;\r\n\r\n  var URLToolkit = { // jshint ignore:line\r\n    // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //\r\n    // E.g\r\n    // With opts.alwaysNormalize = false (default, spec compliant)\r\n    // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g\r\n    // With opts.alwaysNormalize = true (not spec compliant)\r\n    // http://a.com/b/cd + /e/f/../g => http://a.com/e/g\r\n    buildAbsoluteURL: function(baseURL, relativeURL, opts) {\r\n      opts = opts || {};\r\n      // remove any remaining space and CRLF\r\n      baseURL = baseURL.trim();\r\n      relativeURL = relativeURL.trim();\r\n      if (!relativeURL) {\r\n        // 2a) If the embedded URL is entirely empty, it inherits the\r\n        // entire base URL (i.e., is set equal to the base URL)\r\n        // and we are done.\r\n        if (!opts.alwaysNormalize) {\r\n          return baseURL;\r\n        }\r\n        var basePartsForNormalise = URLToolkit.parseURL(baseURL);\r\n        if (!basePartsForNormalise) {\r\n          throw new Error('Error trying to parse base URL.');\r\n        }\r\n        basePartsForNormalise.path = URLToolkit.normalizePath(basePartsForNormalise.path);\r\n        return URLToolkit.buildURLFromParts(basePartsForNormalise);\r\n      }\r\n      var relativeParts = URLToolkit.parseURL(relativeURL);\r\n      if (!relativeParts) {\r\n        throw new Error('Error trying to parse relative URL.');\r\n      }\r\n      if (relativeParts.scheme) {\r\n        // 2b) If the embedded URL starts with a scheme name, it is\r\n        // interpreted as an absolute URL and we are done.\r\n        if (!opts.alwaysNormalize) {\r\n          return relativeURL;\r\n        }\r\n        relativeParts.path = URLToolkit.normalizePath(relativeParts.path);\r\n        return URLToolkit.buildURLFromParts(relativeParts);\r\n      }\r\n      var baseParts = URLToolkit.parseURL(baseURL);\r\n      if (!baseParts) {\r\n        throw new Error('Error trying to parse base URL.');\r\n      }\r\n      if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {\r\n        // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc\r\n        // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'\r\n        var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);\r\n        baseParts.netLoc = pathParts[1];\r\n        baseParts.path = pathParts[2];\r\n      }\r\n      if (baseParts.netLoc && !baseParts.path) {\r\n        baseParts.path = '/';\r\n      }\r\n      var builtParts = {\r\n        // 2c) Otherwise, the embedded URL inherits the scheme of\r\n        // the base URL.\r\n        scheme: baseParts.scheme,\r\n        netLoc: relativeParts.netLoc,\r\n        path: null,\r\n        params: relativeParts.params,\r\n        query: relativeParts.query,\r\n        fragment: relativeParts.fragment\r\n      };\r\n      if (!relativeParts.netLoc) {\r\n        // 3) If the embedded URL's <net_loc> is non-empty, we skip to\r\n        // Step 7.  Otherwise, the embedded URL inherits the <net_loc>\r\n        // (if any) of the base URL.\r\n        builtParts.netLoc = baseParts.netLoc;\r\n        // 4) If the embedded URL path is preceded by a slash \"/\", the\r\n        // path is not relative and we skip to Step 7.\r\n        if (relativeParts.path[0] !== '/') {\r\n          if (!relativeParts.path) {\r\n            // 5) If the embedded URL path is empty (and not preceded by a\r\n            // slash), then the embedded URL inherits the base URL path\r\n            builtParts.path = baseParts.path;\r\n            // 5a) if the embedded URL's <params> is non-empty, we skip to\r\n            // step 7; otherwise, it inherits the <params> of the base\r\n            // URL (if any) and\r\n            if (!relativeParts.params) {\r\n              builtParts.params = baseParts.params;\r\n              // 5b) if the embedded URL's <query> is non-empty, we skip to\r\n              // step 7; otherwise, it inherits the <query> of the base\r\n              // URL (if any) and we skip to step 7.\r\n              if (!relativeParts.query) {\r\n                builtParts.query = baseParts.query;\r\n              }\r\n            }\r\n          } else {\r\n            // 6) The last segment of the base URL's path (anything\r\n            // following the rightmost slash \"/\", or the entire path if no\r\n            // slash is present) is removed and the embedded URL's path is\r\n            // appended in its place.\r\n            var baseURLPath = baseParts.path;\r\n            var newPath = baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) + relativeParts.path;\r\n            builtParts.path = URLToolkit.normalizePath(newPath);\r\n          }\r\n        }\r\n      }\r\n      if (builtParts.path === null) {\r\n        builtParts.path = opts.alwaysNormalize ? URLToolkit.normalizePath(relativeParts.path) : relativeParts.path;\r\n      }\r\n      return URLToolkit.buildURLFromParts(builtParts);\r\n    },\r\n    parseURL: function(url) {\r\n      var parts = URL_REGEX.exec(url);\r\n      if (!parts) {\r\n        return null;\r\n      }\r\n      return {\r\n        scheme: parts[1] || '',\r\n        netLoc: parts[2] || '',\r\n        path: parts[3] || '',\r\n        params: parts[4] || '',\r\n        query: parts[5] || '',\r\n        fragment: parts[6] || ''\r\n      };\r\n    },\r\n    normalizePath: function(path) {\r\n      // The following operations are\r\n      // then applied, in order, to the new path:\r\n      // 6a) All occurrences of \"./\", where \".\" is a complete path\r\n      // segment, are removed.\r\n      // 6b) If the path ends with \".\" as a complete path segment,\r\n      // that \".\" is removed.\r\n      path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');\r\n      // 6c) All occurrences of \"<segment>/../\", where <segment> is a\r\n      // complete path segment not equal to \"..\", are removed.\r\n      // Removal of these path segments is performed iteratively,\r\n      // removing the leftmost matching pattern on each iteration,\r\n      // until no matching pattern remains.\r\n      // 6d) If the path ends with \"<segment>/..\", where <segment> is a\r\n      // complete path segment not equal to \"..\", that\r\n      // \"<segment>/..\" is removed.\r\n      while (path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length) {} // jshint ignore:line\r\n      return path.split('').reverse().join('');\r\n    },\r\n    buildURLFromParts: function(parts) {\r\n      return parts.scheme + parts.netLoc + parts.path + parts.params + parts.query + parts.fragment;\r\n    }\r\n  };\r\n\r\n/* jshint ignore:start */\r\n  if(true)\r\n    module.exports = URLToolkit;\r\n  else {}\r\n})(this);\r\n/* jshint ignore:end */\r\n\n\n/***/ }),\n/* 4 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return utf8ArrayToStr; });\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * ID3 parser\n */\nvar ID3 = function () {\n  function ID3() {\n    _classCallCheck(this, ID3);\n  }\n\n  /**\n   * Returns true if an ID3 header can be found at offset in data\n   * @param {Uint8Array} data - The data to search in\n   * @param {number} offset - The offset at which to start searching\n   * @return {boolean} - True if an ID3 header is found\n   */\n  ID3.isHeader = function isHeader(data, offset) {\n    /*\n    * http://id3.org/id3v2.3.0\n    * [0]     = 'I'\n    * [1]     = 'D'\n    * [2]     = '3'\n    * [3,4]   = {Version}\n    * [5]     = {Flags}\n    * [6-9]   = {ID3 Size}\n    *\n    * An ID3v2 tag can be detected with the following pattern:\n    *  $49 44 33 yy yy xx zz zz zz zz\n    * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80\n    */\n    if (offset + 10 <= data.length) {\n      // look for 'ID3' identifier\n      if (data[offset] === 0x49 && data[offset + 1] === 0x44 && data[offset + 2] === 0x33) {\n        // check version is within range\n        if (data[offset + 3] < 0xFF && data[offset + 4] < 0xFF) {\n          // check size is within range\n          if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) return true;\n        }\n      }\n    }\n\n    return false;\n  };\n\n  /**\n   * Returns true if an ID3 footer can be found at offset in data\n   * @param {Uint8Array} data - The data to search in\n   * @param {number} offset - The offset at which to start searching\n   * @return {boolean} - True if an ID3 footer is found\n   */\n\n\n  ID3.isFooter = function isFooter(data, offset) {\n    /*\n    * The footer is a copy of the header, but with a different identifier\n    */\n    if (offset + 10 <= data.length) {\n      // look for '3DI' identifier\n      if (data[offset] === 0x33 && data[offset + 1] === 0x44 && data[offset + 2] === 0x49) {\n        // check version is within range\n        if (data[offset + 3] < 0xFF && data[offset + 4] < 0xFF) {\n          // check size is within range\n          if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) return true;\n        }\n      }\n    }\n\n    return false;\n  };\n\n  /**\n   * Returns any adjacent ID3 tags found in data starting at offset, as one block of data\n   * @param {Uint8Array} data - The data to search in\n   * @param {number} offset - The offset at which to start searching\n   * @return {Uint8Array} - The block of data containing any ID3 tags found\n   */\n\n\n  ID3.getID3Data = function getID3Data(data, offset) {\n    var front = offset;\n    var length = 0;\n\n    while (ID3.isHeader(data, offset)) {\n      // ID3 header is 10 bytes\n      length += 10;\n\n      var size = ID3._readSize(data, offset + 6);\n      length += size;\n\n      if (ID3.isFooter(data, offset + 10)) {\n        // ID3 footer is 10 bytes\n        length += 10;\n      }\n\n      offset += length;\n    }\n\n    if (length > 0) return data.subarray(front, front + length);\n\n    return undefined;\n  };\n\n  ID3._readSize = function _readSize(data, offset) {\n    var size = 0;\n    size = (data[offset] & 0x7f) << 21;\n    size |= (data[offset + 1] & 0x7f) << 14;\n    size |= (data[offset + 2] & 0x7f) << 7;\n    size |= data[offset + 3] & 0x7f;\n    return size;\n  };\n\n  /**\n   * Searches for the Elementary Stream timestamp found in the ID3 data chunk\n   * @param {Uint8Array} data - Block of data containing one or more ID3 tags\n   * @return {number} - The timestamp\n   */\n\n\n  ID3.getTimeStamp = function getTimeStamp(data) {\n    var frames = ID3.getID3Frames(data);\n    for (var i = 0; i < frames.length; i++) {\n      var frame = frames[i];\n      if (ID3.isTimeStampFrame(frame)) return ID3._readTimeStamp(frame);\n    }\n\n    return undefined;\n  };\n\n  /**\n   * Returns true if the ID3 frame is an Elementary Stream timestamp frame\n   * @param {ID3 frame} frame\n   */\n\n\n  ID3.isTimeStampFrame = function isTimeStampFrame(frame) {\n    return frame && frame.key === 'PRIV' && frame.info === 'com.apple.streaming.transportStreamTimestamp';\n  };\n\n  ID3._getFrameData = function _getFrameData(data) {\n    /*\n    Frame ID       $xx xx xx xx (four characters)\n    Size           $xx xx xx xx\n    Flags          $xx xx\n    */\n    var type = String.fromCharCode(data[0], data[1], data[2], data[3]);\n    var size = ID3._readSize(data, 4);\n\n    // skip frame id, size, and flags\n    var offset = 10;\n\n    return { type: type, size: size, data: data.subarray(offset, offset + size) };\n  };\n\n  /**\n   * Returns an array of ID3 frames found in all the ID3 tags in the id3Data\n   * @param {Uint8Array} id3Data - The ID3 data containing one or more ID3 tags\n   * @return {ID3 frame[]} - Array of ID3 frame objects\n   */\n\n\n  ID3.getID3Frames = function getID3Frames(id3Data) {\n    var offset = 0;\n    var frames = [];\n\n    while (ID3.isHeader(id3Data, offset)) {\n      var size = ID3._readSize(id3Data, offset + 6);\n      // skip past ID3 header\n      offset += 10;\n      var end = offset + size;\n      // loop through frames in the ID3 tag\n      while (offset + 8 < end) {\n        var frameData = ID3._getFrameData(id3Data.subarray(offset));\n        var frame = ID3._decodeFrame(frameData);\n        if (frame) frames.push(frame);\n\n        // skip frame header and frame data\n        offset += frameData.size + 10;\n      }\n\n      if (ID3.isFooter(id3Data, offset)) offset += 10;\n    }\n\n    return frames;\n  };\n\n  ID3._decodeFrame = function _decodeFrame(frame) {\n    if (frame.type === 'PRIV') return ID3._decodePrivFrame(frame);else if (frame.type[0] === 'T') return ID3._decodeTextFrame(frame);else if (frame.type[0] === 'W') return ID3._decodeURLFrame(frame);\n\n    return undefined;\n  };\n\n  ID3._readTimeStamp = function _readTimeStamp(timeStampFrame) {\n    if (timeStampFrame.data.byteLength === 8) {\n      var data = new Uint8Array(timeStampFrame.data);\n      // timestamp is 33 bit expressed as a big-endian eight-octet number,\n      // with the upper 31 bits set to zero.\n      var pts33Bit = data[3] & 0x1;\n      var timestamp = (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];\n      timestamp /= 45;\n\n      if (pts33Bit) timestamp += 47721858.84; // 2^32 / 90\n\n      return Math.round(timestamp);\n    }\n\n    return undefined;\n  };\n\n  ID3._decodePrivFrame = function _decodePrivFrame(frame) {\n    /*\n    Format: <text string>\\0<binary data>\n    */\n    if (frame.size < 2) return undefined;\n\n    var owner = ID3._utf8ArrayToStr(frame.data, true);\n    var privateData = new Uint8Array(frame.data.subarray(owner.length + 1));\n\n    return { key: frame.type, info: owner, data: privateData.buffer };\n  };\n\n  ID3._decodeTextFrame = function _decodeTextFrame(frame) {\n    if (frame.size < 2) return undefined;\n\n    if (frame.type === 'TXXX') {\n      /*\n      Format:\n      [0]   = {Text Encoding}\n      [1-?] = {Description}\\0{Value}\n      */\n      var index = 1;\n      var description = ID3._utf8ArrayToStr(frame.data.subarray(index));\n\n      index += description.length + 1;\n      var value = ID3._utf8ArrayToStr(frame.data.subarray(index));\n\n      return { key: frame.type, info: description, data: value };\n    } else {\n      /*\n      Format:\n      [0]   = {Text Encoding}\n      [1-?] = {Value}\n      */\n      var text = ID3._utf8ArrayToStr(frame.data.subarray(1));\n      return { key: frame.type, data: text };\n    }\n  };\n\n  ID3._decodeURLFrame = function _decodeURLFrame(frame) {\n    if (frame.type === 'WXXX') {\n      /*\n      Format:\n      [0]   = {Text Encoding}\n      [1-?] = {Description}\\0{URL}\n      */\n      if (frame.size < 2) return undefined;\n\n      var index = 1;\n      var description = ID3._utf8ArrayToStr(frame.data.subarray(index));\n\n      index += description.length + 1;\n      var value = ID3._utf8ArrayToStr(frame.data.subarray(index));\n\n      return { key: frame.type, info: description, data: value };\n    } else {\n      /*\n      Format:\n      [0-?] = {URL}\n      */\n      var url = ID3._utf8ArrayToStr(frame.data);\n      return { key: frame.type, data: url };\n    }\n  };\n\n  // http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197\n  // http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt\n  /* utf.js - UTF-8 <=> UTF-16 convertion\n   *\n   * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n   * Version: 1.0\n   * LastModified: Dec 25 1999\n   * This library is free.  You can redistribute it and/or modify it.\n   */\n\n\n  ID3._utf8ArrayToStr = function _utf8ArrayToStr(array) {\n    var exitOnNull = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n\n    var len = array.length;\n    var c = void 0;\n    var char2 = void 0;\n    var char3 = void 0;\n    var out = '';\n    var i = 0;\n    while (i < len) {\n      c = array[i++];\n      if (c === 0x00 && exitOnNull) {\n        return out;\n      } else if (c === 0x00 || c === 0x03) {\n        // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it\n        continue;\n      }\n      switch (c >> 4) {\n        case 0:case 1:case 2:case 3:case 4:case 5:case 6:case 7:\n          // 0xxxxxxx\n          out += String.fromCharCode(c);\n          break;\n        case 12:case 13:\n          // 110x xxxx   10xx xxxx\n          char2 = array[i++];\n          out += String.fromCharCode((c & 0x1F) << 6 | char2 & 0x3F);\n          break;\n        case 14:\n          // 1110 xxxx  10xx xxxx  10xx xxxx\n          char2 = array[i++];\n          char3 = array[i++];\n          out += String.fromCharCode((c & 0x0F) << 12 | (char2 & 0x3F) << 6 | (char3 & 0x3F) << 0);\n          break;\n        default:\n      }\n    }\n    return out;\n  };\n\n  return ID3;\n}();\n\nvar utf8ArrayToStr = ID3._utf8ArrayToStr;\n\n/* harmony default export */ __webpack_exports__[\"a\"] = (ID3);\n\n\n\n/***/ }),\n/* 5 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n\n// CONCATENATED MODULE: ./src/crypt/aes-crypto.js\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar AESCrypto = function () {\n  function AESCrypto(subtle, iv) {\n    _classCallCheck(this, AESCrypto);\n\n    this.subtle = subtle;\n    this.aesIV = iv;\n  }\n\n  AESCrypto.prototype.decrypt = function decrypt(data, key) {\n    return this.subtle.decrypt({ name: 'AES-CBC', iv: this.aesIV }, key, data);\n  };\n\n  return AESCrypto;\n}();\n\n/* harmony default export */ var aes_crypto = (AESCrypto);\n// CONCATENATED MODULE: ./src/crypt/fast-aes-key.js\nfunction fast_aes_key__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar FastAESKey = function () {\n  function FastAESKey(subtle, key) {\n    fast_aes_key__classCallCheck(this, FastAESKey);\n\n    this.subtle = subtle;\n    this.key = key;\n  }\n\n  FastAESKey.prototype.expandKey = function expandKey() {\n    return this.subtle.importKey('raw', this.key, { name: 'AES-CBC' }, false, ['encrypt', 'decrypt']);\n  };\n\n  return FastAESKey;\n}();\n\n/* harmony default export */ var fast_aes_key = (FastAESKey);\n// CONCATENATED MODULE: ./src/crypt/aes-decryptor.js\nfunction aes_decryptor__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n// PKCS7\nfunction removePadding(buffer) {\n  var outputBytes = buffer.byteLength;\n  var paddingBytes = outputBytes && new DataView(buffer).getUint8(outputBytes - 1);\n  if (paddingBytes) return buffer.slice(0, outputBytes - paddingBytes);else return buffer;\n}\n\nvar AESDecryptor = function () {\n  function AESDecryptor() {\n    aes_decryptor__classCallCheck(this, AESDecryptor);\n\n    // Static after running initTable\n    this.rcon = [0x0, 0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];\n    this.subMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\n    this.invSubMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\n    this.sBox = new Uint32Array(256);\n    this.invSBox = new Uint32Array(256);\n\n    // Changes during runtime\n    this.key = new Uint32Array(0);\n\n    this.initTable();\n  }\n\n  // Using view.getUint32() also swaps the byte order.\n\n\n  AESDecryptor.prototype.uint8ArrayToUint32Array_ = function uint8ArrayToUint32Array_(arrayBuffer) {\n    var view = new DataView(arrayBuffer);\n    var newArray = new Uint32Array(4);\n    for (var i = 0; i < 4; i++) {\n      newArray[i] = view.getUint32(i * 4);\n    }return newArray;\n  };\n\n  AESDecryptor.prototype.initTable = function initTable() {\n    var sBox = this.sBox;\n    var invSBox = this.invSBox;\n    var subMix = this.subMix;\n    var subMix0 = subMix[0];\n    var subMix1 = subMix[1];\n    var subMix2 = subMix[2];\n    var subMix3 = subMix[3];\n    var invSubMix = this.invSubMix;\n    var invSubMix0 = invSubMix[0];\n    var invSubMix1 = invSubMix[1];\n    var invSubMix2 = invSubMix[2];\n    var invSubMix3 = invSubMix[3];\n\n    var d = new Uint32Array(256);\n    var x = 0;\n    var xi = 0;\n    var i = 0;\n    for (i = 0; i < 256; i++) {\n      if (i < 128) d[i] = i << 1;else d[i] = i << 1 ^ 0x11b;\n    }\n\n    for (i = 0; i < 256; i++) {\n      var sx = xi ^ xi << 1 ^ xi << 2 ^ xi << 3 ^ xi << 4;\n      sx = sx >>> 8 ^ sx & 0xff ^ 0x63;\n      sBox[x] = sx;\n      invSBox[sx] = x;\n\n      // Compute multiplication\n      var x2 = d[x];\n      var x4 = d[x2];\n      var x8 = d[x4];\n\n      // Compute sub/invSub bytes, mix columns tables\n      var t = d[sx] * 0x101 ^ sx * 0x1010100;\n      subMix0[x] = t << 24 | t >>> 8;\n      subMix1[x] = t << 16 | t >>> 16;\n      subMix2[x] = t << 8 | t >>> 24;\n      subMix3[x] = t;\n\n      // Compute inv sub bytes, inv mix columns tables\n      t = x8 * 0x1010101 ^ x4 * 0x10001 ^ x2 * 0x101 ^ x * 0x1010100;\n      invSubMix0[sx] = t << 24 | t >>> 8;\n      invSubMix1[sx] = t << 16 | t >>> 16;\n      invSubMix2[sx] = t << 8 | t >>> 24;\n      invSubMix3[sx] = t;\n\n      // Compute next counter\n      if (!x) {\n        x = xi = 1;\n      } else {\n        x = x2 ^ d[d[d[x8 ^ x2]]];\n        xi ^= d[d[xi]];\n      }\n    }\n  };\n\n  AESDecryptor.prototype.expandKey = function expandKey(keyBuffer) {\n    // convert keyBuffer to Uint32Array\n    var key = this.uint8ArrayToUint32Array_(keyBuffer);\n    var sameKey = true;\n    var offset = 0;\n\n    while (offset < key.length && sameKey) {\n      sameKey = key[offset] === this.key[offset];\n      offset++;\n    }\n\n    if (sameKey) return;\n\n    this.key = key;\n    var keySize = this.keySize = key.length;\n\n    if (keySize !== 4 && keySize !== 6 && keySize !== 8) throw new Error('Invalid aes key size=' + keySize);\n\n    var ksRows = this.ksRows = (keySize + 6 + 1) * 4;\n    var ksRow = void 0;\n    var invKsRow = void 0;\n\n    var keySchedule = this.keySchedule = new Uint32Array(ksRows);\n    var invKeySchedule = this.invKeySchedule = new Uint32Array(ksRows);\n    var sbox = this.sBox;\n    var rcon = this.rcon;\n\n    var invSubMix = this.invSubMix;\n    var invSubMix0 = invSubMix[0];\n    var invSubMix1 = invSubMix[1];\n    var invSubMix2 = invSubMix[2];\n    var invSubMix3 = invSubMix[3];\n\n    var prev = void 0;\n    var t = void 0;\n\n    for (ksRow = 0; ksRow < ksRows; ksRow++) {\n      if (ksRow < keySize) {\n        prev = keySchedule[ksRow] = key[ksRow];\n        continue;\n      }\n      t = prev;\n\n      if (ksRow % keySize === 0) {\n        // Rot word\n        t = t << 8 | t >>> 24;\n\n        // Sub word\n        t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\n\n        // Mix Rcon\n        t ^= rcon[ksRow / keySize | 0] << 24;\n      } else if (keySize > 6 && ksRow % keySize === 4) {\n        // Sub word\n        t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\n      }\n\n      keySchedule[ksRow] = prev = (keySchedule[ksRow - keySize] ^ t) >>> 0;\n    }\n\n    for (invKsRow = 0; invKsRow < ksRows; invKsRow++) {\n      ksRow = ksRows - invKsRow;\n      if (invKsRow & 3) t = keySchedule[ksRow];else t = keySchedule[ksRow - 4];\n\n      if (invKsRow < 4 || ksRow <= 4) invKeySchedule[invKsRow] = t;else invKeySchedule[invKsRow] = invSubMix0[sbox[t >>> 24]] ^ invSubMix1[sbox[t >>> 16 & 0xff]] ^ invSubMix2[sbox[t >>> 8 & 0xff]] ^ invSubMix3[sbox[t & 0xff]];\n\n      invKeySchedule[invKsRow] = invKeySchedule[invKsRow] >>> 0;\n    }\n  };\n\n  // Adding this as a method greatly improves performance.\n\n\n  AESDecryptor.prototype.networkToHostOrderSwap = function networkToHostOrderSwap(word) {\n    return word << 24 | (word & 0xff00) << 8 | (word & 0xff0000) >> 8 | word >>> 24;\n  };\n\n  AESDecryptor.prototype.decrypt = function decrypt(inputArrayBuffer, offset, aesIV, removePKCS7Padding) {\n    var nRounds = this.keySize + 6;\n    var invKeySchedule = this.invKeySchedule;\n    var invSBOX = this.invSBox;\n\n    var invSubMix = this.invSubMix;\n    var invSubMix0 = invSubMix[0];\n    var invSubMix1 = invSubMix[1];\n    var invSubMix2 = invSubMix[2];\n    var invSubMix3 = invSubMix[3];\n\n    var initVector = this.uint8ArrayToUint32Array_(aesIV);\n    var initVector0 = initVector[0];\n    var initVector1 = initVector[1];\n    var initVector2 = initVector[2];\n    var initVector3 = initVector[3];\n\n    var inputInt32 = new Int32Array(inputArrayBuffer);\n    var outputInt32 = new Int32Array(inputInt32.length);\n\n    var t0 = void 0,\n        t1 = void 0,\n        t2 = void 0,\n        t3 = void 0;\n    var s0 = void 0,\n        s1 = void 0,\n        s2 = void 0,\n        s3 = void 0;\n    var inputWords0 = void 0,\n        inputWords1 = void 0,\n        inputWords2 = void 0,\n        inputWords3 = void 0;\n\n    var ksRow = void 0,\n        i = void 0;\n    var swapWord = this.networkToHostOrderSwap;\n\n    while (offset < inputInt32.length) {\n      inputWords0 = swapWord(inputInt32[offset]);\n      inputWords1 = swapWord(inputInt32[offset + 1]);\n      inputWords2 = swapWord(inputInt32[offset + 2]);\n      inputWords3 = swapWord(inputInt32[offset + 3]);\n\n      s0 = inputWords0 ^ invKeySchedule[0];\n      s1 = inputWords3 ^ invKeySchedule[1];\n      s2 = inputWords2 ^ invKeySchedule[2];\n      s3 = inputWords1 ^ invKeySchedule[3];\n\n      ksRow = 4;\n\n      // Iterate through the rounds of decryption\n      for (i = 1; i < nRounds; i++) {\n        t0 = invSubMix0[s0 >>> 24] ^ invSubMix1[s1 >> 16 & 0xff] ^ invSubMix2[s2 >> 8 & 0xff] ^ invSubMix3[s3 & 0xff] ^ invKeySchedule[ksRow];\n        t1 = invSubMix0[s1 >>> 24] ^ invSubMix1[s2 >> 16 & 0xff] ^ invSubMix2[s3 >> 8 & 0xff] ^ invSubMix3[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\n        t2 = invSubMix0[s2 >>> 24] ^ invSubMix1[s3 >> 16 & 0xff] ^ invSubMix2[s0 >> 8 & 0xff] ^ invSubMix3[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\n        t3 = invSubMix0[s3 >>> 24] ^ invSubMix1[s0 >> 16 & 0xff] ^ invSubMix2[s1 >> 8 & 0xff] ^ invSubMix3[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\n        // Update state\n        s0 = t0;\n        s1 = t1;\n        s2 = t2;\n        s3 = t3;\n\n        ksRow = ksRow + 4;\n      }\n\n      // Shift rows, sub bytes, add round key\n      t0 = invSBOX[s0 >>> 24] << 24 ^ invSBOX[s1 >> 16 & 0xff] << 16 ^ invSBOX[s2 >> 8 & 0xff] << 8 ^ invSBOX[s3 & 0xff] ^ invKeySchedule[ksRow];\n      t1 = invSBOX[s1 >>> 24] << 24 ^ invSBOX[s2 >> 16 & 0xff] << 16 ^ invSBOX[s3 >> 8 & 0xff] << 8 ^ invSBOX[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\n      t2 = invSBOX[s2 >>> 24] << 24 ^ invSBOX[s3 >> 16 & 0xff] << 16 ^ invSBOX[s0 >> 8 & 0xff] << 8 ^ invSBOX[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\n      t3 = invSBOX[s3 >>> 24] << 24 ^ invSBOX[s0 >> 16 & 0xff] << 16 ^ invSBOX[s1 >> 8 & 0xff] << 8 ^ invSBOX[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\n      ksRow = ksRow + 3;\n\n      // Write\n      outputInt32[offset] = swapWord(t0 ^ initVector0);\n      outputInt32[offset + 1] = swapWord(t3 ^ initVector1);\n      outputInt32[offset + 2] = swapWord(t2 ^ initVector2);\n      outputInt32[offset + 3] = swapWord(t1 ^ initVector3);\n\n      // reset initVector to last 4 unsigned int\n      initVector0 = inputWords0;\n      initVector1 = inputWords1;\n      initVector2 = inputWords2;\n      initVector3 = inputWords3;\n\n      offset = offset + 4;\n    }\n\n    return removePKCS7Padding ? removePadding(outputInt32.buffer) : outputInt32.buffer;\n  };\n\n  AESDecryptor.prototype.destroy = function destroy() {\n    this.key = undefined;\n    this.keySize = undefined;\n    this.ksRows = undefined;\n\n    this.sBox = undefined;\n    this.invSBox = undefined;\n    this.subMix = undefined;\n    this.invSubMix = undefined;\n    this.keySchedule = undefined;\n    this.invKeySchedule = undefined;\n\n    this.rcon = undefined;\n  };\n\n  return AESDecryptor;\n}();\n\n/* harmony default export */ var aes_decryptor = (AESDecryptor);\n// EXTERNAL MODULE: ./src/errors.js\nvar errors = __webpack_require__(2);\n\n// EXTERNAL MODULE: ./src/utils/logger.js\nvar logger = __webpack_require__(0);\n\n// CONCATENATED MODULE: ./src/crypt/decrypter.js\nfunction decrypter__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\n\n\n\n\n\n/* globals self: false */\n\nvar decrypter_Decrypter = function () {\n  function Decrypter(observer, config) {\n    var _ref = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {},\n        _ref$removePKCS7Paddi = _ref.removePKCS7Padding,\n        removePKCS7Padding = _ref$removePKCS7Paddi === undefined ? true : _ref$removePKCS7Paddi;\n\n    decrypter__classCallCheck(this, Decrypter);\n\n    this.logEnabled = true;\n    this.observer = observer;\n    this.config = config;\n    this.removePKCS7Padding = removePKCS7Padding;\n    // built in decryptor expects PKCS7 padding\n    if (removePKCS7Padding) {\n      try {\n        var browserCrypto = crypto || self.crypto;\n        this.subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;\n      } catch (e) {}\n    }\n    this.disableWebCrypto = !this.subtle;\n  }\n\n  Decrypter.prototype.isSync = function isSync() {\n    return this.disableWebCrypto && this.config.enableSoftwareAES;\n  };\n\n  Decrypter.prototype.decrypt = function decrypt(data, key, iv, callback) {\n    var _this = this;\n\n    if (this.disableWebCrypto && this.config.enableSoftwareAES) {\n      if (this.logEnabled) {\n        logger[\"b\" /* logger */].log('JS AES decrypt');\n        this.logEnabled = false;\n      }\n      var decryptor = this.decryptor;\n      if (!decryptor) this.decryptor = decryptor = new aes_decryptor();\n\n      decryptor.expandKey(key);\n      callback(decryptor.decrypt(data, 0, iv, this.removePKCS7Padding));\n    } else {\n      if (this.logEnabled) {\n        logger[\"b\" /* logger */].log('WebCrypto AES decrypt');\n        this.logEnabled = false;\n      }\n      var subtle = this.subtle;\n      if (this.key !== key) {\n        this.key = key;\n        this.fastAesKey = new fast_aes_key(subtle, key);\n      }\n\n      this.fastAesKey.expandKey().then(function (aesKey) {\n        // decrypt using web crypto\n        var crypto = new aes_crypto(subtle, iv);\n        crypto.decrypt(data, aesKey).catch(function (err) {\n          _this.onWebCryptoError(err, data, key, iv, callback);\n        }).then(function (result) {\n          callback(result);\n        });\n      }).catch(function (err) {\n        _this.onWebCryptoError(err, data, key, iv, callback);\n      });\n    }\n  };\n\n  Decrypter.prototype.onWebCryptoError = function onWebCryptoError(err, data, key, iv, callback) {\n    if (this.config.enableSoftwareAES) {\n      logger[\"b\" /* logger */].log('WebCrypto Error, disable WebCrypto API');\n      this.disableWebCrypto = true;\n      this.logEnabled = true;\n      this.decrypt(data, key, iv, callback);\n    } else {\n      logger[\"b\" /* logger */].error('decrypting error : ' + err.message);\n      this.observer.trigger(Event.ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].FRAG_DECRYPT_ERROR, fatal: true, reason: err.message });\n    }\n  };\n\n  Decrypter.prototype.destroy = function destroy() {\n    var decryptor = this.decryptor;\n    if (decryptor) {\n      decryptor.destroy();\n      this.decryptor = undefined;\n    }\n  };\n\n  return Decrypter;\n}();\n\n/* harmony default export */ var decrypter = __webpack_exports__[\"a\"] = (decrypter_Decrypter);\n\n/***/ }),\n/* 6 */\n/***/ (function(module, exports) {\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nfunction EventEmitter() {\n  this._events = this._events || {};\n  this._maxListeners = this._maxListeners || undefined;\n}\nmodule.exports = EventEmitter;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nEventEmitter.defaultMaxListeners = 10;\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function(n) {\n  if (!isNumber(n) || n < 0 || isNaN(n))\n    throw TypeError('n must be a positive number');\n  this._maxListeners = n;\n  return this;\n};\n\nEventEmitter.prototype.emit = function(type) {\n  var er, handler, len, args, i, listeners;\n\n  if (!this._events)\n    this._events = {};\n\n  // If there is no 'error' event listener then throw.\n  if (type === 'error') {\n    if (!this._events.error ||\n        (isObject(this._events.error) && !this._events.error.length)) {\n      er = arguments[1];\n      if (er instanceof Error) {\n        throw er; // Unhandled 'error' event\n      } else {\n        // At least give some kind of context to the user\n        var err = new Error('Uncaught, unspecified \"error\" event. (' + er + ')');\n        err.context = er;\n        throw err;\n      }\n    }\n  }\n\n  handler = this._events[type];\n\n  if (isUndefined(handler))\n    return false;\n\n  if (isFunction(handler)) {\n    switch (arguments.length) {\n      // fast cases\n      case 1:\n        handler.call(this);\n        break;\n      case 2:\n        handler.call(this, arguments[1]);\n        break;\n      case 3:\n        handler.call(this, arguments[1], arguments[2]);\n        break;\n      // slower\n      default:\n        args = Array.prototype.slice.call(arguments, 1);\n        handler.apply(this, args);\n    }\n  } else if (isObject(handler)) {\n    args = Array.prototype.slice.call(arguments, 1);\n    listeners = handler.slice();\n    len = listeners.length;\n    for (i = 0; i < len; i++)\n      listeners[i].apply(this, args);\n  }\n\n  return true;\n};\n\nEventEmitter.prototype.addListener = function(type, listener) {\n  var m;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events)\n    this._events = {};\n\n  // To avoid recursion in the case that type === \"newListener\"! Before\n  // adding it to the listeners, first emit \"newListener\".\n  if (this._events.newListener)\n    this.emit('newListener', type,\n              isFunction(listener.listener) ?\n              listener.listener : listener);\n\n  if (!this._events[type])\n    // Optimize the case of one listener. Don't need the extra array object.\n    this._events[type] = listener;\n  else if (isObject(this._events[type]))\n    // If we've already got an array, just append.\n    this._events[type].push(listener);\n  else\n    // Adding the second element, need to change to array.\n    this._events[type] = [this._events[type], listener];\n\n  // Check for listener leak\n  if (isObject(this._events[type]) && !this._events[type].warned) {\n    if (!isUndefined(this._maxListeners)) {\n      m = this._maxListeners;\n    } else {\n      m = EventEmitter.defaultMaxListeners;\n    }\n\n    if (m && m > 0 && this._events[type].length > m) {\n      this._events[type].warned = true;\n      console.error('(node) warning: possible EventEmitter memory ' +\n                    'leak detected. %d listeners added. ' +\n                    'Use emitter.setMaxListeners() to increase limit.',\n                    this._events[type].length);\n      if (typeof console.trace === 'function') {\n        // not supported in IE 10\n        console.trace();\n      }\n    }\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.once = function(type, listener) {\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  var fired = false;\n\n  function g() {\n    this.removeListener(type, g);\n\n    if (!fired) {\n      fired = true;\n      listener.apply(this, arguments);\n    }\n  }\n\n  g.listener = listener;\n  this.on(type, g);\n\n  return this;\n};\n\n// emits a 'removeListener' event iff the listener was removed\nEventEmitter.prototype.removeListener = function(type, listener) {\n  var list, position, length, i;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events || !this._events[type])\n    return this;\n\n  list = this._events[type];\n  length = list.length;\n  position = -1;\n\n  if (list === listener ||\n      (isFunction(list.listener) && list.listener === listener)) {\n    delete this._events[type];\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n\n  } else if (isObject(list)) {\n    for (i = length; i-- > 0;) {\n      if (list[i] === listener ||\n          (list[i].listener && list[i].listener === listener)) {\n        position = i;\n        break;\n      }\n    }\n\n    if (position < 0)\n      return this;\n\n    if (list.length === 1) {\n      list.length = 0;\n      delete this._events[type];\n    } else {\n      list.splice(position, 1);\n    }\n\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.removeAllListeners = function(type) {\n  var key, listeners;\n\n  if (!this._events)\n    return this;\n\n  // not listening for removeListener, no need to emit\n  if (!this._events.removeListener) {\n    if (arguments.length === 0)\n      this._events = {};\n    else if (this._events[type])\n      delete this._events[type];\n    return this;\n  }\n\n  // emit removeListener for all listeners on all events\n  if (arguments.length === 0) {\n    for (key in this._events) {\n      if (key === 'removeListener') continue;\n      this.removeAllListeners(key);\n    }\n    this.removeAllListeners('removeListener');\n    this._events = {};\n    return this;\n  }\n\n  listeners = this._events[type];\n\n  if (isFunction(listeners)) {\n    this.removeListener(type, listeners);\n  } else if (listeners) {\n    // LIFO order\n    while (listeners.length)\n      this.removeListener(type, listeners[listeners.length - 1]);\n  }\n  delete this._events[type];\n\n  return this;\n};\n\nEventEmitter.prototype.listeners = function(type) {\n  var ret;\n  if (!this._events || !this._events[type])\n    ret = [];\n  else if (isFunction(this._events[type]))\n    ret = [this._events[type]];\n  else\n    ret = this._events[type].slice();\n  return ret;\n};\n\nEventEmitter.prototype.listenerCount = function(type) {\n  if (this._events) {\n    var evlistener = this._events[type];\n\n    if (isFunction(evlistener))\n      return 1;\n    else if (evlistener)\n      return evlistener.length;\n  }\n  return 0;\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  return emitter.listenerCount(type);\n};\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\n\n\n/***/ }),\n/* 7 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__utils_logger__ = __webpack_require__(0);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1__events__ = __webpack_require__(1);\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * MP4 demuxer\n */\n\n\n\nvar UINT32_MAX = Math.pow(2, 32) - 1;\n\nvar MP4Demuxer = function () {\n  function MP4Demuxer(observer, remuxer) {\n    _classCallCheck(this, MP4Demuxer);\n\n    this.observer = observer;\n    this.remuxer = remuxer;\n  }\n\n  MP4Demuxer.prototype.resetTimeStamp = function resetTimeStamp(initPTS) {\n    this.initPTS = initPTS;\n  };\n\n  MP4Demuxer.prototype.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, duration) {\n    // jshint unused:false\n    if (initSegment && initSegment.byteLength) {\n      var initData = this.initData = MP4Demuxer.parseInitSegment(initSegment);\n\n      // default audio codec if nothing specified\n      // TODO : extract that from initsegment\n      if (audioCodec == null) audioCodec = 'mp4a.40.5';\n\n      if (videoCodec == null) videoCodec = 'avc1.42e01e';\n\n      var tracks = {};\n      if (initData.audio && initData.video) {\n        tracks.audiovideo = { container: 'video/mp4', codec: audioCodec + ',' + videoCodec, initSegment: duration ? initSegment : null };\n      } else {\n        if (initData.audio) tracks.audio = { container: 'audio/mp4', codec: audioCodec, initSegment: duration ? initSegment : null };\n\n        if (initData.video) tracks.video = { container: 'video/mp4', codec: videoCodec, initSegment: duration ? initSegment : null };\n      }\n      this.observer.trigger(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].FRAG_PARSING_INIT_SEGMENT, { tracks: tracks });\n    } else {\n      if (audioCodec) this.audioCodec = audioCodec;\n\n      if (videoCodec) this.videoCodec = videoCodec;\n    }\n  };\n\n  MP4Demuxer.probe = function probe(data) {\n    // ensure we find a moof box in the first 16 kB\n    return MP4Demuxer.findBox({ data: data, start: 0, end: Math.min(data.length, 16384) }, ['moof']).length > 0;\n  };\n\n  MP4Demuxer.bin2str = function bin2str(buffer) {\n    return String.fromCharCode.apply(null, buffer);\n  };\n\n  MP4Demuxer.readUint16 = function readUint16(buffer, offset) {\n    if (buffer.data) {\n      offset += buffer.start;\n      buffer = buffer.data;\n    }\n\n    var val = buffer[offset] << 8 | buffer[offset + 1];\n\n    return val < 0 ? 65536 + val : val;\n  };\n\n  MP4Demuxer.readUint32 = function readUint32(buffer, offset) {\n    if (buffer.data) {\n      offset += buffer.start;\n      buffer = buffer.data;\n    }\n\n    var val = buffer[offset] << 24 | buffer[offset + 1] << 16 | buffer[offset + 2] << 8 | buffer[offset + 3];\n    return val < 0 ? 4294967296 + val : val;\n  };\n\n  MP4Demuxer.writeUint32 = function writeUint32(buffer, offset, value) {\n    if (buffer.data) {\n      offset += buffer.start;\n      buffer = buffer.data;\n    }\n    buffer[offset] = value >> 24;\n    buffer[offset + 1] = value >> 16 & 0xff;\n    buffer[offset + 2] = value >> 8 & 0xff;\n    buffer[offset + 3] = value & 0xff;\n  };\n\n  // Find the data for a box specified by its path\n\n\n  MP4Demuxer.findBox = function findBox(data, path) {\n    var results = [],\n        i = void 0,\n        size = void 0,\n        type = void 0,\n        end = void 0,\n        subresults = void 0,\n        start = void 0,\n        endbox = void 0;\n\n    if (data.data) {\n      start = data.start;\n      end = data.end;\n      data = data.data;\n    } else {\n      start = 0;\n      end = data.byteLength;\n    }\n\n    if (!path.length) {\n      // short-circuit the search for empty paths\n      return null;\n    }\n\n    for (i = start; i < end;) {\n      size = MP4Demuxer.readUint32(data, i);\n      type = MP4Demuxer.bin2str(data.subarray(i + 4, i + 8));\n      endbox = size > 1 ? i + size : end;\n\n      if (type === path[0]) {\n        if (path.length === 1) {\n          // this is the end of the path and we've found the box we were\n          // looking for\n          results.push({ data: data, start: i + 8, end: endbox });\n        } else {\n          // recursively search for the next box along the path\n          subresults = MP4Demuxer.findBox({ data: data, start: i + 8, end: endbox }, path.slice(1));\n          if (subresults.length) results = results.concat(subresults);\n        }\n      }\n      i = endbox;\n    }\n\n    // we've finished searching all of data\n    return results;\n  };\n\n  MP4Demuxer.parseSegmentIndex = function parseSegmentIndex(initSegment) {\n    var moov = MP4Demuxer.findBox(initSegment, ['moov'])[0];\n    var moovEndOffset = moov ? moov.end : null; // we need this in case we need to chop of garbage of the end of current data\n\n    var index = 0;\n    var sidx = MP4Demuxer.findBox(initSegment, ['sidx']);\n    var references = void 0;\n\n    if (!sidx || !sidx[0]) return null;\n\n    references = [];\n    sidx = sidx[0];\n\n    var version = sidx.data[0];\n\n    // set initial offset, we skip the reference ID (not needed)\n    index = version === 0 ? 8 : 16;\n\n    var timescale = MP4Demuxer.readUint32(sidx, index);\n    index += 4;\n\n    // TODO: parse earliestPresentationTime and firstOffset\n    // usually zero in our case\n    var earliestPresentationTime = 0;\n    var firstOffset = 0;\n\n    if (version === 0) index += 8;else index += 16;\n\n    // skip reserved\n    index += 2;\n\n    var startByte = sidx.end + firstOffset;\n\n    var referencesCount = MP4Demuxer.readUint16(sidx, index);\n    index += 2;\n\n    for (var i = 0; i < referencesCount; i++) {\n      var referenceIndex = index;\n\n      var referenceInfo = MP4Demuxer.readUint32(sidx, referenceIndex);\n      referenceIndex += 4;\n\n      var referenceSize = referenceInfo & 0x7FFFFFFF;\n      var referenceType = (referenceInfo & 0x80000000) >>> 31;\n\n      if (referenceType === 1) {\n        console.warn('SIDX has hierarchical references (not supported)');\n        return;\n      }\n\n      var subsegmentDuration = MP4Demuxer.readUint32(sidx, referenceIndex);\n      referenceIndex += 4;\n\n      references.push({\n        referenceSize: referenceSize,\n        subsegmentDuration: subsegmentDuration, // unscaled\n        info: {\n          duration: subsegmentDuration / timescale,\n          start: startByte,\n          end: startByte + referenceSize - 1\n        }\n      });\n\n      startByte += referenceSize;\n\n      // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits\n      // for |sapDelta|.\n      referenceIndex += 4;\n\n      // skip to next ref\n      index = referenceIndex;\n    }\n\n    return {\n      earliestPresentationTime: earliestPresentationTime,\n      timescale: timescale,\n      version: version,\n      referencesCount: referencesCount,\n      references: references,\n      moovEndOffset: moovEndOffset\n    };\n  };\n\n  /**\n   * Parses an MP4 initialization segment and extracts stream type and\n   * timescale values for any declared tracks. Timescale values indicate the\n   * number of clock ticks per second to assume for time-based values\n   * elsewhere in the MP4.\n   *\n   * To determine the start time of an MP4, you need two pieces of\n   * information: the timescale unit and the earliest base media decode\n   * time. Multiple timescales can be specified within an MP4 but the\n   * base media decode time is always expressed in the timescale from\n   * the media header box for the track:\n   * ```\n   * moov > trak > mdia > mdhd.timescale\n   * moov > trak > mdia > hdlr\n   * ```\n   * @param init {Uint8Array} the bytes of the init segment\n   * @return {object} a hash of track type to timescale values or null if\n   * the init segment is malformed.\n   */\n\n\n  MP4Demuxer.parseInitSegment = function parseInitSegment(initSegment) {\n    var result = [];\n    var traks = MP4Demuxer.findBox(initSegment, ['moov', 'trak']);\n\n    traks.forEach(function (trak) {\n      var tkhd = MP4Demuxer.findBox(trak, ['tkhd'])[0];\n      if (tkhd) {\n        var version = tkhd.data[tkhd.start];\n        var index = version === 0 ? 12 : 20;\n        var trackId = MP4Demuxer.readUint32(tkhd, index);\n\n        var mdhd = MP4Demuxer.findBox(trak, ['mdia', 'mdhd'])[0];\n        if (mdhd) {\n          version = mdhd.data[mdhd.start];\n          index = version === 0 ? 12 : 20;\n          var timescale = MP4Demuxer.readUint32(mdhd, index);\n\n          var hdlr = MP4Demuxer.findBox(trak, ['mdia', 'hdlr'])[0];\n          if (hdlr) {\n            var hdlrType = MP4Demuxer.bin2str(hdlr.data.subarray(hdlr.start + 8, hdlr.start + 12));\n            var type = { 'soun': 'audio', 'vide': 'video' }[hdlrType];\n            if (type) {\n              // extract codec info. TODO : parse codec details to be able to build MIME type\n              var codecBox = MP4Demuxer.findBox(trak, ['mdia', 'minf', 'stbl', 'stsd']);\n              if (codecBox.length) {\n                codecBox = codecBox[0];\n                var codecType = MP4Demuxer.bin2str(codecBox.data.subarray(codecBox.start + 12, codecBox.start + 16));\n                __WEBPACK_IMPORTED_MODULE_0__utils_logger__[\"b\" /* logger */].log('MP4Demuxer:' + type + ':' + codecType + ' found');\n              }\n              result[trackId] = { timescale: timescale, type: type };\n              result[type] = { timescale: timescale, id: trackId };\n            }\n          }\n        }\n      }\n    });\n    return result;\n  };\n\n  /**\n  * Determine the base media decode start time, in seconds, for an MP4\n  * fragment. If multiple fragments are specified, the earliest time is\n  * returned.\n  *\n  * The base media decode time can be parsed from track fragment\n  * metadata:\n  * ```\n  * moof > traf > tfdt.baseMediaDecodeTime\n  * ```\n  * It requires the timescale value from the mdhd to interpret.\n  *\n  * @param timescale {object} a hash of track ids to timescale values.\n  * @return {number} the earliest base media decode start time for the\n  * fragment, in seconds\n  */\n\n\n  MP4Demuxer.getStartDTS = function getStartDTS(initData, fragment) {\n    var trafs = void 0,\n        baseTimes = void 0,\n        result = void 0;\n\n    // we need info from two childrend of each track fragment box\n    trafs = MP4Demuxer.findBox(fragment, ['moof', 'traf']);\n\n    // determine the start times for each track\n    baseTimes = [].concat.apply([], trafs.map(function (traf) {\n      return MP4Demuxer.findBox(traf, ['tfhd']).map(function (tfhd) {\n        var id = void 0,\n            scale = void 0,\n            baseTime = void 0;\n\n        // get the track id from the tfhd\n        id = MP4Demuxer.readUint32(tfhd, 4);\n        // assume a 90kHz clock if no timescale was specified\n        scale = initData[id].timescale || 90e3;\n\n        // get the base media decode time from the tfdt\n        baseTime = MP4Demuxer.findBox(traf, ['tfdt']).map(function (tfdt) {\n          var version = void 0,\n              result = void 0;\n\n          version = tfdt.data[tfdt.start];\n          result = MP4Demuxer.readUint32(tfdt, 4);\n          if (version === 1) {\n            result *= Math.pow(2, 32);\n\n            result += MP4Demuxer.readUint32(tfdt, 8);\n          }\n          return result;\n        })[0];\n        // convert base time to seconds\n        return baseTime / scale;\n      });\n    }));\n\n    // return the minimum\n    result = Math.min.apply(null, baseTimes);\n    return isFinite(result) ? result : 0;\n  };\n\n  MP4Demuxer.offsetStartDTS = function offsetStartDTS(initData, fragment, timeOffset) {\n    MP4Demuxer.findBox(fragment, ['moof', 'traf']).map(function (traf) {\n      return MP4Demuxer.findBox(traf, ['tfhd']).map(function (tfhd) {\n        // get the track id from the tfhd\n        var id = MP4Demuxer.readUint32(tfhd, 4);\n        // assume a 90kHz clock if no timescale was specified\n        var timescale = initData[id].timescale || 90e3;\n\n        // get the base media decode time from the tfdt\n        MP4Demuxer.findBox(traf, ['tfdt']).map(function (tfdt) {\n          var version = tfdt.data[tfdt.start];\n          var baseMediaDecodeTime = MP4Demuxer.readUint32(tfdt, 4);\n          if (version === 0) {\n            MP4Demuxer.writeUint32(tfdt, 4, baseMediaDecodeTime - timeOffset * timescale);\n          } else {\n            baseMediaDecodeTime *= Math.pow(2, 32);\n            baseMediaDecodeTime += MP4Demuxer.readUint32(tfdt, 8);\n            baseMediaDecodeTime -= timeOffset * timescale;\n            baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);\n            var upper = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));\n            var lower = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));\n            MP4Demuxer.writeUint32(tfdt, 4, upper);\n            MP4Demuxer.writeUint32(tfdt, 8, lower);\n          }\n        });\n      });\n    });\n  };\n\n  // feed incoming data to the front of the parsing pipeline\n\n\n  MP4Demuxer.prototype.append = function append(data, timeOffset, contiguous, accurateTimeOffset) {\n    var initData = this.initData;\n    if (!initData) {\n      this.resetInitSegment(data, this.audioCodec, this.videoCodec, false);\n      initData = this.initData;\n    }\n    var startDTS = void 0,\n        initPTS = this.initPTS;\n    if (initPTS === undefined) {\n      var _startDTS = MP4Demuxer.getStartDTS(initData, data);\n      this.initPTS = initPTS = _startDTS - timeOffset;\n      this.observer.trigger(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].INIT_PTS_FOUND, { initPTS: initPTS });\n    }\n    MP4Demuxer.offsetStartDTS(initData, data, initPTS);\n    startDTS = MP4Demuxer.getStartDTS(initData, data);\n    this.remuxer.remux(initData.audio, initData.video, null, null, startDTS, contiguous, accurateTimeOffset, data);\n  };\n\n  MP4Demuxer.prototype.destroy = function destroy() {};\n\n  return MP4Demuxer;\n}();\n\n/* harmony default export */ __webpack_exports__[\"a\"] = (MP4Demuxer);\n\n/***/ }),\n/* 8 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n\n// EXTERNAL MODULE: ./src/events.js\nvar events = __webpack_require__(1);\n\n// EXTERNAL MODULE: ./src/errors.js\nvar errors = __webpack_require__(2);\n\n// EXTERNAL MODULE: ./src/crypt/decrypter.js + 3 modules\nvar crypt_decrypter = __webpack_require__(5);\n\n// EXTERNAL MODULE: ./src/utils/logger.js\nvar logger = __webpack_require__(0);\n\n// CONCATENATED MODULE: ./src/demux/adts.js\n/**\n *  ADTS parser helper\n */\n\n\n\nfunction getAudioConfig(observer, data, offset, audioCodec) {\n  var adtsObjectType = void 0,\n      // :int\n  adtsSampleingIndex = void 0,\n      // :int\n  adtsExtensionSampleingIndex = void 0,\n      // :int\n  adtsChanelConfig = void 0,\n      // :int\n  config = void 0,\n      userAgent = navigator.userAgent.toLowerCase(),\n      manifestCodec = audioCodec,\n      adtsSampleingRates = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];\n  // byte 2\n  adtsObjectType = ((data[offset + 2] & 0xC0) >>> 6) + 1;\n  adtsSampleingIndex = (data[offset + 2] & 0x3C) >>> 2;\n  if (adtsSampleingIndex > adtsSampleingRates.length - 1) {\n    observer.trigger(Event.ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].FRAG_PARSING_ERROR, fatal: true, reason: 'invalid ADTS sampling index:' + adtsSampleingIndex });\n    return;\n  }\n  adtsChanelConfig = (data[offset + 2] & 0x01) << 2;\n  // byte 3\n  adtsChanelConfig |= (data[offset + 3] & 0xC0) >>> 6;\n  logger[\"b\" /* logger */].log('manifest codec:' + audioCodec + ',ADTS data:type:' + adtsObjectType + ',sampleingIndex:' + adtsSampleingIndex + '[' + adtsSampleingRates[adtsSampleingIndex] + 'Hz],channelConfig:' + adtsChanelConfig);\n  // firefox: freq less than 24kHz = AAC SBR (HE-AAC)\n  if (/firefox/i.test(userAgent)) {\n    if (adtsSampleingIndex >= 6) {\n      adtsObjectType = 5;\n      config = new Array(4);\n      // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\n      // there is a factor 2 between frame sample rate and output sample rate\n      // multiply frequency by 2 (see table below, equivalent to substract 3)\n      adtsExtensionSampleingIndex = adtsSampleingIndex - 3;\n    } else {\n      adtsObjectType = 2;\n      config = new Array(2);\n      adtsExtensionSampleingIndex = adtsSampleingIndex;\n    }\n    // Android : always use AAC\n  } else if (userAgent.indexOf('android') !== -1) {\n    adtsObjectType = 2;\n    config = new Array(2);\n    adtsExtensionSampleingIndex = adtsSampleingIndex;\n  } else {\n    /*  for other browsers (Chrome/Vivaldi/Opera ...)\n        always force audio type to be HE-AAC SBR, as some browsers do not support audio codec switch properly (like Chrome ...)\n    */\n    adtsObjectType = 5;\n    config = new Array(4);\n    // if (manifest codec is HE-AAC or HE-AACv2) OR (manifest codec not specified AND frequency less than 24kHz)\n    if (audioCodec && (audioCodec.indexOf('mp4a.40.29') !== -1 || audioCodec.indexOf('mp4a.40.5') !== -1) || !audioCodec && adtsSampleingIndex >= 6) {\n      // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\n      // there is a factor 2 between frame sample rate and output sample rate\n      // multiply frequency by 2 (see table below, equivalent to substract 3)\n      adtsExtensionSampleingIndex = adtsSampleingIndex - 3;\n    } else {\n      // if (manifest codec is AAC) AND (frequency less than 24kHz AND nb channel is 1) OR (manifest codec not specified and mono audio)\n      // Chrome fails to play back with low frequency AAC LC mono when initialized with HE-AAC.  This is not a problem with stereo.\n      if (audioCodec && audioCodec.indexOf('mp4a.40.2') !== -1 && (adtsSampleingIndex >= 6 && adtsChanelConfig === 1 || /vivaldi/i.test(userAgent)) || !audioCodec && adtsChanelConfig === 1) {\n        adtsObjectType = 2;\n        config = new Array(2);\n      }\n      adtsExtensionSampleingIndex = adtsSampleingIndex;\n    }\n  }\n  /* refer to http://wiki.multimedia.cx/index.php?title=MPEG-4_Audio#Audio_Specific_Config\n      ISO 14496-3 (AAC).pdf - Table 1.13 — Syntax of AudioSpecificConfig()\n    Audio Profile / Audio Object Type\n    0: Null\n    1: AAC Main\n    2: AAC LC (Low Complexity)\n    3: AAC SSR (Scalable Sample Rate)\n    4: AAC LTP (Long Term Prediction)\n    5: SBR (Spectral Band Replication)\n    6: AAC Scalable\n   sampling freq\n    0: 96000 Hz\n    1: 88200 Hz\n    2: 64000 Hz\n    3: 48000 Hz\n    4: 44100 Hz\n    5: 32000 Hz\n    6: 24000 Hz\n    7: 22050 Hz\n    8: 16000 Hz\n    9: 12000 Hz\n    10: 11025 Hz\n    11: 8000 Hz\n    12: 7350 Hz\n    13: Reserved\n    14: Reserved\n    15: frequency is written explictly\n    Channel Configurations\n    These are the channel configurations:\n    0: Defined in AOT Specifc Config\n    1: 1 channel: front-center\n    2: 2 channels: front-left, front-right\n  */\n  // audioObjectType = profile => profile, the MPEG-4 Audio Object Type minus 1\n  config[0] = adtsObjectType << 3;\n  // samplingFrequencyIndex\n  config[0] |= (adtsSampleingIndex & 0x0E) >> 1;\n  config[1] |= (adtsSampleingIndex & 0x01) << 7;\n  // channelConfiguration\n  config[1] |= adtsChanelConfig << 3;\n  if (adtsObjectType === 5) {\n    // adtsExtensionSampleingIndex\n    config[1] |= (adtsExtensionSampleingIndex & 0x0E) >> 1;\n    config[2] = (adtsExtensionSampleingIndex & 0x01) << 7;\n    // adtsObjectType (force to 2, chrome is checking that object type is less than 5 ???\n    //    https://chromium.googlesource.com/chromium/src.git/+/master/media/formats/mp4/aac.cc\n    config[2] |= 2 << 2;\n    config[3] = 0;\n  }\n  return { config: config, samplerate: adtsSampleingRates[adtsSampleingIndex], channelCount: adtsChanelConfig, codec: 'mp4a.40.' + adtsObjectType, manifestCodec: manifestCodec };\n}\n\nfunction isHeaderPattern(data, offset) {\n  return data[offset] === 0xff && (data[offset + 1] & 0xf6) === 0xf0;\n}\n\nfunction getHeaderLength(data, offset) {\n  return data[offset + 1] & 0x01 ? 7 : 9;\n}\n\nfunction getFullFrameLength(data, offset) {\n  return (data[offset + 3] & 0x03) << 11 | data[offset + 4] << 3 | (data[offset + 5] & 0xE0) >>> 5;\n}\n\nfunction isHeader(data, offset) {\n  // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\n  // Layer bits (position 14 and 15) in header should be always 0 for ADTS\n  // More info https://wiki.multimedia.cx/index.php?title=ADTS\n  if (offset + 1 < data.length && isHeaderPattern(data, offset)) return true;\n\n  return false;\n}\n\nfunction adts_probe(data, offset) {\n  // same as isHeader but we also check that ADTS frame follows last ADTS frame\n  // or end of data is reached\n  if (offset + 1 < data.length && isHeaderPattern(data, offset)) {\n    // ADTS header Length\n    var headerLength = getHeaderLength(data, offset);\n    // ADTS frame Length\n    var frameLength = headerLength;\n    if (offset + 5 < data.length) frameLength = getFullFrameLength(data, offset);\n\n    var newOffset = offset + frameLength;\n    if (newOffset === data.length || newOffset + 1 < data.length && isHeaderPattern(data, newOffset)) return true;\n  }\n  return false;\n}\n\nfunction initTrackConfig(track, observer, data, offset, audioCodec) {\n  if (!track.samplerate) {\n    var config = getAudioConfig(observer, data, offset, audioCodec);\n    track.config = config.config;\n    track.samplerate = config.samplerate;\n    track.channelCount = config.channelCount;\n    track.codec = config.codec;\n    track.manifestCodec = config.manifestCodec;\n    logger[\"b\" /* logger */].log('parsed codec:' + track.codec + ',rate:' + config.samplerate + ',nb channel:' + config.channelCount);\n  }\n}\n\nfunction getFrameDuration(samplerate) {\n  return 1024 * 90000 / samplerate;\n}\n\nfunction parseFrameHeader(data, offset, pts, frameIndex, frameDuration) {\n  var headerLength = void 0,\n      frameLength = void 0,\n      stamp = void 0;\n  var length = data.length;\n\n  // The protection skip bit tells us if we have 2 bytes of CRC data at the end of the ADTS header\n  headerLength = getHeaderLength(data, offset);\n  // retrieve frame size\n  frameLength = getFullFrameLength(data, offset);\n  frameLength -= headerLength;\n\n  if (frameLength > 0 && offset + headerLength + frameLength <= length) {\n    stamp = pts + frameIndex * frameDuration;\n    // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}/${(stamp/90).toFixed(0)}`);\n    return { headerLength: headerLength, frameLength: frameLength, stamp: stamp };\n  }\n\n  return undefined;\n}\n\nfunction appendFrame(track, data, offset, pts, frameIndex) {\n  var frameDuration = getFrameDuration(track.samplerate);\n  var header = parseFrameHeader(data, offset, pts, frameIndex, frameDuration);\n  if (header) {\n    var stamp = header.stamp;\n    var headerLength = header.headerLength;\n    var frameLength = header.frameLength;\n\n    // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}/${(stamp/90).toFixed(0)}`);\n    var aacSample = {\n      unit: data.subarray(offset + headerLength, offset + headerLength + frameLength),\n      pts: stamp,\n      dts: stamp\n    };\n\n    track.samples.push(aacSample);\n    track.len += frameLength;\n\n    return { sample: aacSample, length: frameLength + headerLength };\n  }\n\n  return undefined;\n}\n// EXTERNAL MODULE: ./src/demux/id3.js\nvar id3 = __webpack_require__(4);\n\n// CONCATENATED MODULE: ./src/demux/aacdemuxer.js\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * AAC demuxer\n */\n\n\n\n\nvar aacdemuxer_AACDemuxer = function () {\n  function AACDemuxer(observer, remuxer, config) {\n    _classCallCheck(this, AACDemuxer);\n\n    this.observer = observer;\n    this.config = config;\n    this.remuxer = remuxer;\n  }\n\n  AACDemuxer.prototype.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, duration) {\n    this._audioTrack = { container: 'audio/adts', type: 'audio', id: 0, sequenceNumber: 0, isAAC: true, samples: [], len: 0, manifestCodec: audioCodec, duration: duration, inputTimeScale: 90000 };\n  };\n\n  AACDemuxer.prototype.resetTimeStamp = function resetTimeStamp() {};\n\n  AACDemuxer.probe = function probe(data) {\n    if (!data) return false;\n\n    // Check for the ADTS sync word\n    // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\n    // Layer bits (position 14 and 15) in header should be always 0 for ADTS\n    // More info https://wiki.multimedia.cx/index.php?title=ADTS\n    var id3Data = id3[\"a\" /* default */].getID3Data(data, 0) || [];\n    var offset = id3Data.length;\n\n    for (var length = data.length; offset < length; offset++) {\n      if (adts_probe(data, offset)) {\n        logger[\"b\" /* logger */].log('ADTS sync word found !');\n        return true;\n      }\n    }\n    return false;\n  };\n\n  // feed incoming data to the front of the parsing pipeline\n\n\n  AACDemuxer.prototype.append = function append(data, timeOffset, contiguous, accurateTimeOffset) {\n    var track = this._audioTrack;\n    var id3Data = id3[\"a\" /* default */].getID3Data(data, 0) || [];\n    var timestamp = id3[\"a\" /* default */].getTimeStamp(id3Data);\n    var pts = timestamp ? 90 * timestamp : timeOffset * 90000;\n    var frameIndex = 0;\n    var stamp = pts;\n    var length = data.length;\n    var offset = id3Data.length;\n\n    var id3Samples = [{ pts: stamp, dts: stamp, data: id3Data }];\n\n    while (offset < length - 1) {\n      if (isHeader(data, offset) && offset + 5 < length) {\n        initTrackConfig(track, this.observer, data, offset, track.manifestCodec);\n        var frame = appendFrame(track, data, offset, pts, frameIndex);\n        if (frame) {\n          offset += frame.length;\n          stamp = frame.sample.pts;\n          frameIndex++;\n        } else {\n          logger[\"b\" /* logger */].log('Unable to parse AAC frame');\n          break;\n        }\n      } else if (id3[\"a\" /* default */].isHeader(data, offset)) {\n        id3Data = id3[\"a\" /* default */].getID3Data(data, offset);\n        id3Samples.push({ pts: stamp, dts: stamp, data: id3Data });\n        offset += id3Data.length;\n      } else {\n        // nothing found, keep looking\n        offset++;\n      }\n    }\n\n    this.remuxer.remux(track, { samples: [] }, { samples: id3Samples, inputTimeScale: 90000 }, { samples: [] }, timeOffset, contiguous, accurateTimeOffset);\n  };\n\n  AACDemuxer.prototype.destroy = function destroy() {};\n\n  return AACDemuxer;\n}();\n\n/* harmony default export */ var aacdemuxer = (aacdemuxer_AACDemuxer);\n// EXTERNAL MODULE: ./src/demux/mp4demuxer.js\nvar mp4demuxer = __webpack_require__(7);\n\n// CONCATENATED MODULE: ./src/demux/mpegaudio.js\n/**\n *  MPEG parser helper\n */\n\nvar MpegAudio = {\n\n  BitratesMap: [32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160],\n\n  SamplingRateMap: [44100, 48000, 32000, 22050, 24000, 16000, 11025, 12000, 8000],\n\n  SamplesCoefficients: [\n  // MPEG 2.5\n  [0, // Reserved\n  72, // Layer3\n  144, // Layer2\n  12 // Layer1\n  ],\n  // Reserved\n  [0, // Reserved\n  0, // Layer3\n  0, // Layer2\n  0 // Layer1\n  ],\n  // MPEG 2\n  [0, // Reserved\n  72, // Layer3\n  144, // Layer2\n  12 // Layer1\n  ],\n  // MPEG 1\n  [0, // Reserved\n  144, // Layer3\n  144, // Layer2\n  12 // Layer1\n  ]],\n\n  BytesInSlot: [0, // Reserved\n  1, // Layer3\n  1, // Layer2\n  4 // Layer1\n  ],\n\n  appendFrame: function appendFrame(track, data, offset, pts, frameIndex) {\n    // Using http://www.datavoyage.com/mpgscript/mpeghdr.htm as a reference\n    if (offset + 24 > data.length) return undefined;\n\n    var header = this.parseHeader(data, offset);\n    if (header && offset + header.frameLength <= data.length) {\n      var frameDuration = header.samplesPerFrame * 90000 / header.sampleRate;\n      var stamp = pts + frameIndex * frameDuration;\n      var sample = { unit: data.subarray(offset, offset + header.frameLength), pts: stamp, dts: stamp };\n\n      track.config = [];\n      track.channelCount = header.channelCount;\n      track.samplerate = header.sampleRate;\n      track.samples.push(sample);\n      track.len += header.frameLength;\n\n      return { sample: sample, length: header.frameLength };\n    }\n\n    return undefined;\n  },\n\n  parseHeader: function parseHeader(data, offset) {\n    var headerB = data[offset + 1] >> 3 & 3;\n    var headerC = data[offset + 1] >> 1 & 3;\n    var headerE = data[offset + 2] >> 4 & 15;\n    var headerF = data[offset + 2] >> 2 & 3;\n    var headerG = data[offset + 2] >> 1 & 1;\n    if (headerB !== 1 && headerE !== 0 && headerE !== 15 && headerF !== 3) {\n      var columnInBitrates = headerB === 3 ? 3 - headerC : headerC === 3 ? 3 : 4;\n      var bitRate = MpegAudio.BitratesMap[columnInBitrates * 14 + headerE - 1] * 1000;\n      var columnInSampleRates = headerB === 3 ? 0 : headerB === 2 ? 1 : 2;\n      var sampleRate = MpegAudio.SamplingRateMap[columnInSampleRates * 3 + headerF];\n      var channelCount = data[offset + 3] >> 6 === 3 ? 1 : 2; // If bits of channel mode are `11` then it is a single channel (Mono)\n      var sampleCoefficient = MpegAudio.SamplesCoefficients[headerB][headerC];\n      var bytesInSlot = MpegAudio.BytesInSlot[headerC];\n      var samplesPerFrame = sampleCoefficient * 8 * bytesInSlot;\n      var frameLength = parseInt(sampleCoefficient * bitRate / sampleRate + headerG, 10) * bytesInSlot;\n\n      return { sampleRate: sampleRate, channelCount: channelCount, frameLength: frameLength, samplesPerFrame: samplesPerFrame };\n    }\n\n    return undefined;\n  },\n\n  isHeaderPattern: function isHeaderPattern(data, offset) {\n    return data[offset] === 0xff && (data[offset + 1] & 0xe0) === 0xe0 && (data[offset + 1] & 0x06) !== 0x00;\n  },\n\n  isHeader: function isHeader(data, offset) {\n    // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\n    // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\n    // More info http://www.mp3-tech.org/programmer/frame_header.html\n    if (offset + 1 < data.length && this.isHeaderPattern(data, offset)) return true;\n\n    return false;\n  },\n\n  probe: function probe(data, offset) {\n    // same as isHeader but we also check that MPEG frame follows last MPEG frame\n    // or end of data is reached\n    if (offset + 1 < data.length && this.isHeaderPattern(data, offset)) {\n      // MPEG header Length\n      var headerLength = 4;\n      // MPEG frame Length\n      var header = this.parseHeader(data, offset);\n      var frameLength = headerLength;\n      if (header && header.frameLength) frameLength = header.frameLength;\n\n      var newOffset = offset + frameLength;\n      if (newOffset === data.length || newOffset + 1 < data.length && this.isHeaderPattern(data, newOffset)) return true;\n    }\n    return false;\n  }\n};\n\n/* harmony default export */ var mpegaudio = (MpegAudio);\n// CONCATENATED MODULE: ./src/demux/exp-golomb.js\nfunction exp_golomb__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * Parser for exponential Golomb codes, a variable-bitwidth number encoding scheme used by h264.\n*/\n\n\n\nvar exp_golomb_ExpGolomb = function () {\n  function ExpGolomb(data) {\n    exp_golomb__classCallCheck(this, ExpGolomb);\n\n    this.data = data;\n    // the number of bytes left to examine in this.data\n    this.bytesAvailable = data.byteLength;\n    // the current word being examined\n    this.word = 0; // :uint\n    // the number of bits left to examine in the current word\n    this.bitsAvailable = 0; // :uint\n  }\n\n  // ():void\n\n\n  ExpGolomb.prototype.loadWord = function loadWord() {\n    var data = this.data,\n        bytesAvailable = this.bytesAvailable,\n        position = data.byteLength - bytesAvailable,\n        workingBytes = new Uint8Array(4),\n        availableBytes = Math.min(4, bytesAvailable);\n    if (availableBytes === 0) throw new Error('no bytes available');\n\n    workingBytes.set(data.subarray(position, position + availableBytes));\n    this.word = new DataView(workingBytes.buffer).getUint32(0);\n    // track the amount of this.data that has been processed\n    this.bitsAvailable = availableBytes * 8;\n    this.bytesAvailable -= availableBytes;\n  };\n\n  // (count:int):void\n\n\n  ExpGolomb.prototype.skipBits = function skipBits(count) {\n    var skipBytes = void 0; // :int\n    if (this.bitsAvailable > count) {\n      this.word <<= count;\n      this.bitsAvailable -= count;\n    } else {\n      count -= this.bitsAvailable;\n      skipBytes = count >> 3;\n      count -= skipBytes >> 3;\n      this.bytesAvailable -= skipBytes;\n      this.loadWord();\n      this.word <<= count;\n      this.bitsAvailable -= count;\n    }\n  };\n\n  // (size:int):uint\n\n\n  ExpGolomb.prototype.readBits = function readBits(size) {\n    var bits = Math.min(this.bitsAvailable, size),\n        // :uint\n    valu = this.word >>> 32 - bits; // :uint\n    if (size > 32) logger[\"b\" /* logger */].error('Cannot read more than 32 bits at a time');\n\n    this.bitsAvailable -= bits;\n    if (this.bitsAvailable > 0) this.word <<= bits;else if (this.bytesAvailable > 0) this.loadWord();\n\n    bits = size - bits;\n    if (bits > 0 && this.bitsAvailable) return valu << bits | this.readBits(bits);else return valu;\n  };\n\n  // ():uint\n\n\n  ExpGolomb.prototype.skipLZ = function skipLZ() {\n    var leadingZeroCount = void 0; // :uint\n    for (leadingZeroCount = 0; leadingZeroCount < this.bitsAvailable; ++leadingZeroCount) {\n      if ((this.word & 0x80000000 >>> leadingZeroCount) !== 0) {\n        // the first bit of working word is 1\n        this.word <<= leadingZeroCount;\n        this.bitsAvailable -= leadingZeroCount;\n        return leadingZeroCount;\n      }\n    }\n    // we exhausted word and still have not found a 1\n    this.loadWord();\n    return leadingZeroCount + this.skipLZ();\n  };\n\n  // ():void\n\n\n  ExpGolomb.prototype.skipUEG = function skipUEG() {\n    this.skipBits(1 + this.skipLZ());\n  };\n\n  // ():void\n\n\n  ExpGolomb.prototype.skipEG = function skipEG() {\n    this.skipBits(1 + this.skipLZ());\n  };\n\n  // ():uint\n\n\n  ExpGolomb.prototype.readUEG = function readUEG() {\n    var clz = this.skipLZ(); // :uint\n    return this.readBits(clz + 1) - 1;\n  };\n\n  // ():int\n\n\n  ExpGolomb.prototype.readEG = function readEG() {\n    var valu = this.readUEG(); // :int\n    if (0x01 & valu) {\n      // the number is odd if the low order bit is set\n      return 1 + valu >>> 1; // add 1 to make it even, and divide by 2\n    } else {\n      return -1 * (valu >>> 1); // divide by two then make it negative\n    }\n  };\n\n  // Some convenience functions\n  // :Boolean\n\n\n  ExpGolomb.prototype.readBoolean = function readBoolean() {\n    return this.readBits(1) === 1;\n  };\n\n  // ():int\n\n\n  ExpGolomb.prototype.readUByte = function readUByte() {\n    return this.readBits(8);\n  };\n\n  // ():int\n\n\n  ExpGolomb.prototype.readUShort = function readUShort() {\n    return this.readBits(16);\n  };\n  // ():int\n\n\n  ExpGolomb.prototype.readUInt = function readUInt() {\n    return this.readBits(32);\n  };\n\n  /**\n   * Advance the ExpGolomb decoder past a scaling list. The scaling\n   * list is optionally transmitted as part of a sequence parameter\n   * set and is not relevant to transmuxing.\n   * @param count {number} the number of entries in this scaling list\n   * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1\n   */\n\n\n  ExpGolomb.prototype.skipScalingList = function skipScalingList(count) {\n    var lastScale = 8,\n        nextScale = 8,\n        j = void 0,\n        deltaScale = void 0;\n    for (j = 0; j < count; j++) {\n      if (nextScale !== 0) {\n        deltaScale = this.readEG();\n        nextScale = (lastScale + deltaScale + 256) % 256;\n      }\n      lastScale = nextScale === 0 ? lastScale : nextScale;\n    }\n  };\n\n  /**\n   * Read a sequence parameter set and return some interesting video\n   * properties. A sequence parameter set is the H264 metadata that\n   * describes the properties of upcoming video frames.\n   * @param data {Uint8Array} the bytes of a sequence parameter set\n   * @return {object} an object with configuration parsed from the\n   * sequence parameter set, including the dimensions of the\n   * associated video frames.\n   */\n\n\n  ExpGolomb.prototype.readSPS = function readSPS() {\n    var frameCropLeftOffset = 0,\n        frameCropRightOffset = 0,\n        frameCropTopOffset = 0,\n        frameCropBottomOffset = 0,\n        profileIdc = void 0,\n        profileCompat = void 0,\n        levelIdc = void 0,\n        numRefFramesInPicOrderCntCycle = void 0,\n        picWidthInMbsMinus1 = void 0,\n        picHeightInMapUnitsMinus1 = void 0,\n        frameMbsOnlyFlag = void 0,\n        scalingListCount = void 0,\n        i = void 0,\n        readUByte = this.readUByte.bind(this),\n        readBits = this.readBits.bind(this),\n        readUEG = this.readUEG.bind(this),\n        readBoolean = this.readBoolean.bind(this),\n        skipBits = this.skipBits.bind(this),\n        skipEG = this.skipEG.bind(this),\n        skipUEG = this.skipUEG.bind(this),\n        skipScalingList = this.skipScalingList.bind(this);\n\n    readUByte();\n    profileIdc = readUByte(); // profile_idc\n    profileCompat = readBits(5); // constraint_set[0-4]_flag, u(5)\n    skipBits(3); // reserved_zero_3bits u(3),\n    levelIdc = readUByte(); // level_idc u(8)\n    skipUEG(); // seq_parameter_set_id\n    // some profiles have more optional data we don't need\n    if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {\n      var chromaFormatIdc = readUEG();\n      if (chromaFormatIdc === 3) skipBits(1); // separate_colour_plane_flag\n\n      skipUEG(); // bit_depth_luma_minus8\n      skipUEG(); // bit_depth_chroma_minus8\n      skipBits(1); // qpprime_y_zero_transform_bypass_flag\n      if (readBoolean()) {\n        // seq_scaling_matrix_present_flag\n        scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;\n        for (i = 0; i < scalingListCount; i++) {\n          if (readBoolean()) {\n            // seq_scaling_list_present_flag[ i ]\n            if (i < 6) skipScalingList(16);else skipScalingList(64);\n          }\n        }\n      }\n    }\n    skipUEG(); // log2_max_frame_num_minus4\n    var picOrderCntType = readUEG();\n    if (picOrderCntType === 0) {\n      readUEG(); // log2_max_pic_order_cnt_lsb_minus4\n    } else if (picOrderCntType === 1) {\n      skipBits(1); // delta_pic_order_always_zero_flag\n      skipEG(); // offset_for_non_ref_pic\n      skipEG(); // offset_for_top_to_bottom_field\n      numRefFramesInPicOrderCntCycle = readUEG();\n      for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\n        skipEG();\n      } // offset_for_ref_frame[ i ]\n    }\n    skipUEG(); // max_num_ref_frames\n    skipBits(1); // gaps_in_frame_num_value_allowed_flag\n    picWidthInMbsMinus1 = readUEG();\n    picHeightInMapUnitsMinus1 = readUEG();\n    frameMbsOnlyFlag = readBits(1);\n    if (frameMbsOnlyFlag === 0) skipBits(1); // mb_adaptive_frame_field_flag\n\n    skipBits(1); // direct_8x8_inference_flag\n    if (readBoolean()) {\n      // frame_cropping_flag\n      frameCropLeftOffset = readUEG();\n      frameCropRightOffset = readUEG();\n      frameCropTopOffset = readUEG();\n      frameCropBottomOffset = readUEG();\n    }\n    var pixelRatio = [1, 1];\n    if (readBoolean()) {\n      // vui_parameters_present_flag\n      if (readBoolean()) {\n        // aspect_ratio_info_present_flag\n        var aspectRatioIdc = readUByte();\n        switch (aspectRatioIdc) {\n          case 1:\n            pixelRatio = [1, 1];break;\n          case 2:\n            pixelRatio = [12, 11];break;\n          case 3:\n            pixelRatio = [10, 11];break;\n          case 4:\n            pixelRatio = [16, 11];break;\n          case 5:\n            pixelRatio = [40, 33];break;\n          case 6:\n            pixelRatio = [24, 11];break;\n          case 7:\n            pixelRatio = [20, 11];break;\n          case 8:\n            pixelRatio = [32, 11];break;\n          case 9:\n            pixelRatio = [80, 33];break;\n          case 10:\n            pixelRatio = [18, 11];break;\n          case 11:\n            pixelRatio = [15, 11];break;\n          case 12:\n            pixelRatio = [64, 33];break;\n          case 13:\n            pixelRatio = [160, 99];break;\n          case 14:\n            pixelRatio = [4, 3];break;\n          case 15:\n            pixelRatio = [3, 2];break;\n          case 16:\n            pixelRatio = [2, 1];break;\n          case 255:\n            {\n              pixelRatio = [readUByte() << 8 | readUByte(), readUByte() << 8 | readUByte()];\n              break;\n            }\n        }\n      }\n    }\n    return {\n      width: Math.ceil((picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2),\n      height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - (frameMbsOnlyFlag ? 2 : 4) * (frameCropTopOffset + frameCropBottomOffset),\n      pixelRatio: pixelRatio\n    };\n  };\n\n  ExpGolomb.prototype.readSliceType = function readSliceType() {\n    // skip NALu type\n    this.readUByte();\n    // discard first_mb_in_slice\n    this.readUEG();\n    // return slice_type\n    return this.readUEG();\n  };\n\n  return ExpGolomb;\n}();\n\n/* harmony default export */ var exp_golomb = (exp_golomb_ExpGolomb);\n// CONCATENATED MODULE: ./src/demux/sample-aes.js\nfunction sample_aes__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * SAMPLE-AES decrypter\n*/\n\n\n\nvar sample_aes_SampleAesDecrypter = function () {\n  function SampleAesDecrypter(observer, config, decryptdata, discardEPB) {\n    sample_aes__classCallCheck(this, SampleAesDecrypter);\n\n    this.decryptdata = decryptdata;\n    this.discardEPB = discardEPB;\n    this.decrypter = new crypt_decrypter[\"a\" /* default */](observer, config, { removePKCS7Padding: false });\n  }\n\n  SampleAesDecrypter.prototype.decryptBuffer = function decryptBuffer(encryptedData, callback) {\n    this.decrypter.decrypt(encryptedData, this.decryptdata.key.buffer, this.decryptdata.iv.buffer, callback);\n  };\n\n  // AAC - encrypt all full 16 bytes blocks starting from offset 16\n\n\n  SampleAesDecrypter.prototype.decryptAacSample = function decryptAacSample(samples, sampleIndex, callback, sync) {\n    var curUnit = samples[sampleIndex].unit;\n    var encryptedData = curUnit.subarray(16, curUnit.length - curUnit.length % 16);\n    var encryptedBuffer = encryptedData.buffer.slice(encryptedData.byteOffset, encryptedData.byteOffset + encryptedData.length);\n\n    var localthis = this;\n    this.decryptBuffer(encryptedBuffer, function (decryptedData) {\n      decryptedData = new Uint8Array(decryptedData);\n      curUnit.set(decryptedData, 16);\n\n      if (!sync) localthis.decryptAacSamples(samples, sampleIndex + 1, callback);\n    });\n  };\n\n  SampleAesDecrypter.prototype.decryptAacSamples = function decryptAacSamples(samples, sampleIndex, callback) {\n    for (;; sampleIndex++) {\n      if (sampleIndex >= samples.length) {\n        callback();\n        return;\n      }\n\n      if (samples[sampleIndex].unit.length < 32) continue;\n\n      var sync = this.decrypter.isSync();\n\n      this.decryptAacSample(samples, sampleIndex, callback, sync);\n\n      if (!sync) return;\n    }\n  };\n\n  // AVC - encrypt one 16 bytes block out of ten, starting from offset 32\n\n\n  SampleAesDecrypter.prototype.getAvcEncryptedData = function getAvcEncryptedData(decodedData) {\n    var encryptedDataLen = Math.floor((decodedData.length - 48) / 160) * 16 + 16;\n    var encryptedData = new Int8Array(encryptedDataLen);\n    var outputPos = 0;\n    for (var inputPos = 32; inputPos <= decodedData.length - 16; inputPos += 160, outputPos += 16) {\n      encryptedData.set(decodedData.subarray(inputPos, inputPos + 16), outputPos);\n    }return encryptedData;\n  };\n\n  SampleAesDecrypter.prototype.getAvcDecryptedUnit = function getAvcDecryptedUnit(decodedData, decryptedData) {\n    decryptedData = new Uint8Array(decryptedData);\n    var inputPos = 0;\n    for (var outputPos = 32; outputPos <= decodedData.length - 16; outputPos += 160, inputPos += 16) {\n      decodedData.set(decryptedData.subarray(inputPos, inputPos + 16), outputPos);\n    }return decodedData;\n  };\n\n  SampleAesDecrypter.prototype.decryptAvcSample = function decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit, sync) {\n    var decodedData = this.discardEPB(curUnit.data);\n    var encryptedData = this.getAvcEncryptedData(decodedData);\n    var localthis = this;\n\n    this.decryptBuffer(encryptedData.buffer, function (decryptedData) {\n      curUnit.data = localthis.getAvcDecryptedUnit(decodedData, decryptedData);\n\n      if (!sync) localthis.decryptAvcSamples(samples, sampleIndex, unitIndex + 1, callback);\n    });\n  };\n\n  SampleAesDecrypter.prototype.decryptAvcSamples = function decryptAvcSamples(samples, sampleIndex, unitIndex, callback) {\n    for (;; sampleIndex++, unitIndex = 0) {\n      if (sampleIndex >= samples.length) {\n        callback();\n        return;\n      }\n\n      var curUnits = samples[sampleIndex].units;\n      for (;; unitIndex++) {\n        if (unitIndex >= curUnits.length) break;\n\n        var curUnit = curUnits[unitIndex];\n        if (curUnit.length <= 48 || curUnit.type !== 1 && curUnit.type !== 5) continue;\n\n        var sync = this.decrypter.isSync();\n\n        this.decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit, sync);\n\n        if (!sync) return;\n      }\n    }\n  };\n\n  return SampleAesDecrypter;\n}();\n\n/* harmony default export */ var sample_aes = (sample_aes_SampleAesDecrypter);\n// CONCATENATED MODULE: ./src/demux/tsdemuxer.js\nfunction tsdemuxer__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * highly optimized TS demuxer:\n * parse PAT, PMT\n * extract PES packet from audio and video PIDs\n * extract AVC/H264 NAL units and AAC/ADTS samples from PES packet\n * trigger the remuxer upon parsing completion\n * it also tries to workaround as best as it can audio codec switch (HE-AAC to AAC and vice versa), without having to restart the MediaSource.\n * it also controls the remuxing process :\n * upon discontinuity or level switch detection, it will also notifies the remuxer so that it can reset its state.\n*/\n\n\n\n\n\n\n// import Hex from '../utils/hex';\n\n\n\n// We are using fixed track IDs for driving the MP4 remuxer\n// instead of following the TS PIDs.\n// There is no reason not to do this and some browsers/SourceBuffer-demuxers\n// may not like if there are TrackID \"switches\"\n// See https://github.com/video-dev/hls.js/issues/1331\n// Here we are mapping our internal track types to constant MP4 track IDs\n// With MSE currently one can only have one track of each, and we are muxing\n// whatever video/audio rendition in them.\nvar RemuxerTrackIdConfig = {\n  video: 0,\n  audio: 1,\n  id3: 2,\n  text: 3\n};\n\nvar tsdemuxer_TSDemuxer = function () {\n  function TSDemuxer(observer, remuxer, config, typeSupported) {\n    tsdemuxer__classCallCheck(this, TSDemuxer);\n\n    this.observer = observer;\n    this.config = config;\n    this.typeSupported = typeSupported;\n    this.remuxer = remuxer;\n    this.sampleAes = null;\n  }\n\n  TSDemuxer.prototype.setDecryptData = function setDecryptData(decryptdata) {\n    if (decryptdata != null && decryptdata.key != null && decryptdata.method === 'SAMPLE-AES') this.sampleAes = new sample_aes(this.observer, this.config, decryptdata, this.discardEPB);else this.sampleAes = null;\n  };\n\n  TSDemuxer.probe = function probe(data) {\n    var syncOffset = TSDemuxer._syncOffset(data);\n    if (syncOffset < 0) {\n      return false;\n    } else {\n      if (syncOffset) logger[\"b\" /* logger */].warn('MPEG2-TS detected but first sync word found @ offset ' + syncOffset + ', junk ahead ?');\n\n      return true;\n    }\n  };\n\n  TSDemuxer._syncOffset = function _syncOffset(data) {\n    // scan 1000 first bytes\n    var scanwindow = Math.min(1000, data.length - 3 * 188);\n    var i = 0;\n    while (i < scanwindow) {\n      // a TS fragment should contain at least 3 TS packets, a PAT, a PMT, and one PID, each starting with 0x47\n      if (data[i] === 0x47 && data[i + 188] === 0x47 && data[i + 2 * 188] === 0x47) return i;else i++;\n    }\n    return -1;\n  };\n\n  /**\n   * Creates a track model internal to demuxer used to drive remuxing input\n   *\n   * @param {string} type 'audio' | 'video' | 'id3' | 'text'\n   * @param {number} duration\n   * @return {object} TSDemuxer's internal track model\n   */\n\n\n  TSDemuxer.createTrack = function createTrack(type, duration) {\n    return {\n      container: type === 'video' || type === 'audio' ? 'video/mp2t' : undefined,\n      type: type,\n      id: RemuxerTrackIdConfig[type],\n      pid: -1,\n      inputTimeScale: 90000,\n      sequenceNumber: 0,\n      samples: [],\n      len: 0,\n      dropped: type === 'video' ? 0 : undefined,\n      isAAC: type === 'audio' ? true : undefined,\n      duration: type === 'audio' ? duration : undefined\n    };\n  };\n\n  /**\n   * Initializes a new init segment on the demuxer/remuxer interface. Needed for discontinuities/track-switches (or at stream start)\n   * Resets all internal track instances of the demuxer.\n   *\n   * @override Implements generic demuxing/remuxing interface (see DemuxerInline)\n   * @param {object} initSegment\n   * @param {string} audioCodec\n   * @param {string} videoCodec\n   * @param {number} duration (in TS timescale = 90kHz)\n   */\n\n\n  TSDemuxer.prototype.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, duration) {\n    this.pmtParsed = false;\n    this._pmtId = -1;\n\n    this._avcTrack = TSDemuxer.createTrack('video', duration);\n    this._audioTrack = TSDemuxer.createTrack('audio', duration);\n    this._id3Track = TSDemuxer.createTrack('id3', duration);\n    this._txtTrack = TSDemuxer.createTrack('text', duration);\n\n    // flush any partial content\n    this.aacOverFlow = null;\n    this.aacLastPTS = null;\n    this.avcSample = null;\n    this.audioCodec = audioCodec;\n    this.videoCodec = videoCodec;\n    this._duration = duration;\n  };\n\n  /**\n   *\n   * @override\n   */\n\n\n  TSDemuxer.prototype.resetTimeStamp = function resetTimeStamp() {};\n\n  // feed incoming data to the front of the parsing pipeline\n\n\n  TSDemuxer.prototype.append = function append(data, timeOffset, contiguous, accurateTimeOffset) {\n    var start = void 0,\n        len = data.length,\n        stt = void 0,\n        pid = void 0,\n        atf = void 0,\n        offset = void 0,\n        pes = void 0,\n        unknownPIDs = false;\n    this.contiguous = contiguous;\n    var pmtParsed = this.pmtParsed,\n        avcTrack = this._avcTrack,\n        audioTrack = this._audioTrack,\n        id3Track = this._id3Track,\n        avcId = avcTrack.pid,\n        audioId = audioTrack.pid,\n        id3Id = id3Track.pid,\n        pmtId = this._pmtId,\n        avcData = avcTrack.pesData,\n        audioData = audioTrack.pesData,\n        id3Data = id3Track.pesData,\n        parsePAT = this._parsePAT,\n        parsePMT = this._parsePMT,\n        parsePES = this._parsePES,\n        parseAVCPES = this._parseAVCPES.bind(this),\n        parseAACPES = this._parseAACPES.bind(this),\n        parseMPEGPES = this._parseMPEGPES.bind(this),\n        parseID3PES = this._parseID3PES.bind(this);\n\n    var syncOffset = TSDemuxer._syncOffset(data);\n\n    // don't parse last TS packet if incomplete\n    len -= (len + syncOffset) % 188;\n\n    // loop through TS packets\n    for (start = syncOffset; start < len; start += 188) {\n      if (data[start] === 0x47) {\n        stt = !!(data[start + 1] & 0x40);\n        // pid is a 13-bit field starting at the last bit of TS[1]\n        pid = ((data[start + 1] & 0x1f) << 8) + data[start + 2];\n        atf = (data[start + 3] & 0x30) >> 4;\n        // if an adaption field is present, its length is specified by the fifth byte of the TS packet header.\n        if (atf > 1) {\n          offset = start + 5 + data[start + 4];\n          // continue if there is only adaptation field\n          if (offset === start + 188) continue;\n        } else {\n          offset = start + 4;\n        }\n        switch (pid) {\n          case avcId:\n            if (stt) {\n              if (avcData && (pes = parsePES(avcData)) && pes.pts !== undefined) parseAVCPES(pes, false);\n\n              avcData = { data: [], size: 0 };\n            }\n            if (avcData) {\n              avcData.data.push(data.subarray(offset, start + 188));\n              avcData.size += start + 188 - offset;\n            }\n            break;\n          case audioId:\n            if (stt) {\n              if (audioData && (pes = parsePES(audioData)) && pes.pts !== undefined) {\n                if (audioTrack.isAAC) parseAACPES(pes);else parseMPEGPES(pes);\n              }\n              audioData = { data: [], size: 0 };\n            }\n            if (audioData) {\n              audioData.data.push(data.subarray(offset, start + 188));\n              audioData.size += start + 188 - offset;\n            }\n            break;\n          case id3Id:\n            if (stt) {\n              if (id3Data && (pes = parsePES(id3Data)) && pes.pts !== undefined) parseID3PES(pes);\n\n              id3Data = { data: [], size: 0 };\n            }\n            if (id3Data) {\n              id3Data.data.push(data.subarray(offset, start + 188));\n              id3Data.size += start + 188 - offset;\n            }\n            break;\n          case 0:\n            if (stt) offset += data[offset] + 1;\n\n            pmtId = this._pmtId = parsePAT(data, offset);\n            break;\n          case pmtId:\n            if (stt) offset += data[offset] + 1;\n\n            var parsedPIDs = parsePMT(data, offset, this.typeSupported.mpeg === true || this.typeSupported.mp3 === true, this.sampleAes != null);\n\n            // only update track id if track PID found while parsing PMT\n            // this is to avoid resetting the PID to -1 in case\n            // track PID transiently disappears from the stream\n            // this could happen in case of transient missing audio samples for example\n            // NOTE this is only the PID of the track as found in TS,\n            // but we are not using this for MP4 track IDs.\n            avcId = parsedPIDs.avc;\n            if (avcId > 0) avcTrack.pid = avcId;\n\n            audioId = parsedPIDs.audio;\n            if (audioId > 0) {\n              audioTrack.pid = audioId;\n              audioTrack.isAAC = parsedPIDs.isAAC;\n            }\n            id3Id = parsedPIDs.id3;\n            if (id3Id > 0) id3Track.pid = id3Id;\n\n            if (unknownPIDs && !pmtParsed) {\n              logger[\"b\" /* logger */].log('reparse from beginning');\n              unknownPIDs = false;\n              // we set it to -188, the += 188 in the for loop will reset start to 0\n              start = syncOffset - 188;\n            }\n            pmtParsed = this.pmtParsed = true;\n            break;\n          case 17:\n          case 0x1fff:\n            break;\n          default:\n            unknownPIDs = true;\n            break;\n        }\n      } else {\n        this.observer.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].FRAG_PARSING_ERROR, fatal: false, reason: 'TS packet did not start with 0x47' });\n      }\n    }\n    // try to parse last PES packets\n    if (avcData && (pes = parsePES(avcData)) && pes.pts !== undefined) {\n      parseAVCPES(pes, true);\n      avcTrack.pesData = null;\n    } else {\n      // either avcData null or PES truncated, keep it for next frag parsing\n      avcTrack.pesData = avcData;\n    }\n\n    if (audioData && (pes = parsePES(audioData)) && pes.pts !== undefined) {\n      if (audioTrack.isAAC) parseAACPES(pes);else parseMPEGPES(pes);\n\n      audioTrack.pesData = null;\n    } else {\n      if (audioData && audioData.size) logger[\"b\" /* logger */].log('last AAC PES packet truncated,might overlap between fragments');\n\n      // either audioData null or PES truncated, keep it for next frag parsing\n      audioTrack.pesData = audioData;\n    }\n\n    if (id3Data && (pes = parsePES(id3Data)) && pes.pts !== undefined) {\n      parseID3PES(pes);\n      id3Track.pesData = null;\n    } else {\n      // either id3Data null or PES truncated, keep it for next frag parsing\n      id3Track.pesData = id3Data;\n    }\n\n    if (this.sampleAes == null) this.remuxer.remux(audioTrack, avcTrack, id3Track, this._txtTrack, timeOffset, contiguous, accurateTimeOffset);else this.decryptAndRemux(audioTrack, avcTrack, id3Track, this._txtTrack, timeOffset, contiguous, accurateTimeOffset);\n  };\n\n  TSDemuxer.prototype.decryptAndRemux = function decryptAndRemux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset) {\n    if (audioTrack.samples && audioTrack.isAAC) {\n      var localthis = this;\n      this.sampleAes.decryptAacSamples(audioTrack.samples, 0, function () {\n        localthis.decryptAndRemuxAvc(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset);\n      });\n    } else {\n      this.decryptAndRemuxAvc(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset);\n    }\n  };\n\n  TSDemuxer.prototype.decryptAndRemuxAvc = function decryptAndRemuxAvc(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset) {\n    if (videoTrack.samples) {\n      var localthis = this;\n      this.sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, function () {\n        localthis.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset);\n      });\n    } else {\n      this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset);\n    }\n  };\n\n  TSDemuxer.prototype.destroy = function destroy() {\n    this._initPTS = this._initDTS = undefined;\n    this._duration = 0;\n  };\n\n  TSDemuxer.prototype._parsePAT = function _parsePAT(data, offset) {\n    // skip the PSI header and parse the first PMT entry\n    return (data[offset + 10] & 0x1F) << 8 | data[offset + 11];\n    // logger.log('PMT PID:'  + this._pmtId);\n  };\n\n  TSDemuxer.prototype._parsePMT = function _parsePMT(data, offset, mpegSupported, isSampleAes) {\n    var sectionLength = void 0,\n        tableEnd = void 0,\n        programInfoLength = void 0,\n        pid = void 0,\n        result = { audio: -1, avc: -1, id3: -1, isAAC: true };\n    sectionLength = (data[offset + 1] & 0x0f) << 8 | data[offset + 2];\n    tableEnd = offset + 3 + sectionLength - 4;\n    // to determine where the table is, we have to figure out how\n    // long the program info descriptors are\n    programInfoLength = (data[offset + 10] & 0x0f) << 8 | data[offset + 11];\n    // advance the offset to the first entry in the mapping table\n    offset += 12 + programInfoLength;\n    while (offset < tableEnd) {\n      pid = (data[offset + 1] & 0x1F) << 8 | data[offset + 2];\n      switch (data[offset]) {\n        case 0xcf:\n          // SAMPLE-AES AAC\n          if (!isSampleAes) {\n            logger[\"b\" /* logger */].log('unkown stream type:' + data[offset]);\n            break;\n          }\n        /* falls through */\n\n        // ISO/IEC 13818-7 ADTS AAC (MPEG-2 lower bit-rate audio)\n        case 0x0f:\n          // logger.log('AAC PID:'  + pid);\n          if (result.audio === -1) result.audio = pid;\n\n          break;\n\n        // Packetized metadata (ID3)\n        case 0x15:\n          // logger.log('ID3 PID:'  + pid);\n          if (result.id3 === -1) result.id3 = pid;\n\n          break;\n\n        case 0xdb:\n          // SAMPLE-AES AVC\n          if (!isSampleAes) {\n            logger[\"b\" /* logger */].log('unkown stream type:' + data[offset]);\n            break;\n          }\n        /* falls through */\n\n        // ITU-T Rec. H.264 and ISO/IEC 14496-10 (lower bit-rate video)\n        case 0x1b:\n          // logger.log('AVC PID:'  + pid);\n          if (result.avc === -1) result.avc = pid;\n\n          break;\n\n        // ISO/IEC 11172-3 (MPEG-1 audio)\n        // or ISO/IEC 13818-3 (MPEG-2 halved sample rate audio)\n        case 0x03:\n        case 0x04:\n          // logger.log('MPEG PID:'  + pid);\n          if (!mpegSupported) {\n            logger[\"b\" /* logger */].log('MPEG audio found, not supported in this browser for now');\n          } else if (result.audio === -1) {\n            result.audio = pid;\n            result.isAAC = false;\n          }\n          break;\n\n        case 0x24:\n          logger[\"b\" /* logger */].warn('HEVC stream type found, not supported for now');\n          break;\n\n        default:\n          logger[\"b\" /* logger */].log('unkown stream type:' + data[offset]);\n          break;\n      }\n      // move to the next table entry\n      // skip past the elementary stream descriptors, if present\n      offset += ((data[offset + 3] & 0x0F) << 8 | data[offset + 4]) + 5;\n    }\n    return result;\n  };\n\n  TSDemuxer.prototype._parsePES = function _parsePES(stream) {\n    var i = 0,\n        frag = void 0,\n        pesFlags = void 0,\n        pesPrefix = void 0,\n        pesLen = void 0,\n        pesHdrLen = void 0,\n        pesData = void 0,\n        pesPts = void 0,\n        pesDts = void 0,\n        payloadStartOffset = void 0,\n        data = stream.data;\n    // safety check\n    if (!stream || stream.size === 0) return null;\n\n    // we might need up to 19 bytes to read PES header\n    // if first chunk of data is less than 19 bytes, let's merge it with following ones until we get 19 bytes\n    // usually only one merge is needed (and this is rare ...)\n    while (data[0].length < 19 && data.length > 1) {\n      var newData = new Uint8Array(data[0].length + data[1].length);\n      newData.set(data[0]);\n      newData.set(data[1], data[0].length);\n      data[0] = newData;\n      data.splice(1, 1);\n    }\n    // retrieve PTS/DTS from first fragment\n    frag = data[0];\n    pesPrefix = (frag[0] << 16) + (frag[1] << 8) + frag[2];\n    if (pesPrefix === 1) {\n      pesLen = (frag[4] << 8) + frag[5];\n      // if PES parsed length is not zero and greater than total received length, stop parsing. PES might be truncated\n      // minus 6 : PES header size\n      if (pesLen && pesLen > stream.size - 6) return null;\n\n      pesFlags = frag[7];\n      if (pesFlags & 0xC0) {\n        /* PES header described here : http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n            as PTS / DTS is 33 bit we cannot use bitwise operator in JS,\n            as Bitwise operators treat their operands as a sequence of 32 bits */\n        pesPts = (frag[9] & 0x0E) * 536870912 + // 1 << 29\n        (frag[10] & 0xFF) * 4194304 + // 1 << 22\n        (frag[11] & 0xFE) * 16384 + // 1 << 14\n        (frag[12] & 0xFF) * 128 + // 1 << 7\n        (frag[13] & 0xFE) / 2;\n        // check if greater than 2^32 -1\n        if (pesPts > 4294967295) {\n          // decrement 2^33\n          pesPts -= 8589934592;\n        }\n        if (pesFlags & 0x40) {\n          pesDts = (frag[14] & 0x0E) * 536870912 + // 1 << 29\n          (frag[15] & 0xFF) * 4194304 + // 1 << 22\n          (frag[16] & 0xFE) * 16384 + // 1 << 14\n          (frag[17] & 0xFF) * 128 + // 1 << 7\n          (frag[18] & 0xFE) / 2;\n          // check if greater than 2^32 -1\n          if (pesDts > 4294967295) {\n            // decrement 2^33\n            pesDts -= 8589934592;\n          }\n          if (pesPts - pesDts > 60 * 90000) {\n            logger[\"b\" /* logger */].warn(Math.round((pesPts - pesDts) / 90000) + 's delta between PTS and DTS, align them');\n            pesPts = pesDts;\n          }\n        } else {\n          pesDts = pesPts;\n        }\n      }\n      pesHdrLen = frag[8];\n      // 9 bytes : 6 bytes for PES header + 3 bytes for PES extension\n      payloadStartOffset = pesHdrLen + 9;\n\n      stream.size -= payloadStartOffset;\n      // reassemble PES packet\n      pesData = new Uint8Array(stream.size);\n      for (var j = 0, dataLen = data.length; j < dataLen; j++) {\n        frag = data[j];\n        var len = frag.byteLength;\n        if (payloadStartOffset) {\n          if (payloadStartOffset > len) {\n            // trim full frag if PES header bigger than frag\n            payloadStartOffset -= len;\n            continue;\n          } else {\n            // trim partial frag if PES header smaller than frag\n            frag = frag.subarray(payloadStartOffset);\n            len -= payloadStartOffset;\n            payloadStartOffset = 0;\n          }\n        }\n        pesData.set(frag, i);\n        i += len;\n      }\n      if (pesLen) {\n        // payload size : remove PES header + PES extension\n        pesLen -= pesHdrLen + 3;\n      }\n      return { data: pesData, pts: pesPts, dts: pesDts, len: pesLen };\n    } else {\n      return null;\n    }\n  };\n\n  TSDemuxer.prototype.pushAccesUnit = function pushAccesUnit(avcSample, avcTrack) {\n    if (avcSample.units.length && avcSample.frame) {\n      var samples = avcTrack.samples;\n      var nbSamples = samples.length;\n      // only push AVC sample if starting with a keyframe is not mandatory OR\n      //    if keyframe already found in this fragment OR\n      //       keyframe found in last fragment (track.sps) AND\n      //          samples already appended (we already found a keyframe in this fragment) OR fragment is contiguous\n      if (!this.config.forceKeyFrameOnDiscontinuity || avcSample.key === true || avcTrack.sps && (nbSamples || this.contiguous)) {\n        avcSample.id = nbSamples;\n        samples.push(avcSample);\n      } else {\n        // dropped samples, track it\n        avcTrack.dropped++;\n      }\n    }\n    if (avcSample.debug.length) logger[\"b\" /* logger */].log(avcSample.pts + '/' + avcSample.dts + ':' + avcSample.debug);\n  };\n\n  TSDemuxer.prototype._parseAVCPES = function _parseAVCPES(pes, last) {\n    var _this = this;\n\n    // logger.log('parse new PES');\n    var track = this._avcTrack,\n        units = this._parseAVCNALu(pes.data),\n        debug = false,\n        expGolombDecoder = void 0,\n        avcSample = this.avcSample,\n        push = void 0,\n        spsfound = false,\n        i = void 0,\n        pushAccesUnit = this.pushAccesUnit.bind(this),\n        createAVCSample = function createAVCSample(key, pts, dts, debug) {\n      return { key: key, pts: pts, dts: dts, units: [], debug: debug };\n    };\n    // free pes.data to save up some memory\n    pes.data = null;\n\n    // if new NAL units found and last sample still there, let's push ...\n    // this helps parsing streams with missing AUD (only do this if AUD never found)\n    if (avcSample && units.length && !track.audFound) {\n      pushAccesUnit(avcSample, track);\n      avcSample = this.avcSample = createAVCSample(false, pes.pts, pes.dts, '');\n    }\n\n    units.forEach(function (unit) {\n      switch (unit.type) {\n        // NDR\n        case 1:\n          push = true;\n          if (!avcSample) avcSample = _this.avcSample = createAVCSample(true, pes.pts, pes.dts, '');\n\n          if (debug) avcSample.debug += 'NDR ';\n\n          avcSample.frame = true;\n          var data = unit.data;\n          // only check slice type to detect KF in case SPS found in same packet (any keyframe is preceded by SPS ...)\n          if (spsfound && data.length > 4) {\n            // retrieve slice type by parsing beginning of NAL unit (follow H264 spec, slice_header definition) to detect keyframe embedded in NDR\n            var sliceType = new exp_golomb(data).readSliceType();\n            // 2 : I slice, 4 : SI slice, 7 : I slice, 9: SI slice\n            // SI slice : A slice that is coded using intra prediction only and using quantisation of the prediction samples.\n            // An SI slice can be coded such that its decoded samples can be constructed identically to an SP slice.\n            // I slice: A slice that is not an SI slice that is decoded using intra prediction only.\n            // if (sliceType === 2 || sliceType === 7) {\n            if (sliceType === 2 || sliceType === 4 || sliceType === 7 || sliceType === 9) avcSample.key = true;\n          }\n          break;\n        // IDR\n        case 5:\n          push = true;\n          // handle PES not starting with AUD\n          if (!avcSample) avcSample = _this.avcSample = createAVCSample(true, pes.pts, pes.dts, '');\n\n          if (debug) avcSample.debug += 'IDR ';\n\n          avcSample.key = true;\n          avcSample.frame = true;\n          break;\n        // SEI\n        case 6:\n          push = true;\n          if (debug && avcSample) avcSample.debug += 'SEI ';\n\n          expGolombDecoder = new exp_golomb(_this.discardEPB(unit.data));\n\n          // skip frameType\n          expGolombDecoder.readUByte();\n\n          var payloadType = 0;\n          var payloadSize = 0;\n          var endOfCaptions = false;\n          var b = 0;\n\n          while (!endOfCaptions && expGolombDecoder.bytesAvailable > 1) {\n            payloadType = 0;\n            do {\n              b = expGolombDecoder.readUByte();\n              payloadType += b;\n            } while (b === 0xFF);\n\n            // Parse payload size.\n            payloadSize = 0;\n            do {\n              b = expGolombDecoder.readUByte();\n              payloadSize += b;\n            } while (b === 0xFF);\n\n            // TODO: there can be more than one payload in an SEI packet...\n            // TODO: need to read type and size in a while loop to get them all\n            if (payloadType === 4 && expGolombDecoder.bytesAvailable !== 0) {\n              endOfCaptions = true;\n\n              var countryCode = expGolombDecoder.readUByte();\n\n              if (countryCode === 181) {\n                var providerCode = expGolombDecoder.readUShort();\n\n                if (providerCode === 49) {\n                  var userStructure = expGolombDecoder.readUInt();\n\n                  if (userStructure === 0x47413934) {\n                    var userDataType = expGolombDecoder.readUByte();\n\n                    // Raw CEA-608 bytes wrapped in CEA-708 packet\n                    if (userDataType === 3) {\n                      var firstByte = expGolombDecoder.readUByte();\n                      var secondByte = expGolombDecoder.readUByte();\n\n                      var totalCCs = 31 & firstByte;\n                      var byteArray = [firstByte, secondByte];\n\n                      for (i = 0; i < totalCCs; i++) {\n                        // 3 bytes per CC\n                        byteArray.push(expGolombDecoder.readUByte());\n                        byteArray.push(expGolombDecoder.readUByte());\n                        byteArray.push(expGolombDecoder.readUByte());\n                      }\n\n                      _this._insertSampleInOrder(_this._txtTrack.samples, { type: 3, pts: pes.pts, bytes: byteArray });\n                    }\n                  }\n                }\n              }\n            } else if (payloadSize < expGolombDecoder.bytesAvailable) {\n              for (i = 0; i < payloadSize; i++) {\n                expGolombDecoder.readUByte();\n              }\n            }\n          }\n          break;\n        // SPS\n        case 7:\n          push = true;\n          spsfound = true;\n          if (debug && avcSample) avcSample.debug += 'SPS ';\n\n          if (!track.sps) {\n            expGolombDecoder = new exp_golomb(unit.data);\n            var config = expGolombDecoder.readSPS();\n            track.width = config.width;\n            track.height = config.height;\n            track.pixelRatio = config.pixelRatio;\n            track.sps = [unit.data];\n            track.duration = _this._duration;\n            var codecarray = unit.data.subarray(1, 4);\n            var codecstring = 'avc1.';\n            for (i = 0; i < 3; i++) {\n              var h = codecarray[i].toString(16);\n              if (h.length < 2) h = '0' + h;\n\n              codecstring += h;\n            }\n            track.codec = codecstring;\n          }\n          break;\n        // PPS\n        case 8:\n          push = true;\n          if (debug && avcSample) avcSample.debug += 'PPS ';\n\n          if (!track.pps) track.pps = [unit.data];\n\n          break;\n        // AUD\n        case 9:\n          push = false;\n          track.audFound = true;\n          if (avcSample) pushAccesUnit(avcSample, track);\n\n          avcSample = _this.avcSample = createAVCSample(false, pes.pts, pes.dts, debug ? 'AUD ' : '');\n          break;\n        // Filler Data\n        case 12:\n          push = false;\n          break;\n        default:\n          push = false;\n          if (avcSample) avcSample.debug += 'unknown NAL ' + unit.type + ' ';\n\n          break;\n      }\n      if (avcSample && push) {\n        var _units = avcSample.units;\n        _units.push(unit);\n      }\n    });\n    // if last PES packet, push samples\n    if (last && avcSample) {\n      pushAccesUnit(avcSample, track);\n      this.avcSample = null;\n    }\n  };\n\n  TSDemuxer.prototype._insertSampleInOrder = function _insertSampleInOrder(arr, data) {\n    var len = arr.length;\n    if (len > 0) {\n      if (data.pts >= arr[len - 1].pts) {\n        arr.push(data);\n      } else {\n        for (var pos = len - 1; pos >= 0; pos--) {\n          if (data.pts < arr[pos].pts) {\n            arr.splice(pos, 0, data);\n            break;\n          }\n        }\n      }\n    } else {\n      arr.push(data);\n    }\n  };\n\n  TSDemuxer.prototype._getLastNalUnit = function _getLastNalUnit() {\n    var avcSample = this.avcSample,\n        lastUnit = void 0;\n    // try to fallback to previous sample if current one is empty\n    if (!avcSample || avcSample.units.length === 0) {\n      var track = this._avcTrack,\n          samples = track.samples;\n      avcSample = samples[samples.length - 1];\n    }\n    if (avcSample) {\n      var units = avcSample.units;\n      lastUnit = units[units.length - 1];\n    }\n    return lastUnit;\n  };\n\n  TSDemuxer.prototype._parseAVCNALu = function _parseAVCNALu(array) {\n    var i = 0,\n        len = array.byteLength,\n        value = void 0,\n        overflow = void 0,\n        track = this._avcTrack,\n        state = track.naluState || 0,\n        lastState = state;\n    var units = [],\n        unit = void 0,\n        unitType = void 0,\n        lastUnitStart = -1,\n        lastUnitType = void 0;\n    // logger.log('PES:' + Hex.hexDump(array));\n\n    if (state === -1) {\n      // special use case where we found 3 or 4-byte start codes exactly at the end of previous PES packet\n      lastUnitStart = 0;\n      // NALu type is value read from offset 0\n      lastUnitType = array[0] & 0x1f;\n      state = 0;\n      i = 1;\n    }\n\n    while (i < len) {\n      value = array[i++];\n      // optimization. state 0 and 1 are the predominant case. let's handle them outside of the switch/case\n      if (!state) {\n        state = value ? 0 : 1;\n        continue;\n      }\n      if (state === 1) {\n        state = value ? 0 : 2;\n        continue;\n      }\n      // here we have state either equal to 2 or 3\n      if (!value) {\n        state = 3;\n      } else if (value === 1) {\n        if (lastUnitStart >= 0) {\n          unit = { data: array.subarray(lastUnitStart, i - state - 1), type: lastUnitType };\n          // logger.log('pushing NALU, type/size:' + unit.type + '/' + unit.data.byteLength);\n          units.push(unit);\n        } else {\n          // lastUnitStart is undefined => this is the first start code found in this PES packet\n          // first check if start code delimiter is overlapping between 2 PES packets,\n          // ie it started in last packet (lastState not zero)\n          // and ended at the beginning of this PES packet (i <= 4 - lastState)\n          var lastUnit = this._getLastNalUnit();\n          if (lastUnit) {\n            if (lastState && i <= 4 - lastState) {\n              // start delimiter overlapping between PES packets\n              // strip start delimiter bytes from the end of last NAL unit\n              // check if lastUnit had a state different from zero\n              if (lastUnit.state) {\n                // strip last bytes\n                lastUnit.data = lastUnit.data.subarray(0, lastUnit.data.byteLength - lastState);\n              }\n            }\n            // If NAL units are not starting right at the beginning of the PES packet, push preceding data into previous NAL unit.\n            overflow = i - state - 1;\n            if (overflow > 0) {\n              // logger.log('first NALU found with overflow:' + overflow);\n              var tmp = new Uint8Array(lastUnit.data.byteLength + overflow);\n              tmp.set(lastUnit.data, 0);\n              tmp.set(array.subarray(0, overflow), lastUnit.data.byteLength);\n              lastUnit.data = tmp;\n            }\n          }\n        }\n        // check if we can read unit type\n        if (i < len) {\n          unitType = array[i] & 0x1f;\n          // logger.log('find NALU @ offset:' + i + ',type:' + unitType);\n          lastUnitStart = i;\n          lastUnitType = unitType;\n          state = 0;\n        } else {\n          // not enough byte to read unit type. let's read it on next PES parsing\n          state = -1;\n        }\n      } else {\n        state = 0;\n      }\n    }\n    if (lastUnitStart >= 0 && state >= 0) {\n      unit = { data: array.subarray(lastUnitStart, len), type: lastUnitType, state: state };\n      units.push(unit);\n      // logger.log('pushing NALU, type/size/state:' + unit.type + '/' + unit.data.byteLength + '/' + state);\n    }\n    // no NALu found\n    if (units.length === 0) {\n      // append pes.data to previous NAL unit\n      var _lastUnit = this._getLastNalUnit();\n      if (_lastUnit) {\n        var _tmp = new Uint8Array(_lastUnit.data.byteLength + array.byteLength);\n        _tmp.set(_lastUnit.data, 0);\n        _tmp.set(array, _lastUnit.data.byteLength);\n        _lastUnit.data = _tmp;\n      }\n    }\n    track.naluState = state;\n    return units;\n  };\n\n  /**\n   * remove Emulation Prevention bytes from a RBSP\n   */\n\n\n  TSDemuxer.prototype.discardEPB = function discardEPB(data) {\n    var length = data.byteLength,\n        EPBPositions = [],\n        i = 1,\n        newLength = void 0,\n        newData = void 0;\n\n    // Find all `Emulation Prevention Bytes`\n    while (i < length - 2) {\n      if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n        EPBPositions.push(i + 2);\n        i += 2;\n      } else {\n        i++;\n      }\n    }\n\n    // If no Emulation Prevention Bytes were found just return the original\n    // array\n    if (EPBPositions.length === 0) return data;\n\n    // Create a new array to hold the NAL unit data\n    newLength = length - EPBPositions.length;\n    newData = new Uint8Array(newLength);\n    var sourceIndex = 0;\n\n    for (i = 0; i < newLength; sourceIndex++, i++) {\n      if (sourceIndex === EPBPositions[0]) {\n        // Skip this byte\n        sourceIndex++;\n        // Remove this position index\n        EPBPositions.shift();\n      }\n      newData[i] = data[sourceIndex];\n    }\n    return newData;\n  };\n\n  TSDemuxer.prototype._parseAACPES = function _parseAACPES(pes) {\n    var track = this._audioTrack,\n        data = pes.data,\n        pts = pes.pts,\n        startOffset = 0,\n        aacOverFlow = this.aacOverFlow,\n        aacLastPTS = this.aacLastPTS,\n        frameDuration = void 0,\n        frameIndex = void 0,\n        offset = void 0,\n        stamp = void 0,\n        len = void 0;\n    if (aacOverFlow) {\n      var tmp = new Uint8Array(aacOverFlow.byteLength + data.byteLength);\n      tmp.set(aacOverFlow, 0);\n      tmp.set(data, aacOverFlow.byteLength);\n      // logger.log(`AAC: append overflowing ${aacOverFlow.byteLength} bytes to beginning of new PES`);\n      data = tmp;\n    }\n    // look for ADTS header (0xFFFx)\n    for (offset = startOffset, len = data.length; offset < len - 1; offset++) {\n      if (isHeader(data, offset)) break;\n    }\n    // if ADTS header does not start straight from the beginning of the PES payload, raise an error\n    if (offset) {\n      var reason = void 0,\n          fatal = void 0;\n      if (offset < len - 1) {\n        reason = 'AAC PES did not start with ADTS header,offset:' + offset;\n        fatal = false;\n      } else {\n        reason = 'no ADTS header found in AAC PES';\n        fatal = true;\n      }\n      logger[\"b\" /* logger */].warn('parsing error:' + reason);\n      this.observer.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].FRAG_PARSING_ERROR, fatal: fatal, reason: reason });\n      if (fatal) return;\n    }\n\n    initTrackConfig(track, this.observer, data, offset, this.audioCodec);\n    frameIndex = 0;\n    frameDuration = getFrameDuration(track.samplerate);\n\n    // if last AAC frame is overflowing, we should ensure timestamps are contiguous:\n    // first sample PTS should be equal to last sample PTS + frameDuration\n    if (aacOverFlow && aacLastPTS) {\n      var newPTS = aacLastPTS + frameDuration;\n      if (Math.abs(newPTS - pts) > 1) {\n        logger[\"b\" /* logger */].log('AAC: align PTS for overlapping frames by ' + Math.round((newPTS - pts) / 90));\n        pts = newPTS;\n      }\n    }\n\n    // scan for aac samples\n    while (offset < len) {\n      if (isHeader(data, offset) && offset + 5 < len) {\n        var frame = appendFrame(track, data, offset, pts, frameIndex);\n        if (frame) {\n          // logger.log(`${Math.round(frame.sample.pts)} : AAC`);\n          offset += frame.length;\n          stamp = frame.sample.pts;\n          frameIndex++;\n        } else {\n          // logger.log('Unable to parse AAC frame');\n          break;\n        }\n      } else {\n        // nothing found, keep looking\n        offset++;\n      }\n    }\n\n    if (offset < len) aacOverFlow = data.subarray(offset, len);\n    // logger.log(`AAC: overflow detected:${len-offset}`);\n    else aacOverFlow = null;\n\n    this.aacOverFlow = aacOverFlow;\n    this.aacLastPTS = stamp;\n  };\n\n  TSDemuxer.prototype._parseMPEGPES = function _parseMPEGPES(pes) {\n    var data = pes.data;\n    var length = data.length;\n    var frameIndex = 0;\n    var offset = 0;\n    var pts = pes.pts;\n\n    while (offset < length) {\n      if (mpegaudio.isHeader(data, offset)) {\n        var frame = mpegaudio.appendFrame(this._audioTrack, data, offset, pts, frameIndex);\n        if (frame) {\n          offset += frame.length;\n          frameIndex++;\n        } else {\n          // logger.log('Unable to parse Mpeg audio frame');\n          break;\n        }\n      } else {\n        // nothing found, keep looking\n        offset++;\n      }\n    }\n  };\n\n  TSDemuxer.prototype._parseID3PES = function _parseID3PES(pes) {\n    this._id3Track.samples.push(pes);\n  };\n\n  return TSDemuxer;\n}();\n\n/* harmony default export */ var tsdemuxer = (tsdemuxer_TSDemuxer);\n// CONCATENATED MODULE: ./src/demux/mp3demuxer.js\nfunction mp3demuxer__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * MP3 demuxer\n */\n\n\n\n\nvar mp3demuxer_MP3Demuxer = function () {\n  function MP3Demuxer(observer, remuxer, config) {\n    mp3demuxer__classCallCheck(this, MP3Demuxer);\n\n    this.observer = observer;\n    this.config = config;\n    this.remuxer = remuxer;\n  }\n\n  MP3Demuxer.prototype.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, duration) {\n    this._audioTrack = { container: 'audio/mpeg', type: 'audio', id: -1, sequenceNumber: 0, isAAC: false, samples: [], len: 0, manifestCodec: audioCodec, duration: duration, inputTimeScale: 90000 };\n  };\n\n  MP3Demuxer.prototype.resetTimeStamp = function resetTimeStamp() {};\n\n  MP3Demuxer.probe = function probe(data) {\n    // check if data contains ID3 timestamp and MPEG sync word\n    var offset = void 0,\n        length = void 0;\n    var id3Data = id3[\"a\" /* default */].getID3Data(data, 0);\n    if (id3Data && id3[\"a\" /* default */].getTimeStamp(id3Data) !== undefined) {\n      // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\n      // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\n      // More info http://www.mp3-tech.org/programmer/frame_header.html\n      for (offset = id3Data.length, length = Math.min(data.length - 1, offset + 100); offset < length; offset++) {\n        if (mpegaudio.probe(data, offset)) {\n          logger[\"b\" /* logger */].log('MPEG Audio sync word found !');\n          return true;\n        }\n      }\n    }\n    return false;\n  };\n\n  // feed incoming data to the front of the parsing pipeline\n\n\n  MP3Demuxer.prototype.append = function append(data, timeOffset, contiguous, accurateTimeOffset) {\n    var id3Data = id3[\"a\" /* default */].getID3Data(data, 0);\n    var timestamp = id3[\"a\" /* default */].getTimeStamp(id3Data);\n    var pts = timestamp ? 90 * timestamp : timeOffset * 90000;\n    var offset = id3Data.length;\n    var length = data.length;\n    var frameIndex = 0,\n        stamp = 0;\n    var track = this._audioTrack;\n\n    var id3Samples = [{ pts: pts, dts: pts, data: id3Data }];\n\n    while (offset < length) {\n      if (mpegaudio.isHeader(data, offset)) {\n        var frame = mpegaudio.appendFrame(track, data, offset, pts, frameIndex);\n        if (frame) {\n          offset += frame.length;\n          stamp = frame.sample.pts;\n          frameIndex++;\n        } else {\n          // logger.log('Unable to parse Mpeg audio frame');\n          break;\n        }\n      } else if (id3[\"a\" /* default */].isHeader(data, offset)) {\n        id3Data = id3[\"a\" /* default */].getID3Data(data, offset);\n        id3Samples.push({ pts: stamp, dts: stamp, data: id3Data });\n        offset += id3Data.length;\n      } else {\n        // nothing found, keep looking\n        offset++;\n      }\n    }\n\n    this.remuxer.remux(track, { samples: [] }, { samples: id3Samples, inputTimeScale: 90000 }, { samples: [] }, timeOffset, contiguous, accurateTimeOffset);\n  };\n\n  MP3Demuxer.prototype.destroy = function destroy() {};\n\n  return MP3Demuxer;\n}();\n\n/* harmony default export */ var mp3demuxer = (mp3demuxer_MP3Demuxer);\n// CONCATENATED MODULE: ./src/helper/aac.js\nfunction aac__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n *  AAC helper\n */\n\nvar AAC = function () {\n  function AAC() {\n    aac__classCallCheck(this, AAC);\n  }\n\n  AAC.getSilentFrame = function getSilentFrame(codec, channelCount) {\n    switch (codec) {\n      case 'mp4a.40.2':\n        if (channelCount === 1) return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);else if (channelCount === 2) return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);else if (channelCount === 3) return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);else if (channelCount === 4) return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);else if (channelCount === 5) return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);else if (channelCount === 6) return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);\n\n        break;\n      // handle HE-AAC below (mp4a.40.5 / mp4a.40.29)\n      default:\n        if (channelCount === 1) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0:d=0.05\" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        } else if (channelCount === 2) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0|0:d=0.05\" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        } else if (channelCount === 3) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0|0|0:d=0.05\" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        }\n        break;\n    }\n    return null;\n  };\n\n  return AAC;\n}();\n\n/* harmony default export */ var aac = (AAC);\n// CONCATENATED MODULE: ./src/remux/mp4-generator.js\nfunction mp4_generator__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * Generate MP4 Box\n*/\n\n// import Hex from '../utils/hex';\n\nvar UINT32_MAX = Math.pow(2, 32) - 1;\n\nvar MP4 = function () {\n  function MP4() {\n    mp4_generator__classCallCheck(this, MP4);\n  }\n\n  MP4.init = function init() {\n    MP4.types = {\n      avc1: [], // codingname\n      avcC: [],\n      btrt: [],\n      dinf: [],\n      dref: [],\n      esds: [],\n      ftyp: [],\n      hdlr: [],\n      mdat: [],\n      mdhd: [],\n      mdia: [],\n      mfhd: [],\n      minf: [],\n      moof: [],\n      moov: [],\n      mp4a: [],\n      '.mp3': [],\n      mvex: [],\n      mvhd: [],\n      pasp: [],\n      sdtp: [],\n      stbl: [],\n      stco: [],\n      stsc: [],\n      stsd: [],\n      stsz: [],\n      stts: [],\n      tfdt: [],\n      tfhd: [],\n      traf: [],\n      trak: [],\n      trun: [],\n      trex: [],\n      tkhd: [],\n      vmhd: [],\n      smhd: []\n    };\n\n    var i = void 0;\n    for (i in MP4.types) {\n      if (MP4.types.hasOwnProperty(i)) {\n        MP4.types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];\n      }\n    }\n\n    var videoHdlr = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n    ]);\n\n    var audioHdlr = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x73, 0x6f, 0x75, 0x6e, // handler_type: 'soun'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\n    ]);\n\n    MP4.HDLR_TYPES = {\n      'video': videoHdlr,\n      'audio': audioHdlr\n    };\n\n    var dref = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x01, // entry_count\n    0x00, 0x00, 0x00, 0x0c, // entry_size\n    0x75, 0x72, 0x6c, 0x20, // 'url' type\n    0x00, // version 0\n    0x00, 0x00, 0x01 // entry_flags\n    ]);\n\n    var stco = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n    ]);\n\n    MP4.STTS = MP4.STSC = MP4.STCO = stco;\n\n    MP4.STSZ = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // sample_size\n    0x00, 0x00, 0x00, 0x00 // sample_count\n    ]);\n    MP4.VMHD = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x01, // flags\n    0x00, 0x00, // graphicsmode\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor\n    ]);\n    MP4.SMHD = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, // balance\n    0x00, 0x00 // reserved\n    ]);\n\n    MP4.STSD = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x01]); // entry_count\n\n    var majorBrand = new Uint8Array([105, 115, 111, 109]); // isom\n    var avc1Brand = new Uint8Array([97, 118, 99, 49]); // avc1\n    var minorVersion = new Uint8Array([0, 0, 0, 1]);\n\n    MP4.FTYP = MP4.box(MP4.types.ftyp, majorBrand, minorVersion, majorBrand, avc1Brand);\n    MP4.DINF = MP4.box(MP4.types.dinf, MP4.box(MP4.types.dref, dref));\n  };\n\n  MP4.box = function box(type) {\n    var payload = Array.prototype.slice.call(arguments, 1),\n        size = 8,\n        i = payload.length,\n        len = i,\n        result = void 0;\n    // calculate the total size we need to allocate\n    while (i--) {\n      size += payload[i].byteLength;\n    }result = new Uint8Array(size);\n    result[0] = size >> 24 & 0xff;\n    result[1] = size >> 16 & 0xff;\n    result[2] = size >> 8 & 0xff;\n    result[3] = size & 0xff;\n    result.set(type, 4);\n    // copy the payload into the result\n    for (i = 0, size = 8; i < len; i++) {\n      // copy payload[i] array @ offset size\n      result.set(payload[i], size);\n      size += payload[i].byteLength;\n    }\n    return result;\n  };\n\n  MP4.hdlr = function hdlr(type) {\n    return MP4.box(MP4.types.hdlr, MP4.HDLR_TYPES[type]);\n  };\n\n  MP4.mdat = function mdat(data) {\n    return MP4.box(MP4.types.mdat, data);\n  };\n\n  MP4.mdhd = function mdhd(timescale, duration) {\n    duration *= timescale;\n    var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n    var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.mdhd, new Uint8Array([0x01, // version 1\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time\n    timescale >> 24 & 0xFF, timescale >> 16 & 0xFF, timescale >> 8 & 0xFF, timescale & 0xFF, // timescale\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xFF, upperWordDuration >> 8 & 0xFF, upperWordDuration & 0xFF, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xFF, lowerWordDuration >> 8 & 0xFF, lowerWordDuration & 0xFF, 0x55, 0xc4, // 'und' language (undetermined)\n    0x00, 0x00]));\n  };\n\n  MP4.mdia = function mdia(track) {\n    return MP4.box(MP4.types.mdia, MP4.mdhd(track.timescale, track.duration), MP4.hdlr(track.type), MP4.minf(track));\n  };\n\n  MP4.mfhd = function mfhd(sequenceNumber) {\n    return MP4.box(MP4.types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // flags\n    sequenceNumber >> 24, sequenceNumber >> 16 & 0xFF, sequenceNumber >> 8 & 0xFF, sequenceNumber & 0xFF // sequence_number\n    ]));\n  };\n\n  MP4.minf = function minf(track) {\n    if (track.type === 'audio') return MP4.box(MP4.types.minf, MP4.box(MP4.types.smhd, MP4.SMHD), MP4.DINF, MP4.stbl(track));else return MP4.box(MP4.types.minf, MP4.box(MP4.types.vmhd, MP4.VMHD), MP4.DINF, MP4.stbl(track));\n  };\n\n  MP4.moof = function moof(sn, baseMediaDecodeTime, track) {\n    return MP4.box(MP4.types.moof, MP4.mfhd(sn), MP4.traf(track, baseMediaDecodeTime));\n  };\n  /**\n  * @param tracks... (optional) {array} the tracks associated with this movie\n  */\n\n\n  MP4.moov = function moov(tracks) {\n    var i = tracks.length,\n        boxes = [];\n\n    while (i--) {\n      boxes[i] = MP4.trak(tracks[i]);\n    }return MP4.box.apply(null, [MP4.types.moov, MP4.mvhd(tracks[0].timescale, tracks[0].duration)].concat(boxes).concat(MP4.mvex(tracks)));\n  };\n\n  MP4.mvex = function mvex(tracks) {\n    var i = tracks.length,\n        boxes = [];\n\n    while (i--) {\n      boxes[i] = MP4.trex(tracks[i]);\n    }return MP4.box.apply(null, [MP4.types.mvex].concat(boxes));\n  };\n\n  MP4.mvhd = function mvhd(timescale, duration) {\n    duration *= timescale;\n    var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n    var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    var bytes = new Uint8Array([0x01, // version 1\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time\n    timescale >> 24 & 0xFF, timescale >> 16 & 0xFF, timescale >> 8 & 0xFF, timescale & 0xFF, // timescale\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xFF, upperWordDuration >> 8 & 0xFF, upperWordDuration & 0xFF, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xFF, lowerWordDuration >> 8 & 0xFF, lowerWordDuration & 0xFF, 0x00, 0x01, 0x00, 0x00, // 1.0 rate\n    0x01, 0x00, // 1.0 volume\n    0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\n    0xff, 0xff, 0xff, 0xff // next_track_ID\n    ]);\n    return MP4.box(MP4.types.mvhd, bytes);\n  };\n\n  MP4.sdtp = function sdtp(track) {\n    var samples = track.samples || [],\n        bytes = new Uint8Array(4 + samples.length),\n        flags = void 0,\n        i = void 0;\n    // leave the full box header (4 bytes) all zero\n    // write the sample table\n    for (i = 0; i < samples.length; i++) {\n      flags = samples[i].flags;\n      bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;\n    }\n\n    return MP4.box(MP4.types.sdtp, bytes);\n  };\n\n  MP4.stbl = function stbl(track) {\n    return MP4.box(MP4.types.stbl, MP4.stsd(track), MP4.box(MP4.types.stts, MP4.STTS), MP4.box(MP4.types.stsc, MP4.STSC), MP4.box(MP4.types.stsz, MP4.STSZ), MP4.box(MP4.types.stco, MP4.STCO));\n  };\n\n  MP4.avc1 = function avc1(track) {\n    var sps = [],\n        pps = [],\n        i = void 0,\n        data = void 0,\n        len = void 0;\n    // assemble the SPSs\n\n    for (i = 0; i < track.sps.length; i++) {\n      data = track.sps[i];\n      len = data.byteLength;\n      sps.push(len >>> 8 & 0xFF);\n      sps.push(len & 0xFF);\n      sps = sps.concat(Array.prototype.slice.call(data)); // SPS\n    }\n\n    // assemble the PPSs\n    for (i = 0; i < track.pps.length; i++) {\n      data = track.pps[i];\n      len = data.byteLength;\n      pps.push(len >>> 8 & 0xFF);\n      pps.push(len & 0xFF);\n      pps = pps.concat(Array.prototype.slice.call(data));\n    }\n\n    var avcc = MP4.box(MP4.types.avcC, new Uint8Array([0x01, // version\n    sps[3], // profile\n    sps[4], // profile compat\n    sps[5], // level\n    0xfc | 3, // lengthSizeMinusOne, hard-coded to 4 bytes\n    0xE0 | track.sps.length // 3bit reserved (111) + numOfSequenceParameterSets\n    ].concat(sps).concat([track.pps.length // numOfPictureParameterSets\n    ]).concat(pps))),\n        // \"PPS\"\n    width = track.width,\n        height = track.height,\n        hSpacing = track.pixelRatio[0],\n        vSpacing = track.pixelRatio[1];\n\n    return MP4.box(MP4.types.avc1, new Uint8Array([0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // data_reference_index\n    0x00, 0x00, // pre_defined\n    0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\n    width >> 8 & 0xFF, width & 0xff, // width\n    height >> 8 & 0xFF, height & 0xff, // height\n    0x00, 0x48, 0x00, 0x00, // horizresolution\n    0x00, 0x48, 0x00, 0x00, // vertresolution\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // frame_count\n    0x12, 0x64, 0x61, 0x69, 0x6C, // dailymotion/hls.js\n    0x79, 0x6D, 0x6F, 0x74, 0x69, 0x6F, 0x6E, 0x2F, 0x68, 0x6C, 0x73, 0x2E, 0x6A, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // compressorname\n    0x00, 0x18, // depth = 24\n    0x11, 0x11]), // pre_defined = -1\n    avcc, MP4.box(MP4.types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80, // bufferSizeDB\n    0x00, 0x2d, 0xc6, 0xc0, // maxBitrate\n    0x00, 0x2d, 0xc6, 0xc0])), // avgBitrate\n    MP4.box(MP4.types.pasp, new Uint8Array([hSpacing >> 24, // hSpacing\n    hSpacing >> 16 & 0xFF, hSpacing >> 8 & 0xFF, hSpacing & 0xFF, vSpacing >> 24, // vSpacing\n    vSpacing >> 16 & 0xFF, vSpacing >> 8 & 0xFF, vSpacing & 0xFF])));\n  };\n\n  MP4.esds = function esds(track) {\n    var configlen = track.config.length;\n    return new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n\n    0x03, // descriptor_type\n    0x17 + configlen, // length\n    0x00, 0x01, // es_id\n    0x00, // stream_priority\n\n    0x04, // descriptor_type\n    0x0f + configlen, // length\n    0x40, // codec : mpeg4_audio\n    0x15, // stream_type\n    0x00, 0x00, 0x00, // buffer_size\n    0x00, 0x00, 0x00, 0x00, // maxBitrate\n    0x00, 0x00, 0x00, 0x00, // avgBitrate\n\n    0x05 // descriptor_type\n    ].concat([configlen]).concat(track.config).concat([0x06, 0x01, 0x02])); // GASpecificConfig)); // length + audio config descriptor\n  };\n\n  MP4.mp4a = function mp4a(track) {\n    var samplerate = track.samplerate;\n    return MP4.box(MP4.types.mp4a, new Uint8Array([0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // data_reference_index\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, track.channelCount, // channelcount\n    0x00, 0x10, // sampleSize:16bits\n    0x00, 0x00, 0x00, 0x00, // reserved2\n    samplerate >> 8 & 0xFF, samplerate & 0xff, //\n    0x00, 0x00]), MP4.box(MP4.types.esds, MP4.esds(track)));\n  };\n\n  MP4.mp3 = function mp3(track) {\n    var samplerate = track.samplerate;\n    return MP4.box(MP4.types['.mp3'], new Uint8Array([0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // data_reference_index\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, track.channelCount, // channelcount\n    0x00, 0x10, // sampleSize:16bits\n    0x00, 0x00, 0x00, 0x00, // reserved2\n    samplerate >> 8 & 0xFF, samplerate & 0xff, //\n    0x00, 0x00]));\n  };\n\n  MP4.stsd = function stsd(track) {\n    if (track.type === 'audio') {\n      if (!track.isAAC && track.codec === 'mp3') return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp3(track));\n\n      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp4a(track));\n    } else {\n      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.avc1(track));\n    }\n  };\n\n  MP4.tkhd = function tkhd(track) {\n    var id = track.id,\n        duration = track.duration * track.timescale,\n        width = track.width,\n        height = track.height,\n        upperWordDuration = Math.floor(duration / (UINT32_MAX + 1)),\n        lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.tkhd, new Uint8Array([0x01, // version 1\n    0x00, 0x00, 0x07, // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time\n    id >> 24 & 0xFF, id >> 16 & 0xFF, id >> 8 & 0xFF, id & 0xFF, // track_ID\n    0x00, 0x00, 0x00, 0x00, // reserved\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xFF, upperWordDuration >> 8 & 0xFF, upperWordDuration & 0xFF, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xFF, lowerWordDuration >> 8 & 0xFF, lowerWordDuration & 0xFF, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, // layer\n    0x00, 0x00, // alternate_group\n    0x00, 0x00, // non-audio track volume\n    0x00, 0x00, // reserved\n    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n    width >> 8 & 0xFF, width & 0xFF, 0x00, 0x00, // width\n    height >> 8 & 0xFF, height & 0xFF, 0x00, 0x00 // height\n    ]));\n  };\n\n  MP4.traf = function traf(track, baseMediaDecodeTime) {\n    var sampleDependencyTable = MP4.sdtp(track),\n        id = track.id,\n        upperWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1)),\n        lowerWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.traf, MP4.box(MP4.types.tfhd, new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    id >> 24, id >> 16 & 0XFF, id >> 8 & 0XFF, id & 0xFF]) // track_ID\n    ), MP4.box(MP4.types.tfdt, new Uint8Array([0x01, // version 1\n    0x00, 0x00, 0x00, // flags\n    upperWordBaseMediaDecodeTime >> 24, upperWordBaseMediaDecodeTime >> 16 & 0XFF, upperWordBaseMediaDecodeTime >> 8 & 0XFF, upperWordBaseMediaDecodeTime & 0xFF, lowerWordBaseMediaDecodeTime >> 24, lowerWordBaseMediaDecodeTime >> 16 & 0XFF, lowerWordBaseMediaDecodeTime >> 8 & 0XFF, lowerWordBaseMediaDecodeTime & 0xFF])), MP4.trun(track, sampleDependencyTable.length + 16 + // tfhd\n    20 + // tfdt\n    8 + // traf header\n    16 + // mfhd\n    8 + // moof header\n    8), // mdat header\n    sampleDependencyTable);\n  };\n\n  /**\n   * Generate a track box.\n   * @param track {object} a track definition\n   * @return {Uint8Array} the track box\n   */\n\n\n  MP4.trak = function trak(track) {\n    track.duration = track.duration || 0xffffffff;\n    return MP4.box(MP4.types.trak, MP4.tkhd(track), MP4.mdia(track));\n  };\n\n  MP4.trex = function trex(track) {\n    var id = track.id;\n    return MP4.box(MP4.types.trex, new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    id >> 24, id >> 16 & 0XFF, id >> 8 & 0XFF, id & 0xFF, // track_ID\n    0x00, 0x00, 0x00, 0x01, // default_sample_description_index\n    0x00, 0x00, 0x00, 0x00, // default_sample_duration\n    0x00, 0x00, 0x00, 0x00, // default_sample_size\n    0x00, 0x01, 0x00, 0x01 // default_sample_flags\n    ]));\n  };\n\n  MP4.trun = function trun(track, offset) {\n    var samples = track.samples || [],\n        len = samples.length,\n        arraylen = 12 + 16 * len,\n        array = new Uint8Array(arraylen),\n        i = void 0,\n        sample = void 0,\n        duration = void 0,\n        size = void 0,\n        flags = void 0,\n        cts = void 0;\n    offset += 8 + arraylen;\n    array.set([0x00, // version 0\n    0x00, 0x0f, 0x01, // flags\n    len >>> 24 & 0xFF, len >>> 16 & 0xFF, len >>> 8 & 0xFF, len & 0xFF, // sample_count\n    offset >>> 24 & 0xFF, offset >>> 16 & 0xFF, offset >>> 8 & 0xFF, offset & 0xFF // data_offset\n    ], 0);\n    for (i = 0; i < len; i++) {\n      sample = samples[i];\n      duration = sample.duration;\n      size = sample.size;\n      flags = sample.flags;\n      cts = sample.cts;\n      array.set([duration >>> 24 & 0xFF, duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, // sample_duration\n      size >>> 24 & 0xFF, size >>> 16 & 0xFF, size >>> 8 & 0xFF, size & 0xFF, // sample_size\n      flags.isLeading << 2 | flags.dependsOn, flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.paddingValue << 1 | flags.isNonSync, flags.degradPrio & 0xF0 << 8, flags.degradPrio & 0x0F, // sample_flags\n      cts >>> 24 & 0xFF, cts >>> 16 & 0xFF, cts >>> 8 & 0xFF, cts & 0xFF // sample_composition_time_offset\n      ], 12 + 16 * i);\n    }\n    return MP4.box(MP4.types.trun, array);\n  };\n\n  MP4.initSegment = function initSegment(tracks) {\n    if (!MP4.types) MP4.init();\n\n    var movie = MP4.moov(tracks),\n        result = void 0;\n    result = new Uint8Array(MP4.FTYP.byteLength + movie.byteLength);\n    result.set(MP4.FTYP);\n    result.set(movie, MP4.FTYP.byteLength);\n    return result;\n  };\n\n  return MP4;\n}();\n\n/* harmony default export */ var mp4_generator = (MP4);\n// CONCATENATED MODULE: ./src/remux/mp4-remuxer.js\nfunction mp4_remuxer__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * fMP4 remuxer\n*/\n\n\n\n\n\n\n\n// 10 seconds\nvar MAX_SILENT_FRAME_DURATION = 10 * 1000;\n\nvar mp4_remuxer_MP4Remuxer = function () {\n  function MP4Remuxer(observer, config, typeSupported, vendor) {\n    mp4_remuxer__classCallCheck(this, MP4Remuxer);\n\n    this.observer = observer;\n    this.config = config;\n    this.typeSupported = typeSupported;\n    var userAgent = navigator.userAgent;\n    this.isSafari = vendor && vendor.indexOf('Apple') > -1 && userAgent && !userAgent.match('CriOS');\n    this.ISGenerated = false;\n  }\n\n  MP4Remuxer.prototype.destroy = function destroy() {};\n\n  MP4Remuxer.prototype.resetTimeStamp = function resetTimeStamp(defaultTimeStamp) {\n    this._initPTS = this._initDTS = defaultTimeStamp;\n  };\n\n  MP4Remuxer.prototype.resetInitSegment = function resetInitSegment() {\n    this.ISGenerated = false;\n  };\n\n  MP4Remuxer.prototype.remux = function remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset) {\n    // generate Init Segment if needed\n    if (!this.ISGenerated) this.generateIS(audioTrack, videoTrack, timeOffset);\n\n    if (this.ISGenerated) {\n      var nbAudioSamples = audioTrack.samples.length;\n      var nbVideoSamples = videoTrack.samples.length;\n      var audioTimeOffset = timeOffset;\n      var videoTimeOffset = timeOffset;\n      if (nbAudioSamples && nbVideoSamples) {\n        // timeOffset is expected to be the offset of the first timestamp of this fragment (first DTS)\n        // if first audio DTS is not aligned with first video DTS then we need to take that into account\n        // when providing timeOffset to remuxAudio / remuxVideo. if we don't do that, there might be a permanent / small\n        // drift between audio and video streams\n        var audiovideoDeltaDts = (audioTrack.samples[0].dts - videoTrack.samples[0].dts) / videoTrack.inputTimeScale;\n        audioTimeOffset += Math.max(0, audiovideoDeltaDts);\n        videoTimeOffset += Math.max(0, -audiovideoDeltaDts);\n      }\n      // Purposefully remuxing audio before video, so that remuxVideo can use nextAudioPts, which is\n      // calculated in remuxAudio.\n      // logger.log('nb AAC samples:' + audioTrack.samples.length);\n      if (nbAudioSamples) {\n        // if initSegment was generated without video samples, regenerate it again\n        if (!audioTrack.timescale) {\n          logger[\"b\" /* logger */].warn('regenerate InitSegment as audio detected');\n          this.generateIS(audioTrack, videoTrack, timeOffset);\n        }\n        var audioData = this.remuxAudio(audioTrack, audioTimeOffset, contiguous, accurateTimeOffset);\n        // logger.log('nb AVC samples:' + videoTrack.samples.length);\n        if (nbVideoSamples) {\n          var audioTrackLength = void 0;\n          if (audioData) audioTrackLength = audioData.endPTS - audioData.startPTS;\n\n          // if initSegment was generated without video samples, regenerate it again\n          if (!videoTrack.timescale) {\n            logger[\"b\" /* logger */].warn('regenerate InitSegment as video detected');\n            this.generateIS(audioTrack, videoTrack, timeOffset);\n          }\n          this.remuxVideo(videoTrack, videoTimeOffset, contiguous, audioTrackLength, accurateTimeOffset);\n        }\n      } else {\n        // logger.log('nb AVC samples:' + videoTrack.samples.length);\n        if (nbVideoSamples) {\n          var videoData = this.remuxVideo(videoTrack, videoTimeOffset, contiguous, 0, accurateTimeOffset);\n          if (videoData && audioTrack.codec) this.remuxEmptyAudio(audioTrack, audioTimeOffset, contiguous, videoData);\n        }\n      }\n    }\n    // logger.log('nb ID3 samples:' + audioTrack.samples.length);\n    if (id3Track.samples.length) this.remuxID3(id3Track, timeOffset);\n\n    // logger.log('nb ID3 samples:' + audioTrack.samples.length);\n    if (textTrack.samples.length) this.remuxText(textTrack, timeOffset);\n\n    // notify end of parsing\n    this.observer.trigger(events[\"a\" /* default */].FRAG_PARSED);\n  };\n\n  MP4Remuxer.prototype.generateIS = function generateIS(audioTrack, videoTrack, timeOffset) {\n    var observer = this.observer,\n        audioSamples = audioTrack.samples,\n        videoSamples = videoTrack.samples,\n        typeSupported = this.typeSupported,\n        container = 'audio/mp4',\n        tracks = {},\n        data = { tracks: tracks },\n        computePTSDTS = this._initPTS === undefined,\n        initPTS = void 0,\n        initDTS = void 0;\n\n    if (computePTSDTS) initPTS = initDTS = Infinity;\n\n    if (audioTrack.config && audioSamples.length) {\n      // let's use audio sampling rate as MP4 time scale.\n      // rationale is that there is a integer nb of audio frames per audio sample (1024 for AAC)\n      // using audio sampling rate here helps having an integer MP4 frame duration\n      // this avoids potential rounding issue and AV sync issue\n      audioTrack.timescale = audioTrack.samplerate;\n      logger[\"b\" /* logger */].log('audio sampling rate : ' + audioTrack.samplerate);\n      if (!audioTrack.isAAC) {\n        if (typeSupported.mpeg) {\n          // Chrome and Safari\n          container = 'audio/mpeg';\n          audioTrack.codec = '';\n        } else if (typeSupported.mp3) {\n          // Firefox\n          audioTrack.codec = 'mp3';\n        }\n      }\n      tracks.audio = {\n        container: container,\n        codec: audioTrack.codec,\n        initSegment: !audioTrack.isAAC && typeSupported.mpeg ? new Uint8Array() : mp4_generator.initSegment([audioTrack]),\n        metadata: {\n          channelCount: audioTrack.channelCount\n        }\n      };\n      if (computePTSDTS) {\n        // remember first PTS of this demuxing context. for audio, PTS = DTS\n        initPTS = initDTS = audioSamples[0].pts - audioTrack.inputTimeScale * timeOffset;\n      }\n    }\n\n    if (videoTrack.sps && videoTrack.pps && videoSamples.length) {\n      // let's use input time scale as MP4 video timescale\n      // we use input time scale straight away to avoid rounding issues on frame duration / cts computation\n      var inputTimeScale = videoTrack.inputTimeScale;\n      videoTrack.timescale = inputTimeScale;\n      tracks.video = {\n        container: 'video/mp4',\n        codec: videoTrack.codec,\n        initSegment: mp4_generator.initSegment([videoTrack]),\n        metadata: {\n          width: videoTrack.width,\n          height: videoTrack.height\n        }\n      };\n      if (computePTSDTS) {\n        initPTS = Math.min(initPTS, videoSamples[0].pts - inputTimeScale * timeOffset);\n        initDTS = Math.min(initDTS, videoSamples[0].dts - inputTimeScale * timeOffset);\n        this.observer.trigger(events[\"a\" /* default */].INIT_PTS_FOUND, { initPTS: initPTS });\n      }\n    }\n\n    if (Object.keys(tracks).length) {\n      observer.trigger(events[\"a\" /* default */].FRAG_PARSING_INIT_SEGMENT, data);\n      this.ISGenerated = true;\n      if (computePTSDTS) {\n        this._initPTS = initPTS;\n        this._initDTS = initDTS;\n      }\n    } else {\n      observer.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].FRAG_PARSING_ERROR, fatal: false, reason: 'no audio/video samples found' });\n    }\n  };\n\n  MP4Remuxer.prototype.remuxVideo = function remuxVideo(track, timeOffset, contiguous, audioTrackLength, accurateTimeOffset) {\n    var offset = 8,\n        timeScale = track.timescale,\n        mp4SampleDuration = void 0,\n        mdat = void 0,\n        moof = void 0,\n        firstPTS = void 0,\n        firstDTS = void 0,\n        nextDTS = void 0,\n        lastPTS = void 0,\n        lastDTS = void 0,\n        inputSamples = track.samples,\n        outputSamples = [],\n        nbSamples = inputSamples.length,\n        ptsNormalize = this._PTSNormalize,\n        initDTS = this._initDTS;\n\n    // for (let i = 0; i < track.samples.length; i++) {\n    //   let avcSample = track.samples[i];\n    //   let units = avcSample.units;\n    //   let unitsString = '';\n    //   for (let j = 0; j < units.length ; j++) {\n    //     unitsString += units[j].type + ',';\n    //     if (units[j].data.length < 500) {\n    //       unitsString += Hex.hexDump(units[j].data);\n    //     }\n    //   }\n    //   logger.log(avcSample.pts + '/' + avcSample.dts + ',' + unitsString + avcSample.units.length);\n    // }\n\n    // if parsed fragment is contiguous with last one, let's use last DTS value as reference\n    var nextAvcDts = this.nextAvcDts;\n\n    var isSafari = this.isSafari;\n\n    if (nbSamples === 0) return;\n\n    // Safari does not like overlapping DTS on consecutive fragments. let's use nextAvcDts to overcome this if fragments are consecutive\n    if (isSafari) {\n      // also consider consecutive fragments as being contiguous (even if a level switch occurs),\n      // for sake of clarity:\n      // consecutive fragments are frags with\n      //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR\n      //  - less than 200 ms PTS gaps (timeScale/5)\n      contiguous |= inputSamples.length && nextAvcDts && (accurateTimeOffset && Math.abs(timeOffset - nextAvcDts / timeScale) < 0.1 || Math.abs(inputSamples[0].pts - nextAvcDts - initDTS) < timeScale / 5);\n    }\n\n    if (!contiguous) {\n      // if not contiguous, let's use target timeOffset\n      nextAvcDts = timeOffset * timeScale;\n    }\n\n    // PTS is coded on 33bits, and can loop from -2^32 to 2^32\n    // ptsNormalize will make PTS/DTS value monotonic, we use last known DTS value as reference value\n    inputSamples.forEach(function (sample) {\n      sample.pts = ptsNormalize(sample.pts - initDTS, nextAvcDts);\n      sample.dts = ptsNormalize(sample.dts - initDTS, nextAvcDts);\n    });\n\n    // sort video samples by DTS then PTS then demux id order\n    inputSamples.sort(function (a, b) {\n      var deltadts = a.dts - b.dts;\n      var deltapts = a.pts - b.pts;\n      return deltadts || deltapts || a.id - b.id;\n    });\n\n    // handle broken streams with PTS < DTS, tolerance up 200ms (18000 in 90kHz timescale)\n    var PTSDTSshift = inputSamples.reduce(function (prev, curr) {\n      return Math.max(Math.min(prev, curr.pts - curr.dts), -18000);\n    }, 0);\n    if (PTSDTSshift < 0) {\n      logger[\"b\" /* logger */].warn('PTS < DTS detected in video samples, shifting DTS by ' + Math.round(PTSDTSshift / 90) + ' ms to overcome this issue');\n      for (var i = 0; i < inputSamples.length; i++) {\n        inputSamples[i].dts += PTSDTSshift;\n      }\n    }\n\n    // compute first DTS and last DTS, normalize them against reference value\n    var sample = inputSamples[0];\n    firstDTS = Math.max(sample.dts, 0);\n    firstPTS = Math.max(sample.pts, 0);\n\n    // check timestamp continuity accross consecutive fragments (this is to remove inter-fragment gap/hole)\n    var delta = Math.round((firstDTS - nextAvcDts) / 90);\n    // if fragment are contiguous, detect hole/overlapping between fragments\n    if (contiguous) {\n      if (delta) {\n        if (delta > 1) logger[\"b\" /* logger */].log('AVC:' + delta + ' ms hole between fragments detected,filling it');else if (delta < -1) logger[\"b\" /* logger */].log('AVC:' + -delta + ' ms overlapping between fragments detected');\n\n        // remove hole/gap : set DTS to next expected DTS\n        firstDTS = nextAvcDts;\n        inputSamples[0].dts = firstDTS;\n        // offset PTS as well, ensure that PTS is smaller or equal than new DTS\n        firstPTS = Math.max(firstPTS - delta, nextAvcDts);\n        inputSamples[0].pts = firstPTS;\n        logger[\"b\" /* logger */].log('Video/PTS/DTS adjusted: ' + Math.round(firstPTS / 90) + '/' + Math.round(firstDTS / 90) + ',delta:' + delta + ' ms');\n      }\n    }\n    nextDTS = firstDTS;\n\n    // compute lastPTS/lastDTS\n    sample = inputSamples[inputSamples.length - 1];\n    lastDTS = Math.max(sample.dts, 0);\n    lastPTS = Math.max(sample.pts, 0, lastDTS);\n\n    // on Safari let's signal the same sample duration for all samples\n    // sample duration (as expected by trun MP4 boxes), should be the delta between sample DTS\n    // set this constant duration as being the avg delta between consecutive DTS.\n    if (isSafari) mp4SampleDuration = Math.round((lastDTS - firstDTS) / (inputSamples.length - 1));\n\n    var nbNalu = 0,\n        naluLen = 0;\n    for (var _i = 0; _i < nbSamples; _i++) {\n      // compute total/avc sample length and nb of NAL units\n      var _sample = inputSamples[_i],\n          units = _sample.units,\n          nbUnits = units.length,\n          sampleLen = 0;\n      for (var j = 0; j < nbUnits; j++) {\n        sampleLen += units[j].data.length;\n      }naluLen += sampleLen;\n      nbNalu += nbUnits;\n      _sample.length = sampleLen;\n\n      // normalize PTS/DTS\n      if (isSafari) {\n        // sample DTS is computed using a constant decoding offset (mp4SampleDuration) between samples\n        _sample.dts = firstDTS + _i * mp4SampleDuration;\n      } else {\n        // ensure sample monotonic DTS\n        _sample.dts = Math.max(_sample.dts, firstDTS);\n      }\n      // ensure that computed value is greater or equal than sample DTS\n      _sample.pts = Math.max(_sample.pts, _sample.dts);\n    }\n\n    /* concatenate the video data and construct the mdat in place\n      (need 8 more bytes to fill length and mpdat type) */\n    var mdatSize = naluLen + 4 * nbNalu + 8;\n    try {\n      mdat = new Uint8Array(mdatSize);\n    } catch (err) {\n      this.observer.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MUX_ERROR, details: errors[\"a\" /* ErrorDetails */].REMUX_ALLOC_ERROR, fatal: false, bytes: mdatSize, reason: 'fail allocating video mdat ' + mdatSize });\n      return;\n    }\n    var view = new DataView(mdat.buffer);\n    view.setUint32(0, mdatSize);\n    mdat.set(mp4_generator.types.mdat, 4);\n\n    for (var _i2 = 0; _i2 < nbSamples; _i2++) {\n      var avcSample = inputSamples[_i2],\n          avcSampleUnits = avcSample.units,\n          mp4SampleLength = 0,\n          compositionTimeOffset = void 0;\n      // convert NALU bitstream to MP4 format (prepend NALU with size field)\n      for (var _j = 0, _nbUnits = avcSampleUnits.length; _j < _nbUnits; _j++) {\n        var unit = avcSampleUnits[_j],\n            unitData = unit.data,\n            unitDataLen = unit.data.byteLength;\n        view.setUint32(offset, unitDataLen);\n        offset += 4;\n        mdat.set(unitData, offset);\n        offset += unitDataLen;\n        mp4SampleLength += 4 + unitDataLen;\n      }\n\n      if (!isSafari) {\n        // expected sample duration is the Decoding Timestamp diff of consecutive samples\n        if (_i2 < nbSamples - 1) {\n          mp4SampleDuration = inputSamples[_i2 + 1].dts - avcSample.dts;\n        } else {\n          var config = this.config,\n              lastFrameDuration = avcSample.dts - inputSamples[_i2 > 0 ? _i2 - 1 : _i2].dts;\n          if (config.stretchShortVideoTrack) {\n            // In some cases, a segment's audio track duration may exceed the video track duration.\n            // Since we've already remuxed audio, and we know how long the audio track is, we look to\n            // see if the delta to the next segment is longer than maxBufferHole.\n            // If so, playback would potentially get stuck, so we artificially inflate\n            // the duration of the last frame to minimize any potential gap between segments.\n            var maxBufferHole = config.maxBufferHole,\n                gapTolerance = Math.floor(maxBufferHole * timeScale),\n                deltaToFrameEnd = (audioTrackLength ? firstPTS + audioTrackLength * timeScale : this.nextAudioPts) - avcSample.pts;\n            if (deltaToFrameEnd > gapTolerance) {\n              // We subtract lastFrameDuration from deltaToFrameEnd to try to prevent any video\n              // frame overlap. maxBufferHole should be >> lastFrameDuration anyway.\n              mp4SampleDuration = deltaToFrameEnd - lastFrameDuration;\n              if (mp4SampleDuration < 0) mp4SampleDuration = lastFrameDuration;\n\n              logger[\"b\" /* logger */].log('It is approximately ' + deltaToFrameEnd / 90 + ' ms to the next segment; using duration ' + mp4SampleDuration / 90 + ' ms for the last video frame.');\n            } else {\n              mp4SampleDuration = lastFrameDuration;\n            }\n          } else {\n            mp4SampleDuration = lastFrameDuration;\n          }\n        }\n        compositionTimeOffset = Math.round(avcSample.pts - avcSample.dts);\n      } else {\n        compositionTimeOffset = Math.max(0, mp4SampleDuration * Math.round((avcSample.pts - avcSample.dts) / mp4SampleDuration));\n      }\n\n      // console.log('PTS/DTS/initDTS/normPTS/normDTS/relative PTS : ${avcSample.pts}/${avcSample.dts}/${initDTS}/${ptsnorm}/${dtsnorm}/${(avcSample.pts/4294967296).toFixed(3)}');\n      outputSamples.push({\n        size: mp4SampleLength,\n        // constant duration\n        duration: mp4SampleDuration,\n        cts: compositionTimeOffset,\n        flags: {\n          isLeading: 0,\n          isDependedOn: 0,\n          hasRedundancy: 0,\n          degradPrio: 0,\n          dependsOn: avcSample.key ? 2 : 1,\n          isNonSync: avcSample.key ? 0 : 1\n        }\n      });\n    }\n    // next AVC sample DTS should be equal to last sample DTS + last sample duration (in PES timescale)\n    this.nextAvcDts = lastDTS + mp4SampleDuration;\n    var dropped = track.dropped;\n    track.len = 0;\n    track.nbNalu = 0;\n    track.dropped = 0;\n    if (outputSamples.length && navigator.userAgent.toLowerCase().indexOf('chrome') > -1) {\n      var flags = outputSamples[0].flags;\n      // chrome workaround, mark first sample as being a Random Access Point to avoid sourcebuffer append issue\n      // https://code.google.com/p/chromium/issues/detail?id=229412\n      flags.dependsOn = 2;\n      flags.isNonSync = 0;\n    }\n    track.samples = outputSamples;\n    moof = mp4_generator.moof(track.sequenceNumber++, firstDTS, track);\n    track.samples = [];\n\n    var data = {\n      data1: moof,\n      data2: mdat,\n      startPTS: firstPTS / timeScale,\n      endPTS: (lastPTS + mp4SampleDuration) / timeScale,\n      startDTS: firstDTS / timeScale,\n      endDTS: this.nextAvcDts / timeScale,\n      type: 'video',\n      hasAudio: false,\n      hasVideo: true,\n      nb: outputSamples.length,\n      dropped: dropped\n    };\n    this.observer.trigger(events[\"a\" /* default */].FRAG_PARSING_DATA, data);\n    return data;\n  };\n\n  MP4Remuxer.prototype.remuxAudio = function remuxAudio(track, timeOffset, contiguous, accurateTimeOffset) {\n    var inputTimeScale = track.inputTimeScale,\n        mp4timeScale = track.timescale,\n        scaleFactor = inputTimeScale / mp4timeScale,\n        mp4SampleDuration = track.isAAC ? 1024 : 1152,\n        inputSampleDuration = mp4SampleDuration * scaleFactor,\n        ptsNormalize = this._PTSNormalize,\n        initDTS = this._initDTS,\n        rawMPEG = !track.isAAC && this.typeSupported.mpeg;\n\n    var offset = void 0,\n        mp4Sample = void 0,\n        fillFrame = void 0,\n        mdat = void 0,\n        moof = void 0,\n        firstPTS = void 0,\n        lastPTS = void 0,\n        inputSamples = track.samples,\n        outputSamples = [],\n        nextAudioPts = this.nextAudioPts;\n\n    // for audio samples, also consider consecutive fragments as being contiguous (even if a level switch occurs),\n    // for sake of clarity:\n    // consecutive fragments are frags with\n    //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR\n    //  - less than 20 audio frames distance\n    // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)\n    // this helps ensuring audio continuity\n    // and this also avoids audio glitches/cut when switching quality, or reporting wrong duration on first audio frame\n    contiguous |= inputSamples.length && nextAudioPts && (accurateTimeOffset && Math.abs(timeOffset - nextAudioPts / inputTimeScale) < 0.1 || Math.abs(inputSamples[0].pts - nextAudioPts - initDTS) < 20 * inputSampleDuration);\n\n    // compute normalized PTS\n    inputSamples.forEach(function (sample) {\n      sample.pts = sample.dts = ptsNormalize(sample.pts - initDTS, timeOffset * inputTimeScale);\n    });\n\n    // filter out sample with negative PTS that are not playable anyway\n    // if we don't remove these negative samples, they will shift all audio samples forward.\n    // leading to audio overlap between current / next fragment\n    inputSamples = inputSamples.filter(function (sample) {\n      return sample.pts >= 0;\n    });\n\n    // in case all samples have negative PTS, and have been filtered out, return now\n    if (inputSamples.length === 0) return;\n\n    if (!contiguous) {\n      if (!accurateTimeOffset) {\n        // if frag are mot contiguous and if we cant trust time offset, let's use first sample PTS as next audio PTS\n        nextAudioPts = inputSamples[0].pts;\n      } else {\n        // if timeOffset is accurate, let's use it as predicted next audio PTS\n        nextAudioPts = timeOffset * inputTimeScale;\n      }\n    }\n\n    // If the audio track is missing samples, the frames seem to get \"left-shifted\" within the\n    // resulting mp4 segment, causing sync issues and leaving gaps at the end of the audio segment.\n    // In an effort to prevent this from happening, we inject frames here where there are gaps.\n    // When possible, we inject a silent frame; when that's not possible, we duplicate the last\n    // frame.\n\n    if (track.isAAC) {\n      var maxAudioFramesDrift = this.config.maxAudioFramesDrift;\n      for (var i = 0, nextPts = nextAudioPts; i < inputSamples.length;) {\n        // First, let's see how far off this frame is from where we expect it to be\n        var sample = inputSamples[i],\n            delta;\n        var pts = sample.pts;\n        delta = pts - nextPts;\n\n        var duration = Math.abs(1000 * delta / inputTimeScale);\n\n        // If we're overlapping by more than a duration, drop this sample\n        if (delta <= -maxAudioFramesDrift * inputSampleDuration) {\n          logger[\"b\" /* logger */].warn('Dropping 1 audio frame @ ' + (nextPts / inputTimeScale).toFixed(3) + 's due to ' + Math.round(duration) + ' ms overlap.');\n          inputSamples.splice(i, 1);\n          track.len -= sample.unit.length;\n          // Don't touch nextPtsNorm or i\n        } // eslint-disable-line brace-style\n\n        // Insert missing frames if:\n        // 1: We're more than maxAudioFramesDrift frame away\n        // 2: Not more than MAX_SILENT_FRAME_DURATION away\n        // 3: currentTime (aka nextPtsNorm) is not 0\n        else if (delta >= maxAudioFramesDrift * inputSampleDuration && duration < MAX_SILENT_FRAME_DURATION && nextPts) {\n            var missing = Math.round(delta / inputSampleDuration);\n            logger[\"b\" /* logger */].warn('Injecting ' + missing + ' audio frame @ ' + (nextPts / inputTimeScale).toFixed(3) + 's due to ' + Math.round(1000 * delta / inputTimeScale) + ' ms gap.');\n            for (var j = 0; j < missing; j++) {\n              var newStamp = Math.max(nextPts, 0);\n              fillFrame = aac.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\n              if (!fillFrame) {\n                logger[\"b\" /* logger */].log('Unable to get silent frame for given audio codec; duplicating last frame instead.');\n                fillFrame = sample.unit.subarray();\n              }\n              inputSamples.splice(i, 0, { unit: fillFrame, pts: newStamp, dts: newStamp });\n              track.len += fillFrame.length;\n              nextPts += inputSampleDuration;\n              i++;\n            }\n\n            // Adjust sample to next expected pts\n            sample.pts = sample.dts = nextPts;\n            nextPts += inputSampleDuration;\n            i++;\n          } else {\n            // Otherwise, just adjust pts\n            if (Math.abs(delta) > 0.1 * inputSampleDuration) {\n              // logger.log(`Invalid frame delta ${Math.round(delta + inputSampleDuration)} at PTS ${Math.round(pts / 90)} (should be ${Math.round(inputSampleDuration)}).`);\n            }\n            sample.pts = sample.dts = nextPts;\n            nextPts += inputSampleDuration;\n            i++;\n          }\n      }\n    }\n\n    for (var _j2 = 0, _nbSamples = inputSamples.length; _j2 < _nbSamples; _j2++) {\n      var audioSample = inputSamples[_j2];\n      var unit = audioSample.unit;\n      var _pts = audioSample.pts;\n      // logger.log(`Audio/PTS:${Math.round(pts/90)}`);\n      // if not first sample\n      if (lastPTS !== undefined) {\n        mp4Sample.duration = Math.round((_pts - lastPTS) / scaleFactor);\n      } else {\n        var _delta = Math.round(1000 * (_pts - nextAudioPts) / inputTimeScale),\n            numMissingFrames = 0;\n        // if fragment are contiguous, detect hole/overlapping between fragments\n        // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)\n        if (contiguous && track.isAAC) {\n          // log delta\n          if (_delta) {\n            if (_delta > 0 && _delta < MAX_SILENT_FRAME_DURATION) {\n              numMissingFrames = Math.round((_pts - nextAudioPts) / inputSampleDuration);\n              logger[\"b\" /* logger */].log(_delta + ' ms hole between AAC samples detected,filling it');\n              if (numMissingFrames > 0) {\n                fillFrame = aac.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\n                if (!fillFrame) fillFrame = unit.subarray();\n\n                track.len += numMissingFrames * fillFrame.length;\n              }\n              // if we have frame overlap, overlapping for more than half a frame duraion\n            } else if (_delta < -12) {\n              // drop overlapping audio frames... browser will deal with it\n              logger[\"b\" /* logger */].log('drop overlapping AAC sample, expected/parsed/delta:' + (nextAudioPts / inputTimeScale).toFixed(3) + 's/' + (_pts / inputTimeScale).toFixed(3) + 's/' + -_delta + 'ms');\n              track.len -= unit.byteLength;\n              continue;\n            }\n            // set PTS/DTS to expected PTS/DTS\n            _pts = nextAudioPts;\n          }\n        }\n        // remember first PTS of our audioSamples\n        firstPTS = _pts;\n        if (track.len > 0) {\n          /* concatenate the audio data and construct the mdat in place\n            (need 8 more bytes to fill length and mdat type) */\n          var mdatSize = rawMPEG ? track.len : track.len + 8;\n          offset = rawMPEG ? 0 : 8;\n          try {\n            mdat = new Uint8Array(mdatSize);\n          } catch (err) {\n            this.observer.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MUX_ERROR, details: errors[\"a\" /* ErrorDetails */].REMUX_ALLOC_ERROR, fatal: false, bytes: mdatSize, reason: 'fail allocating audio mdat ' + mdatSize });\n            return;\n          }\n          if (!rawMPEG) {\n            var view = new DataView(mdat.buffer);\n            view.setUint32(0, mdatSize);\n            mdat.set(mp4_generator.types.mdat, 4);\n          }\n        } else {\n          // no audio samples\n          return;\n        }\n        for (var _i3 = 0; _i3 < numMissingFrames; _i3++) {\n          fillFrame = aac.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\n          if (!fillFrame) {\n            logger[\"b\" /* logger */].log('Unable to get silent frame for given audio codec; duplicating this frame instead.');\n            fillFrame = unit.subarray();\n          }\n          mdat.set(fillFrame, offset);\n          offset += fillFrame.byteLength;\n          mp4Sample = {\n            size: fillFrame.byteLength,\n            cts: 0,\n            duration: 1024,\n            flags: {\n              isLeading: 0,\n              isDependedOn: 0,\n              hasRedundancy: 0,\n              degradPrio: 0,\n              dependsOn: 1\n            }\n          };\n          outputSamples.push(mp4Sample);\n        }\n      }\n      mdat.set(unit, offset);\n      var unitLen = unit.byteLength;\n      offset += unitLen;\n      // console.log('PTS/DTS/initDTS/normPTS/normDTS/relative PTS : ${audioSample.pts}/${audioSample.dts}/${initDTS}/${ptsnorm}/${dtsnorm}/${(audioSample.pts/4294967296).toFixed(3)}');\n      mp4Sample = {\n        size: unitLen,\n        cts: 0,\n        duration: 0,\n        flags: {\n          isLeading: 0,\n          isDependedOn: 0,\n          hasRedundancy: 0,\n          degradPrio: 0,\n          dependsOn: 1\n        }\n      };\n      outputSamples.push(mp4Sample);\n      lastPTS = _pts;\n    }\n    var lastSampleDuration = 0;\n    var nbSamples = outputSamples.length;\n    // set last sample duration as being identical to previous sample\n    if (nbSamples >= 2) {\n      lastSampleDuration = outputSamples[nbSamples - 2].duration;\n      mp4Sample.duration = lastSampleDuration;\n    }\n    if (nbSamples) {\n      // next audio sample PTS should be equal to last sample PTS + duration\n      this.nextAudioPts = nextAudioPts = lastPTS + scaleFactor * lastSampleDuration;\n      // logger.log('Audio/PTS/PTSend:' + audioSample.pts.toFixed(0) + '/' + this.nextAacDts.toFixed(0));\n      track.len = 0;\n      track.samples = outputSamples;\n      if (rawMPEG) moof = new Uint8Array();else moof = mp4_generator.moof(track.sequenceNumber++, firstPTS / scaleFactor, track);\n\n      track.samples = [];\n      var start = firstPTS / inputTimeScale;\n      var end = nextAudioPts / inputTimeScale;\n      var audioData = {\n        data1: moof,\n        data2: mdat,\n        startPTS: start,\n        endPTS: end,\n        startDTS: start,\n        endDTS: end,\n        type: 'audio',\n        hasAudio: true,\n        hasVideo: false,\n        nb: nbSamples\n      };\n      this.observer.trigger(events[\"a\" /* default */].FRAG_PARSING_DATA, audioData);\n      return audioData;\n    }\n    return null;\n  };\n\n  MP4Remuxer.prototype.remuxEmptyAudio = function remuxEmptyAudio(track, timeOffset, contiguous, videoData) {\n    var inputTimeScale = track.inputTimeScale,\n        mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale,\n        scaleFactor = inputTimeScale / mp4timeScale,\n        nextAudioPts = this.nextAudioPts,\n\n\n    // sync with video's timestamp\n    startDTS = (nextAudioPts !== undefined ? nextAudioPts : videoData.startDTS * inputTimeScale) + this._initDTS,\n        endDTS = videoData.endDTS * inputTimeScale + this._initDTS,\n\n    // one sample's duration value\n    sampleDuration = 1024,\n        frameDuration = scaleFactor * sampleDuration,\n\n\n    // samples count of this segment's duration\n    nbSamples = Math.ceil((endDTS - startDTS) / frameDuration),\n\n\n    // silent frame\n    silentFrame = aac.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\n\n    logger[\"b\" /* logger */].warn('remux empty Audio');\n    // Can't remux if we can't generate a silent frame...\n    if (!silentFrame) {\n      logger[\"b\" /* logger */].trace('Unable to remuxEmptyAudio since we were unable to get a silent frame for given audio codec!');\n      return;\n    }\n\n    var samples = [];\n    for (var i = 0; i < nbSamples; i++) {\n      var stamp = startDTS + i * frameDuration;\n      samples.push({ unit: silentFrame, pts: stamp, dts: stamp });\n      track.len += silentFrame.length;\n    }\n    track.samples = samples;\n\n    this.remuxAudio(track, timeOffset, contiguous);\n  };\n\n  MP4Remuxer.prototype.remuxID3 = function remuxID3(track, timeOffset) {\n    var length = track.samples.length,\n        sample = void 0;\n    var inputTimeScale = track.inputTimeScale;\n    var initPTS = this._initPTS;\n    var initDTS = this._initDTS;\n    // consume samples\n    if (length) {\n      for (var index = 0; index < length; index++) {\n        sample = track.samples[index];\n        // setting id3 pts, dts to relative time\n        // using this._initPTS and this._initDTS to calculate relative time\n        sample.pts = (sample.pts - initPTS) / inputTimeScale;\n        sample.dts = (sample.dts - initDTS) / inputTimeScale;\n      }\n      this.observer.trigger(events[\"a\" /* default */].FRAG_PARSING_METADATA, {\n        samples: track.samples\n      });\n    }\n\n    track.samples = [];\n    timeOffset = timeOffset;\n  };\n\n  MP4Remuxer.prototype.remuxText = function remuxText(track, timeOffset) {\n    track.samples.sort(function (a, b) {\n      return a.pts - b.pts;\n    });\n\n    var length = track.samples.length,\n        sample = void 0;\n    var inputTimeScale = track.inputTimeScale;\n    var initPTS = this._initPTS;\n    // consume samples\n    if (length) {\n      for (var index = 0; index < length; index++) {\n        sample = track.samples[index];\n        // setting text pts, dts to relative time\n        // using this._initPTS and this._initDTS to calculate relative time\n        sample.pts = (sample.pts - initPTS) / inputTimeScale;\n      }\n      this.observer.trigger(events[\"a\" /* default */].FRAG_PARSING_USERDATA, {\n        samples: track.samples\n      });\n    }\n\n    track.samples = [];\n    timeOffset = timeOffset;\n  };\n\n  MP4Remuxer.prototype._PTSNormalize = function _PTSNormalize(value, reference) {\n    var offset = void 0;\n    if (reference === undefined) return value;\n\n    if (reference < value) {\n      // - 2^33\n      offset = -8589934592;\n    } else {\n      // + 2^33\n      offset = 8589934592;\n    }\n    /* PTS is 33bit (from 0 to 2^33 -1)\n      if diff between value and reference is bigger than half of the amplitude (2^32) then it means that\n      PTS looping occured. fill the gap */\n    while (Math.abs(value - reference) > 4294967296) {\n      value += offset;\n    }return value;\n  };\n\n  return MP4Remuxer;\n}();\n\n/* harmony default export */ var mp4_remuxer = (mp4_remuxer_MP4Remuxer);\n// CONCATENATED MODULE: ./src/remux/passthrough-remuxer.js\nfunction passthrough_remuxer__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * passthrough remuxer\n*/\n\n\nvar passthrough_remuxer_PassThroughRemuxer = function () {\n  function PassThroughRemuxer(observer) {\n    passthrough_remuxer__classCallCheck(this, PassThroughRemuxer);\n\n    this.observer = observer;\n  }\n\n  PassThroughRemuxer.prototype.destroy = function destroy() {};\n\n  PassThroughRemuxer.prototype.resetTimeStamp = function resetTimeStamp() {};\n\n  PassThroughRemuxer.prototype.resetInitSegment = function resetInitSegment() {};\n\n  PassThroughRemuxer.prototype.remux = function remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset, rawData) {\n    var observer = this.observer;\n    var streamType = '';\n    if (audioTrack) streamType += 'audio';\n\n    if (videoTrack) streamType += 'video';\n\n    observer.trigger(events[\"a\" /* default */].FRAG_PARSING_DATA, {\n      data1: rawData,\n      startPTS: timeOffset,\n      startDTS: timeOffset,\n      type: streamType,\n      hasAudio: !!audioTrack,\n      hasVideo: !!videoTrack,\n      nb: 1,\n      dropped: 0\n    });\n    // notify end of parsing\n    observer.trigger(events[\"a\" /* default */].FRAG_PARSED);\n  };\n\n  return PassThroughRemuxer;\n}();\n\n/* harmony default export */ var passthrough_remuxer = (passthrough_remuxer_PassThroughRemuxer);\n// CONCATENATED MODULE: ./src/demux/demuxer-inline.js\nfunction demuxer_inline__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/*  inline demuxer.\n *   probe fragments and instantiate appropriate demuxer depending on content type (TSDemuxer, AACDemuxer, ...)\n */\n\n\n\n\n\n\n\n\n\n\n\nvar demuxer_inline_DemuxerInline = function () {\n  function DemuxerInline(observer, typeSupported, config, vendor) {\n    demuxer_inline__classCallCheck(this, DemuxerInline);\n\n    this.observer = observer;\n    this.typeSupported = typeSupported;\n    this.config = config;\n    this.vendor = vendor;\n  }\n\n  DemuxerInline.prototype.destroy = function destroy() {\n    var demuxer = this.demuxer;\n    if (demuxer) demuxer.destroy();\n  };\n\n  DemuxerInline.prototype.push = function push(data, decryptdata, initSegment, audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS) {\n    if (data.byteLength > 0 && decryptdata != null && decryptdata.key != null && decryptdata.method === 'AES-128') {\n      var decrypter = this.decrypter;\n      if (decrypter == null) decrypter = this.decrypter = new crypt_decrypter[\"a\" /* default */](this.observer, this.config);\n\n      var localthis = this;\n      // performance.now() not available on WebWorker, at least on Safari Desktop\n      var startTime = void 0;\n      try {\n        startTime = performance.now();\n      } catch (error) {\n        startTime = Date.now();\n      }\n      decrypter.decrypt(data, decryptdata.key.buffer, decryptdata.iv.buffer, function (decryptedData) {\n        var endTime = void 0;\n        try {\n          endTime = performance.now();\n        } catch (error) {\n          endTime = Date.now();\n        }\n        localthis.observer.trigger(events[\"a\" /* default */].FRAG_DECRYPTED, { stats: { tstart: startTime, tdecrypt: endTime } });\n        localthis.pushDecrypted(new Uint8Array(decryptedData), decryptdata, new Uint8Array(initSegment), audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS);\n      });\n    } else {\n      this.pushDecrypted(new Uint8Array(data), decryptdata, new Uint8Array(initSegment), audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS);\n    }\n  };\n\n  DemuxerInline.prototype.pushDecrypted = function pushDecrypted(data, decryptdata, initSegment, audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS) {\n    var demuxer = this.demuxer;\n    if (!demuxer ||\n    // in case of continuity change, or track switch\n    // we might switch from content type (AAC container to TS container, or TS to fmp4 for example)\n    // so let's check that current demuxer is still valid\n    (discontinuity || trackSwitch) && !this.probe(data)) {\n      var observer = this.observer;\n      var typeSupported = this.typeSupported;\n      var config = this.config;\n      // probing order is TS/AAC/MP3/MP4\n      var muxConfig = [{ demux: tsdemuxer, remux: mp4_remuxer }, { demux: mp4demuxer[\"a\" /* default */], remux: passthrough_remuxer }, { demux: aacdemuxer, remux: mp4_remuxer }, { demux: mp3demuxer, remux: mp4_remuxer }];\n\n      // probe for content type\n      for (var i = 0, len = muxConfig.length; i < len; i++) {\n        var mux = muxConfig[i];\n        var probe = mux.demux.probe;\n        if (probe(data)) {\n          var _remuxer = this.remuxer = new mux.remux(observer, config, typeSupported, this.vendor);\n          demuxer = new mux.demux(observer, _remuxer, config, typeSupported);\n          this.probe = probe;\n          break;\n        }\n      }\n      if (!demuxer) {\n        observer.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].FRAG_PARSING_ERROR, fatal: true, reason: 'no demux matching with content found' });\n        return;\n      }\n      this.demuxer = demuxer;\n    }\n    var remuxer = this.remuxer;\n\n    if (discontinuity || trackSwitch) {\n      demuxer.resetInitSegment(initSegment, audioCodec, videoCodec, duration);\n      remuxer.resetInitSegment();\n    }\n    if (discontinuity) {\n      demuxer.resetTimeStamp(defaultInitPTS);\n      remuxer.resetTimeStamp(defaultInitPTS);\n    }\n    if (typeof demuxer.setDecryptData === 'function') demuxer.setDecryptData(decryptdata);\n\n    demuxer.append(data, timeOffset, contiguous, accurateTimeOffset);\n  };\n\n  return DemuxerInline;\n}();\n\n/* harmony default export */ var demuxer_inline = __webpack_exports__[\"a\"] = (demuxer_inline_DemuxerInline);\n\n/***/ }),\n/* 9 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nObject.defineProperty(__webpack_exports__, \"__esModule\", { value: true });\nvar cues_namespaceObject = {};\n__webpack_require__.d(cues_namespaceObject, \"newCue\", function() { return newCue; });\n\n// EXTERNAL MODULE: ./node_modules/url-toolkit/src/url-toolkit.js\nvar url_toolkit = __webpack_require__(3);\nvar url_toolkit_default = /*#__PURE__*/__webpack_require__.n(url_toolkit);\n\n// EXTERNAL MODULE: ./src/errors.js\nvar errors = __webpack_require__(2);\n\n// EXTERNAL MODULE: ./src/events.js\nvar events = __webpack_require__(1);\n\n// EXTERNAL MODULE: ./src/utils/logger.js\nvar logger = __webpack_require__(0);\n\n// CONCATENATED MODULE: ./src/event-handler.js\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/*\n*\n* All objects in the event handling chain should inherit from this class\n*\n*/\n\n\n\n\n\nvar FORBIDDEN_EVENT_NAMES = new Set(['hlsEventGeneric', 'hlsHandlerDestroying', 'hlsHandlerDestroyed']);\n\nvar event_handler_EventHandler = function () {\n  function EventHandler(hls) {\n    _classCallCheck(this, EventHandler);\n\n    this.hls = hls;\n    this.onEvent = this.onEvent.bind(this);\n\n    for (var _len = arguments.length, events = Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      events[_key - 1] = arguments[_key];\n    }\n\n    this.handledEvents = events;\n    this.useGenericHandler = true;\n\n    this.registerListeners();\n  }\n\n  EventHandler.prototype.destroy = function destroy() {\n    this.onHandlerDestroying();\n    this.unregisterListeners();\n    this.onHandlerDestroyed();\n  };\n\n  EventHandler.prototype.onHandlerDestroying = function onHandlerDestroying() {};\n\n  EventHandler.prototype.onHandlerDestroyed = function onHandlerDestroyed() {};\n\n  EventHandler.prototype.isEventHandler = function isEventHandler() {\n    return _typeof(this.handledEvents) === 'object' && this.handledEvents.length && typeof this.onEvent === 'function';\n  };\n\n  EventHandler.prototype.registerListeners = function registerListeners() {\n    if (this.isEventHandler()) {\n      this.handledEvents.forEach(function (event) {\n        if (FORBIDDEN_EVENT_NAMES.has(event)) throw new Error('Forbidden event-name: ' + event);\n\n        this.hls.on(event, this.onEvent);\n      }, this);\n    }\n  };\n\n  EventHandler.prototype.unregisterListeners = function unregisterListeners() {\n    if (this.isEventHandler()) {\n      this.handledEvents.forEach(function (event) {\n        this.hls.off(event, this.onEvent);\n      }, this);\n    }\n  };\n\n  /**\n   * arguments: event (string), data (any)\n   */\n\n\n  EventHandler.prototype.onEvent = function onEvent(event, data) {\n    this.onEventGeneric(event, data);\n  };\n\n  EventHandler.prototype.onEventGeneric = function onEventGeneric(event, data) {\n    var eventToFunction = function eventToFunction(event, data) {\n      var funcName = 'on' + event.replace('hls', '');\n      if (typeof this[funcName] !== 'function') throw new Error('Event ' + event + ' has no generic handler in this ' + this.constructor.name + ' class (tried ' + funcName + ')');\n\n      return this[funcName].bind(this, data);\n    };\n    try {\n      eventToFunction.call(this, event, data).call();\n    } catch (err) {\n      logger[\"b\" /* logger */].error('An internal error happened while handling event ' + event + '. Error message: \"' + err.message + '\". Here is a stacktrace:', err);\n      this.hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].OTHER_ERROR, details: errors[\"a\" /* ErrorDetails */].INTERNAL_EXCEPTION, fatal: false, event: event, err: err });\n    }\n  };\n\n  return EventHandler;\n}();\n\n/* harmony default export */ var event_handler = (event_handler_EventHandler);\n// EXTERNAL MODULE: ./src/demux/mp4demuxer.js\nvar mp4demuxer = __webpack_require__(7);\n\n// CONCATENATED MODULE: ./src/loader/level-key.js\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction level_key__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\nvar level_key_LevelKey = function () {\n  function LevelKey() {\n    level_key__classCallCheck(this, LevelKey);\n\n    this.method = null;\n    this.key = null;\n    this.iv = null;\n    this._uri = null;\n  }\n\n  _createClass(LevelKey, [{\n    key: 'uri',\n    get: function get() {\n      if (!this._uri && this.reluri) this._uri = url_toolkit_default.a.buildAbsoluteURL(this.baseuri, this.reluri, { alwaysNormalize: true });\n\n      return this._uri;\n    }\n  }]);\n\n  return LevelKey;\n}();\n\n/* harmony default export */ var level_key = (level_key_LevelKey);\n// CONCATENATED MODULE: ./src/loader/fragment.js\nvar fragment__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction fragment__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\n\n\nvar fragment_Fragment = function () {\n  function Fragment() {\n    var _elementaryStreams;\n\n    fragment__classCallCheck(this, Fragment);\n\n    this._url = null;\n    this._byteRange = null;\n    this._decryptdata = null;\n    this.tagList = [];\n\n    // Holds the types of data this fragment supports\n    this._elementaryStreams = (_elementaryStreams = {}, _elementaryStreams[Fragment.ElementaryStreamTypes.AUDIO] = false, _elementaryStreams[Fragment.ElementaryStreamTypes.VIDEO] = false, _elementaryStreams);\n  }\n\n  /**\n   * `type` property for this._elementaryStreams\n   *\n   * @enum\n   */\n\n\n  /**\n   * @param {ElementaryStreamType} type\n   */\n  Fragment.prototype.addElementaryStream = function addElementaryStream(type) {\n    this._elementaryStreams[type] = true;\n  };\n\n  /**\n   * @param {ElementaryStreamType} type\n   */\n\n\n  Fragment.prototype.hasElementaryStream = function hasElementaryStream(type) {\n    return this._elementaryStreams[type] === true;\n  };\n\n  /**\n   * Utility method for parseLevelPlaylist to create an initialization vector for a given segment\n   * @returns {Uint8Array}\n   */\n\n\n  Fragment.prototype.createInitializationVector = function createInitializationVector(segmentNumber) {\n    var uint8View = new Uint8Array(16);\n\n    for (var i = 12; i < 16; i++) {\n      uint8View[i] = segmentNumber >> 8 * (15 - i) & 0xff;\n    }return uint8View;\n  };\n\n  /**\n   * Utility method for parseLevelPlaylist to get a fragment's decryption data from the currently parsed encryption key data\n   * @param levelkey - a playlist's encryption info\n   * @param segmentNumber - the fragment's segment number\n   * @returns {*} - an object to be applied as a fragment's decryptdata\n   */\n\n\n  Fragment.prototype.fragmentDecryptdataFromLevelkey = function fragmentDecryptdataFromLevelkey(levelkey, segmentNumber) {\n    var decryptdata = levelkey;\n\n    if (levelkey && levelkey.method && levelkey.uri && !levelkey.iv) {\n      decryptdata = new level_key();\n      decryptdata.method = levelkey.method;\n      decryptdata.baseuri = levelkey.baseuri;\n      decryptdata.reluri = levelkey.reluri;\n      decryptdata.iv = this.createInitializationVector(segmentNumber);\n    }\n\n    return decryptdata;\n  };\n\n  fragment__createClass(Fragment, [{\n    key: 'url',\n    get: function get() {\n      if (!this._url && this.relurl) this._url = url_toolkit_default.a.buildAbsoluteURL(this.baseurl, this.relurl, { alwaysNormalize: true });\n\n      return this._url;\n    },\n    set: function set(value) {\n      this._url = value;\n    }\n  }, {\n    key: 'programDateTime',\n    get: function get() {\n      if (!this._programDateTime && this.rawProgramDateTime) this._programDateTime = new Date(Date.parse(this.rawProgramDateTime));\n\n      return this._programDateTime;\n    }\n  }, {\n    key: 'byteRange',\n    get: function get() {\n      if (!this._byteRange && !this.rawByteRange) return [];\n\n      if (this._byteRange) return this._byteRange;\n\n      var byteRange = [];\n      if (this.rawByteRange) {\n        var params = this.rawByteRange.split('@', 2);\n        if (params.length === 1) {\n          var lastByteRangeEndOffset = this.lastByteRangeEndOffset;\n          byteRange[0] = lastByteRangeEndOffset || 0;\n        } else {\n          byteRange[0] = parseInt(params[1]);\n        }\n        byteRange[1] = parseInt(params[0]) + byteRange[0];\n        this._byteRange = byteRange;\n      }\n      return byteRange;\n    }\n\n    /**\n     * @type {number}\n     */\n\n  }, {\n    key: 'byteRangeStartOffset',\n    get: function get() {\n      return this.byteRange[0];\n    }\n  }, {\n    key: 'byteRangeEndOffset',\n    get: function get() {\n      return this.byteRange[1];\n    }\n  }, {\n    key: 'decryptdata',\n    get: function get() {\n      if (!this._decryptdata) this._decryptdata = this.fragmentDecryptdataFromLevelkey(this.levelkey, this.sn);\n\n      return this._decryptdata;\n    }\n  }], [{\n    key: 'ElementaryStreamTypes',\n    get: function get() {\n      return {\n        AUDIO: 'audio',\n        VIDEO: 'video'\n      };\n    }\n  }]);\n\n  return Fragment;\n}();\n\n/* harmony default export */ var loader_fragment = (fragment_Fragment);\n// CONCATENATED MODULE: ./src/utils/attr-list.js\nfunction attr_list__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar DECIMAL_RESOLUTION_REGEX = /^(\\d+)x(\\d+)$/; // eslint-disable-line no-useless-escape\nvar ATTR_LIST_REGEX = /\\s*(.+?)\\s*=((?:\\\".*?\\\")|.*?)(?:,|$)/g; // eslint-disable-line no-useless-escape\n\n// adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js\n\nvar AttrList = function () {\n  function AttrList(attrs) {\n    attr_list__classCallCheck(this, AttrList);\n\n    if (typeof attrs === 'string') attrs = AttrList.parseAttrList(attrs);\n\n    for (var attr in attrs) {\n      if (attrs.hasOwnProperty(attr)) this[attr] = attrs[attr];\n    }\n  }\n\n  AttrList.prototype.decimalInteger = function decimalInteger(attrName) {\n    var intValue = parseInt(this[attrName], 10);\n    if (intValue > Number.MAX_SAFE_INTEGER) return Infinity;\n\n    return intValue;\n  };\n\n  AttrList.prototype.hexadecimalInteger = function hexadecimalInteger(attrName) {\n    if (this[attrName]) {\n      var stringValue = (this[attrName] || '0x').slice(2);\n      stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;\n\n      var value = new Uint8Array(stringValue.length / 2);\n      for (var i = 0; i < stringValue.length / 2; i++) {\n        value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);\n      }return value;\n    } else {\n      return null;\n    }\n  };\n\n  AttrList.prototype.hexadecimalIntegerAsNumber = function hexadecimalIntegerAsNumber(attrName) {\n    var intValue = parseInt(this[attrName], 16);\n    if (intValue > Number.MAX_SAFE_INTEGER) return Infinity;\n\n    return intValue;\n  };\n\n  AttrList.prototype.decimalFloatingPoint = function decimalFloatingPoint(attrName) {\n    return parseFloat(this[attrName]);\n  };\n\n  AttrList.prototype.enumeratedString = function enumeratedString(attrName) {\n    return this[attrName];\n  };\n\n  AttrList.prototype.decimalResolution = function decimalResolution(attrName) {\n    var res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);\n    if (res === null) return undefined;\n\n    return {\n      width: parseInt(res[1], 10),\n      height: parseInt(res[2], 10)\n    };\n  };\n\n  AttrList.parseAttrList = function parseAttrList(input) {\n    var match = void 0,\n        attrs = {};\n    ATTR_LIST_REGEX.lastIndex = 0;\n    while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {\n      var value = match[2],\n          quote = '\"';\n\n      if (value.indexOf(quote) === 0 && value.lastIndexOf(quote) === value.length - 1) value = value.slice(1, -1);\n\n      attrs[match[1]] = value;\n    }\n    return attrs;\n  };\n\n  return AttrList;\n}();\n\n/* harmony default export */ var attr_list = (AttrList);\n// CONCATENATED MODULE: ./src/utils/codecs.js\n// from http://mp4ra.org/codecs.html\nvar sampleEntryCodesISO = {\n  audio: {\n    'a3ds': true,\n    'ac-3': true,\n    'ac-4': true,\n    'alac': true,\n    'alaw': true,\n    'dra1': true,\n    'dts+': true,\n    'dts-': true,\n    'dtsc': true,\n    'dtse': true,\n    'dtsh': true,\n    'ec-3': true,\n    'enca': true,\n    'g719': true,\n    'g726': true,\n    'm4ae': true,\n    'mha1': true,\n    'mha2': true,\n    'mhm1': true,\n    'mhm2': true,\n    'mlpa': true,\n    'mp4a': true,\n    'raw ': true,\n    'Opus': true,\n    'samr': true,\n    'sawb': true,\n    'sawp': true,\n    'sevc': true,\n    'sqcp': true,\n    'ssmv': true,\n    'twos': true,\n    'ulaw': true\n  },\n  video: {\n    'avc1': true,\n    'avc2': true,\n    'avc3': true,\n    'avc4': true,\n    'avcp': true,\n    'drac': true,\n    'dvav': true,\n    'dvhe': true,\n    'encv': true,\n    'hev1': true,\n    'hvc1': true,\n    'mjp2': true,\n    'mp4v': true,\n    'mvc1': true,\n    'mvc2': true,\n    'mvc3': true,\n    'mvc4': true,\n    'resv': true,\n    'rv60': true,\n    's263': true,\n    'svc1': true,\n    'svc2': true,\n    'vc-1': true,\n    'vp08': true,\n    'vp09': true\n  }\n};\n\nfunction isCodecType(codec, type) {\n  var typeCodes = sampleEntryCodesISO[type];\n  return !!typeCodes && typeCodes[codec.slice(0, 4)] === true;\n}\n\nfunction isCodecSupportedInMp4(codec, type) {\n  return MediaSource.isTypeSupported((type || 'video') + '/mp4;codecs=\"' + codec + '\"');\n}\n\n\n// CONCATENATED MODULE: ./src/loader/m3u8-parser.js\nfunction m3u8_parser__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\n\n\n\n\n\n\n\n/**\n * M3U8 parser\n * @module\n */\n\n// https://regex101.com is your friend\nvar MASTER_PLAYLIST_REGEX = /#EXT-X-STREAM-INF:([^\\n\\r]*)[\\r\\n]+([^\\r\\n]+)/g;\nvar MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;\n\nvar LEVEL_PLAYLIST_REGEX_FAST = new RegExp([/#EXTINF:\\s*(\\d*(?:\\.\\d+)?)(?:,(.*)\\s+)?/.source, // duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title\n/|(?!#)(\\S+)/.source, // segment URI, group 3 => the URI (note newline is not eaten)\n/|#EXT-X-BYTERANGE:*(.+)/.source, // next segment's byterange, group 4 => range spec (x@y)\n/|#EXT-X-PROGRAM-DATE-TIME:(.+)/.source, // next segment's program date/time group 5 => the datetime spec\n/|#.*/.source // All other non-segment oriented tags will match with all groups empty\n].join(''), 'g');\n\nvar LEVEL_PLAYLIST_REGEX_SLOW = /(?:(?:#(EXTM3U))|(?:#EXT-X-(PLAYLIST-TYPE):(.+))|(?:#EXT-X-(MEDIA-SEQUENCE): *(\\d+))|(?:#EXT-X-(TARGETDURATION): *(\\d+))|(?:#EXT-X-(KEY):(.+))|(?:#EXT-X-(START):(.+))|(?:#EXT-X-(ENDLIST))|(?:#EXT-X-(DISCONTINUITY-SEQ)UENCE:(\\d+))|(?:#EXT-X-(DIS)CONTINUITY))|(?:#EXT-X-(VERSION):(\\d+))|(?:#EXT-X-(MAP):(.+))|(?:(#)(.*):(.*))|(?:(#)(.*))(?:.*)\\r?\\n?/;\n\nvar m3u8_parser_M3U8Parser = function () {\n  function M3U8Parser() {\n    m3u8_parser__classCallCheck(this, M3U8Parser);\n  }\n\n  M3U8Parser.findGroup = function findGroup(groups, mediaGroupId) {\n    if (!groups) return null;\n\n    var matchingGroup = null;\n\n    for (var i = 0; i < groups.length; i++) {\n      var group = groups[i];\n      if (group.id === mediaGroupId) matchingGroup = group;\n    }\n\n    return matchingGroup;\n  };\n\n  M3U8Parser.convertAVC1ToAVCOTI = function convertAVC1ToAVCOTI(codec) {\n    var result = void 0,\n        avcdata = codec.split('.');\n    if (avcdata.length > 2) {\n      result = avcdata.shift() + '.';\n      result += parseInt(avcdata.shift()).toString(16);\n      result += ('000' + parseInt(avcdata.shift()).toString(16)).substr(-4);\n    } else {\n      result = codec;\n    }\n    return result;\n  };\n\n  M3U8Parser.resolve = function resolve(url, baseUrl) {\n    return url_toolkit_default.a.buildAbsoluteURL(baseUrl, url, { alwaysNormalize: true });\n  };\n\n  M3U8Parser.parseMasterPlaylist = function parseMasterPlaylist(string, baseurl) {\n    var levels = [],\n        result = void 0;\n    MASTER_PLAYLIST_REGEX.lastIndex = 0;\n\n    function setCodecs(codecs, level) {\n      ['video', 'audio'].forEach(function (type) {\n        var filtered = codecs.filter(function (codec) {\n          return isCodecType(codec, type);\n        });\n        if (filtered.length) {\n          var preferred = filtered.filter(function (codec) {\n            return codec.lastIndexOf('avc1', 0) === 0 || codec.lastIndexOf('mp4a', 0) === 0;\n          });\n          level[type + 'Codec'] = preferred.length > 0 ? preferred[0] : filtered[0];\n\n          // remove from list\n          codecs = codecs.filter(function (codec) {\n            return filtered.indexOf(codec) === -1;\n          });\n        }\n      });\n\n      level.unknownCodecs = codecs;\n    }\n\n    while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {\n      var level = {};\n\n      var attrs = level.attrs = new attr_list(result[1]);\n      level.url = M3U8Parser.resolve(result[2], baseurl);\n\n      var resolution = attrs.decimalResolution('RESOLUTION');\n      if (resolution) {\n        level.width = resolution.width;\n        level.height = resolution.height;\n      }\n      level.bitrate = attrs.decimalInteger('AVERAGE-BANDWIDTH') || attrs.decimalInteger('BANDWIDTH');\n      level.name = attrs.NAME;\n\n      setCodecs([].concat((attrs.CODECS || '').split(/[ ,]+/)), level);\n\n      if (level.videoCodec && level.videoCodec.indexOf('avc1') !== -1) level.videoCodec = M3U8Parser.convertAVC1ToAVCOTI(level.videoCodec);\n\n      levels.push(level);\n    }\n    return levels;\n  };\n\n  M3U8Parser.parseMasterPlaylistMedia = function parseMasterPlaylistMedia(string, baseurl, type) {\n    var audioGroups = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [];\n\n    var result = void 0;\n    var medias = [];\n    var id = 0;\n    MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;\n    while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {\n      var media = {};\n      var attrs = new attr_list(result[1]);\n      if (attrs.TYPE === type) {\n        media.groupId = attrs['GROUP-ID'];\n        media.name = attrs.NAME;\n        media.type = type;\n        media.default = attrs.DEFAULT === 'YES';\n        media.autoselect = attrs.AUTOSELECT === 'YES';\n        media.forced = attrs.FORCED === 'YES';\n        if (attrs.URI) media.url = M3U8Parser.resolve(attrs.URI, baseurl);\n\n        media.lang = attrs.LANGUAGE;\n        if (!media.name) media.name = media.lang;\n\n        if (audioGroups.length) {\n          var groupCodec = M3U8Parser.findGroup(audioGroups, media.groupId);\n          media.audioCodec = groupCodec ? groupCodec.codec : audioGroups[0].codec;\n        }\n        media.id = id++;\n        medias.push(media);\n      }\n    }\n    return medias;\n  };\n\n  M3U8Parser.parseLevelPlaylist = function parseLevelPlaylist(string, baseurl, id, type) {\n    var currentSN = 0,\n        totalduration = 0,\n        level = { type: null, version: null, url: baseurl, fragments: [], live: true, startSN: 0 },\n        levelkey = new level_key(),\n        cc = 0,\n        prevFrag = null,\n        frag = new loader_fragment(),\n        result = void 0,\n        i = void 0;\n\n    LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;\n\n    while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {\n      var duration = result[1];\n      if (duration) {\n        // INF\n        frag.duration = parseFloat(duration);\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        var title = (' ' + result[2]).slice(1);\n        frag.title = title || null;\n        frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);\n      } else if (result[3]) {\n        // url\n        if (!isNaN(frag.duration)) {\n          var sn = currentSN++;\n          frag.type = type;\n          frag.start = totalduration;\n          frag.levelkey = levelkey;\n          frag.sn = sn;\n          frag.level = id;\n          frag.cc = cc;\n          frag.baseurl = baseurl;\n          // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n          frag.relurl = (' ' + result[3]).slice(1);\n\n          if (level.programDateTime) {\n            if (prevFrag) {\n              if (frag.rawProgramDateTime) {\n                // PDT discontinuity found\n                frag.pdt = Date.parse(frag.rawProgramDateTime);\n              } else {\n                // Contiguous fragment\n                frag.pdt = prevFrag.pdt + prevFrag.duration * 1000;\n              }\n            } else {\n              // First fragment\n              frag.pdt = Date.parse(level.programDateTime);\n            }\n            frag.endPdt = frag.pdt + frag.duration * 1000;\n          }\n\n          level.fragments.push(frag);\n          prevFrag = frag;\n          totalduration += frag.duration;\n\n          frag = new loader_fragment();\n        }\n      } else if (result[4]) {\n        // X-BYTERANGE\n        frag.rawByteRange = (' ' + result[4]).slice(1);\n        if (prevFrag) {\n          var lastByteRangeEndOffset = prevFrag.byteRangeEndOffset;\n          if (lastByteRangeEndOffset) frag.lastByteRangeEndOffset = lastByteRangeEndOffset;\n        }\n      } else if (result[5]) {\n        // PROGRAM-DATE-TIME\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        frag.rawProgramDateTime = (' ' + result[5]).slice(1);\n        frag.tagList.push(['PROGRAM-DATE-TIME', frag.rawProgramDateTime]);\n        if (level.programDateTime === undefined) level.programDateTime = new Date(new Date(Date.parse(result[5])) - 1000 * totalduration);\n      } else {\n        result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);\n        for (i = 1; i < result.length; i++) {\n          if (result[i] !== undefined) break;\n        }\n\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        var value1 = (' ' + result[i + 1]).slice(1);\n        var value2 = (' ' + result[i + 2]).slice(1);\n\n        switch (result[i]) {\n          case '#':\n            frag.tagList.push(value2 ? [value1, value2] : [value1]);\n            break;\n          case 'PLAYLIST-TYPE':\n            level.type = value1.toUpperCase();\n            break;\n          case 'MEDIA-SEQUENCE':\n            currentSN = level.startSN = parseInt(value1);\n            break;\n          case 'TARGETDURATION':\n            level.targetduration = parseFloat(value1);\n            break;\n          case 'VERSION':\n            level.version = parseInt(value1);\n            break;\n          case 'EXTM3U':\n            break;\n          case 'ENDLIST':\n            level.live = false;\n            break;\n          case 'DIS':\n            cc++;\n            frag.tagList.push(['DIS']);\n            break;\n          case 'DISCONTINUITY-SEQ':\n            cc = parseInt(value1);\n            break;\n          case 'KEY':\n            // https://tools.ietf.org/html/draft-pantos-http-live-streaming-08#section-3.4.4\n            var decryptparams = value1;\n            var keyAttrs = new attr_list(decryptparams);\n            var decryptmethod = keyAttrs.enumeratedString('METHOD'),\n                decrypturi = keyAttrs.URI,\n                decryptiv = keyAttrs.hexadecimalInteger('IV');\n            if (decryptmethod) {\n              levelkey = new level_key();\n              if (decrypturi && ['AES-128', 'SAMPLE-AES', 'SAMPLE-AES-CENC'].indexOf(decryptmethod) >= 0) {\n                levelkey.method = decryptmethod;\n                // URI to get the key\n                levelkey.baseuri = baseurl;\n                levelkey.reluri = decrypturi;\n                levelkey.key = null;\n                // Initialization Vector (IV)\n                levelkey.iv = decryptiv;\n              }\n            }\n            break;\n          case 'START':\n            var startParams = value1;\n            var startAttrs = new attr_list(startParams);\n            var startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET');\n            // TIME-OFFSET can be 0\n            if (!isNaN(startTimeOffset)) level.startTimeOffset = startTimeOffset;\n\n            break;\n          case 'MAP':\n            var mapAttrs = new attr_list(value1);\n            frag.relurl = mapAttrs.URI;\n            frag.rawByteRange = mapAttrs.BYTERANGE;\n            frag.baseurl = baseurl;\n            frag.level = id;\n            frag.type = type;\n            frag.sn = 'initSegment';\n            level.initSegment = frag;\n            frag = new loader_fragment();\n            break;\n          default:\n            logger[\"b\" /* logger */].warn('line parsed but not handled: ' + result);\n            break;\n        }\n      }\n    }\n    frag = prevFrag;\n    // logger.log('found ' + level.fragments.length + ' fragments');\n    if (frag && !frag.relurl) {\n      level.fragments.pop();\n      totalduration -= frag.duration;\n    }\n    level.totalduration = totalduration;\n    level.averagetargetduration = totalduration / level.fragments.length;\n    level.endSN = currentSN - 1;\n    level.startCC = level.fragments[0] ? level.fragments[0].cc : 0;\n    level.endCC = cc;\n\n    if (!level.initSegment && level.fragments.length) {\n      // this is a bit lurky but HLS really has no other way to tell us\n      // if the fragments are TS or MP4, except if we download them :/\n      // but this is to be able to handle SIDX.\n      // FIXME: replace string test by a regex that matches\n      //        also `m4s` `m4a` `m4v` and other popular extensions\n      if (level.fragments.every(function (frag) {\n        return frag.relurl.endsWith('.mp4');\n      })) {\n        logger[\"b\" /* logger */].warn('MP4 fragments found but no init segment (probably no MAP, incomplete M3U8), trying to fetch SIDX');\n\n        frag = new loader_fragment();\n        frag.relurl = level.fragments[0].relurl;\n        frag.baseurl = baseurl;\n        frag.level = id;\n        frag.type = type;\n        frag.sn = 'initSegment';\n\n        level.initSegment = frag;\n        level.needSidxRanges = true;\n      }\n    }\n\n    return level;\n  };\n\n  return M3U8Parser;\n}();\n\n/* harmony default export */ var m3u8_parser = (m3u8_parser_M3U8Parser);\n// CONCATENATED MODULE: ./src/loader/playlist-loader.js\nvar playlist_loader__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction playlist_loader__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/**\n * PlaylistLoader - delegate for media manifest/playlist loading tasks. Takes care of parsing media to internal data-models.\n *\n * Once loaded, dispatches events with parsed data-models of manifest/levels/audio/subtitle tracks.\n *\n * Uses loader(s) set in config to do actual internal loading of resource tasks.\n *\n * @module\n *\n */\n\n\n\n\n\n\n\n\n\n\n/**\n * `type` property values for this loaders' context object\n * @enum\n *\n */\nvar ContextType = {\n  MANIFEST: 'manifest',\n  LEVEL: 'level',\n  AUDIO_TRACK: 'audioTrack',\n  SUBTITLE_TRACK: 'subtitleTrack'\n};\n\n/**\n * @enum {string}\n */\nvar LevelType = {\n  MAIN: 'main',\n  AUDIO: 'audio',\n  SUBTITLE: 'subtitle'\n};\n\n/**\n * @constructor\n */\n\nvar playlist_loader_PlaylistLoader = function (_EventHandler) {\n  _inherits(PlaylistLoader, _EventHandler);\n\n  /**\n   * @constructs\n   * @param {Hls} hls\n   */\n  function PlaylistLoader(hls) {\n    playlist_loader__classCallCheck(this, PlaylistLoader);\n\n    var _this = _possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MANIFEST_LOADING, events[\"a\" /* default */].LEVEL_LOADING, events[\"a\" /* default */].AUDIO_TRACK_LOADING, events[\"a\" /* default */].SUBTITLE_TRACK_LOADING));\n\n    _this.loaders = {};\n    return _this;\n  }\n\n  /**\n   * @param {ContextType} type\n   * @returns {boolean}\n   */\n  PlaylistLoader.canHaveQualityLevels = function canHaveQualityLevels(type) {\n    return type !== ContextType.AUDIO_TRACK && type !== ContextType.SUBTITLE_TRACK;\n  };\n\n  /**\n   * Map context.type to LevelType\n   * @param {{type: ContextType}} context\n   * @returns {LevelType}\n   */\n\n\n  PlaylistLoader.mapContextToLevelType = function mapContextToLevelType(context) {\n    var type = context.type;\n\n\n    switch (type) {\n      case ContextType.AUDIO_TRACK:\n        return LevelType.AUDIO;\n      case ContextType.SUBTITLE_TRACK:\n        return LevelType.SUBTITLE;\n      default:\n        return LevelType.MAIN;\n    }\n  };\n\n  PlaylistLoader.getResponseUrl = function getResponseUrl(response, context) {\n    var url = response.url;\n    // responseURL not supported on some browsers (it is used to detect URL redirection)\n    // data-uri mode also not supported (but no need to detect redirection)\n    if (url === undefined || url.indexOf('data:') === 0) {\n      // fallback to initial URL\n      url = context.url;\n    }\n    return url;\n  };\n\n  /**\n   * Returns defaults or configured loader-type overloads (pLoader and loader config params)\n   * Default loader is XHRLoader (see utils)\n   * @param {object} context\n   * @returns {XHRLoader} or other compatible configured overload\n   */\n\n\n  PlaylistLoader.prototype.createInternalLoader = function createInternalLoader(context) {\n    var config = this.hls.config;\n    var PLoader = config.pLoader;\n    var Loader = config.loader;\n    var InternalLoader = PLoader || Loader;\n\n    var loader = new InternalLoader(config);\n\n    context.loader = loader;\n    this.loaders[context.type] = loader;\n\n    return loader;\n  };\n\n  PlaylistLoader.prototype.getInternalLoader = function getInternalLoader(context) {\n    return this.loaders[context.type];\n  };\n\n  PlaylistLoader.prototype.resetInternalLoader = function resetInternalLoader(contextType) {\n    if (this.loaders[contextType]) delete this.loaders[contextType];\n  };\n\n  /**\n   * Call `destroy` on all internal loader instances mapped (one per context type)\n   */\n\n\n  PlaylistLoader.prototype.destroyInternalLoaders = function destroyInternalLoaders() {\n    for (var contextType in this.loaders) {\n      var loader = this.loaders[contextType];\n      if (loader) loader.destroy();\n\n      this.resetInternalLoader(contextType);\n    }\n  };\n\n  PlaylistLoader.prototype.destroy = function destroy() {\n    this.destroyInternalLoaders();\n\n    _EventHandler.prototype.destroy.call(this);\n  };\n\n  PlaylistLoader.prototype.onManifestLoading = function onManifestLoading(data) {\n    this.load(data.url, { type: ContextType.MANIFEST });\n  };\n\n  PlaylistLoader.prototype.onLevelLoading = function onLevelLoading(data) {\n    this.load(data.url, { type: ContextType.LEVEL, level: data.level, id: data.id });\n  };\n\n  PlaylistLoader.prototype.onAudioTrackLoading = function onAudioTrackLoading(data) {\n    this.load(data.url, { type: ContextType.AUDIO_TRACK, id: data.id });\n  };\n\n  PlaylistLoader.prototype.onSubtitleTrackLoading = function onSubtitleTrackLoading(data) {\n    this.load(data.url, { type: ContextType.SUBTITLE_TRACK, id: data.id });\n  };\n\n  PlaylistLoader.prototype.load = function load(url, context) {\n    var config = this.hls.config;\n\n    // Check if a loader for this context already exists\n    var loader = this.getInternalLoader(context);\n    if (loader) {\n      var loaderContext = loader.context;\n      if (loaderContext && loaderContext.url === url) {\n        // same URL can't overlap\n        logger[\"b\" /* logger */].trace('playlist request ongoing');\n        return false;\n      } else {\n        logger[\"b\" /* logger */].warn('aborting previous loader for type: ' + context.type);\n        loader.abort();\n      }\n    }\n    var maxRetry = void 0,\n        timeout = void 0,\n        retryDelay = void 0,\n        maxRetryDelay = void 0;\n\n    // apply different configs for retries depending on\n    // context (manifest, level, audio/subs playlist)\n    switch (context.type) {\n      case ContextType.MANIFEST:\n        maxRetry = config.manifestLoadingMaxRetry;\n        timeout = config.manifestLoadingTimeOut;\n        retryDelay = config.manifestLoadingRetryDelay;\n        maxRetryDelay = config.manifestLoadingMaxRetryTimeout;\n        break;\n      case ContextType.LEVEL:\n        // Disable internal loader retry logic, since we are managing retries in Level Controller\n        maxRetry = 0;\n        timeout = config.levelLoadingTimeOut;\n        // TODO Introduce retry settings for audio-track and subtitle-track, it should not use level retry config\n        break;\n      default:\n        maxRetry = config.levelLoadingMaxRetry;\n        timeout = config.levelLoadingTimeOut;\n        retryDelay = config.levelLoadingRetryDelay;\n        maxRetryDelay = config.levelLoadingMaxRetryTimeout;\n        logger[\"b\" /* logger */].log('Playlist loader for ' + context.type + ' ' + (context.level || context.id));\n        break;\n    }\n\n    loader = this.createInternalLoader(context);\n\n    context.url = url;\n    context.responseType = context.responseType || ''; // FIXME: (should not be necessary to do this)\n\n    var loaderConfig = void 0,\n        loaderCallbacks = void 0;\n\n    loaderConfig = {\n      timeout: timeout,\n      maxRetry: maxRetry,\n      retryDelay: retryDelay,\n      maxRetryDelay: maxRetryDelay\n    };\n\n    loaderCallbacks = {\n      onSuccess: this.loadsuccess.bind(this),\n      onError: this.loaderror.bind(this),\n      onTimeout: this.loadtimeout.bind(this)\n    };\n\n    loader.load(context, loaderConfig, loaderCallbacks);\n\n    return true;\n  };\n\n  PlaylistLoader.prototype.loadsuccess = function loadsuccess(response, stats, context) {\n    var networkDetails = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n\n    if (context.isSidxRequest) {\n      this._handleSidxRequest(response, context);\n      this._handlePlaylistLoaded(response, stats, context, networkDetails);\n      return;\n    }\n\n    this.resetInternalLoader(context.type);\n\n    var string = response.data;\n\n    stats.tload = performance.now();\n    // stats.mtime = new Date(target.getResponseHeader('Last-Modified'));\n\n    // Validate if it is an M3U8 at all\n    if (string.indexOf('#EXTM3U') !== 0) {\n      this._handleManifestParsingError(response, context, 'no EXTM3U delimiter', networkDetails);\n      return;\n    }\n\n    // Check if chunk-list or master. handle empty chunk list case (first EXTINF not signaled, but TARGETDURATION present)\n    if (string.indexOf('#EXTINF:') > 0 || string.indexOf('#EXT-X-TARGETDURATION:') > 0) this._handleTrackOrLevelPlaylist(response, stats, context, networkDetails);else this._handleMasterPlaylist(response, stats, context, networkDetails);\n  };\n\n  PlaylistLoader.prototype.loaderror = function loaderror(response, context) {\n    var networkDetails = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n\n    this._handleNetworkError(context, networkDetails);\n  };\n\n  PlaylistLoader.prototype.loadtimeout = function loadtimeout(stats, context) {\n    var networkDetails = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n\n    this._handleNetworkError(context, networkDetails, true);\n  };\n\n  PlaylistLoader.prototype._handleMasterPlaylist = function _handleMasterPlaylist(response, stats, context, networkDetails) {\n    var hls = this.hls;\n    var string = response.data;\n\n    var url = PlaylistLoader.getResponseUrl(response, context);\n\n    var levels = m3u8_parser.parseMasterPlaylist(string, url);\n    if (!levels.length) {\n      this._handleManifestParsingError(response, context, 'no level found in manifest', networkDetails);\n      return;\n    }\n\n    // multi level playlist, parse level info\n\n    var audioGroups = levels.map(function (level) {\n      return {\n        id: level.attrs.AUDIO,\n        codec: level.audioCodec\n      };\n    });\n\n    var audioTracks = m3u8_parser.parseMasterPlaylistMedia(string, url, 'AUDIO', audioGroups);\n    var subtitles = m3u8_parser.parseMasterPlaylistMedia(string, url, 'SUBTITLES');\n\n    if (audioTracks.length) {\n      // check if we have found an audio track embedded in main playlist (audio track without URI attribute)\n      var embeddedAudioFound = false;\n      audioTracks.forEach(function (audioTrack) {\n        if (!audioTrack.url) embeddedAudioFound = true;\n      });\n\n      // if no embedded audio track defined, but audio codec signaled in quality level,\n      // we need to signal this main audio track this could happen with playlists with\n      // alt audio rendition in which quality levels (main)\n      // contains both audio+video. but with mixed audio track not signaled\n      if (embeddedAudioFound === false && levels[0].audioCodec && !levels[0].attrs.AUDIO) {\n        logger[\"b\" /* logger */].log('audio codec signaled in quality level, but no embedded audio track signaled, create one');\n        audioTracks.unshift({\n          type: 'main',\n          name: 'main'\n        });\n      }\n    }\n\n    hls.trigger(events[\"a\" /* default */].MANIFEST_LOADED, {\n      levels: levels,\n      audioTracks: audioTracks,\n      subtitles: subtitles,\n      url: url,\n      stats: stats,\n      networkDetails: networkDetails\n    });\n  };\n\n  PlaylistLoader.prototype._handleTrackOrLevelPlaylist = function _handleTrackOrLevelPlaylist(response, stats, context, networkDetails) {\n    var hls = this.hls;\n\n    var id = context.id,\n        level = context.level,\n        type = context.type;\n\n\n    var url = PlaylistLoader.getResponseUrl(response, context);\n\n    var levelId = !isNaN(level) ? level : !isNaN(id) ? id : 0; // level -> id -> 0\n    var levelType = PlaylistLoader.mapContextToLevelType(context);\n\n    var levelDetails = m3u8_parser.parseLevelPlaylist(response.data, url, levelId, levelType);\n\n    // set stats on level structure\n    levelDetails.tload = stats.tload;\n\n    // We have done our first request (Manifest-type) and receive\n    // not a master playlist but a chunk-list (track/level)\n    // We fire the manifest-loaded event anyway with the parsed level-details\n    // by creating a single-level structure for it.\n    if (type === ContextType.MANIFEST) {\n      var singleLevel = {\n        url: url,\n        details: levelDetails\n      };\n\n      hls.trigger(events[\"a\" /* default */].MANIFEST_LOADED, {\n        levels: [singleLevel],\n        audioTracks: [],\n        url: url,\n        stats: stats,\n        networkDetails: networkDetails\n      });\n    }\n\n    // save parsing time\n    stats.tparsed = performance.now();\n\n    // in case we need SIDX ranges\n    // return early after calling load for\n    // the SIDX box.\n    if (levelDetails.needSidxRanges) {\n      var sidxUrl = levelDetails.initSegment.url;\n      this.load(sidxUrl, {\n        isSidxRequest: true,\n        type: type,\n        level: level,\n        levelDetails: levelDetails,\n        id: id,\n        rangeStart: 0,\n        rangeEnd: 2048,\n        responseType: 'arraybuffer'\n      });\n      return;\n    }\n\n    // extend the context with the new levelDetails property\n    context.levelDetails = levelDetails;\n\n    this._handlePlaylistLoaded(response, stats, context, networkDetails);\n  };\n\n  PlaylistLoader.prototype._handleSidxRequest = function _handleSidxRequest(response, context) {\n    var sidxInfo = mp4demuxer[\"a\" /* default */].parseSegmentIndex(new Uint8Array(response.data));\n    sidxInfo.references.forEach(function (segmentRef, index) {\n      var segRefInfo = segmentRef.info;\n      var frag = context.levelDetails.fragments[index];\n\n      if (frag.byteRange.length === 0) frag.rawByteRange = String(1 + segRefInfo.end - segRefInfo.start) + '@' + String(segRefInfo.start);\n    });\n\n    context.levelDetails.initSegment.rawByteRange = String(sidxInfo.moovEndOffset) + '@0';\n  };\n\n  PlaylistLoader.prototype._handleManifestParsingError = function _handleManifestParsingError(response, context, reason, networkDetails) {\n    this.hls.trigger(events[\"a\" /* default */].ERROR, {\n      type: errors[\"b\" /* ErrorTypes */].NETWORK_ERROR,\n      details: errors[\"a\" /* ErrorDetails */].MANIFEST_PARSING_ERROR,\n      fatal: true,\n      url: response.url,\n      reason: reason,\n      networkDetails: networkDetails\n    });\n  };\n\n  PlaylistLoader.prototype._handleNetworkError = function _handleNetworkError(context, networkDetails) {\n    var timeout = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n\n    var details = void 0;\n    var fatal = void 0;\n\n    var loader = this.getInternalLoader(context);\n\n    switch (context.type) {\n      case ContextType.MANIFEST:\n        details = timeout ? errors[\"a\" /* ErrorDetails */].MANIFEST_LOAD_TIMEOUT : errors[\"a\" /* ErrorDetails */].MANIFEST_LOAD_ERROR;\n        fatal = true;\n        break;\n      case ContextType.LEVEL:\n        details = timeout ? errors[\"a\" /* ErrorDetails */].LEVEL_LOAD_TIMEOUT : errors[\"a\" /* ErrorDetails */].LEVEL_LOAD_ERROR;\n        fatal = false;\n        break;\n      case ContextType.AUDIO_TRACK:\n        details = timeout ? errors[\"a\" /* ErrorDetails */].AUDIO_TRACK_LOAD_TIMEOUT : errors[\"a\" /* ErrorDetails */].AUDIO_TRACK_LOAD_ERROR;\n        fatal = false;\n        break;\n      default:\n        // details = ...?\n        fatal = false;\n    }\n\n    if (loader) {\n      loader.abort();\n      this.resetInternalLoader(context.type);\n    }\n\n    this.hls.trigger(events[\"a\" /* default */].ERROR, {\n      type: errors[\"b\" /* ErrorTypes */].NETWORK_ERROR,\n      details: details,\n      fatal: fatal,\n      url: loader.url,\n      loader: loader,\n      context: context,\n      networkDetails: networkDetails\n    });\n  };\n\n  PlaylistLoader.prototype._handlePlaylistLoaded = function _handlePlaylistLoaded(response, stats, context, networkDetails) {\n    var type = context.type,\n        level = context.level,\n        id = context.id,\n        levelDetails = context.levelDetails;\n\n\n    if (!levelDetails.targetduration) {\n      this._handleManifestParsingError(response, context, 'invalid target duration', networkDetails);\n      return;\n    }\n\n    var canHaveLevels = PlaylistLoader.canHaveQualityLevels(context.type);\n    if (canHaveLevels) {\n      this.hls.trigger(events[\"a\" /* default */].LEVEL_LOADED, {\n        details: levelDetails,\n        level: level || 0,\n        id: id || 0,\n        stats: stats,\n        networkDetails: networkDetails\n      });\n    } else {\n      switch (type) {\n        case ContextType.AUDIO_TRACK:\n          this.hls.trigger(events[\"a\" /* default */].AUDIO_TRACK_LOADED, {\n            details: levelDetails,\n            id: id,\n            stats: stats,\n            networkDetails: networkDetails\n          });\n          break;\n        case ContextType.SUBTITLE_TRACK:\n          this.hls.trigger(events[\"a\" /* default */].SUBTITLE_TRACK_LOADED, {\n            details: levelDetails,\n            id: id,\n            stats: stats,\n            networkDetails: networkDetails\n          });\n          break;\n      }\n    }\n  };\n\n  playlist_loader__createClass(PlaylistLoader, null, [{\n    key: 'ContextType',\n    get: function get() {\n      return ContextType;\n    }\n  }, {\n    key: 'LevelType',\n    get: function get() {\n      return LevelType;\n    }\n  }]);\n\n  return PlaylistLoader;\n}(event_handler);\n\n/* harmony default export */ var playlist_loader = (playlist_loader_PlaylistLoader);\n// CONCATENATED MODULE: ./src/loader/fragment-loader.js\nfunction fragment_loader__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction fragment_loader__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction fragment_loader__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * Fragment Loader\n*/\n\n\n\n\n\n\nvar fragment_loader_FragmentLoader = function (_EventHandler) {\n  fragment_loader__inherits(FragmentLoader, _EventHandler);\n\n  function FragmentLoader(hls) {\n    fragment_loader__classCallCheck(this, FragmentLoader);\n\n    var _this = fragment_loader__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].FRAG_LOADING));\n\n    _this.loaders = {};\n    return _this;\n  }\n\n  FragmentLoader.prototype.destroy = function destroy() {\n    var loaders = this.loaders;\n    for (var loaderName in loaders) {\n      var loader = loaders[loaderName];\n      if (loader) loader.destroy();\n    }\n    this.loaders = {};\n\n    _EventHandler.prototype.destroy.call(this);\n  };\n\n  FragmentLoader.prototype.onFragLoading = function onFragLoading(data) {\n    var frag = data.frag,\n        type = frag.type,\n        loaders = this.loaders,\n        config = this.hls.config,\n        FragmentILoader = config.fLoader,\n        DefaultILoader = config.loader;\n\n    // reset fragment state\n    frag.loaded = 0;\n\n    var loader = loaders[type];\n    if (loader) {\n      logger[\"b\" /* logger */].warn('abort previous fragment loader for type: ' + type);\n      loader.abort();\n    }\n\n    loader = loaders[type] = frag.loader = config.fLoader ? new FragmentILoader(config) : new DefaultILoader(config);\n\n    var loaderContext = void 0,\n        loaderConfig = void 0,\n        loaderCallbacks = void 0;\n\n    loaderContext = { url: frag.url, frag: frag, responseType: 'arraybuffer', progressData: false };\n\n    var start = frag.byteRangeStartOffset,\n        end = frag.byteRangeEndOffset;\n\n    if (!isNaN(start) && !isNaN(end)) {\n      loaderContext.rangeStart = start;\n      loaderContext.rangeEnd = end;\n    }\n\n    loaderConfig = {\n      timeout: config.fragLoadingTimeOut,\n      maxRetry: 0,\n      retryDelay: 0,\n      maxRetryDelay: config.fragLoadingMaxRetryTimeout\n    };\n\n    loaderCallbacks = {\n      onSuccess: this.loadsuccess.bind(this),\n      onError: this.loaderror.bind(this),\n      onTimeout: this.loadtimeout.bind(this),\n      onProgress: this.loadprogress.bind(this)\n    };\n\n    loader.load(loaderContext, loaderConfig, loaderCallbacks);\n  };\n\n  FragmentLoader.prototype.loadsuccess = function loadsuccess(response, stats, context) {\n    var networkDetails = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n\n    var payload = response.data,\n        frag = context.frag;\n    // detach fragment loader on load success\n    frag.loader = undefined;\n    this.loaders[frag.type] = undefined;\n    this.hls.trigger(events[\"a\" /* default */].FRAG_LOADED, { payload: payload, frag: frag, stats: stats, networkDetails: networkDetails });\n  };\n\n  FragmentLoader.prototype.loaderror = function loaderror(response, context) {\n    var networkDetails = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n\n    var loader = context.loader;\n    if (loader) loader.abort();\n\n    this.loaders[context.type] = undefined;\n    this.hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].NETWORK_ERROR, details: errors[\"a\" /* ErrorDetails */].FRAG_LOAD_ERROR, fatal: false, frag: context.frag, response: response, networkDetails: networkDetails });\n  };\n\n  FragmentLoader.prototype.loadtimeout = function loadtimeout(stats, context) {\n    var networkDetails = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n\n    var loader = context.loader;\n    if (loader) loader.abort();\n\n    this.loaders[context.type] = undefined;\n    this.hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].NETWORK_ERROR, details: errors[\"a\" /* ErrorDetails */].FRAG_LOAD_TIMEOUT, fatal: false, frag: context.frag, networkDetails: networkDetails });\n  };\n\n  // data will be used for progressive parsing\n\n\n  FragmentLoader.prototype.loadprogress = function loadprogress(stats, context, data) {\n    var networkDetails = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    // jshint ignore:line\n    var frag = context.frag;\n    frag.loaded = stats.loaded;\n    this.hls.trigger(events[\"a\" /* default */].FRAG_LOAD_PROGRESS, { frag: frag, stats: stats, networkDetails: networkDetails });\n  };\n\n  return FragmentLoader;\n}(event_handler);\n\n/* harmony default export */ var fragment_loader = (fragment_loader_FragmentLoader);\n// CONCATENATED MODULE: ./src/loader/key-loader.js\nfunction key_loader__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction key_loader__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction key_loader__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * Decrypt key Loader\n*/\n\n\n\n\n\n\nvar key_loader_KeyLoader = function (_EventHandler) {\n  key_loader__inherits(KeyLoader, _EventHandler);\n\n  function KeyLoader(hls) {\n    key_loader__classCallCheck(this, KeyLoader);\n\n    var _this = key_loader__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].KEY_LOADING));\n\n    _this.loaders = {};\n    _this.decryptkey = null;\n    _this.decrypturl = null;\n    return _this;\n  }\n\n  KeyLoader.prototype.destroy = function destroy() {\n    for (var loaderName in this.loaders) {\n      var loader = this.loaders[loaderName];\n      if (loader) loader.destroy();\n    }\n    this.loaders = {};\n    event_handler.prototype.destroy.call(this);\n  };\n\n  KeyLoader.prototype.onKeyLoading = function onKeyLoading(data) {\n    var frag = data.frag,\n        type = frag.type,\n        loader = this.loaders[type],\n        decryptdata = frag.decryptdata,\n        uri = decryptdata.uri;\n    // if uri is different from previous one or if decrypt key not retrieved yet\n    if (uri !== this.decrypturl || this.decryptkey === null) {\n      var config = this.hls.config;\n\n      if (loader) {\n        logger[\"b\" /* logger */].warn('abort previous key loader for type:' + type);\n        loader.abort();\n      }\n      frag.loader = this.loaders[type] = new config.loader(config);\n      this.decrypturl = uri;\n      this.decryptkey = null;\n\n      var loaderContext = void 0,\n          loaderConfig = void 0,\n          loaderCallbacks = void 0;\n      loaderContext = { url: uri, frag: frag, responseType: 'arraybuffer' };\n      loaderConfig = { timeout: config.fragLoadingTimeOut, maxRetry: config.fragLoadingMaxRetry, retryDelay: config.fragLoadingRetryDelay, maxRetryDelay: config.fragLoadingMaxRetryTimeout };\n      loaderCallbacks = { onSuccess: this.loadsuccess.bind(this), onError: this.loaderror.bind(this), onTimeout: this.loadtimeout.bind(this) };\n      frag.loader.load(loaderContext, loaderConfig, loaderCallbacks);\n    } else if (this.decryptkey) {\n      // we already loaded this key, return it\n      decryptdata.key = this.decryptkey;\n      this.hls.trigger(events[\"a\" /* default */].KEY_LOADED, { frag: frag });\n    }\n  };\n\n  KeyLoader.prototype.loadsuccess = function loadsuccess(response, stats, context) {\n    var frag = context.frag;\n    this.decryptkey = frag.decryptdata.key = new Uint8Array(response.data);\n    // detach fragment loader on load success\n    frag.loader = undefined;\n    this.loaders[frag.type] = undefined;\n    this.hls.trigger(events[\"a\" /* default */].KEY_LOADED, { frag: frag });\n  };\n\n  KeyLoader.prototype.loaderror = function loaderror(response, context) {\n    var frag = context.frag,\n        loader = frag.loader;\n    if (loader) loader.abort();\n\n    this.loaders[context.type] = undefined;\n    this.hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].NETWORK_ERROR, details: errors[\"a\" /* ErrorDetails */].KEY_LOAD_ERROR, fatal: false, frag: frag, response: response });\n  };\n\n  KeyLoader.prototype.loadtimeout = function loadtimeout(stats, context) {\n    var frag = context.frag,\n        loader = frag.loader;\n    if (loader) loader.abort();\n\n    this.loaders[context.type] = undefined;\n    this.hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].NETWORK_ERROR, details: errors[\"a\" /* ErrorDetails */].KEY_LOAD_TIMEOUT, fatal: false, frag: frag });\n  };\n\n  return KeyLoader;\n}(event_handler);\n\n/* harmony default export */ var key_loader = (key_loader_KeyLoader);\n// CONCATENATED MODULE: ./src/utils/binary-search.js\nvar BinarySearch = {\n  /**\n     * Searches for an item in an array which matches a certain condition.\n     * This requires the condition to only match one item in the array,\n     * and for the array to be ordered.\n     *\n     * @param {Array} list The array to search.\n     * @param {Function} comparisonFunction\n     *      Called and provided a candidate item as the first argument.\n     *      Should return:\n     *          > -1 if the item should be located at a lower index than the provided item.\n     *          > 1 if the item should be located at a higher index than the provided item.\n     *          > 0 if the item is the item you're looking for.\n     *\n     * @return {*} The object if it is found or null otherwise.\n     */\n  search: function search(list, comparisonFunction) {\n    var minIndex = 0;\n    var maxIndex = list.length - 1;\n    var currentIndex = null;\n    var currentElement = null;\n\n    while (minIndex <= maxIndex) {\n      currentIndex = (minIndex + maxIndex) / 2 | 0;\n      currentElement = list[currentIndex];\n\n      var comparisonResult = comparisonFunction(currentElement);\n      if (comparisonResult > 0) minIndex = currentIndex + 1;else if (comparisonResult < 0) maxIndex = currentIndex - 1;else return currentElement;\n    }\n\n    return null;\n  }\n};\n\n/* harmony default export */ var binary_search = (BinarySearch);\n// CONCATENATED MODULE: ./src/helper/buffer-helper.js\n/**\n * Buffer Helper utils, providing methods dealing buffer length retrieval\n*/\n\nvar BufferHelper = {\n  /**\n   * Return true if `media`'s buffered include `position`\n   * @param {HTMLMediaElement|SourceBuffer} media\n   * @param {number} position\n   * @returns {boolean}\n   */\n  isBuffered: function isBuffered(media, position) {\n    try {\n      if (media) {\n        var buffered = media.buffered;\n        for (var i = 0; i < buffered.length; i++) {\n          if (position >= buffered.start(i) && position <= buffered.end(i)) return true;\n        }\n      }\n    } catch (error) {\n      // this is to catch\n      // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':\n      // This SourceBuffer has been removed from the parent media source\n    }\n    return false;\n  },\n\n  bufferInfo: function bufferInfo(media, pos, maxHoleDuration) {\n    try {\n      if (media) {\n        var vbuffered = media.buffered,\n            buffered = [],\n            i = void 0;\n        for (i = 0; i < vbuffered.length; i++) {\n          buffered.push({ start: vbuffered.start(i), end: vbuffered.end(i) });\n        }return this.bufferedInfo(buffered, pos, maxHoleDuration);\n      }\n    } catch (error) {\n      // this is to catch\n      // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':\n      // This SourceBuffer has been removed from the parent media source\n    }\n    return { len: 0, start: pos, end: pos, nextStart: undefined };\n  },\n\n  bufferedInfo: function bufferedInfo(buffered, pos, maxHoleDuration) {\n    var buffered2 = [],\n\n    // bufferStart and bufferEnd are buffer boundaries around current video position\n    bufferLen = void 0,\n        bufferStart = void 0,\n        bufferEnd = void 0,\n        bufferStartNext = void 0,\n        i = void 0;\n    // sort on buffer.start/smaller end (IE does not always return sorted buffered range)\n    buffered.sort(function (a, b) {\n      var diff = a.start - b.start;\n      if (diff) return diff;else return b.end - a.end;\n    });\n    // there might be some small holes between buffer time range\n    // consider that holes smaller than maxHoleDuration are irrelevant and build another\n    // buffer time range representations that discards those holes\n    for (i = 0; i < buffered.length; i++) {\n      var buf2len = buffered2.length;\n      if (buf2len) {\n        var buf2end = buffered2[buf2len - 1].end;\n        // if small hole (value between 0 or maxHoleDuration ) or overlapping (negative)\n        if (buffered[i].start - buf2end < maxHoleDuration) {\n          // merge overlapping time ranges\n          // update lastRange.end only if smaller than item.end\n          // e.g.  [ 1, 15] with  [ 2,8] => [ 1,15] (no need to modify lastRange.end)\n          // whereas [ 1, 8] with  [ 2,15] => [ 1,15] ( lastRange should switch from [1,8] to [1,15])\n          if (buffered[i].end > buf2end) buffered2[buf2len - 1].end = buffered[i].end;\n        } else {\n          // big hole\n          buffered2.push(buffered[i]);\n        }\n      } else {\n        // first value\n        buffered2.push(buffered[i]);\n      }\n    }\n    for (i = 0, bufferLen = 0, bufferStart = bufferEnd = pos; i < buffered2.length; i++) {\n      var start = buffered2[i].start,\n          end = buffered2[i].end;\n      // logger.log('buf start/end:' + buffered.start(i) + '/' + buffered.end(i));\n      if (pos + maxHoleDuration >= start && pos < end) {\n        // play position is inside this buffer TimeRange, retrieve end of buffer position and buffer length\n        bufferStart = start;\n        bufferEnd = end;\n        bufferLen = bufferEnd - pos;\n      } else if (pos + maxHoleDuration < start) {\n        bufferStartNext = start;\n        break;\n      }\n    }\n    return { len: bufferLen, start: bufferStart, end: bufferEnd, nextStart: bufferStartNext };\n  }\n};\n\n/* harmony default export */ var buffer_helper = (BufferHelper);\n// EXTERNAL MODULE: ./src/demux/demuxer-inline.js + 11 modules\nvar demuxer_inline = __webpack_require__(8);\n\n// EXTERNAL MODULE: ./node_modules/events/events.js\nvar events_events = __webpack_require__(6);\nvar events_default = /*#__PURE__*/__webpack_require__.n(events_events);\n\n// EXTERNAL MODULE: ./node_modules/webworkify-webpack/index.js\nvar webworkify_webpack = __webpack_require__(10);\nvar webworkify_webpack_default = /*#__PURE__*/__webpack_require__.n(webworkify_webpack);\n\n// CONCATENATED MODULE: ./src/helper/mediasource-helper.js\n/**\n * MediaSource helper\n */\n\nfunction getMediaSource() {\n  if (typeof window !== 'undefined') return window.MediaSource || window.WebKitMediaSource;\n}\n// CONCATENATED MODULE: ./src/demux/demuxer.js\nfunction demuxer__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\n\n\n\n\n\n\nvar demuxer_MediaSource = getMediaSource();\n\nvar demuxer_Demuxer = function () {\n  function Demuxer(hls, id) {\n    demuxer__classCallCheck(this, Demuxer);\n\n    this.hls = hls;\n    this.id = id;\n    // observer setup\n    var observer = this.observer = new events_default.a();\n    var config = hls.config;\n    observer.trigger = function trigger(event) {\n      for (var _len = arguments.length, data = Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        data[_key - 1] = arguments[_key];\n      }\n\n      observer.emit.apply(observer, [event, event].concat(data));\n    };\n\n    observer.off = function off(event) {\n      for (var _len2 = arguments.length, data = Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n        data[_key2 - 1] = arguments[_key2];\n      }\n\n      observer.removeListener.apply(observer, [event].concat(data));\n    };\n\n    var forwardMessage = function (ev, data) {\n      data = data || {};\n      data.frag = this.frag;\n      data.id = this.id;\n      hls.trigger(ev, data);\n    }.bind(this);\n\n    // forward events to main thread\n    observer.on(events[\"a\" /* default */].FRAG_DECRYPTED, forwardMessage);\n    observer.on(events[\"a\" /* default */].FRAG_PARSING_INIT_SEGMENT, forwardMessage);\n    observer.on(events[\"a\" /* default */].FRAG_PARSING_DATA, forwardMessage);\n    observer.on(events[\"a\" /* default */].FRAG_PARSED, forwardMessage);\n    observer.on(events[\"a\" /* default */].ERROR, forwardMessage);\n    observer.on(events[\"a\" /* default */].FRAG_PARSING_METADATA, forwardMessage);\n    observer.on(events[\"a\" /* default */].FRAG_PARSING_USERDATA, forwardMessage);\n    observer.on(events[\"a\" /* default */].INIT_PTS_FOUND, forwardMessage);\n\n    var typeSupported = {\n      mp4: demuxer_MediaSource.isTypeSupported('video/mp4'),\n      mpeg: demuxer_MediaSource.isTypeSupported('audio/mpeg'),\n      mp3: demuxer_MediaSource.isTypeSupported('audio/mp4; codecs=\"mp3\"')\n    };\n    // navigator.vendor is not always available in Web Worker\n    // refer to https://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope/navigator\n    var vendor = navigator.vendor;\n    if (config.enableWorker && typeof Worker !== 'undefined') {\n      logger[\"b\" /* logger */].log('demuxing in webworker');\n      var w = void 0;\n      try {\n        w = this.w = webworkify_webpack_default()(/*require.resolve*/(11));\n        this.onwmsg = this.onWorkerMessage.bind(this);\n        w.addEventListener('message', this.onwmsg);\n        w.onerror = function (event) {\n          hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].OTHER_ERROR, details: errors[\"a\" /* ErrorDetails */].INTERNAL_EXCEPTION, fatal: true, event: 'demuxerWorker', err: { message: event.message + ' (' + event.filename + ':' + event.lineno + ')' } });\n        };\n        w.postMessage({ cmd: 'init', typeSupported: typeSupported, vendor: vendor, id: id, config: JSON.stringify(config) });\n      } catch (err) {\n        logger[\"b\" /* logger */].error('error while initializing DemuxerWorker, fallback on DemuxerInline');\n        if (w) {\n          // revoke the Object URL that was used to create demuxer worker, so as not to leak it\n          URL.revokeObjectURL(w.objectURL);\n        }\n        this.demuxer = new demuxer_inline[\"a\" /* default */](observer, typeSupported, config, vendor);\n        this.w = undefined;\n      }\n    } else {\n      this.demuxer = new demuxer_inline[\"a\" /* default */](observer, typeSupported, config, vendor);\n    }\n  }\n\n  Demuxer.prototype.destroy = function destroy() {\n    var w = this.w;\n    if (w) {\n      w.removeEventListener('message', this.onwmsg);\n      w.terminate();\n      this.w = null;\n    } else {\n      var demuxer = this.demuxer;\n      if (demuxer) {\n        demuxer.destroy();\n        this.demuxer = null;\n      }\n    }\n    var observer = this.observer;\n    if (observer) {\n      observer.removeAllListeners();\n      this.observer = null;\n    }\n  };\n\n  Demuxer.prototype.push = function push(data, initSegment, audioCodec, videoCodec, frag, duration, accurateTimeOffset, defaultInitPTS) {\n    var w = this.w;\n    var timeOffset = !isNaN(frag.startDTS) ? frag.startDTS : frag.start;\n    var decryptdata = frag.decryptdata;\n    var lastFrag = this.frag;\n    var discontinuity = !(lastFrag && frag.cc === lastFrag.cc);\n    var trackSwitch = !(lastFrag && frag.level === lastFrag.level);\n    var nextSN = lastFrag && frag.sn === lastFrag.sn + 1;\n    var contiguous = !trackSwitch && nextSN;\n    if (discontinuity) logger[\"b\" /* logger */].log(this.id + ':discontinuity detected');\n\n    if (trackSwitch) logger[\"b\" /* logger */].log(this.id + ':switch detected');\n\n    this.frag = frag;\n    if (w) {\n      // post fragment payload as transferable objects for ArrayBuffer (no copy)\n      w.postMessage({ cmd: 'demux', data: data, decryptdata: decryptdata, initSegment: initSegment, audioCodec: audioCodec, videoCodec: videoCodec, timeOffset: timeOffset, discontinuity: discontinuity, trackSwitch: trackSwitch, contiguous: contiguous, duration: duration, accurateTimeOffset: accurateTimeOffset, defaultInitPTS: defaultInitPTS }, data instanceof ArrayBuffer ? [data] : []);\n    } else {\n      var demuxer = this.demuxer;\n      if (demuxer) demuxer.push(data, decryptdata, initSegment, audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS);\n    }\n  };\n\n  Demuxer.prototype.onWorkerMessage = function onWorkerMessage(ev) {\n    var data = ev.data,\n        hls = this.hls;\n    switch (data.event) {\n      case 'init':\n        // revoke the Object URL that was used to create demuxer worker, so as not to leak it\n        URL.revokeObjectURL(this.w.objectURL);\n        break;\n      // special case for FRAG_PARSING_DATA: data1 and data2 are transferable objects\n      case events[\"a\" /* default */].FRAG_PARSING_DATA:\n        data.data.data1 = new Uint8Array(data.data1);\n        if (data.data2) data.data.data2 = new Uint8Array(data.data2);\n\n      /* falls through */\n      default:\n        data.data = data.data || {};\n        data.data.frag = this.frag;\n        data.data.id = this.id;\n        hls.trigger(data.event, data.data);\n        break;\n    }\n  };\n\n  return Demuxer;\n}();\n\n/* harmony default export */ var demux_demuxer = (demuxer_Demuxer);\n// CONCATENATED MODULE: ./src/helper/fragment-tracker.js\nfunction fragment_tracker__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction fragment_tracker__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction fragment_tracker__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n\n\n\nvar FragmentState = {\n  NOT_LOADED: 'NOT_LOADED',\n  APPENDING: 'APPENDING',\n  PARTIAL: 'PARTIAL',\n  OK: 'OK'\n};\n\nvar fragment_tracker_FragmentTracker = function (_EventHandler) {\n  fragment_tracker__inherits(FragmentTracker, _EventHandler);\n\n  function FragmentTracker(hls) {\n    fragment_tracker__classCallCheck(this, FragmentTracker);\n\n    var _this = fragment_tracker__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].BUFFER_APPENDED, events[\"a\" /* default */].FRAG_BUFFERED, events[\"a\" /* default */].FRAG_LOADED));\n\n    _this.bufferPadding = 0.2;\n\n    _this.fragments = Object.create(null);\n    _this.timeRanges = Object.create(null);\n\n    _this.config = hls.config;\n    return _this;\n  }\n\n  FragmentTracker.prototype.destroy = function destroy() {\n    this.fragments = null;\n    this.timeRanges = null;\n    this.config = null;\n    event_handler.prototype.destroy.call(this);\n    _EventHandler.prototype.destroy.call(this);\n  };\n\n  /**\n   * Return a Fragment that match the position and levelType.\n   * If not found any Fragment, return null\n   * @param {number} position\n   * @param {LevelType} levelType\n   * @returns {Fragment|null}\n   */\n\n\n  FragmentTracker.prototype.getBufferedFrag = function getBufferedFrag(position, levelType) {\n    var fragments = this.fragments;\n    var bufferedFrags = Object.keys(fragments).filter(function (key) {\n      var fragmentEntity = fragments[key];\n      if (fragmentEntity.body.type !== levelType) return false;\n\n      if (!fragmentEntity.buffered) return false;\n\n      var frag = fragmentEntity.body;\n      return frag.startPTS <= position && position <= frag.endPTS;\n    });\n    if (bufferedFrags.length === 0) {\n      return null;\n    } else {\n      // https://github.com/video-dev/hls.js/pull/1545#discussion_r166229566\n      var bufferedFragKey = bufferedFrags.pop();\n      return fragments[bufferedFragKey].body;\n    }\n  };\n\n  /**\n   * Partial fragments effected by coded frame eviction will be removed\n   * The browser will unload parts of the buffer to free up memory for new buffer data\n   * Fragments will need to be reloaded when the buffer is freed up, removing partial fragments will allow them to reload(since there might be parts that are still playable)\n   * @param {String} elementaryStream The elementaryStream of media this is (eg. video/audio)\n   * @param {TimeRanges} timeRange TimeRange object from a sourceBuffer\n   */\n\n\n  FragmentTracker.prototype.detectEvictedFragments = function detectEvictedFragments(elementaryStream, timeRange) {\n    var _this2 = this;\n\n    var fragmentTimes = void 0,\n        time = void 0;\n    // Check if any flagged fragments have been unloaded\n    Object.keys(this.fragments).forEach(function (key) {\n      var fragmentEntity = _this2.fragments[key];\n      if (fragmentEntity.buffered === true) {\n        var esData = fragmentEntity.range[elementaryStream];\n        if (esData) {\n          fragmentTimes = esData.time;\n          for (var i = 0; i < fragmentTimes.length; i++) {\n            time = fragmentTimes[i];\n\n            if (_this2.isTimeBuffered(time.startPTS, time.endPTS, timeRange) === false) {\n              // Unregister partial fragment as it needs to load again to be reused\n              _this2.removeFragment(fragmentEntity.body);\n              break;\n            }\n          }\n        }\n      }\n    });\n  };\n\n  /**\n   * Checks if the fragment passed in is loaded in the buffer properly\n   * Partially loaded fragments will be registered as a partial fragment\n   * @param {Object} fragment Check the fragment against all sourceBuffers loaded\n   */\n\n\n  FragmentTracker.prototype.detectPartialFragments = function detectPartialFragments(fragment) {\n    var _this3 = this;\n\n    var fragKey = this.getFragmentKey(fragment);\n    var fragmentEntity = this.fragments[fragKey];\n    if (fragmentEntity) {\n      fragmentEntity.buffered = true;\n\n      Object.keys(this.timeRanges).forEach(function (elementaryStream) {\n        if (fragment.hasElementaryStream(elementaryStream) === true) {\n          var timeRange = _this3.timeRanges[elementaryStream];\n          // Check for malformed fragments\n          // Gaps need to be calculated for each elementaryStream\n          fragmentEntity.range[elementaryStream] = _this3.getBufferedTimes(fragment.startPTS, fragment.endPTS, timeRange);\n        }\n      });\n    }\n  };\n\n  FragmentTracker.prototype.getBufferedTimes = function getBufferedTimes(startPTS, endPTS, timeRange) {\n    var fragmentTimes = [];\n    var startTime = void 0,\n        endTime = void 0;\n    var fragmentPartial = false;\n    for (var i = 0; i < timeRange.length; i++) {\n      startTime = timeRange.start(i) - this.bufferPadding;\n      endTime = timeRange.end(i) + this.bufferPadding;\n      if (startPTS >= startTime && endPTS <= endTime) {\n        // Fragment is entirely contained in buffer\n        // No need to check the other timeRange times since it's completely playable\n        fragmentTimes.push({\n          startPTS: Math.max(startPTS, timeRange.start(i)),\n          endPTS: Math.min(endPTS, timeRange.end(i))\n        });\n        break;\n      } else if (startPTS < endTime && endPTS > startTime) {\n        // Check for intersection with buffer\n        // Get playable sections of the fragment\n        fragmentTimes.push({\n          startPTS: Math.max(startPTS, timeRange.start(i)),\n          endPTS: Math.min(endPTS, timeRange.end(i))\n        });\n        fragmentPartial = true;\n      } else if (endPTS <= startTime) {\n        // No need to check the rest of the timeRange as it is in order\n        break;\n      }\n    }\n\n    return {\n      time: fragmentTimes,\n      partial: fragmentPartial\n    };\n  };\n\n  FragmentTracker.prototype.getFragmentKey = function getFragmentKey(fragment) {\n    return fragment.type + '_' + fragment.level + '_' + fragment.sn;\n  };\n\n  /**\n   * Gets the partial fragment for a certain time\n   * @param {Number} time\n   * @returns {Object} fragment Returns a partial fragment at a time or null if there is no partial fragment\n   */\n\n\n  FragmentTracker.prototype.getPartialFragment = function getPartialFragment(time) {\n    var _this4 = this;\n\n    var timePadding = void 0,\n        startTime = void 0,\n        endTime = void 0;\n    var bestFragment = null;\n    var bestOverlap = 0;\n    Object.keys(this.fragments).forEach(function (key) {\n      var fragmentEntity = _this4.fragments[key];\n      if (_this4.isPartial(fragmentEntity)) {\n        startTime = fragmentEntity.body.startPTS - _this4.bufferPadding;\n        endTime = fragmentEntity.body.endPTS + _this4.bufferPadding;\n        if (time >= startTime && time <= endTime) {\n          // Use the fragment that has the most padding from start and end time\n          timePadding = Math.min(time - startTime, endTime - time);\n          if (bestOverlap <= timePadding) {\n            bestFragment = fragmentEntity.body;\n            bestOverlap = timePadding;\n          }\n        }\n      }\n    });\n    return bestFragment;\n  };\n\n  /**\n   * @param {Object} fragment The fragment to check\n   * @returns {String} Returns the fragment state when a fragment never loaded or if it partially loaded\n   */\n\n\n  FragmentTracker.prototype.getState = function getState(fragment) {\n    var fragKey = this.getFragmentKey(fragment);\n    var fragmentEntity = this.fragments[fragKey];\n    var state = FragmentState.NOT_LOADED;\n\n    if (fragmentEntity !== undefined) {\n      if (!fragmentEntity.buffered) state = FragmentState.APPENDING;else if (this.isPartial(fragmentEntity) === true) state = FragmentState.PARTIAL;else state = FragmentState.OK;\n    }\n\n    return state;\n  };\n\n  FragmentTracker.prototype.isPartial = function isPartial(fragmentEntity) {\n    return fragmentEntity.buffered === true && (fragmentEntity.range.video !== undefined && fragmentEntity.range.video.partial === true || fragmentEntity.range.audio !== undefined && fragmentEntity.range.audio.partial === true);\n  };\n\n  FragmentTracker.prototype.isTimeBuffered = function isTimeBuffered(startPTS, endPTS, timeRange) {\n    var startTime = void 0,\n        endTime = void 0;\n    for (var i = 0; i < timeRange.length; i++) {\n      startTime = timeRange.start(i) - this.bufferPadding;\n      endTime = timeRange.end(i) + this.bufferPadding;\n      if (startPTS >= startTime && endPTS <= endTime) return true;\n\n      if (endPTS <= startTime) {\n        // No need to check the rest of the timeRange as it is in order\n        return false;\n      }\n    }\n\n    return false;\n  };\n\n  /**\n   * Fires when a fragment loading is completed\n   */\n\n\n  FragmentTracker.prototype.onFragLoaded = function onFragLoaded(e) {\n    var fragment = e.frag;\n    // dont track initsegment (for which sn is not a number)\n    if (!isNaN(fragment.sn)) {\n      var fragKey = this.getFragmentKey(fragment);\n      var fragmentEntity = {\n        body: fragment,\n        range: Object.create(null),\n        buffered: false\n      };\n      this.fragments[fragKey] = fragmentEntity;\n    }\n  };\n\n  /**\n   * Fires when the buffer is updated\n   */\n\n\n  FragmentTracker.prototype.onBufferAppended = function onBufferAppended(e) {\n    var _this5 = this;\n\n    // Store the latest timeRanges loaded in the buffer\n    this.timeRanges = e.timeRanges;\n    Object.keys(this.timeRanges).forEach(function (elementaryStream) {\n      var timeRange = _this5.timeRanges[elementaryStream];\n      _this5.detectEvictedFragments(elementaryStream, timeRange);\n    });\n  };\n\n  /**\n   * Fires after a fragment has been loaded into the source buffer\n   */\n\n\n  FragmentTracker.prototype.onFragBuffered = function onFragBuffered(e) {\n    this.detectPartialFragments(e.frag);\n  };\n\n  /**\n   * Return true if fragment tracker has the fragment.\n   * @param {Object} fragment\n   * @returns {boolean}\n   */\n\n\n  FragmentTracker.prototype.hasFragment = function hasFragment(fragment) {\n    var fragKey = this.getFragmentKey(fragment);\n    return this.fragments[fragKey] !== undefined;\n  };\n\n  /**\n   * Remove a fragment from fragment tracker until it is loaded again\n   * @param {Object} fragment The fragment to remove\n   */\n\n\n  FragmentTracker.prototype.removeFragment = function removeFragment(fragment) {\n    var fragKey = this.getFragmentKey(fragment);\n    delete this.fragments[fragKey];\n  };\n\n  /**\n   * Remove all fragments from fragment tracker.\n   */\n\n\n  FragmentTracker.prototype.removeAllFragments = function removeAllFragments() {\n    this.fragments = Object.create(null);\n  };\n\n  return FragmentTracker;\n}(event_handler);\n// CONCATENATED MODULE: ./src/helper/level-helper.js\n/**\n * Level Helper class, providing methods dealing with playlist sliding and drift\n*/\n\n\n\nfunction updatePTS(fragments, fromIdx, toIdx) {\n  var fragFrom = fragments[fromIdx],\n      fragTo = fragments[toIdx],\n      fragToPTS = fragTo.startPTS;\n  // if we know startPTS[toIdx]\n  if (!isNaN(fragToPTS)) {\n    // update fragment duration.\n    // it helps to fix drifts between playlist reported duration and fragment real duration\n    if (toIdx > fromIdx) {\n      fragFrom.duration = fragToPTS - fragFrom.start;\n      if (fragFrom.duration < 0) logger[\"b\" /* logger */].warn('negative duration computed for frag ' + fragFrom.sn + ',level ' + fragFrom.level + ', there should be some duration drift between playlist and fragment!');\n    } else {\n      fragTo.duration = fragFrom.start - fragToPTS;\n      if (fragTo.duration < 0) logger[\"b\" /* logger */].warn('negative duration computed for frag ' + fragTo.sn + ',level ' + fragTo.level + ', there should be some duration drift between playlist and fragment!');\n    }\n  } else {\n    // we dont know startPTS[toIdx]\n    if (toIdx > fromIdx) fragTo.start = fragFrom.start + fragFrom.duration;else fragTo.start = Math.max(fragFrom.start - fragTo.duration, 0);\n  }\n}\n\nfunction updateFragPTSDTS(details, frag, startPTS, endPTS, startDTS, endDTS) {\n  // update frag PTS/DTS\n  var maxStartPTS = startPTS;\n  if (!isNaN(frag.startPTS)) {\n    // delta PTS between audio and video\n    var deltaPTS = Math.abs(frag.startPTS - startPTS);\n    if (isNaN(frag.deltaPTS)) frag.deltaPTS = deltaPTS;else frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS);\n\n    maxStartPTS = Math.max(startPTS, frag.startPTS);\n    startPTS = Math.min(startPTS, frag.startPTS);\n    endPTS = Math.max(endPTS, frag.endPTS);\n    startDTS = Math.min(startDTS, frag.startDTS);\n    endDTS = Math.max(endDTS, frag.endDTS);\n  }\n\n  var drift = startPTS - frag.start;\n  frag.start = frag.startPTS = startPTS;\n  frag.maxStartPTS = maxStartPTS;\n  frag.endPTS = endPTS;\n  frag.startDTS = startDTS;\n  frag.endDTS = endDTS;\n  frag.duration = endPTS - startPTS;\n\n  var sn = frag.sn;\n  // exit if sn out of range\n  if (!details || sn < details.startSN || sn > details.endSN) return 0;\n\n  var fragIdx = void 0,\n      fragments = void 0,\n      i = void 0;\n  fragIdx = sn - details.startSN;\n  fragments = details.fragments;\n  // update frag reference in fragments array\n  // rationale is that fragments array might not contain this frag object.\n  // this will happpen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()\n  // if we don't update frag, we won't be able to propagate PTS info on the playlist\n  // resulting in invalid sliding computation\n  fragments[fragIdx] = frag;\n  // adjust fragment PTS/duration from seqnum-1 to frag 0\n  for (i = fragIdx; i > 0; i--) {\n    updatePTS(fragments, i, i - 1);\n  } // adjust fragment PTS/duration from seqnum to last frag\n  for (i = fragIdx; i < fragments.length - 1; i++) {\n    updatePTS(fragments, i, i + 1);\n  }details.PTSKnown = true;\n  // logger.log(`                                            frag start/end:${startPTS.toFixed(3)}/${endPTS.toFixed(3)}`);\n\n  return drift;\n}\n\nfunction mergeDetails(oldDetails, newDetails) {\n  var start = Math.max(oldDetails.startSN, newDetails.startSN) - newDetails.startSN,\n      end = Math.min(oldDetails.endSN, newDetails.endSN) - newDetails.startSN,\n      delta = newDetails.startSN - oldDetails.startSN,\n      oldfragments = oldDetails.fragments,\n      newfragments = newDetails.fragments,\n      ccOffset = 0,\n      PTSFrag = void 0;\n\n  // potentially retrieve cached initsegment\n  if (newDetails.initSegment && oldDetails.initSegment) newDetails.initSegment = oldDetails.initSegment;\n\n  // check if old/new playlists have fragments in common\n  if (end < start) {\n    newDetails.PTSKnown = false;\n    return;\n  }\n  // loop through overlapping SN and update startPTS , cc, and duration if any found\n  for (var i = start; i <= end; i++) {\n    var oldFrag = oldfragments[delta + i],\n        newFrag = newfragments[i];\n    if (newFrag && oldFrag) {\n      ccOffset = oldFrag.cc - newFrag.cc;\n      if (!isNaN(oldFrag.startPTS)) {\n        newFrag.start = newFrag.startPTS = oldFrag.startPTS;\n        newFrag.endPTS = oldFrag.endPTS;\n        newFrag.duration = oldFrag.duration;\n        newFrag.backtracked = oldFrag.backtracked;\n        newFrag.dropped = oldFrag.dropped;\n        PTSFrag = newFrag;\n      }\n    }\n  }\n\n  if (ccOffset) {\n    logger[\"b\" /* logger */].log('discontinuity sliding from playlist, take drift into account');\n    for (i = 0; i < newfragments.length; i++) {\n      newfragments[i].cc += ccOffset;\n    }\n  }\n\n  // if at least one fragment contains PTS info, recompute PTS information for all fragments\n  if (PTSFrag) {\n    updateFragPTSDTS(newDetails, PTSFrag, PTSFrag.startPTS, PTSFrag.endPTS, PTSFrag.startDTS, PTSFrag.endDTS);\n  } else {\n    // ensure that delta is within oldfragments range\n    // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])\n    // in that case we also need to adjust start offset of all fragments\n    if (delta >= 0 && delta < oldfragments.length) {\n      // adjust start by sliding offset\n      var sliding = oldfragments[delta].start;\n      for (i = 0; i < newfragments.length; i++) {\n        newfragments[i].start += sliding;\n      }\n    }\n  }\n  // if we are here, it means we have fragments overlapping between\n  // old and new level. reliable PTS info is thus relying on old level\n  newDetails.PTSKnown = oldDetails.PTSKnown;\n}\n// CONCATENATED MODULE: ./src/utils/time-ranges.js\n/**\n *  TimeRanges to string helper\n */\n\nvar TimeRanges = {\n  toString: function toString(r) {\n    var log = '',\n        len = r.length;\n    for (var i = 0; i < len; i++) {\n      log += '[' + r.start(i).toFixed(3) + ',' + r.end(i).toFixed(3) + ']';\n    }return log;\n  }\n};\n\n/* harmony default export */ var time_ranges = (TimeRanges);\n// CONCATENATED MODULE: ./src/utils/discontinuities.js\n\n\n\nfunction findFirstFragWithCC(fragments, cc) {\n  var firstFrag = null;\n\n  for (var i = 0; i < fragments.length; i += 1) {\n    var currentFrag = fragments[i];\n    if (currentFrag && currentFrag.cc === cc) {\n      firstFrag = currentFrag;\n      break;\n    }\n  }\n\n  return firstFrag;\n}\n\nfunction findFragWithCC(fragments, CC) {\n  return binary_search.search(fragments, function (candidate) {\n    if (candidate.cc < CC) return 1;else if (candidate.cc > CC) return -1;else return 0;\n  });\n}\n\nfunction shouldAlignOnDiscontinuities(lastFrag, lastLevel, details) {\n  var shouldAlign = false;\n  if (lastLevel && lastLevel.details && details) {\n    if (details.endCC > details.startCC || lastFrag && lastFrag.cc < details.startCC) shouldAlign = true;\n  }\n  return shouldAlign;\n}\n\n// Find the first frag in the previous level which matches the CC of the first frag of the new level\nfunction findDiscontinuousReferenceFrag(prevDetails, curDetails) {\n  var prevFrags = prevDetails.fragments;\n  var curFrags = curDetails.fragments;\n\n  if (!curFrags.length || !prevFrags.length) {\n    logger[\"b\" /* logger */].log('No fragments to align');\n    return;\n  }\n\n  var prevStartFrag = findFirstFragWithCC(prevFrags, curFrags[0].cc);\n\n  if (!prevStartFrag || prevStartFrag && !prevStartFrag.startPTS) {\n    logger[\"b\" /* logger */].log('No frag in previous level to align on');\n    return;\n  }\n\n  return prevStartFrag;\n}\n\nfunction adjustPts(sliding, details) {\n  details.fragments.forEach(function (frag) {\n    if (frag) {\n      var start = frag.start + sliding;\n      frag.start = frag.startPTS = start;\n      frag.endPTS = start + frag.duration;\n    }\n  });\n  details.PTSKnown = true;\n}\n\n// If a change in CC is detected, the PTS can no longer be relied upon\n// Attempt to align the level by using the last level - find the last frag matching the current CC and use it's PTS\n// as a reference\nfunction alignDiscontinuities(lastFrag, lastLevel, details) {\n  if (shouldAlignOnDiscontinuities(lastFrag, lastLevel, details)) {\n    var referenceFrag = findDiscontinuousReferenceFrag(lastLevel.details, details);\n    if (referenceFrag) {\n      logger[\"b\" /* logger */].log('Adjusting PTS using last level due to CC increase within current level');\n      adjustPts(referenceFrag.start, details);\n    }\n  }\n  // try to align using programDateTime attribute (if available)\n  if (details.PTSKnown === false && lastLevel && lastLevel.details && lastLevel.details.fragments && lastLevel.details.fragments.length) {\n    // if last level sliding is 1000 and its first frag PROGRAM-DATE-TIME is 2017-08-20 1:10:00 AM\n    // and if new details first frag PROGRAM DATE-TIME is 2017-08-20 1:10:08 AM\n    // then we can deduce that playlist B sliding is 1000+8 = 1008s\n    var lastPDT = lastLevel.details.programDateTime;\n    var newPDT = details.programDateTime;\n    // date diff is in ms. frag.start is in seconds\n    var sliding = (newPDT - lastPDT) / 1000 + lastLevel.details.fragments[0].start;\n    if (!isNaN(sliding)) {\n      logger[\"b\" /* logger */].log('adjusting PTS using programDateTime delta, sliding:' + sliding.toFixed(3));\n      adjustPts(sliding, details);\n    }\n  }\n}\n// CONCATENATED MODULE: ./src/task-loop.js\nfunction task_loop__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction task_loop__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction task_loop__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n\n\nvar TaskLoop = function (_EventHandler) {\n  task_loop__inherits(TaskLoop, _EventHandler);\n\n  function TaskLoop(hls) {\n    task_loop__classCallCheck(this, TaskLoop);\n\n    for (var _len = arguments.length, events = Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      events[_key - 1] = arguments[_key];\n    }\n\n    var _this = task_loop__possibleConstructorReturn(this, _EventHandler.call.apply(_EventHandler, [this, hls].concat(events)));\n\n    _this._tickInterval = null;\n    _this._tickCallCount = 0;\n    return _this;\n  }\n\n  /**\n   * @override\n   */\n\n\n  TaskLoop.prototype.destroy = function destroy() {\n    this.clearInterval();\n    _EventHandler.prototype.destroy.call(this);\n  };\n\n  /**\n   * @returns {boolean}\n   */\n\n\n  TaskLoop.prototype.hasInterval = function hasInterval() {\n    return this._tickInterval !== null;\n  };\n\n  /**\n   * @param {number} millis Interval time (ms)\n   * @returns {boolean} True when interval has been scheduled, false when already scheduled (no effect)\n   */\n\n\n  TaskLoop.prototype.setInterval = function (_setInterval) {\n    function setInterval(_x) {\n      return _setInterval.apply(this, arguments);\n    }\n\n    setInterval.toString = function () {\n      return _setInterval.toString();\n    };\n\n    return setInterval;\n  }(function (millis) {\n    if (!this._tickInterval) {\n      this._tickInterval = setInterval(this.tick.bind(this, false), millis);\n      return true;\n    }\n    return false;\n  });\n\n  /**\n   * @returns {boolean} True when interval was cleared, false when none was set (no effect)\n   */\n\n\n  TaskLoop.prototype.clearInterval = function (_clearInterval) {\n    function clearInterval() {\n      return _clearInterval.apply(this, arguments);\n    }\n\n    clearInterval.toString = function () {\n      return _clearInterval.toString();\n    };\n\n    return clearInterval;\n  }(function () {\n    if (this._tickInterval) {\n      clearInterval(this._tickInterval);\n      this._tickInterval = null;\n      return true;\n    }\n    return false;\n  });\n\n  /**\n   *\n   * @param {Wether to force async} forceAsync\n   * @returns {boolean} True when async, false when sync\n   */\n\n\n  TaskLoop.prototype.tick = function tick() {\n    this._tickCallCount++;\n    if (this._tickCallCount === 1) {\n      this.doTick();\n      if (this._tickCallCount > 1) setTimeout(this.tick.bind(this), 0);\n\n      this._tickCallCount = 0;\n    }\n  };\n\n  /**\n   * For subclass to implement task logic\n   * @abstract\n   */\n\n\n  TaskLoop.prototype.doTick = function doTick() {\n    throw new Error('TaskLoop is abstract and `doLoop` must be implemented');\n  };\n\n  return TaskLoop;\n}(event_handler);\n\n/* harmony default export */ var task_loop = (TaskLoop);\n// CONCATENATED MODULE: ./src/controller/stream-controller.js\nvar stream_controller__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction stream_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction stream_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction stream_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * Stream Controller\n*/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar State = {\n  STOPPED: 'STOPPED',\n  IDLE: 'IDLE',\n  KEY_LOADING: 'KEY_LOADING',\n  FRAG_LOADING: 'FRAG_LOADING',\n  FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',\n  WAITING_LEVEL: 'WAITING_LEVEL',\n  PARSING: 'PARSING',\n  PARSED: 'PARSED',\n  BUFFER_FLUSHING: 'BUFFER_FLUSHING',\n  ENDED: 'ENDED',\n  ERROR: 'ERROR'\n};\n\nvar stream_controller_StreamController = function (_TaskLoop) {\n  stream_controller__inherits(StreamController, _TaskLoop);\n\n  function StreamController(hls, fragmentTracker) {\n    stream_controller__classCallCheck(this, StreamController);\n\n    var _this = stream_controller__possibleConstructorReturn(this, _TaskLoop.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHED, events[\"a\" /* default */].MEDIA_DETACHING, events[\"a\" /* default */].MANIFEST_LOADING, events[\"a\" /* default */].MANIFEST_PARSED, events[\"a\" /* default */].LEVEL_LOADED, events[\"a\" /* default */].KEY_LOADED, events[\"a\" /* default */].FRAG_LOADED, events[\"a\" /* default */].FRAG_LOAD_EMERGENCY_ABORTED, events[\"a\" /* default */].FRAG_PARSING_INIT_SEGMENT, events[\"a\" /* default */].FRAG_PARSING_DATA, events[\"a\" /* default */].FRAG_PARSED, events[\"a\" /* default */].ERROR, events[\"a\" /* default */].AUDIO_TRACK_SWITCHING, events[\"a\" /* default */].AUDIO_TRACK_SWITCHED, events[\"a\" /* default */].BUFFER_CREATED, events[\"a\" /* default */].BUFFER_APPENDED, events[\"a\" /* default */].BUFFER_FLUSHED));\n\n    _this.fragmentTracker = fragmentTracker;\n    _this.config = hls.config;\n    _this.audioCodecSwap = false;\n    _this._state = State.STOPPED;\n    return _this;\n  }\n\n  StreamController.prototype.onHandlerDestroying = function onHandlerDestroying() {\n    this.stopLoad();\n  };\n\n  StreamController.prototype.onHandlerDestroyed = function onHandlerDestroyed() {\n    this.state = State.STOPPED;\n    this.fragmentTracker = null;\n  };\n\n  StreamController.prototype.startLoad = function startLoad(startPosition) {\n    if (this.levels) {\n      var lastCurrentTime = this.lastCurrentTime,\n          hls = this.hls;\n      this.stopLoad();\n      this.setInterval(100);\n      this.level = -1;\n      this.fragLoadError = 0;\n      if (!this.startFragRequested) {\n        // determine load level\n        var startLevel = hls.startLevel;\n        if (startLevel === -1) {\n          // -1 : guess start Level by doing a bitrate test by loading first fragment of lowest quality level\n          startLevel = 0;\n          this.bitrateTest = true;\n        }\n        // set new level to playlist loader : this will trigger start level load\n        // hls.nextLoadLevel remains until it is set to a new value or until a new frag is successfully loaded\n        this.level = hls.nextLoadLevel = startLevel;\n        this.loadedmetadata = false;\n      }\n      // if startPosition undefined but lastCurrentTime set, set startPosition to last currentTime\n      if (lastCurrentTime > 0 && startPosition === -1) {\n        logger[\"b\" /* logger */].log('override startPosition with lastCurrentTime @' + lastCurrentTime.toFixed(3));\n        startPosition = lastCurrentTime;\n      }\n      this.state = State.IDLE;\n      this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;\n      this.tick();\n    } else {\n      this.forceStartLoad = true;\n      this.state = State.STOPPED;\n    }\n  };\n\n  StreamController.prototype.stopLoad = function stopLoad() {\n    var frag = this.fragCurrent;\n    if (frag) {\n      if (frag.loader) frag.loader.abort();\n\n      this.fragmentTracker.removeFragment(frag);\n      this.fragCurrent = null;\n    }\n    this.fragPrevious = null;\n    if (this.demuxer) {\n      this.demuxer.destroy();\n      this.demuxer = null;\n    }\n    this.clearInterval();\n    this.state = State.STOPPED;\n    this.forceStartLoad = false;\n  };\n\n  StreamController.prototype.doTick = function doTick() {\n    switch (this.state) {\n      case State.BUFFER_FLUSHING:\n        // in buffer flushing state, reset fragLoadError counter\n        this.fragLoadError = 0;\n        break;\n      case State.IDLE:\n        this._doTickIdle();\n        break;\n      case State.WAITING_LEVEL:\n        var level = this.levels[this.level];\n        // check if playlist is already loaded\n        if (level && level.details) this.state = State.IDLE;\n\n        break;\n      case State.FRAG_LOADING_WAITING_RETRY:\n        var now = performance.now();\n        var retryDate = this.retryDate;\n        // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\n        if (!retryDate || now >= retryDate || this.media && this.media.seeking) {\n          logger[\"b\" /* logger */].log('mediaController: retryDate reached, switch back to IDLE state');\n          this.state = State.IDLE;\n        }\n        break;\n      case State.ERROR:\n      case State.STOPPED:\n      case State.FRAG_LOADING:\n      case State.PARSING:\n      case State.PARSED:\n      case State.ENDED:\n        break;\n      default:\n        break;\n    }\n    // check buffer\n    this._checkBuffer();\n    // check/update current fragment\n    this._checkFragmentChanged();\n  };\n\n  // Ironically the \"idle\" state is the on we do the most logic in it seems ....\n  // NOTE: Maybe we could rather schedule a check for buffer length after half of the currently\n  //       played segment, or on pause/play/seek instead of naively checking every 100ms?\n\n\n  StreamController.prototype._doTickIdle = function _doTickIdle() {\n    var hls = this.hls,\n        config = hls.config,\n        media = this.media;\n\n    // if start level not parsed yet OR\n    // if video not attached AND start fragment already requested OR start frag prefetch disable\n    // exit loop, as we either need more info (level not parsed) or we need media to be attached to load new fragment\n    if (this.levelLastLoaded === undefined || !media && (this.startFragRequested || !config.startFragPrefetch)) return;\n\n    // if we have not yet loaded any fragment, start loading from start position\n    var pos = void 0;\n    if (this.loadedmetadata) pos = media.currentTime;else pos = this.nextLoadPosition;\n\n    // determine next load level\n    var level = hls.nextLoadLevel,\n        levelInfo = this.levels[level];\n\n    if (!levelInfo) return;\n\n    var levelBitrate = levelInfo.bitrate,\n        maxBufLen = void 0;\n\n    // compute max Buffer Length that we could get from this load level, based on level bitrate. don't buffer more than 60 MB and more than 30s\n    if (levelBitrate) maxBufLen = Math.max(8 * config.maxBufferSize / levelBitrate, config.maxBufferLength);else maxBufLen = config.maxBufferLength;\n\n    maxBufLen = Math.min(maxBufLen, config.maxMaxBufferLength);\n\n    // determine next candidate fragment to be loaded, based on current position and end of buffer position\n    // ensure up to `config.maxMaxBufferLength` of buffer upfront\n\n    var bufferInfo = buffer_helper.bufferInfo(this.mediaBuffer ? this.mediaBuffer : media, pos, config.maxBufferHole),\n        bufferLen = bufferInfo.len;\n    // Stay idle if we are still with buffer margins\n    if (bufferLen >= maxBufLen) return;\n\n    // if buffer length is less than maxBufLen try to load a new fragment ...\n    logger[\"b\" /* logger */].trace('buffer length of ' + bufferLen.toFixed(3) + ' is below max of ' + maxBufLen.toFixed(3) + '. checking for more payload ...');\n\n    // set next load level : this will trigger a playlist load if needed\n    this.level = hls.nextLoadLevel = level;\n\n    var levelDetails = levelInfo.details;\n    // if level info not retrieved yet, switch state and wait for level retrieval\n    // if live playlist, ensure that new playlist has been refreshed to avoid loading/try to load\n    // a useless and outdated fragment (that might even introduce load error if it is already out of the live playlist)\n    if (levelDetails === undefined || levelDetails.live === true && this.levelLastLoaded !== level) {\n      this.state = State.WAITING_LEVEL;\n      return;\n    }\n\n    // we just got done loading the final fragment and there is no other buffered range after ...\n    // rationale is that in case there are any buffered ranges after, it means that there are unbuffered portion in between\n    // so we should not switch to ENDED in that case, to be able to buffer them\n    // dont switch to ENDED if we need to backtrack last fragment\n    var fragPrevious = this.fragPrevious;\n    if (!levelDetails.live && fragPrevious && !fragPrevious.backtracked && fragPrevious.sn === levelDetails.endSN && !bufferInfo.nextStart) {\n      // fragPrevious is last fragment. retrieve level duration using last frag start offset + duration\n      // real duration might be lower than initial duration if there are drifts between real frag duration and playlist signaling\n      var duration = Math.min(media.duration, fragPrevious.start + fragPrevious.duration);\n      // if everything (almost) til the end is buffered, let's signal eos\n      // we don't compare exactly media.duration === bufferInfo.end as there could be some subtle media duration difference (audio/video offsets...)\n      // tolerate up to one frag duration to cope with these cases.\n      // also cope with almost zero last frag duration (max last frag duration with 200ms) refer to https://github.com/video-dev/hls.js/pull/657\n      if (duration - Math.max(bufferInfo.end, fragPrevious.start) <= Math.max(0.2, fragPrevious.duration)) {\n        // Finalize the media stream\n        var data = {};\n        if (this.altAudio) data.type = 'video';\n\n        this.hls.trigger(events[\"a\" /* default */].BUFFER_EOS, data);\n        this.state = State.ENDED;\n        return;\n      }\n    }\n\n    // if we have the levelDetails for the selected variant, lets continue enrichen our stream (load keys/fragments or trigger EOS, etc..)\n    this._fetchPayloadOrEos(pos, bufferInfo, levelDetails);\n  };\n\n  StreamController.prototype._fetchPayloadOrEos = function _fetchPayloadOrEos(pos, bufferInfo, levelDetails) {\n    var fragPrevious = this.fragPrevious,\n        level = this.level,\n        fragments = levelDetails.fragments,\n        fragLen = fragments.length;\n\n    // empty playlist\n    if (fragLen === 0) return;\n\n    // find fragment index, contiguous with end of buffer position\n    var start = fragments[0].start,\n        end = fragments[fragLen - 1].start + fragments[fragLen - 1].duration,\n        bufferEnd = bufferInfo.end,\n        frag = void 0;\n\n    if (levelDetails.initSegment && !levelDetails.initSegment.data) {\n      frag = levelDetails.initSegment;\n    } else {\n      // in case of live playlist we need to ensure that requested position is not located before playlist start\n      if (levelDetails.live) {\n        var initialLiveManifestSize = this.config.initialLiveManifestSize;\n        if (fragLen < initialLiveManifestSize) {\n          logger[\"b\" /* logger */].warn('Can not start playback of a level, reason: not enough fragments ' + fragLen + ' < ' + initialLiveManifestSize);\n          return;\n        }\n\n        frag = this._ensureFragmentAtLivePoint(levelDetails, bufferEnd, start, end, fragPrevious, fragments, fragLen);\n        // if it explicitely returns null don't load any fragment and exit function now\n        if (frag === null) return;\n      } else {\n        // VoD playlist: if bufferEnd before start of playlist, load first fragment\n        if (bufferEnd < start) frag = fragments[0];\n      }\n    }\n    if (!frag) frag = this._findFragment(start, fragPrevious, fragLen, fragments, bufferEnd, end, levelDetails);\n\n    if (frag) this._loadFragmentOrKey(frag, level, levelDetails, pos, bufferEnd);\n  };\n\n  StreamController.prototype._ensureFragmentAtLivePoint = function _ensureFragmentAtLivePoint(levelDetails, bufferEnd, start, end, fragPrevious, fragments, fragLen) {\n    var config = this.hls.config,\n        media = this.media;\n\n    var frag = void 0;\n\n    // check if requested position is within seekable boundaries :\n    // logger.log(`start/pos/bufEnd/seeking:${start.toFixed(3)}/${pos.toFixed(3)}/${bufferEnd.toFixed(3)}/${this.media.seeking}`);\n    var maxLatency = config.liveMaxLatencyDuration !== undefined ? config.liveMaxLatencyDuration : config.liveMaxLatencyDurationCount * levelDetails.targetduration;\n\n    if (bufferEnd < Math.max(start - config.maxFragLookUpTolerance, end - maxLatency)) {\n      var liveSyncPosition = this.liveSyncPosition = this.computeLivePosition(start, levelDetails);\n      logger[\"b\" /* logger */].log('buffer end: ' + bufferEnd.toFixed(3) + ' is located too far from the end of live sliding playlist, reset currentTime to : ' + liveSyncPosition.toFixed(3));\n      bufferEnd = liveSyncPosition;\n      if (media && media.readyState && media.duration > liveSyncPosition) media.currentTime = liveSyncPosition;\n\n      this.nextLoadPosition = liveSyncPosition;\n    }\n\n    // if end of buffer greater than live edge, don't load any fragment\n    // this could happen if live playlist intermittently slides in the past.\n    // level 1 loaded [182580161,182580167]\n    // level 1 loaded [182580162,182580169]\n    // Loading 182580168 of [182580162 ,182580169],level 1 ..\n    // Loading 182580169 of [182580162 ,182580169],level 1 ..\n    // level 1 loaded [182580162,182580168] <============= here we should have bufferEnd > end. in that case break to avoid reloading 182580168\n    // level 1 loaded [182580164,182580171]\n    //\n    // don't return null in case media not loaded yet (readystate === 0)\n    if (levelDetails.PTSKnown && bufferEnd > end && media && media.readyState) return null;\n\n    if (this.startFragRequested && !levelDetails.PTSKnown) {\n      /* we are switching level on live playlist, but we don't have any PTS info for that quality level ...\n         try to load frag matching with next SN.\n         even if SN are not synchronized between playlists, loading this frag will help us\n         compute playlist sliding and find the right one after in case it was not the right consecutive one */\n      if (fragPrevious) {\n        if (!levelDetails.programDateTime) {\n          // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)\n          var targetSN = fragPrevious.sn + 1;\n          if (targetSN >= levelDetails.startSN && targetSN <= levelDetails.endSN) {\n            var fragNext = fragments[targetSN - levelDetails.startSN];\n            if (fragPrevious.cc === fragNext.cc) {\n              frag = fragNext;\n              logger[\"b\" /* logger */].log('live playlist, switching playlist, load frag with next SN: ' + frag.sn);\n            }\n          }\n          // next frag SN not available (or not with same continuity counter)\n          // look for a frag sharing the same CC\n          if (!frag) {\n            frag = binary_search.search(fragments, function (frag) {\n              return fragPrevious.cc - frag.cc;\n            });\n            if (frag) logger[\"b\" /* logger */].log('live playlist, switching playlist, load frag with same CC: ' + frag.sn);\n          }\n        } else {\n          // Relies on PDT in order to switch bitrates (Support EXT-X-DISCONTINUITY without EXT-X-DISCONTINUITY-SEQUENCE)\n          frag = this._findFragmentByPDT(fragments, fragPrevious.endPdt + 1);\n        }\n      }\n      if (!frag) {\n        /* we have no idea about which fragment should be loaded.\n           so let's load mid fragment. it will help computing playlist sliding and find the right one\n        */\n        frag = fragments[Math.min(fragLen - 1, Math.round(fragLen / 2))];\n        logger[\"b\" /* logger */].log('live playlist, switching playlist, unknown, load middle frag : ' + frag.sn);\n      }\n    }\n    return frag;\n  };\n\n  StreamController.prototype._findFragmentByPDT = function _findFragmentByPDT(fragments, PDTValue) {\n    if (!fragments || PDTValue === undefined) return null;\n\n    // if less than start\n    var firstSegment = fragments[0];\n\n    if (PDTValue < firstSegment.pdt) return null;\n\n    var lastSegment = fragments[fragments.length - 1];\n\n    if (PDTValue >= lastSegment.endPdt) return null;\n\n    for (var seg = 0; seg < fragments.length; ++seg) {\n      var frag = fragments[seg];\n      if (PDTValue < frag.endPdt) return frag;\n    }\n    return null;\n  };\n\n  StreamController.prototype._findFragmentBySN = function _findFragmentBySN(fragPrevious, fragments, bufferEnd, end) {\n    var config = this.hls.config;\n    var foundFrag = void 0;\n    var maxFragLookUpTolerance = config.maxFragLookUpTolerance;\n    var fragNext = fragPrevious ? fragments[fragPrevious.sn - fragments[0].sn + 1] : undefined;\n    var fragmentWithinToleranceTest = function fragmentWithinToleranceTest(candidate) {\n      // offset should be within fragment boundary - config.maxFragLookUpTolerance\n      // this is to cope with situations like\n      // bufferEnd = 9.991\n      // frag[Ø] : [0,10]\n      // frag[1] : [10,20]\n      // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here\n      //              frag start               frag start+duration\n      //                  |-----------------------------|\n      //              <--->                         <--->\n      //  ...--------><-----------------------------><---------....\n      // previous frag         matching fragment         next frag\n      //  return -1             return 0                 return 1\n      // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);\n      // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments\n      var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0));\n      if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) return 1;\n      // if maxFragLookUpTolerance will have negative value then don't return -1 for first element\n      else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) return -1;\n\n      return 0;\n    };\n\n    if (bufferEnd < end) {\n      if (bufferEnd > end - maxFragLookUpTolerance) maxFragLookUpTolerance = 0;\n\n      // Prefer the next fragment if it's within tolerance\n      if (fragNext && !fragmentWithinToleranceTest(fragNext)) foundFrag = fragNext;else foundFrag = binary_search.search(fragments, fragmentWithinToleranceTest);\n    }\n    return foundFrag;\n  };\n\n  StreamController.prototype._findFragment = function _findFragment(start, fragPrevious, fragLen, fragments, bufferEnd, end, levelDetails) {\n    var config = this.hls.config;\n    var frag = void 0;\n    var foundFrag = void 0;\n\n    if (bufferEnd < end) {\n      if (!levelDetails.programDateTime) {\n        // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)\n        foundFrag = this._findFragmentBySN(fragPrevious, fragments, bufferEnd, end);\n      } else {\n        // Relies on PDT in order to switch bitrates (Support EXT-X-DISCONTINUITY without EXT-X-DISCONTINUITY-SEQUENCE)\n        // compute PDT of bufferEnd: PDT(bufferEnd) = 1000*bufferEnd + PDT(start) = 1000*bufferEnd + PDT(level) - level sliding\n        foundFrag = this._findFragmentByPDT(fragments, bufferEnd * 1000 + (levelDetails.programDateTime ? Date.parse(levelDetails.programDateTime) : 0) - 1000 * start);\n      }\n    } else {\n      // reach end of playlist\n      foundFrag = fragments[fragLen - 1];\n    }\n    if (foundFrag) {\n      frag = foundFrag;\n      var curSNIdx = frag.sn - levelDetails.startSN;\n      var sameLevel = fragPrevious && frag.level === fragPrevious.level;\n      var prevFrag = fragments[curSNIdx - 1];\n      var nextFrag = fragments[curSNIdx + 1];\n      // logger.log('find SN matching with pos:' +  bufferEnd + ':' + frag.sn);\n      if (fragPrevious && frag.sn === fragPrevious.sn) {\n        if (sameLevel && !frag.backtracked) {\n          if (frag.sn < levelDetails.endSN) {\n            var deltaPTS = fragPrevious.deltaPTS;\n            // if there is a significant delta between audio and video, larger than max allowed hole,\n            // and if previous remuxed fragment did not start with a keyframe. (fragPrevious.dropped)\n            // let's try to load previous fragment again to get last keyframe\n            // then we will reload again current fragment (that way we should be able to fill the buffer hole ...)\n            if (deltaPTS && deltaPTS > config.maxBufferHole && fragPrevious.dropped && curSNIdx) {\n              frag = prevFrag;\n              logger[\"b\" /* logger */].warn('SN just loaded, with large PTS gap between audio and video, maybe frag is not starting with a keyframe ? load previous one to try to overcome this');\n            } else {\n              frag = nextFrag;\n              logger[\"b\" /* logger */].log('SN just loaded, load next one: ' + frag.sn);\n            }\n          } else {\n            frag = null;\n          }\n        } else if (frag.backtracked) {\n          // Only backtrack a max of 1 consecutive fragment to prevent sliding back too far when little or no frags start with keyframes\n          if (nextFrag && nextFrag.backtracked) {\n            logger[\"b\" /* logger */].warn('Already backtracked from fragment ' + nextFrag.sn + ', will not backtrack to fragment ' + frag.sn + '. Loading fragment ' + nextFrag.sn);\n            frag = nextFrag;\n          } else {\n            // If a fragment has dropped frames and it's in a same level/sequence, load the previous fragment to try and find the keyframe\n            // Reset the dropped count now since it won't be reset until we parse the fragment again, which prevents infinite backtracking on the same segment\n            logger[\"b\" /* logger */].warn('Loaded fragment with dropped frames, backtracking 1 segment to find a keyframe');\n            frag.dropped = 0;\n            if (prevFrag) {\n              frag = prevFrag;\n              frag.backtracked = true;\n            } else if (curSNIdx) {\n              // can't backtrack on very first fragment\n              frag = null;\n            }\n          }\n        }\n      }\n    }\n    return frag;\n  };\n\n  StreamController.prototype._loadFragmentOrKey = function _loadFragmentOrKey(frag, level, levelDetails, pos, bufferEnd) {\n    // logger.log('loading frag ' + i +',pos/bufEnd:' + pos.toFixed(3) + '/' + bufferEnd.toFixed(3));\n    if (frag.decryptdata && frag.decryptdata.uri != null && frag.decryptdata.key == null) {\n      logger[\"b\" /* logger */].log('Loading key for ' + frag.sn + ' of [' + levelDetails.startSN + ' ,' + levelDetails.endSN + '],level ' + level);\n      this.state = State.KEY_LOADING;\n      this.hls.trigger(events[\"a\" /* default */].KEY_LOADING, { frag: frag });\n    } else {\n      logger[\"b\" /* logger */].log('Loading ' + frag.sn + ' of [' + levelDetails.startSN + ' ,' + levelDetails.endSN + '],level ' + level + ', currentTime:' + pos.toFixed(3) + ',bufferEnd:' + bufferEnd.toFixed(3));\n      // Check if fragment is not loaded\n      var fragState = this.fragmentTracker.getState(frag);\n\n      this.fragCurrent = frag;\n      this.startFragRequested = true;\n      // Don't update nextLoadPosition for fragments which are not buffered\n      if (!isNaN(frag.sn) && !frag.bitrateTest) this.nextLoadPosition = frag.start + frag.duration;\n\n      // Allow backtracked fragments to load\n      if (frag.backtracked || fragState === FragmentState.NOT_LOADED) {\n        frag.autoLevel = this.hls.autoLevelEnabled;\n        frag.bitrateTest = this.bitrateTest;\n\n        this.hls.trigger(events[\"a\" /* default */].FRAG_LOADING, { frag: frag });\n        // lazy demuxer init, as this could take some time ... do it during frag loading\n        if (!this.demuxer) this.demuxer = new demux_demuxer(this.hls, 'main');\n\n        this.state = State.FRAG_LOADING;\n      } else if (fragState === FragmentState.APPENDING) {\n        // Lower the buffer size and try again\n        if (this._reduceMaxBufferLength(frag.duration)) this.fragmentTracker.removeFragment(frag);\n      }\n    }\n  };\n\n  StreamController.prototype.getBufferedFrag = function getBufferedFrag(position) {\n    return this.fragmentTracker.getBufferedFrag(position, playlist_loader.LevelType.MAIN);\n  };\n\n  StreamController.prototype.followingBufferedFrag = function followingBufferedFrag(frag) {\n    if (frag) {\n      // try to get range of next fragment (500ms after this range)\n      return this.getBufferedFrag(frag.endPTS + 0.5);\n    }\n    return null;\n  };\n\n  StreamController.prototype._checkFragmentChanged = function _checkFragmentChanged() {\n    var fragPlayingCurrent = void 0,\n        currentTime = void 0,\n        video = this.media;\n    if (video && video.readyState && video.seeking === false) {\n      currentTime = video.currentTime;\n      /* if video element is in seeked state, currentTime can only increase.\n        (assuming that playback rate is positive ...)\n        As sometimes currentTime jumps back to zero after a\n        media decode error, check this, to avoid seeking back to\n        wrong position after a media decode error\n      */\n      if (currentTime > video.playbackRate * this.lastCurrentTime) this.lastCurrentTime = currentTime;\n\n      if (buffer_helper.isBuffered(video, currentTime)) {\n        fragPlayingCurrent = this.getBufferedFrag(currentTime);\n      } else if (buffer_helper.isBuffered(video, currentTime + 0.1)) {\n        /* ensure that FRAG_CHANGED event is triggered at startup,\n          when first video frame is displayed and playback is paused.\n          add a tolerance of 100ms, in case current position is not buffered,\n          check if current pos+100ms is buffered and use that buffer range\n          for FRAG_CHANGED event reporting */\n        fragPlayingCurrent = this.getBufferedFrag(currentTime + 0.1);\n      }\n      if (fragPlayingCurrent) {\n        var fragPlaying = fragPlayingCurrent;\n        if (fragPlaying !== this.fragPlaying) {\n          this.hls.trigger(events[\"a\" /* default */].FRAG_CHANGED, { frag: fragPlaying });\n          var fragPlayingLevel = fragPlaying.level;\n          if (!this.fragPlaying || this.fragPlaying.level !== fragPlayingLevel) this.hls.trigger(events[\"a\" /* default */].LEVEL_SWITCHED, { level: fragPlayingLevel });\n\n          this.fragPlaying = fragPlaying;\n        }\n      }\n    }\n  };\n\n  /*\n    on immediate level switch :\n     - pause playback if playing\n     - cancel any pending load request\n     - and trigger a buffer flush\n  */\n\n\n  StreamController.prototype.immediateLevelSwitch = function immediateLevelSwitch() {\n    logger[\"b\" /* logger */].log('immediateLevelSwitch');\n    if (!this.immediateSwitch) {\n      this.immediateSwitch = true;\n      var media = this.media,\n          previouslyPaused = void 0;\n      if (media) {\n        previouslyPaused = media.paused;\n        media.pause();\n      } else {\n        // don't restart playback after instant level switch in case media not attached\n        previouslyPaused = true;\n      }\n      this.previouslyPaused = previouslyPaused;\n    }\n    var fragCurrent = this.fragCurrent;\n    if (fragCurrent && fragCurrent.loader) fragCurrent.loader.abort();\n\n    this.fragCurrent = null;\n    // flush everything\n    this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\n  };\n\n  /**\n   * on immediate level switch end, after new fragment has been buffered:\n   * - nudge video decoder by slightly adjusting video currentTime (if currentTime buffered)\n   * - resume the playback if needed\n   */\n\n\n  StreamController.prototype.immediateLevelSwitchEnd = function immediateLevelSwitchEnd() {\n    var media = this.media;\n    if (media && media.buffered.length) {\n      this.immediateSwitch = false;\n      if (buffer_helper.isBuffered(media, media.currentTime)) {\n        // only nudge if currentTime is buffered\n        media.currentTime -= 0.0001;\n      }\n      if (!this.previouslyPaused) media.play();\n    }\n  };\n\n  /**\n   * try to switch ASAP without breaking video playback:\n   * in order to ensure smooth but quick level switching,\n   * we need to find the next flushable buffer range\n   * we should take into account new segment fetch time\n   */\n\n\n  StreamController.prototype.nextLevelSwitch = function nextLevelSwitch() {\n    var media = this.media;\n    // ensure that media is defined and that metadata are available (to retrieve currentTime)\n    if (media && media.readyState) {\n      var fetchdelay = void 0,\n          fragPlayingCurrent = void 0,\n          nextBufferedFrag = void 0;\n      fragPlayingCurrent = this.getBufferedFrag(media.currentTime);\n      if (fragPlayingCurrent && fragPlayingCurrent.startPTS > 1) {\n        // flush buffer preceding current fragment (flush until current fragment start offset)\n        // minus 1s to avoid video freezing, that could happen if we flush keyframe of current video ...\n        this.flushMainBuffer(0, fragPlayingCurrent.startPTS - 1);\n      }\n      if (!media.paused) {\n        // add a safety delay of 1s\n        var nextLevelId = this.hls.nextLoadLevel,\n            nextLevel = this.levels[nextLevelId],\n            fragLastKbps = this.fragLastKbps;\n        if (fragLastKbps && this.fragCurrent) fetchdelay = this.fragCurrent.duration * nextLevel.bitrate / (1000 * fragLastKbps) + 1;else fetchdelay = 0;\n      } else {\n        fetchdelay = 0;\n      }\n      // logger.log('fetchdelay:'+fetchdelay);\n      // find buffer range that will be reached once new fragment will be fetched\n      nextBufferedFrag = this.getBufferedFrag(media.currentTime + fetchdelay);\n      if (nextBufferedFrag) {\n        // we can flush buffer range following this one without stalling playback\n        nextBufferedFrag = this.followingBufferedFrag(nextBufferedFrag);\n        if (nextBufferedFrag) {\n          // if we are here, we can also cancel any loading/demuxing in progress, as they are useless\n          var fragCurrent = this.fragCurrent;\n          if (fragCurrent && fragCurrent.loader) fragCurrent.loader.abort();\n\n          this.fragCurrent = null;\n          // start flush position is the start PTS of next buffered frag.\n          // we use frag.naxStartPTS which is max(audio startPTS, video startPTS).\n          // in case there is a small PTS Delta between audio and video, using maxStartPTS avoids flushing last samples from current fragment\n          this.flushMainBuffer(nextBufferedFrag.maxStartPTS, Number.POSITIVE_INFINITY);\n        }\n      }\n    }\n  };\n\n  StreamController.prototype.flushMainBuffer = function flushMainBuffer(startOffset, endOffset) {\n    this.state = State.BUFFER_FLUSHING;\n    var flushScope = { startOffset: startOffset, endOffset: endOffset };\n    // if alternate audio tracks are used, only flush video, otherwise flush everything\n    if (this.altAudio) flushScope.type = 'video';\n\n    this.hls.trigger(events[\"a\" /* default */].BUFFER_FLUSHING, flushScope);\n  };\n\n  StreamController.prototype.onMediaAttached = function onMediaAttached(data) {\n    var media = this.media = this.mediaBuffer = data.media;\n    this.onvseeking = this.onMediaSeeking.bind(this);\n    this.onvseeked = this.onMediaSeeked.bind(this);\n    this.onvended = this.onMediaEnded.bind(this);\n    media.addEventListener('seeking', this.onvseeking);\n    media.addEventListener('seeked', this.onvseeked);\n    media.addEventListener('ended', this.onvended);\n    var config = this.config;\n    if (this.levels && config.autoStartLoad) this.hls.startLoad(config.startPosition);\n  };\n\n  StreamController.prototype.onMediaDetaching = function onMediaDetaching() {\n    var media = this.media;\n    if (media && media.ended) {\n      logger[\"b\" /* logger */].log('MSE detaching and video ended, reset startPosition');\n      this.startPosition = this.lastCurrentTime = 0;\n    }\n\n    // reset fragment backtracked flag\n    var levels = this.levels;\n    if (levels) {\n      levels.forEach(function (level) {\n        if (level.details) {\n          level.details.fragments.forEach(function (fragment) {\n            fragment.backtracked = undefined;\n          });\n        }\n      });\n    }\n    // remove video listeners\n    if (media) {\n      media.removeEventListener('seeking', this.onvseeking);\n      media.removeEventListener('seeked', this.onvseeked);\n      media.removeEventListener('ended', this.onvended);\n      this.onvseeking = this.onvseeked = this.onvended = null;\n    }\n    this.media = this.mediaBuffer = null;\n    this.loadedmetadata = false;\n    this.stopLoad();\n  };\n\n  StreamController.prototype.onMediaSeeking = function onMediaSeeking() {\n    var media = this.media,\n        currentTime = media ? media.currentTime : undefined,\n        config = this.config;\n    if (!isNaN(currentTime)) logger[\"b\" /* logger */].log('media seeking to ' + currentTime.toFixed(3));\n\n    var mediaBuffer = this.mediaBuffer ? this.mediaBuffer : media;\n    var bufferInfo = buffer_helper.bufferInfo(mediaBuffer, currentTime, this.config.maxBufferHole);\n    if (this.state === State.FRAG_LOADING) {\n      var fragCurrent = this.fragCurrent;\n      // check if we are seeking to a unbuffered area AND if frag loading is in progress\n      if (bufferInfo.len === 0 && fragCurrent) {\n        var tolerance = config.maxFragLookUpTolerance,\n            fragStartOffset = fragCurrent.start - tolerance,\n            fragEndOffset = fragCurrent.start + fragCurrent.duration + tolerance;\n        // check if we seek position will be out of currently loaded frag range : if out cancel frag load, if in, don't do anything\n        if (currentTime < fragStartOffset || currentTime > fragEndOffset) {\n          if (fragCurrent.loader) {\n            logger[\"b\" /* logger */].log('seeking outside of buffer while fragment load in progress, cancel fragment load');\n            fragCurrent.loader.abort();\n          }\n          this.fragCurrent = null;\n          this.fragPrevious = null;\n          // switch to IDLE state to load new fragment\n          this.state = State.IDLE;\n        } else {\n          logger[\"b\" /* logger */].log('seeking outside of buffer but within currently loaded fragment range');\n        }\n      }\n    } else if (this.state === State.ENDED) {\n      // if seeking to unbuffered area, clean up fragPrevious\n      if (bufferInfo.len === 0) this.fragPrevious = 0;\n\n      // switch to IDLE state to check for potential new fragment\n      this.state = State.IDLE;\n    }\n    if (media) this.lastCurrentTime = currentTime;\n\n    // in case seeking occurs although no media buffered, adjust startPosition and nextLoadPosition to seek target\n    if (!this.loadedmetadata) this.nextLoadPosition = this.startPosition = currentTime;\n\n    // tick to speed up processing\n    this.tick();\n  };\n\n  StreamController.prototype.onMediaSeeked = function onMediaSeeked() {\n    var media = this.media,\n        currentTime = media ? media.currentTime : undefined;\n    if (!isNaN(currentTime)) logger[\"b\" /* logger */].log('media seeked to ' + currentTime.toFixed(3));\n\n    // tick to speed up FRAGMENT_PLAYING triggering\n    this.tick();\n  };\n\n  StreamController.prototype.onMediaEnded = function onMediaEnded() {\n    logger[\"b\" /* logger */].log('media ended');\n    // reset startPosition and lastCurrentTime to restart playback @ stream beginning\n    this.startPosition = this.lastCurrentTime = 0;\n  };\n\n  StreamController.prototype.onManifestLoading = function onManifestLoading() {\n    // reset buffer on manifest loading\n    logger[\"b\" /* logger */].log('trigger BUFFER_RESET');\n    this.hls.trigger(events[\"a\" /* default */].BUFFER_RESET);\n    this.fragmentTracker.removeAllFragments();\n    this.stalled = false;\n    this.startPosition = this.lastCurrentTime = 0;\n  };\n\n  StreamController.prototype.onManifestParsed = function onManifestParsed(data) {\n    var aac = false,\n        heaac = false,\n        codec = void 0;\n    data.levels.forEach(function (level) {\n      // detect if we have different kind of audio codecs used amongst playlists\n      codec = level.audioCodec;\n      if (codec) {\n        if (codec.indexOf('mp4a.40.2') !== -1) aac = true;\n\n        if (codec.indexOf('mp4a.40.5') !== -1) heaac = true;\n      }\n    });\n    this.audioCodecSwitch = aac && heaac;\n    if (this.audioCodecSwitch) logger[\"b\" /* logger */].log('both AAC/HE-AAC audio found in levels; declaring level codec as HE-AAC');\n\n    this.levels = data.levels;\n    this.startFragRequested = false;\n    var config = this.config;\n    if (config.autoStartLoad || this.forceStartLoad) this.hls.startLoad(config.startPosition);\n  };\n\n  StreamController.prototype.onLevelLoaded = function onLevelLoaded(data) {\n    var newDetails = data.details;\n    var newLevelId = data.level;\n    var lastLevel = this.levels[this.levelLastLoaded];\n    var curLevel = this.levels[newLevelId];\n    var duration = newDetails.totalduration;\n    var sliding = 0;\n\n    logger[\"b\" /* logger */].log('level ' + newLevelId + ' loaded [' + newDetails.startSN + ',' + newDetails.endSN + '],duration:' + duration);\n\n    if (newDetails.live) {\n      var curDetails = curLevel.details;\n      if (curDetails && newDetails.fragments.length > 0) {\n        // we already have details for that level, merge them\n        mergeDetails(curDetails, newDetails);\n        sliding = newDetails.fragments[0].start;\n        this.liveSyncPosition = this.computeLivePosition(sliding, curDetails);\n        if (newDetails.PTSKnown && !isNaN(sliding)) {\n          logger[\"b\" /* logger */].log('live playlist sliding:' + sliding.toFixed(3));\n        } else {\n          logger[\"b\" /* logger */].log('live playlist - outdated PTS, unknown sliding');\n          alignDiscontinuities(this.fragPrevious, lastLevel, newDetails);\n        }\n      } else {\n        logger[\"b\" /* logger */].log('live playlist - first load, unknown sliding');\n        newDetails.PTSKnown = false;\n        alignDiscontinuities(this.fragPrevious, lastLevel, newDetails);\n      }\n    } else {\n      newDetails.PTSKnown = false;\n    }\n    // override level info\n    curLevel.details = newDetails;\n    this.levelLastLoaded = newLevelId;\n    this.hls.trigger(events[\"a\" /* default */].LEVEL_UPDATED, { details: newDetails, level: newLevelId });\n\n    if (this.startFragRequested === false) {\n      // compute start position if set to -1. use it straight away if value is defined\n      if (this.startPosition === -1 || this.lastCurrentTime === -1) {\n        // first, check if start time offset has been set in playlist, if yes, use this value\n        var startTimeOffset = newDetails.startTimeOffset;\n        if (!isNaN(startTimeOffset)) {\n          if (startTimeOffset < 0) {\n            logger[\"b\" /* logger */].log('negative start time offset ' + startTimeOffset + ', count from end of last fragment');\n            startTimeOffset = sliding + duration + startTimeOffset;\n          }\n          logger[\"b\" /* logger */].log('start time offset found in playlist, adjust startPosition to ' + startTimeOffset);\n          this.startPosition = startTimeOffset;\n        } else {\n          // if live playlist, set start position to be fragment N-this.config.liveSyncDurationCount (usually 3)\n          if (newDetails.live) {\n            this.startPosition = this.computeLivePosition(sliding, newDetails);\n            logger[\"b\" /* logger */].log('configure startPosition to ' + this.startPosition);\n          } else {\n            this.startPosition = 0;\n          }\n        }\n        this.lastCurrentTime = this.startPosition;\n      }\n      this.nextLoadPosition = this.startPosition;\n    }\n    // only switch batck to IDLE state if we were waiting for level to start downloading a new fragment\n    if (this.state === State.WAITING_LEVEL) this.state = State.IDLE;\n\n    // trigger handler right now\n    this.tick();\n  };\n\n  StreamController.prototype.onKeyLoaded = function onKeyLoaded() {\n    if (this.state === State.KEY_LOADING) {\n      this.state = State.IDLE;\n      this.tick();\n    }\n  };\n\n  StreamController.prototype.onFragLoaded = function onFragLoaded(data) {\n    var fragCurrent = this.fragCurrent,\n        fragLoaded = data.frag;\n    if (this.state === State.FRAG_LOADING && fragCurrent && fragLoaded.type === 'main' && fragLoaded.level === fragCurrent.level && fragLoaded.sn === fragCurrent.sn) {\n      var stats = data.stats,\n          currentLevel = this.levels[fragCurrent.level],\n          details = currentLevel.details;\n      logger[\"b\" /* logger */].log('Loaded  ' + fragCurrent.sn + ' of [' + details.startSN + ' ,' + details.endSN + '],level ' + fragCurrent.level);\n      // reset frag bitrate test in any case after frag loaded event\n      this.bitrateTest = false;\n      this.stats = stats;\n      // if this frag was loaded to perform a bitrate test AND if hls.nextLoadLevel is greater than 0\n      // then this means that we should be able to load a fragment at a higher quality level\n      if (fragLoaded.bitrateTest === true && this.hls.nextLoadLevel) {\n        // switch back to IDLE state ... we just loaded a fragment to determine adequate start bitrate and initialize autoswitch algo\n        this.state = State.IDLE;\n        this.startFragRequested = false;\n        stats.tparsed = stats.tbuffered = performance.now();\n        this.hls.trigger(events[\"a\" /* default */].FRAG_BUFFERED, { stats: stats, frag: fragCurrent, id: 'main' });\n        this.tick();\n      } else if (fragLoaded.sn === 'initSegment') {\n        this.state = State.IDLE;\n        stats.tparsed = stats.tbuffered = performance.now();\n        details.initSegment.data = data.payload;\n        this.hls.trigger(events[\"a\" /* default */].FRAG_BUFFERED, { stats: stats, frag: fragCurrent, id: 'main' });\n        this.tick();\n      } else {\n        this.state = State.PARSING;\n        // transmux the MPEG-TS data to ISO-BMFF segments\n        var duration = details.totalduration,\n            level = fragCurrent.level,\n            sn = fragCurrent.sn,\n            audioCodec = this.config.defaultAudioCodec || currentLevel.audioCodec;\n        if (this.audioCodecSwap) {\n          logger[\"b\" /* logger */].log('swapping playlist audio codec');\n          if (audioCodec === undefined) audioCodec = this.lastAudioCodec;\n\n          if (audioCodec) {\n            if (audioCodec.indexOf('mp4a.40.5') !== -1) audioCodec = 'mp4a.40.2';else audioCodec = 'mp4a.40.5';\n          }\n        }\n        this.pendingBuffering = true;\n        this.appended = false;\n        logger[\"b\" /* logger */].log('Parsing ' + sn + ' of [' + details.startSN + ' ,' + details.endSN + '],level ' + level + ', cc ' + fragCurrent.cc);\n        var demuxer = this.demuxer;\n        if (!demuxer) demuxer = this.demuxer = new demux_demuxer(this.hls, 'main');\n\n        // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live) and if media is not seeking (this is to overcome potential timestamp drifts between playlists and fragments)\n        var media = this.media;\n        var mediaSeeking = media && media.seeking;\n        var accurateTimeOffset = !mediaSeeking && (details.PTSKnown || !details.live);\n        var initSegmentData = details.initSegment ? details.initSegment.data : [];\n        demuxer.push(data.payload, initSegmentData, audioCodec, currentLevel.videoCodec, fragCurrent, duration, accurateTimeOffset, undefined);\n      }\n    }\n    this.fragLoadError = 0;\n  };\n\n  StreamController.prototype.onFragParsingInitSegment = function onFragParsingInitSegment(data) {\n    var fragCurrent = this.fragCurrent;\n    var fragNew = data.frag;\n\n    if (fragCurrent && data.id === 'main' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === State.PARSING) {\n      var tracks = data.tracks,\n          trackName = void 0,\n          track = void 0;\n\n      // if audio track is expected to come from audio stream controller, discard any coming from main\n      if (tracks.audio && this.altAudio) delete tracks.audio;\n\n      // include levelCodec in audio and video tracks\n      track = tracks.audio;\n      if (track) {\n        var audioCodec = this.levels[this.level].audioCodec,\n            ua = navigator.userAgent.toLowerCase();\n        if (audioCodec && this.audioCodecSwap) {\n          logger[\"b\" /* logger */].log('swapping playlist audio codec');\n          if (audioCodec.indexOf('mp4a.40.5') !== -1) audioCodec = 'mp4a.40.2';else audioCodec = 'mp4a.40.5';\n        }\n        // in case AAC and HE-AAC audio codecs are signalled in manifest\n        // force HE-AAC , as it seems that most browsers prefers that way,\n        // except for mono streams OR on FF\n        // these conditions might need to be reviewed ...\n        if (this.audioCodecSwitch) {\n          // don't force HE-AAC if mono stream\n          if (track.metadata.channelCount !== 1 &&\n          // don't force HE-AAC if firefox\n          ua.indexOf('firefox') === -1) audioCodec = 'mp4a.40.5';\n        }\n        // HE-AAC is broken on Android, always signal audio codec as AAC even if variant manifest states otherwise\n        if (ua.indexOf('android') !== -1 && track.container !== 'audio/mpeg') {\n          // Exclude mpeg audio\n          audioCodec = 'mp4a.40.2';\n          logger[\"b\" /* logger */].log('Android: force audio codec to ' + audioCodec);\n        }\n        track.levelCodec = audioCodec;\n        track.id = data.id;\n      }\n      track = tracks.video;\n      if (track) {\n        track.levelCodec = this.levels[this.level].videoCodec;\n        track.id = data.id;\n      }\n      this.hls.trigger(events[\"a\" /* default */].BUFFER_CODECS, tracks);\n      // loop through tracks that are going to be provided to bufferController\n      for (trackName in tracks) {\n        track = tracks[trackName];\n        logger[\"b\" /* logger */].log('main track:' + trackName + ',container:' + track.container + ',codecs[level/parsed]=[' + track.levelCodec + '/' + track.codec + ']');\n        var initSegment = track.initSegment;\n        if (initSegment) {\n          this.appended = true;\n          // arm pending Buffering flag before appending a segment\n          this.pendingBuffering = true;\n          this.hls.trigger(events[\"a\" /* default */].BUFFER_APPENDING, { type: trackName, data: initSegment, parent: 'main', content: 'initSegment' });\n        }\n      }\n      // trigger handler right now\n      this.tick();\n    }\n  };\n\n  StreamController.prototype.onFragParsingData = function onFragParsingData(data) {\n    var _this2 = this;\n\n    var fragCurrent = this.fragCurrent;\n    var fragNew = data.frag;\n    if (fragCurrent && data.id === 'main' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && !(data.type === 'audio' && this.altAudio) && // filter out main audio if audio track is loaded through audio stream controller\n    this.state === State.PARSING) {\n      var level = this.levels[this.level],\n          frag = fragCurrent;\n      if (isNaN(data.endPTS)) {\n        data.endPTS = data.startPTS + fragCurrent.duration;\n        data.endDTS = data.startDTS + fragCurrent.duration;\n      }\n\n      if (data.hasAudio === true) frag.addElementaryStream(loader_fragment.ElementaryStreamTypes.AUDIO);\n\n      if (data.hasVideo === true) frag.addElementaryStream(loader_fragment.ElementaryStreamTypes.VIDEO);\n\n      logger[\"b\" /* logger */].log('Parsed ' + data.type + ',PTS:[' + data.startPTS.toFixed(3) + ',' + data.endPTS.toFixed(3) + '],DTS:[' + data.startDTS.toFixed(3) + '/' + data.endDTS.toFixed(3) + '],nb:' + data.nb + ',dropped:' + (data.dropped || 0));\n\n      // Detect gaps in a fragment  and try to fix it by finding a keyframe in the previous fragment (see _findFragments)\n      if (data.type === 'video') {\n        frag.dropped = data.dropped;\n        if (frag.dropped) {\n          if (!frag.backtracked) {\n            var levelDetails = level.details;\n            if (levelDetails && frag.sn === levelDetails.startSN) {\n              logger[\"b\" /* logger */].warn('missing video frame(s) on first frag, appending with gap');\n            } else {\n              logger[\"b\" /* logger */].warn('missing video frame(s), backtracking fragment');\n              // Return back to the IDLE state without appending to buffer\n              // Causes findFragments to backtrack a segment and find the keyframe\n              // Audio fragments arriving before video sets the nextLoadPosition, causing _findFragments to skip the backtracked fragment\n              this.fragmentTracker.removeFragment(frag);\n              frag.backtracked = true;\n              this.nextLoadPosition = data.startPTS;\n              this.state = State.IDLE;\n              this.fragPrevious = frag;\n              this.tick();\n              return;\n            }\n          } else {\n            logger[\"b\" /* logger */].warn('Already backtracked on this fragment, appending with the gap');\n          }\n        } else {\n          // Only reset the backtracked flag if we've loaded the frag without any dropped frames\n          frag.backtracked = false;\n        }\n      }\n\n      var drift = updateFragPTSDTS(level.details, frag, data.startPTS, data.endPTS, data.startDTS, data.endDTS),\n          hls = this.hls;\n      hls.trigger(events[\"a\" /* default */].LEVEL_PTS_UPDATED, { details: level.details, level: this.level, drift: drift, type: data.type, start: data.startPTS, end: data.endPTS });\n      // has remuxer dropped video frames located before first keyframe ?\n      [data.data1, data.data2].forEach(function (buffer) {\n        // only append in PARSING state (rationale is that an appending error could happen synchronously on first segment appending)\n        // in that case it is useless to append following segments\n        if (buffer && buffer.length && _this2.state === State.PARSING) {\n          _this2.appended = true;\n          // arm pending Buffering flag before appending a segment\n          _this2.pendingBuffering = true;\n          hls.trigger(events[\"a\" /* default */].BUFFER_APPENDING, { type: data.type, data: buffer, parent: 'main', content: 'data' });\n        }\n      });\n      // trigger handler right now\n      this.tick();\n    }\n  };\n\n  StreamController.prototype.onFragParsed = function onFragParsed(data) {\n    var fragCurrent = this.fragCurrent;\n    var fragNew = data.frag;\n    if (fragCurrent && data.id === 'main' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === State.PARSING) {\n      this.stats.tparsed = performance.now();\n      this.state = State.PARSED;\n      this._checkAppendedParsed();\n    }\n  };\n\n  StreamController.prototype.onAudioTrackSwitching = function onAudioTrackSwitching(data) {\n    // if any URL found on new audio track, it is an alternate audio track\n    var altAudio = !!data.url,\n        trackId = data.id;\n    // if we switch on main audio, ensure that main fragment scheduling is synced with media.buffered\n    // don't do anything if we switch to alt audio: audio stream controller is handling it.\n    // we will just have to change buffer scheduling on audioTrackSwitched\n    if (!altAudio) {\n      if (this.mediaBuffer !== this.media) {\n        logger[\"b\" /* logger */].log('switching on main audio, use media.buffered to schedule main fragment loading');\n        this.mediaBuffer = this.media;\n        var fragCurrent = this.fragCurrent;\n        // we need to refill audio buffer from main: cancel any frag loading to speed up audio switch\n        if (fragCurrent.loader) {\n          logger[\"b\" /* logger */].log('switching to main audio track, cancel main fragment load');\n          fragCurrent.loader.abort();\n        }\n        this.fragCurrent = null;\n        this.fragPrevious = null;\n        // destroy demuxer to force init segment generation (following audio switch)\n        if (this.demuxer) {\n          this.demuxer.destroy();\n          this.demuxer = null;\n        }\n        // switch to IDLE state to load new fragment\n        this.state = State.IDLE;\n      }\n      var hls = this.hls;\n      // switching to main audio, flush all audio and trigger track switched\n      hls.trigger(events[\"a\" /* default */].BUFFER_FLUSHING, { startOffset: 0, endOffset: Number.POSITIVE_INFINITY, type: 'audio' });\n      hls.trigger(events[\"a\" /* default */].AUDIO_TRACK_SWITCHED, { id: trackId });\n      this.altAudio = false;\n    }\n  };\n\n  StreamController.prototype.onAudioTrackSwitched = function onAudioTrackSwitched(data) {\n    var trackId = data.id,\n        altAudio = !!this.hls.audioTracks[trackId].url;\n    if (altAudio) {\n      var videoBuffer = this.videoBuffer;\n      // if we switched on alternate audio, ensure that main fragment scheduling is synced with video sourcebuffer buffered\n      if (videoBuffer && this.mediaBuffer !== videoBuffer) {\n        logger[\"b\" /* logger */].log('switching on alternate audio, use video.buffered to schedule main fragment loading');\n        this.mediaBuffer = videoBuffer;\n      }\n    }\n    this.altAudio = altAudio;\n    this.tick();\n  };\n\n  StreamController.prototype.onBufferCreated = function onBufferCreated(data) {\n    var tracks = data.tracks,\n        mediaTrack = void 0,\n        name = void 0,\n        alternate = false;\n    for (var type in tracks) {\n      var track = tracks[type];\n      if (track.id === 'main') {\n        name = type;\n        mediaTrack = track;\n        // keep video source buffer reference\n        if (type === 'video') this.videoBuffer = tracks[type].buffer;\n      } else {\n        alternate = true;\n      }\n    }\n    if (alternate && mediaTrack) {\n      logger[\"b\" /* logger */].log('alternate track found, use ' + name + '.buffered to schedule main fragment loading');\n      this.mediaBuffer = mediaTrack.buffer;\n    } else {\n      this.mediaBuffer = this.media;\n    }\n  };\n\n  StreamController.prototype.onBufferAppended = function onBufferAppended(data) {\n    if (data.parent === 'main') {\n      var state = this.state;\n      if (state === State.PARSING || state === State.PARSED) {\n        // check if all buffers have been appended\n        this.pendingBuffering = data.pending > 0;\n        this._checkAppendedParsed();\n      }\n    }\n  };\n\n  StreamController.prototype._checkAppendedParsed = function _checkAppendedParsed() {\n    // trigger handler right now\n    if (this.state === State.PARSED && (!this.appended || !this.pendingBuffering)) {\n      var frag = this.fragCurrent;\n      if (frag) {\n        var media = this.mediaBuffer ? this.mediaBuffer : this.media;\n        logger[\"b\" /* logger */].log('main buffered : ' + time_ranges.toString(media.buffered));\n        this.fragPrevious = frag;\n        var stats = this.stats;\n        stats.tbuffered = performance.now();\n        // we should get rid of this.fragLastKbps\n        this.fragLastKbps = Math.round(8 * stats.total / (stats.tbuffered - stats.tfirst));\n        this.hls.trigger(events[\"a\" /* default */].FRAG_BUFFERED, { stats: stats, frag: frag, id: 'main' });\n        this.state = State.IDLE;\n      }\n      this.tick();\n    }\n  };\n\n  StreamController.prototype.onError = function onError(data) {\n    var frag = data.frag || this.fragCurrent;\n    // don't handle frag error not related to main fragment\n    if (frag && frag.type !== 'main') return;\n\n    // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end\n    var mediaBuffered = !!this.media && buffer_helper.isBuffered(this.media, this.media.currentTime) && buffer_helper.isBuffered(this.media, this.media.currentTime + 0.5);\n\n    switch (data.details) {\n      case errors[\"a\" /* ErrorDetails */].FRAG_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].FRAG_LOAD_TIMEOUT:\n      case errors[\"a\" /* ErrorDetails */].KEY_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].KEY_LOAD_TIMEOUT:\n        if (!data.fatal) {\n          // keep retrying until the limit will be reached\n          if (this.fragLoadError + 1 <= this.config.fragLoadingMaxRetry) {\n            // exponential backoff capped to config.fragLoadingMaxRetryTimeout\n            var delay = Math.min(Math.pow(2, this.fragLoadError) * this.config.fragLoadingRetryDelay, this.config.fragLoadingMaxRetryTimeout);\n            logger[\"b\" /* logger */].warn('mediaController: frag loading failed, retry in ' + delay + ' ms');\n            this.retryDate = performance.now() + delay;\n            // retry loading state\n            // if loadedmetadata is not set, it means that we are emergency switch down on first frag\n            // in that case, reset startFragRequested flag\n            if (!this.loadedmetadata) {\n              this.startFragRequested = false;\n              this.nextLoadPosition = this.startPosition;\n            }\n            this.fragLoadError++;\n            this.state = State.FRAG_LOADING_WAITING_RETRY;\n          } else {\n            logger[\"b\" /* logger */].error('mediaController: ' + data.details + ' reaches max retry, redispatch as fatal ...');\n            // switch error to fatal\n            data.fatal = true;\n            this.state = State.ERROR;\n          }\n        }\n        break;\n      case errors[\"a\" /* ErrorDetails */].LEVEL_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].LEVEL_LOAD_TIMEOUT:\n        if (this.state !== State.ERROR) {\n          if (data.fatal) {\n            // if fatal error, stop processing\n            this.state = State.ERROR;\n            logger[\"b\" /* logger */].warn('streamController: ' + data.details + ',switch to ' + this.state + ' state ...');\n          } else {\n            // in case of non fatal error while loading level, if level controller is not retrying to load level , switch back to IDLE\n            if (!data.levelRetry && this.state === State.WAITING_LEVEL) this.state = State.IDLE;\n          }\n        }\n        break;\n      case errors[\"a\" /* ErrorDetails */].BUFFER_FULL_ERROR:\n        // if in appending state\n        if (data.parent === 'main' && (this.state === State.PARSING || this.state === State.PARSED)) {\n          // reduce max buf len if current position is buffered\n          if (mediaBuffered) {\n            this._reduceMaxBufferLength(this.config.maxBufferLength);\n            this.state = State.IDLE;\n          } else {\n            // current position is not buffered, but browser is still complaining about buffer full error\n            // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708\n            // in that case flush the whole buffer to recover\n            logger[\"b\" /* logger */].warn('buffer full error also media.currentTime is not buffered, flush everything');\n            this.fragCurrent = null;\n            // flush everything\n            this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\n          }\n        }\n        break;\n      default:\n        break;\n    }\n  };\n\n  StreamController.prototype._reduceMaxBufferLength = function _reduceMaxBufferLength(minLength) {\n    var config = this.config;\n    if (config.maxMaxBufferLength >= minLength) {\n      // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...\n      config.maxMaxBufferLength /= 2;\n      logger[\"b\" /* logger */].warn('main:reduce max buffer length to ' + config.maxMaxBufferLength + 's');\n      return true;\n    }\n    return false;\n  };\n\n  StreamController.prototype._checkBuffer = function _checkBuffer() {\n    var media = this.media,\n        config = this.config;\n    // if ready state different from HAVE_NOTHING (numeric value 0), we are allowed to seek\n    if (media && media.readyState) {\n      var currentTime = media.currentTime,\n          mediaBuffer = this.mediaBuffer ? this.mediaBuffer : media,\n          buffered = mediaBuffer.buffered;\n      // adjust currentTime to start position on loaded metadata\n      if (!this.loadedmetadata && buffered.length) {\n        this.loadedmetadata = true;\n        // only adjust currentTime if different from startPosition or if startPosition not buffered\n        // at that stage, there should be only one buffered range, as we reach that code after first fragment has been buffered\n        var startPosition = media.seeking ? currentTime : this.startPosition;\n        // if currentTime not matching with expected startPosition or startPosition not buffered but close to first buffered\n        if (currentTime !== startPosition) {\n          // if startPosition not buffered, let's seek to buffered.start(0)\n\n          logger[\"b\" /* logger */].log('target start position not buffered, seek to buffered.start(0) ' + startPosition + ' from current time' + currentTime + ' ');\n          media.currentTime = startPosition;\n        }\n      } else if (this.immediateSwitch) {\n        this.immediateLevelSwitchEnd();\n      } else {\n        var bufferInfo = buffer_helper.bufferInfo(media, currentTime, config.maxBufferHole),\n            expectedPlaying = !(media.paused && media.readyState > 1 || // not playing when media is paused and sufficiently buffered\n        media.ended || // not playing when media is ended\n        media.buffered.length === 0),\n            // not playing if nothing buffered\n        jumpThreshold = 0.5,\n            // tolerance needed as some browsers stalls playback before reaching buffered range end\n        playheadMoving = currentTime !== this.lastCurrentTime;\n\n        if (playheadMoving) {\n          // played moving, but was previously stalled => now not stuck anymore\n          if (this.stallReported) {\n            logger[\"b\" /* logger */].warn('playback not stuck anymore @' + currentTime + ', after ' + Math.round(performance.now() - this.stalled) + 'ms');\n            this.stallReported = false;\n          }\n          this.stalled = undefined;\n          this.nudgeRetry = 0;\n        } else {\n          // playhead not moving\n          if (expectedPlaying) {\n            // playhead not moving BUT media expected to play\n            var tnow = performance.now();\n            var hls = this.hls;\n            if (!this.stalled) {\n              // stall just detected, store current time\n              this.stalled = tnow;\n              this.stallReported = false;\n            } else {\n              // playback already stalled, check stalling duration\n              // if stalling for more than a given threshold, let's try to recover\n              var stalledDuration = tnow - this.stalled;\n              var bufferLen = bufferInfo.len;\n              var nudgeRetry = this.nudgeRetry || 0;\n              // Check if fragment is broken\n              var partial = this.fragmentTracker.getPartialFragment(currentTime);\n              if (partial !== null) {\n                var lastEndTime = 0;\n                // Check if currentTime is between unbuffered regions of partial fragments\n                for (var i = 0; i < media.buffered.length; i++) {\n                  var startTime = media.buffered.start(i);\n                  if (currentTime >= lastEndTime && currentTime < startTime) {\n                    media.currentTime = Math.max(startTime, media.currentTime + 0.1);\n                    logger[\"b\" /* logger */].warn('skipping hole, adjusting currentTime from ' + currentTime + ' to ' + media.currentTime);\n                    this.stalled = undefined;\n                    hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].BUFFER_SEEK_OVER_HOLE, fatal: false, reason: 'fragment loaded with buffer holes, seeking from ' + currentTime + ' to ' + media.currentTime, frag: partial });\n                    return;\n                  }\n                  lastEndTime = media.buffered.end(i);\n                }\n              }\n              if (bufferLen > jumpThreshold && stalledDuration > config.highBufferWatchdogPeriod * 1000) {\n                // report stalled error once\n                if (!this.stallReported) {\n                  this.stallReported = true;\n                  logger[\"b\" /* logger */].warn('playback stalling in high buffer @' + currentTime);\n                  hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].BUFFER_STALLED_ERROR, fatal: false, buffer: bufferLen });\n                }\n                // reset stalled so to rearm watchdog timer\n                this.stalled = undefined;\n                this.nudgeRetry = ++nudgeRetry;\n                if (nudgeRetry < config.nudgeMaxRetry) {\n                  var _currentTime = media.currentTime;\n                  var targetTime = _currentTime + nudgeRetry * config.nudgeOffset;\n                  logger[\"b\" /* logger */].log('adjust currentTime from ' + _currentTime + ' to ' + targetTime);\n                  // playback stalled in buffered area ... let's nudge currentTime to try to overcome this\n                  media.currentTime = targetTime;\n                  hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].BUFFER_NUDGE_ON_STALL, fatal: false });\n                } else {\n                  logger[\"b\" /* logger */].error('still stuck in high buffer @' + currentTime + ' after ' + config.nudgeMaxRetry + ', raise fatal error');\n                  hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].BUFFER_STALLED_ERROR, fatal: true });\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  };\n\n  StreamController.prototype.onFragLoadEmergencyAborted = function onFragLoadEmergencyAborted() {\n    this.state = State.IDLE;\n    // if loadedmetadata is not set, it means that we are emergency switch down on first frag\n    // in that case, reset startFragRequested flag\n    if (!this.loadedmetadata) {\n      this.startFragRequested = false;\n      this.nextLoadPosition = this.startPosition;\n    }\n    this.tick();\n  };\n\n  StreamController.prototype.onBufferFlushed = function onBufferFlushed() {\n    /* after successful buffer flushing, filter flushed fragments from bufferedFrags\n      use mediaBuffered instead of media (so that we will check against video.buffered ranges in case of alt audio track)\n    */\n    var media = this.mediaBuffer ? this.mediaBuffer : this.media;\n    // filter fragments potentially evicted from buffer. this is to avoid memleak on live streams\n    this.fragmentTracker.detectEvictedFragments(loader_fragment.ElementaryStreamTypes.VIDEO, media.buffered);\n\n    // move to IDLE once flush complete. this should trigger new fragment loading\n    this.state = State.IDLE;\n    // reset reference to frag\n    this.fragPrevious = null;\n  };\n\n  StreamController.prototype.swapAudioCodec = function swapAudioCodec() {\n    this.audioCodecSwap = !this.audioCodecSwap;\n  };\n\n  StreamController.prototype.computeLivePosition = function computeLivePosition(sliding, levelDetails) {\n    var targetLatency = this.config.liveSyncDuration !== undefined ? this.config.liveSyncDuration : this.config.liveSyncDurationCount * levelDetails.targetduration;\n    return sliding + Math.max(0, levelDetails.totalduration - targetLatency);\n  };\n\n  stream_controller__createClass(StreamController, [{\n    key: 'state',\n    set: function set(nextState) {\n      if (this.state !== nextState) {\n        var previousState = this.state;\n        this._state = nextState;\n        logger[\"b\" /* logger */].log('main stream:' + previousState + '->' + nextState);\n        this.hls.trigger(events[\"a\" /* default */].STREAM_STATE_TRANSITION, { previousState: previousState, nextState: nextState });\n      }\n    },\n    get: function get() {\n      return this._state;\n    }\n  }, {\n    key: 'currentLevel',\n    get: function get() {\n      var media = this.media;\n      if (media) {\n        var frag = this.getBufferedFrag(media.currentTime);\n        if (frag) return frag.level;\n      }\n      return -1;\n    }\n  }, {\n    key: 'nextBufferedFrag',\n    get: function get() {\n      var media = this.media;\n      if (media) {\n        // first get end range of current fragment\n        return this.followingBufferedFrag(this.getBufferedFrag(media.currentTime));\n      } else {\n        return null;\n      }\n    }\n  }, {\n    key: 'nextLevel',\n    get: function get() {\n      var frag = this.nextBufferedFrag;\n      if (frag) return frag.level;else return -1;\n    }\n  }, {\n    key: 'liveSyncPosition',\n    get: function get() {\n      return this._liveSyncPosition;\n    },\n    set: function set(value) {\n      this._liveSyncPosition = value;\n    }\n  }]);\n\n  return StreamController;\n}(task_loop);\n\n/* harmony default export */ var stream_controller = (stream_controller_StreamController);\n// CONCATENATED MODULE: ./src/controller/level-controller.js\nvar level_controller__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction level_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction level_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction level_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * Level Controller\n*/\n\n\n\n\n\n\n\nvar level_controller_LevelController = function (_EventHandler) {\n  level_controller__inherits(LevelController, _EventHandler);\n\n  function LevelController(hls) {\n    level_controller__classCallCheck(this, LevelController);\n\n    var _this = level_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MANIFEST_LOADED, events[\"a\" /* default */].LEVEL_LOADED, events[\"a\" /* default */].FRAG_LOADED, events[\"a\" /* default */].ERROR));\n\n    _this.canload = false;\n    _this.currentLevelIndex = null;\n    _this.manualLevelIndex = -1;\n    _this.timer = null;\n    return _this;\n  }\n\n  LevelController.prototype.onHandlerDestroying = function onHandlerDestroying() {\n    this.cleanTimer();\n    this.manualLevelIndex = -1;\n  };\n\n  LevelController.prototype.cleanTimer = function cleanTimer() {\n    if (this.timer !== null) {\n      clearTimeout(this.timer);\n      this.timer = null;\n    }\n  };\n\n  LevelController.prototype.startLoad = function startLoad() {\n    var levels = this._levels;\n\n    this.canload = true;\n    this.levelRetryCount = 0;\n\n    // clean up live level details to force reload them, and reset load errors\n    if (levels) {\n      levels.forEach(function (level) {\n        level.loadError = 0;\n        var levelDetails = level.details;\n        if (levelDetails && levelDetails.live) level.details = undefined;\n      });\n    }\n    // speed up live playlist refresh if timer exists\n    if (this.timer !== null) this.loadLevel();\n  };\n\n  LevelController.prototype.stopLoad = function stopLoad() {\n    this.canload = false;\n  };\n\n  LevelController.prototype.onManifestLoaded = function onManifestLoaded(data) {\n    var levels = [];\n    var bitrateStart = void 0;\n    var levelSet = {};\n    var levelFromSet = null;\n    var videoCodecFound = false;\n    var audioCodecFound = false;\n    var chromeOrFirefox = /chrome|firefox/.test(navigator.userAgent.toLowerCase());\n    var audioTracks = [];\n\n    // regroup redundant levels together\n    data.levels.forEach(function (level) {\n      level.loadError = 0;\n      level.fragmentError = false;\n\n      videoCodecFound = videoCodecFound || !!level.videoCodec;\n      audioCodecFound = audioCodecFound || !!level.audioCodec || !!(level.attrs && level.attrs.AUDIO);\n\n      // erase audio codec info if browser does not support mp4a.40.34.\n      // demuxer will autodetect codec and fallback to mpeg/audio\n      if (chromeOrFirefox === true && level.audioCodec && level.audioCodec.indexOf('mp4a.40.34') !== -1) level.audioCodec = undefined;\n\n      levelFromSet = levelSet[level.bitrate];\n\n      if (levelFromSet === undefined) {\n        level.url = [level.url];\n        level.urlId = 0;\n        levelSet[level.bitrate] = level;\n        levels.push(level);\n      } else {\n        levelFromSet.url.push(level.url);\n      }\n    });\n\n    // remove audio-only level if we also have levels with audio+video codecs signalled\n    if (videoCodecFound === true && audioCodecFound === true) levels = levels.filter(function (_ref) {\n      var videoCodec = _ref.videoCodec;\n      return !!videoCodec;\n    });\n\n    // only keep levels with supported audio/video codecs\n    levels = levels.filter(function (_ref2) {\n      var audioCodec = _ref2.audioCodec,\n          videoCodec = _ref2.videoCodec;\n\n      return (!audioCodec || isCodecSupportedInMp4(audioCodec)) && (!videoCodec || isCodecSupportedInMp4(videoCodec));\n    });\n\n    if (data.audioTracks) audioTracks = data.audioTracks.filter(function (track) {\n      return !track.audioCodec || isCodecSupportedInMp4(track.audioCodec, 'audio');\n    });\n\n    if (levels.length > 0) {\n      // start bitrate is the first bitrate of the manifest\n      bitrateStart = levels[0].bitrate;\n      // sort level on bitrate\n      levels.sort(function (a, b) {\n        return a.bitrate - b.bitrate;\n      });\n      this._levels = levels;\n      // find index of first level in sorted levels\n      for (var i = 0; i < levels.length; i++) {\n        if (levels[i].bitrate === bitrateStart) {\n          this._firstLevel = i;\n          logger[\"b\" /* logger */].log('manifest loaded,' + levels.length + ' level(s) found, first bitrate:' + bitrateStart);\n          break;\n        }\n      }\n      this.hls.trigger(events[\"a\" /* default */].MANIFEST_PARSED, {\n        levels: levels,\n        audioTracks: audioTracks,\n        firstLevel: this._firstLevel,\n        stats: data.stats,\n        audio: audioCodecFound,\n        video: videoCodecFound,\n        altAudio: audioTracks.length > 0\n      });\n    } else {\n      this.hls.trigger(events[\"a\" /* default */].ERROR, {\n        type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR,\n        details: errors[\"a\" /* ErrorDetails */].MANIFEST_INCOMPATIBLE_CODECS_ERROR,\n        fatal: true,\n        url: this.hls.url,\n        reason: 'no level with compatible codecs found in manifest'\n      });\n    }\n  };\n\n  LevelController.prototype.setLevelInternal = function setLevelInternal(newLevel) {\n    var levels = this._levels;\n    var hls = this.hls;\n    // check if level idx is valid\n    if (newLevel >= 0 && newLevel < levels.length) {\n      // stopping live reloading timer if any\n      this.cleanTimer();\n      if (this.currentLevelIndex !== newLevel) {\n        logger[\"b\" /* logger */].log('switching to level ' + newLevel);\n        this.currentLevelIndex = newLevel;\n        var levelProperties = levels[newLevel];\n        levelProperties.level = newLevel;\n        hls.trigger(events[\"a\" /* default */].LEVEL_SWITCHING, levelProperties);\n      }\n      var level = levels[newLevel],\n          levelDetails = level.details;\n      // check if we need to load playlist for this level\n      if (!levelDetails || levelDetails.live === true) {\n        // level not retrieved yet, or live playlist we need to (re)load it\n        var urlId = level.urlId;\n        hls.trigger(events[\"a\" /* default */].LEVEL_LOADING, { url: level.url[urlId], level: newLevel, id: urlId });\n      }\n    } else {\n      // invalid level id given, trigger error\n      hls.trigger(events[\"a\" /* default */].ERROR, {\n        type: errors[\"b\" /* ErrorTypes */].OTHER_ERROR,\n        details: errors[\"a\" /* ErrorDetails */].LEVEL_SWITCH_ERROR,\n        level: newLevel,\n        fatal: false,\n        reason: 'invalid level idx'\n      });\n    }\n  };\n\n  LevelController.prototype.onError = function onError(data) {\n    if (data.fatal === true) {\n      if (data.type === errors[\"b\" /* ErrorTypes */].NETWORK_ERROR) this.cleanTimer();\n\n      return;\n    }\n\n    var levelError = false,\n        fragmentError = false;\n    var levelIndex = void 0;\n\n    // try to recover not fatal errors\n    switch (data.details) {\n      case errors[\"a\" /* ErrorDetails */].FRAG_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].FRAG_LOAD_TIMEOUT:\n      case errors[\"a\" /* ErrorDetails */].KEY_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].KEY_LOAD_TIMEOUT:\n        levelIndex = data.frag.level;\n        fragmentError = true;\n        break;\n      case errors[\"a\" /* ErrorDetails */].LEVEL_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].LEVEL_LOAD_TIMEOUT:\n        levelIndex = data.context.level;\n        levelError = true;\n        break;\n      case errors[\"a\" /* ErrorDetails */].REMUX_ALLOC_ERROR:\n        levelIndex = data.level;\n        levelError = true;\n        break;\n    }\n\n    if (levelIndex !== undefined) this.recoverLevel(data, levelIndex, levelError, fragmentError);\n  };\n\n  /**\n   * Switch to a redundant stream if any available.\n   * If redundant stream is not available, emergency switch down if ABR mode is enabled.\n   *\n   * @param {Object} errorEvent\n   * @param {Number} levelIndex current level index\n   * @param {Boolean} levelError\n   * @param {Boolean} fragmentError\n   */\n  // FIXME Find a better abstraction where fragment/level retry management is well decoupled\n\n\n  LevelController.prototype.recoverLevel = function recoverLevel(errorEvent, levelIndex, levelError, fragmentError) {\n    var _this2 = this;\n\n    var config = this.hls.config;\n    var errorDetails = errorEvent.details;\n\n    var level = this._levels[levelIndex];\n    var redundantLevels = void 0,\n        delay = void 0,\n        nextLevel = void 0;\n\n    level.loadError++;\n    level.fragmentError = fragmentError;\n\n    if (levelError === true) {\n      if (this.levelRetryCount + 1 <= config.levelLoadingMaxRetry) {\n        // exponential backoff capped to max retry timeout\n        delay = Math.min(Math.pow(2, this.levelRetryCount) * config.levelLoadingRetryDelay, config.levelLoadingMaxRetryTimeout);\n        // Schedule level reload\n        this.timer = setTimeout(function () {\n          return _this2.loadLevel();\n        }, delay);\n        // boolean used to inform stream controller not to switch back to IDLE on non fatal error\n        errorEvent.levelRetry = true;\n        this.levelRetryCount++;\n        logger[\"b\" /* logger */].warn('level controller, ' + errorDetails + ', retry in ' + delay + ' ms, current retry count is ' + this.levelRetryCount);\n      } else {\n        logger[\"b\" /* logger */].error('level controller, cannot recover from ' + errorDetails + ' error');\n        this.currentLevelIndex = null;\n        // stopping live reloading timer if any\n        this.cleanTimer();\n        // switch error to fatal\n        errorEvent.fatal = true;\n        return;\n      }\n    }\n\n    // Try any redundant streams if available for both errors: level and fragment\n    // If level.loadError reaches redundantLevels it means that we tried them all, no hope  => let's switch down\n    if (levelError === true || fragmentError === true) {\n      redundantLevels = level.url.length;\n\n      if (redundantLevels > 1 && level.loadError < redundantLevels) {\n        logger[\"b\" /* logger */].warn('level controller, ' + errorDetails + ' for level ' + levelIndex + ': switching to redundant stream id ' + level.urlId);\n        level.urlId = (level.urlId + 1) % redundantLevels;\n        level.details = undefined;\n      } else {\n        // Search for available level\n        if (this.manualLevelIndex === -1) {\n          // When lowest level has been reached, let's start hunt from the top\n          nextLevel = levelIndex === 0 ? this._levels.length - 1 : levelIndex - 1;\n          logger[\"b\" /* logger */].warn('level controller, ' + errorDetails + ': switch to ' + nextLevel);\n          this.hls.nextAutoLevel = this.currentLevelIndex = nextLevel;\n        } else if (fragmentError === true) {\n          // Allow fragment retry as long as configuration allows.\n          // reset this._level so that another call to set level() will trigger again a frag load\n          logger[\"b\" /* logger */].warn('level controller, ' + errorDetails + ': reload a fragment');\n          this.currentLevelIndex = null;\n        }\n      }\n    }\n  };\n\n  // reset errors on the successful load of a fragment\n\n\n  LevelController.prototype.onFragLoaded = function onFragLoaded(_ref3) {\n    var frag = _ref3.frag;\n\n    if (frag !== undefined && frag.type === 'main') {\n      var level = this._levels[frag.level];\n      if (level !== undefined) {\n        level.fragmentError = false;\n        level.loadError = 0;\n        this.levelRetryCount = 0;\n      }\n    }\n  };\n\n  LevelController.prototype.onLevelLoaded = function onLevelLoaded(data) {\n    var _this3 = this;\n\n    var levelId = data.level;\n    // only process level loaded events matching with expected level\n    if (levelId === this.currentLevelIndex) {\n      var curLevel = this._levels[levelId];\n      // reset level load error counter on successful level loaded only if there is no issues with fragments\n      if (curLevel.fragmentError === false) {\n        curLevel.loadError = 0;\n        this.levelRetryCount = 0;\n      }\n      var newDetails = data.details;\n      // if current playlist is a live playlist, arm a timer to reload it\n      if (newDetails.live) {\n        var targetdurationMs = 1000 * (newDetails.averagetargetduration ? newDetails.averagetargetduration : newDetails.targetduration);\n        var reloadInterval = targetdurationMs,\n            curDetails = curLevel.details;\n        if (curDetails && newDetails.endSN === curDetails.endSN) {\n          // follow HLS Spec, If the client reloads a Playlist file and finds that it has not\n          // changed then it MUST wait for a period of one-half the target\n          // duration before retrying.\n          reloadInterval /= 2;\n          logger[\"b\" /* logger */].log('same live playlist, reload twice faster');\n        }\n        // decrement reloadInterval with level loading delay\n        reloadInterval -= performance.now() - data.stats.trequest;\n        // in any case, don't reload more than half of target duration\n        reloadInterval = Math.max(targetdurationMs / 2, Math.round(reloadInterval));\n        logger[\"b\" /* logger */].log('live playlist, reload in ' + Math.round(reloadInterval) + ' ms');\n        this.timer = setTimeout(function () {\n          return _this3.loadLevel();\n        }, reloadInterval);\n      } else {\n        this.cleanTimer();\n      }\n    }\n  };\n\n  LevelController.prototype.loadLevel = function loadLevel() {\n    var level = void 0,\n        urlIndex = void 0;\n\n    if (this.currentLevelIndex !== null && this.canload === true) {\n      level = this._levels[this.currentLevelIndex];\n      if (level !== undefined && level.url.length > 0) {\n        urlIndex = level.urlId;\n        this.hls.trigger(events[\"a\" /* default */].LEVEL_LOADING, { url: level.url[urlIndex], level: this.currentLevelIndex, id: urlIndex });\n      }\n    }\n  };\n\n  level_controller__createClass(LevelController, [{\n    key: 'levels',\n    get: function get() {\n      return this._levels;\n    }\n  }, {\n    key: 'level',\n    get: function get() {\n      return this.currentLevelIndex;\n    },\n    set: function set(newLevel) {\n      var levels = this._levels;\n      if (levels) {\n        newLevel = Math.min(newLevel, levels.length - 1);\n        if (this.currentLevelIndex !== newLevel || levels[newLevel].details === undefined) this.setLevelInternal(newLevel);\n      }\n    }\n  }, {\n    key: 'manualLevel',\n    get: function get() {\n      return this.manualLevelIndex;\n    },\n    set: function set(newLevel) {\n      this.manualLevelIndex = newLevel;\n      if (this._startLevel === undefined) this._startLevel = newLevel;\n\n      if (newLevel !== -1) this.level = newLevel;\n    }\n  }, {\n    key: 'firstLevel',\n    get: function get() {\n      return this._firstLevel;\n    },\n    set: function set(newLevel) {\n      this._firstLevel = newLevel;\n    }\n  }, {\n    key: 'startLevel',\n    get: function get() {\n      // hls.startLevel takes precedence over config.startLevel\n      // if none of these values are defined, fallback on this._firstLevel (first quality level appearing in variant manifest)\n      if (this._startLevel === undefined) {\n        var configStartLevel = this.hls.config.startLevel;\n        if (configStartLevel !== undefined) return configStartLevel;else return this._firstLevel;\n      } else {\n        return this._startLevel;\n      }\n    },\n    set: function set(newLevel) {\n      this._startLevel = newLevel;\n    }\n  }, {\n    key: 'nextLoadLevel',\n    get: function get() {\n      if (this.manualLevelIndex !== -1) return this.manualLevelIndex;else return this.hls.nextAutoLevel;\n    },\n    set: function set(nextLevel) {\n      this.level = nextLevel;\n      if (this.manualLevelIndex === -1) this.hls.nextAutoLevel = nextLevel;\n    }\n  }]);\n\n  return LevelController;\n}(event_handler);\n\n/* harmony default export */ var level_controller = (level_controller_LevelController);\n// EXTERNAL MODULE: ./src/demux/id3.js\nvar id3 = __webpack_require__(4);\n\n// CONCATENATED MODULE: ./src/utils/texttrack-utils.js\n\nfunction sendAddTrackEvent(track, videoEl) {\n  var event = null;\n  try {\n    event = new window.Event('addtrack');\n  } catch (err) {\n    // for IE11\n    event = document.createEvent('Event');\n    event.initEvent('addtrack', false, false);\n  }\n  event.track = track;\n  videoEl.dispatchEvent(event);\n}\n\nfunction clearCurrentCues(track) {\n  if (track && track.cues) {\n    while (track.cues.length > 0) {\n      track.removeCue(track.cues[0]);\n    }\n  }\n}\n// CONCATENATED MODULE: ./src/controller/id3-track-controller.js\nfunction id3_track_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction id3_track_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction id3_track_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * id3 metadata track controller\n*/\n\n\n\n\n\n\nvar id3_track_controller_ID3TrackController = function (_EventHandler) {\n  id3_track_controller__inherits(ID3TrackController, _EventHandler);\n\n  function ID3TrackController(hls) {\n    id3_track_controller__classCallCheck(this, ID3TrackController);\n\n    var _this = id3_track_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHED, events[\"a\" /* default */].MEDIA_DETACHING, events[\"a\" /* default */].FRAG_PARSING_METADATA));\n\n    _this.id3Track = undefined;\n    _this.media = undefined;\n    return _this;\n  }\n\n  ID3TrackController.prototype.destroy = function destroy() {\n    event_handler.prototype.destroy.call(this);\n  };\n\n  // Add ID3 metatadata text track.\n\n\n  ID3TrackController.prototype.onMediaAttached = function onMediaAttached(data) {\n    this.media = data.media;\n    if (!this.media) {}\n  };\n\n  ID3TrackController.prototype.onMediaDetaching = function onMediaDetaching() {\n    clearCurrentCues(this.id3Track);\n    this.id3Track = undefined;\n    this.media = undefined;\n  };\n\n  ID3TrackController.prototype.getID3Track = function getID3Track(textTracks) {\n    for (var i = 0; i < textTracks.length; i++) {\n      var textTrack = textTracks[i];\n      if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {\n        // send 'addtrack' when reusing the textTrack for metadata,\n        // same as what we do for captions\n        sendAddTrackEvent(textTrack, this.media);\n\n        return textTrack;\n      }\n    }\n    return this.media.addTextTrack('metadata', 'id3');\n  };\n\n  ID3TrackController.prototype.onFragParsingMetadata = function onFragParsingMetadata(data) {\n    var fragment = data.frag;\n    var samples = data.samples;\n\n    // create track dynamically\n    if (!this.id3Track) {\n      this.id3Track = this.getID3Track(this.media.textTracks);\n      this.id3Track.mode = 'hidden';\n    }\n\n    // Attempt to recreate Safari functionality by creating\n    // WebKitDataCue objects when available and store the decoded\n    // ID3 data in the value property of the cue\n    var Cue = window.WebKitDataCue || window.VTTCue || window.TextTrackCue;\n\n    for (var i = 0; i < samples.length; i++) {\n      var frames = id3[\"a\" /* default */].getID3Frames(samples[i].data);\n      if (frames) {\n        var startTime = samples[i].pts;\n        var endTime = i < samples.length - 1 ? samples[i + 1].pts : fragment.endPTS;\n\n        // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE\n        if (startTime === endTime) endTime += 0.0001;\n\n        for (var j = 0; j < frames.length; j++) {\n          var frame = frames[j];\n          // Safari doesn't put the timestamp frame in the TextTrack\n          if (!id3[\"a\" /* default */].isTimeStampFrame(frame)) {\n            var cue = new Cue(startTime, endTime, '');\n            cue.value = frame;\n            this.id3Track.addCue(cue);\n          }\n        }\n      }\n    }\n  };\n\n  return ID3TrackController;\n}(event_handler);\n\n/* harmony default export */ var id3_track_controller = (id3_track_controller_ID3TrackController);\n// CONCATENATED MODULE: ./src/helper/is-supported.js\n\n\nfunction is_supported_isSupported() {\n  var mediaSource = getMediaSource();\n  var sourceBuffer = window.SourceBuffer || window.WebKitSourceBuffer;\n  var isTypeSupported = mediaSource && typeof mediaSource.isTypeSupported === 'function' && mediaSource.isTypeSupported('video/mp4; codecs=\"avc1.42E01E,mp4a.40.2\"');\n\n  // if SourceBuffer is exposed ensure its API is valid\n  // safari and old version of Chrome doe not expose SourceBuffer globally so checking SourceBuffer.prototype is impossible\n  var sourceBufferValidAPI = !sourceBuffer || sourceBuffer.prototype && typeof sourceBuffer.prototype.appendBuffer === 'function' && typeof sourceBuffer.prototype.remove === 'function';\n  return !!isTypeSupported && !!sourceBufferValidAPI;\n}\n// CONCATENATED MODULE: ./src/utils/ewma.js\nfunction ewma__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/*\n * compute an Exponential Weighted moving average\n * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average\n *  - heavily inspired from shaka-player\n */\n\nvar EWMA = function () {\n  //  About half of the estimated value will be from the last |halfLife| samples by weight.\n  function EWMA(halfLife) {\n    ewma__classCallCheck(this, EWMA);\n\n    // Larger values of alpha expire historical data more slowly.\n    this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;\n    this.estimate_ = 0;\n    this.totalWeight_ = 0;\n  }\n\n  EWMA.prototype.sample = function sample(weight, value) {\n    var adjAlpha = Math.pow(this.alpha_, weight);\n    this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;\n    this.totalWeight_ += weight;\n  };\n\n  EWMA.prototype.getTotalWeight = function getTotalWeight() {\n    return this.totalWeight_;\n  };\n\n  EWMA.prototype.getEstimate = function getEstimate() {\n    if (this.alpha_) {\n      var zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);\n      return this.estimate_ / zeroFactor;\n    } else {\n      return this.estimate_;\n    }\n  };\n\n  return EWMA;\n}();\n\n/* harmony default export */ var ewma = (EWMA);\n// CONCATENATED MODULE: ./src/utils/ewma-bandwidth-estimator.js\nfunction ewma_bandwidth_estimator__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/*\n * EWMA Bandwidth Estimator\n *  - heavily inspired from shaka-player\n * Tracks bandwidth samples and estimates available bandwidth.\n * Based on the minimum of two exponentially-weighted moving averages with\n * different half-lives.\n */\n\n\n\nvar ewma_bandwidth_estimator_EwmaBandWidthEstimator = function () {\n  function EwmaBandWidthEstimator(hls, slow, fast, defaultEstimate) {\n    ewma_bandwidth_estimator__classCallCheck(this, EwmaBandWidthEstimator);\n\n    this.hls = hls;\n    this.defaultEstimate_ = defaultEstimate;\n    this.minWeight_ = 0.001;\n    this.minDelayMs_ = 50;\n    this.slow_ = new ewma(slow);\n    this.fast_ = new ewma(fast);\n  }\n\n  EwmaBandWidthEstimator.prototype.sample = function sample(durationMs, numBytes) {\n    durationMs = Math.max(durationMs, this.minDelayMs_);\n    var bandwidth = 8000 * numBytes / durationMs,\n\n    // console.log('instant bw:'+ Math.round(bandwidth));\n    // we weight sample using loading duration....\n    weight = durationMs / 1000;\n    this.fast_.sample(weight, bandwidth);\n    this.slow_.sample(weight, bandwidth);\n  };\n\n  EwmaBandWidthEstimator.prototype.canEstimate = function canEstimate() {\n    var fast = this.fast_;\n    return fast && fast.getTotalWeight() >= this.minWeight_;\n  };\n\n  EwmaBandWidthEstimator.prototype.getEstimate = function getEstimate() {\n    if (this.canEstimate()) {\n      // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));\n      // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));\n      // Take the minimum of these two estimates.  This should have the effect of\n      // adapting down quickly, but up more slowly.\n      return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());\n    } else {\n      return this.defaultEstimate_;\n    }\n  };\n\n  EwmaBandWidthEstimator.prototype.destroy = function destroy() {};\n\n  return EwmaBandWidthEstimator;\n}();\n\n/* harmony default export */ var ewma_bandwidth_estimator = (ewma_bandwidth_estimator_EwmaBandWidthEstimator);\n// CONCATENATED MODULE: ./src/controller/abr-controller.js\nvar abr_controller__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction abr_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction abr_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction abr_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * simple ABR Controller\n *  - compute next level based on last fragment bw heuristics\n *  - implement an abandon rules triggered if we have less than 2 frag buffered and if computed bw shows that we risk buffer stalling\n */\n\n\n\n\n\n\n\n\nvar abr_controller_AbrController = function (_EventHandler) {\n  abr_controller__inherits(AbrController, _EventHandler);\n\n  function AbrController(hls) {\n    abr_controller__classCallCheck(this, AbrController);\n\n    var _this = abr_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].FRAG_LOADING, events[\"a\" /* default */].FRAG_LOADED, events[\"a\" /* default */].FRAG_BUFFERED, events[\"a\" /* default */].ERROR));\n\n    _this.lastLoadedFragLevel = 0;\n    _this._nextAutoLevel = -1;\n    _this.hls = hls;\n    _this.timer = null;\n    _this._bwEstimator = null;\n    _this.onCheck = _this._abandonRulesCheck.bind(_this);\n    return _this;\n  }\n\n  AbrController.prototype.destroy = function destroy() {\n    this.clearTimer();\n    event_handler.prototype.destroy.call(this);\n  };\n\n  AbrController.prototype.onFragLoading = function onFragLoading(data) {\n    var frag = data.frag;\n    if (frag.type === 'main') {\n      if (!this.timer) this.timer = setInterval(this.onCheck, 100);\n\n      // lazy init of bw Estimator, rationale is that we use different params for Live/VoD\n      // so we need to wait for stream manifest / playlist type to instantiate it.\n      if (!this._bwEstimator) {\n        var hls = this.hls,\n            level = data.frag.level,\n            isLive = hls.levels[level].details.live,\n            config = hls.config,\n            ewmaFast = void 0,\n            ewmaSlow = void 0;\n\n        if (isLive) {\n          ewmaFast = config.abrEwmaFastLive;\n          ewmaSlow = config.abrEwmaSlowLive;\n        } else {\n          ewmaFast = config.abrEwmaFastVoD;\n          ewmaSlow = config.abrEwmaSlowVoD;\n        }\n        this._bwEstimator = new ewma_bandwidth_estimator(hls, ewmaSlow, ewmaFast, config.abrEwmaDefaultEstimate);\n      }\n      this.fragCurrent = frag;\n    }\n  };\n\n  AbrController.prototype._abandonRulesCheck = function _abandonRulesCheck() {\n    /*\n      monitor fragment retrieval time...\n      we compute expected time of arrival of the complete fragment.\n      we compare it to expected time of buffer starvation\n    */\n    var hls = this.hls,\n        v = hls.media,\n        frag = this.fragCurrent,\n        loader = frag.loader,\n        minAutoLevel = hls.minAutoLevel;\n\n    // if loader has been destroyed or loading has been aborted, stop timer and return\n    if (!loader || loader.stats && loader.stats.aborted) {\n      logger[\"b\" /* logger */].warn('frag loader destroy or aborted, disarm abandonRules');\n      this.clearTimer();\n      // reset forced auto level value so that next level will be selected\n      this._nextAutoLevel = -1;\n      return;\n    }\n    var stats = loader.stats;\n    /* only monitor frag retrieval time if\n    (video not paused OR first fragment being loaded(ready state === HAVE_NOTHING = 0)) AND autoswitching enabled AND not lowest level (=> means that we have several levels) */\n    if (v && stats && (!v.paused && v.playbackRate !== 0 || !v.readyState) && frag.autoLevel && frag.level) {\n      var requestDelay = performance.now() - stats.trequest,\n          playbackRate = Math.abs(v.playbackRate);\n      // monitor fragment load progress after half of expected fragment duration,to stabilize bitrate\n      if (requestDelay > 500 * frag.duration / playbackRate) {\n        var levels = hls.levels,\n            loadRate = Math.max(1, stats.bw ? stats.bw / 8 : stats.loaded * 1000 / requestDelay),\n            // byte/s; at least 1 byte/s to avoid division by zero\n        // compute expected fragment length using frag duration and level bitrate. also ensure that expected len is gte than already loaded size\n        level = levels[frag.level],\n            levelBitrate = level.realBitrate ? Math.max(level.realBitrate, level.bitrate) : level.bitrate,\n            expectedLen = stats.total ? stats.total : Math.max(stats.loaded, Math.round(frag.duration * levelBitrate / 8)),\n            pos = v.currentTime,\n            fragLoadedDelay = (expectedLen - stats.loaded) / loadRate,\n            bufferStarvationDelay = (buffer_helper.bufferInfo(v, pos, hls.config.maxBufferHole).end - pos) / playbackRate;\n        // consider emergency switch down only if we have less than 2 frag buffered AND\n        // time to finish loading current fragment is bigger than buffer starvation delay\n        // ie if we risk buffer starvation if bw does not increase quickly\n        if (bufferStarvationDelay < 2 * frag.duration / playbackRate && fragLoadedDelay > bufferStarvationDelay) {\n          var fragLevelNextLoadedDelay = void 0,\n              nextLoadLevel = void 0;\n          // lets iterate through lower level and try to find the biggest one that could avoid rebuffering\n          // we start from current level - 1 and we step down , until we find a matching level\n          for (nextLoadLevel = frag.level - 1; nextLoadLevel > minAutoLevel; nextLoadLevel--) {\n            // compute time to load next fragment at lower level\n            // 0.8 : consider only 80% of current bw to be conservative\n            // 8 = bits per byte (bps/Bps)\n            var levelNextBitrate = levels[nextLoadLevel].realBitrate ? Math.max(levels[nextLoadLevel].realBitrate, levels[nextLoadLevel].bitrate) : levels[nextLoadLevel].bitrate;\n            fragLevelNextLoadedDelay = frag.duration * levelNextBitrate / (8 * 0.8 * loadRate);\n            if (fragLevelNextLoadedDelay < bufferStarvationDelay) {\n              // we found a lower level that be rebuffering free with current estimated bw !\n              break;\n            }\n          }\n          // only emergency switch down if it takes less time to load new fragment at lowest level instead\n          // of finishing loading current one ...\n          if (fragLevelNextLoadedDelay < fragLoadedDelay) {\n            logger[\"b\" /* logger */].warn('loading too slow, abort fragment loading and switch to level ' + nextLoadLevel + ':fragLoadedDelay[' + nextLoadLevel + ']<fragLoadedDelay[' + (frag.level - 1) + '];bufferStarvationDelay:' + fragLevelNextLoadedDelay.toFixed(1) + '<' + fragLoadedDelay.toFixed(1) + ':' + bufferStarvationDelay.toFixed(1));\n            // force next load level in auto mode\n            hls.nextLoadLevel = nextLoadLevel;\n            // update bw estimate for this fragment before cancelling load (this will help reducing the bw)\n            this._bwEstimator.sample(requestDelay, stats.loaded);\n            // abort fragment loading\n            loader.abort();\n            // stop abandon rules timer\n            this.clearTimer();\n            hls.trigger(events[\"a\" /* default */].FRAG_LOAD_EMERGENCY_ABORTED, { frag: frag, stats: stats });\n          }\n        }\n      }\n    }\n  };\n\n  AbrController.prototype.onFragLoaded = function onFragLoaded(data) {\n    var frag = data.frag;\n    if (frag.type === 'main' && !isNaN(frag.sn)) {\n      // stop monitoring bw once frag loaded\n      this.clearTimer();\n      // store level id after successful fragment load\n      this.lastLoadedFragLevel = frag.level;\n      // reset forced auto level value so that next level will be selected\n      this._nextAutoLevel = -1;\n\n      // compute level average bitrate\n      if (this.hls.config.abrMaxWithRealBitrate) {\n        var level = this.hls.levels[frag.level];\n        var loadedBytes = (level.loaded ? level.loaded.bytes : 0) + data.stats.loaded;\n        var loadedDuration = (level.loaded ? level.loaded.duration : 0) + data.frag.duration;\n        level.loaded = { bytes: loadedBytes, duration: loadedDuration };\n        level.realBitrate = Math.round(8 * loadedBytes / loadedDuration);\n      }\n      // if fragment has been loaded to perform a bitrate test,\n      if (data.frag.bitrateTest) {\n        var stats = data.stats;\n        stats.tparsed = stats.tbuffered = stats.tload;\n        this.onFragBuffered(data);\n      }\n    }\n  };\n\n  AbrController.prototype.onFragBuffered = function onFragBuffered(data) {\n    var stats = data.stats,\n        frag = data.frag;\n    // only update stats on first frag buffering\n    // if same frag is loaded multiple times, it might be in browser cache, and loaded quickly\n    // and leading to wrong bw estimation\n    // on bitrate test, also only update stats once (if tload = tbuffered == on FRAG_LOADED)\n    if (stats.aborted !== true && frag.type === 'main' && !isNaN(frag.sn) && (!frag.bitrateTest || stats.tload === stats.tbuffered)) {\n      // use tparsed-trequest instead of tbuffered-trequest to compute fragLoadingProcessing; rationale is that  buffer appending only happens once media is attached\n      // in case we use config.startFragPrefetch while media is not attached yet, fragment might be parsed while media not attached yet, but it will only be buffered on media attached\n      // as a consequence it could happen really late in the process. meaning that appending duration might appears huge ... leading to underestimated throughput estimation\n      var fragLoadingProcessingMs = stats.tparsed - stats.trequest;\n      logger[\"b\" /* logger */].log('latency/loading/parsing/append/kbps:' + Math.round(stats.tfirst - stats.trequest) + '/' + Math.round(stats.tload - stats.tfirst) + '/' + Math.round(stats.tparsed - stats.tload) + '/' + Math.round(stats.tbuffered - stats.tparsed) + '/' + Math.round(8 * stats.loaded / (stats.tbuffered - stats.trequest)));\n      this._bwEstimator.sample(fragLoadingProcessingMs, stats.loaded);\n      stats.bwEstimate = this._bwEstimator.getEstimate();\n      // if fragment has been loaded to perform a bitrate test, (hls.startLevel = -1), store bitrate test delay duration\n      if (frag.bitrateTest) this.bitrateTestDelay = fragLoadingProcessingMs / 1000;else this.bitrateTestDelay = 0;\n    }\n  };\n\n  AbrController.prototype.onError = function onError(data) {\n    // stop timer in case of frag loading error\n    switch (data.details) {\n      case errors[\"a\" /* ErrorDetails */].FRAG_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].FRAG_LOAD_TIMEOUT:\n        this.clearTimer();\n        break;\n      default:\n        break;\n    }\n  };\n\n  AbrController.prototype.clearTimer = function clearTimer() {\n    clearInterval(this.timer);\n    this.timer = null;\n  };\n\n  // return next auto level\n\n\n  AbrController.prototype._findBestLevel = function _findBestLevel(currentLevel, currentFragDuration, currentBw, minAutoLevel, maxAutoLevel, maxFetchDuration, bwFactor, bwUpFactor, levels) {\n    for (var i = maxAutoLevel; i >= minAutoLevel; i--) {\n      var levelInfo = levels[i],\n          levelDetails = levelInfo.details,\n          avgDuration = levelDetails ? levelDetails.totalduration / levelDetails.fragments.length : currentFragDuration,\n          live = levelDetails ? levelDetails.live : false,\n          adjustedbw = void 0;\n      // follow algorithm captured from stagefright :\n      // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp\n      // Pick the highest bandwidth stream below or equal to estimated bandwidth.\n      // consider only 80% of the available bandwidth, but if we are switching up,\n      // be even more conservative (70%) to avoid overestimating and immediately\n      // switching back.\n      if (i <= currentLevel) adjustedbw = bwFactor * currentBw;else adjustedbw = bwUpFactor * currentBw;\n\n      var bitrate = levels[i].realBitrate ? Math.max(levels[i].realBitrate, levels[i].bitrate) : levels[i].bitrate,\n          fetchDuration = bitrate * avgDuration / adjustedbw;\n\n      logger[\"b\" /* logger */].trace('level/adjustedbw/bitrate/avgDuration/maxFetchDuration/fetchDuration: ' + i + '/' + Math.round(adjustedbw) + '/' + bitrate + '/' + avgDuration + '/' + maxFetchDuration + '/' + fetchDuration);\n      // if adjusted bw is greater than level bitrate AND\n      if (adjustedbw > bitrate && (\n      // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches\n      // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...\n      // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that _findBestLevel will return -1\n      !fetchDuration || live && !this.bitrateTestDelay || fetchDuration < maxFetchDuration)) {\n        // as we are looping from highest to lowest, this will return the best achievable quality level\n        return i;\n      }\n    }\n    // not enough time budget even with quality level 0 ... rebuffering might happen\n    return -1;\n  };\n\n  abr_controller__createClass(AbrController, [{\n    key: 'nextAutoLevel',\n    get: function get() {\n      var forcedAutoLevel = this._nextAutoLevel;\n      var bwEstimator = this._bwEstimator;\n      // in case next auto level has been forced, and bw not available or not reliable, return forced value\n      if (forcedAutoLevel !== -1 && (!bwEstimator || !bwEstimator.canEstimate())) return forcedAutoLevel;\n\n      // compute next level using ABR logic\n      var nextABRAutoLevel = this._nextABRAutoLevel;\n      // if forced auto level has been defined, use it to cap ABR computed quality level\n      if (forcedAutoLevel !== -1) nextABRAutoLevel = Math.min(forcedAutoLevel, nextABRAutoLevel);\n\n      return nextABRAutoLevel;\n    },\n    set: function set(nextLevel) {\n      this._nextAutoLevel = nextLevel;\n    }\n  }, {\n    key: '_nextABRAutoLevel',\n    get: function get() {\n      var hls = this.hls,\n          maxAutoLevel = hls.maxAutoLevel,\n          levels = hls.levels,\n          config = hls.config,\n          minAutoLevel = hls.minAutoLevel;\n      var v = hls.media,\n          currentLevel = this.lastLoadedFragLevel,\n          currentFragDuration = this.fragCurrent ? this.fragCurrent.duration : 0,\n          pos = v ? v.currentTime : 0,\n\n      // playbackRate is the absolute value of the playback rate; if v.playbackRate is 0, we use 1 to load as\n      // if we're playing back at the normal rate.\n      playbackRate = v && v.playbackRate !== 0 ? Math.abs(v.playbackRate) : 1.0,\n          avgbw = this._bwEstimator ? this._bwEstimator.getEstimate() : config.abrEwmaDefaultEstimate,\n\n      // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.\n      bufferStarvationDelay = (buffer_helper.bufferInfo(v, pos, config.maxBufferHole).end - pos) / playbackRate;\n\n      // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all\n      var bestLevel = this._findBestLevel(currentLevel, currentFragDuration, avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, config.abrBandWidthFactor, config.abrBandWidthUpFactor, levels);\n      if (bestLevel >= 0) {\n        return bestLevel;\n      } else {\n        logger[\"b\" /* logger */].trace('rebuffering expected to happen, lets try to find a quality level minimizing the rebuffering');\n        // not possible to get rid of rebuffering ... let's try to find level that will guarantee less than maxStarvationDelay of rebuffering\n        // if no matching level found, logic will return 0\n        var maxStarvationDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxStarvationDelay) : config.maxStarvationDelay,\n            bwFactor = config.abrBandWidthFactor,\n            bwUpFactor = config.abrBandWidthUpFactor;\n        if (bufferStarvationDelay === 0) {\n          // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test\n          var bitrateTestDelay = this.bitrateTestDelay;\n          if (bitrateTestDelay) {\n            // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value\n            // max video loading delay used in  automatic start level selection :\n            // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +\n            // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )\n            // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration\n            var maxLoadingDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxLoadingDelay) : config.maxLoadingDelay;\n            maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;\n            logger[\"b\" /* logger */].trace('bitrate test took ' + Math.round(1000 * bitrateTestDelay) + 'ms, set first fragment max fetchDuration to ' + Math.round(1000 * maxStarvationDelay) + ' ms');\n            // don't use conservative factor on bitrate test\n            bwFactor = bwUpFactor = 1;\n          }\n        }\n        bestLevel = this._findBestLevel(currentLevel, currentFragDuration, avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay + maxStarvationDelay, bwFactor, bwUpFactor, levels);\n        return Math.max(bestLevel, 0);\n      }\n    }\n  }]);\n\n  return AbrController;\n}(event_handler);\n\n/* harmony default export */ var abr_controller = (abr_controller_AbrController);\n// CONCATENATED MODULE: ./src/controller/buffer-controller.js\nfunction buffer_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction buffer_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction buffer_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * Buffer Controller\n*/\n\n\n\n\n\n\n\nvar buffer_controller_MediaSource = getMediaSource();\n\nvar buffer_controller_BufferController = function (_EventHandler) {\n  buffer_controller__inherits(BufferController, _EventHandler);\n\n  function BufferController(hls) {\n    buffer_controller__classCallCheck(this, BufferController);\n\n    // the value that we have set mediasource.duration to\n    // (the actual duration may be tweaked slighly by the browser)\n    var _this = buffer_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHING, events[\"a\" /* default */].MEDIA_DETACHING, events[\"a\" /* default */].MANIFEST_PARSED, events[\"a\" /* default */].BUFFER_RESET, events[\"a\" /* default */].BUFFER_APPENDING, events[\"a\" /* default */].BUFFER_CODECS, events[\"a\" /* default */].BUFFER_EOS, events[\"a\" /* default */].BUFFER_FLUSHING, events[\"a\" /* default */].LEVEL_PTS_UPDATED, events[\"a\" /* default */].LEVEL_UPDATED));\n\n    _this._msDuration = null;\n    // the value that we want to set mediaSource.duration to\n    _this._levelDuration = null;\n    // current stream state: true - for live broadcast, false - for VoD content\n    _this._live = null;\n    // cache the self generated object url to detect hijack of video tag\n    _this._objectUrl = null;\n\n    // Source Buffer listeners\n    _this.onsbue = _this.onSBUpdateEnd.bind(_this);\n    _this.onsbe = _this.onSBUpdateError.bind(_this);\n    _this.pendingTracks = {};\n    _this.tracks = {};\n    return _this;\n  }\n\n  BufferController.prototype.destroy = function destroy() {\n    event_handler.prototype.destroy.call(this);\n  };\n\n  BufferController.prototype.onLevelPtsUpdated = function onLevelPtsUpdated(data) {\n    var type = data.type;\n    var audioTrack = this.tracks.audio;\n\n    // Adjusting `SourceBuffer.timestampOffset` (desired point in the timeline where the next frames should be appended)\n    // in Chrome browser when we detect MPEG audio container and time delta between level PTS and `SourceBuffer.timestampOffset`\n    // is greater than 100ms (this is enough to handle seek for VOD or level change for LIVE videos). At the time of change we issue\n    // `SourceBuffer.abort()` and adjusting `SourceBuffer.timestampOffset` if `SourceBuffer.updating` is false or awaiting `updateend`\n    // event if SB is in updating state.\n    // More info here: https://github.com/video-dev/hls.js/issues/332#issuecomment-257986486\n\n    if (type === 'audio' && audioTrack && audioTrack.container === 'audio/mpeg') {\n      // Chrome audio mp3 track\n      var audioBuffer = this.sourceBuffer.audio;\n      var delta = Math.abs(audioBuffer.timestampOffset - data.start);\n\n      // adjust timestamp offset if time delta is greater than 100ms\n      if (delta > 0.1) {\n        var updating = audioBuffer.updating;\n\n        try {\n          audioBuffer.abort();\n        } catch (err) {\n          updating = true;\n          logger[\"b\" /* logger */].warn('can not abort audio buffer: ' + err);\n        }\n\n        if (!updating) {\n          logger[\"b\" /* logger */].warn('change mpeg audio timestamp offset from ' + audioBuffer.timestampOffset + ' to ' + data.start);\n          audioBuffer.timestampOffset = data.start;\n        } else {\n          this.audioTimestampOffset = data.start;\n        }\n      }\n    }\n  };\n\n  BufferController.prototype.onManifestParsed = function onManifestParsed(data) {\n    var audioExpected = data.audio,\n        videoExpected = data.video || data.levels.length && data.audio,\n        sourceBufferNb = 0;\n    // in case of alt audio 2 BUFFER_CODECS events will be triggered, one per stream controller\n    // sourcebuffers will be created all at once when the expected nb of tracks will be reached\n    // in case alt audio is not used, only one BUFFER_CODEC event will be fired from main stream controller\n    // it will contain the expected nb of source buffers, no need to compute it\n    if (data.altAudio && (audioExpected || videoExpected)) {\n      sourceBufferNb = (audioExpected ? 1 : 0) + (videoExpected ? 1 : 0);\n      logger[\"b\" /* logger */].log(sourceBufferNb + ' sourceBuffer(s) expected');\n    }\n    this.sourceBufferNb = sourceBufferNb;\n  };\n\n  BufferController.prototype.onMediaAttaching = function onMediaAttaching(data) {\n    var media = this.media = data.media;\n    if (media) {\n      // setup the media source\n      var ms = this.mediaSource = new buffer_controller_MediaSource();\n      // Media Source listeners\n      this.onmso = this.onMediaSourceOpen.bind(this);\n      this.onmse = this.onMediaSourceEnded.bind(this);\n      this.onmsc = this.onMediaSourceClose.bind(this);\n      ms.addEventListener('sourceopen', this.onmso);\n      ms.addEventListener('sourceended', this.onmse);\n      ms.addEventListener('sourceclose', this.onmsc);\n      // link video and media Source\n      media.src = URL.createObjectURL(ms);\n      // cache the locally generated object url\n      this._objectUrl = media.src;\n    }\n  };\n\n  BufferController.prototype.onMediaDetaching = function onMediaDetaching() {\n    logger[\"b\" /* logger */].log('media source detaching');\n    var ms = this.mediaSource;\n    if (ms) {\n      if (ms.readyState === 'open') {\n        try {\n          // endOfStream could trigger exception if any sourcebuffer is in updating state\n          // we don't really care about checking sourcebuffer state here,\n          // as we are anyway detaching the MediaSource\n          // let's just avoid this exception to propagate\n          ms.endOfStream();\n        } catch (err) {\n          logger[\"b\" /* logger */].warn('onMediaDetaching:' + err.message + ' while calling endOfStream');\n        }\n      }\n      ms.removeEventListener('sourceopen', this.onmso);\n      ms.removeEventListener('sourceended', this.onmse);\n      ms.removeEventListener('sourceclose', this.onmsc);\n\n      // Detach properly the MediaSource from the HTMLMediaElement as\n      // suggested in https://github.com/w3c/media-source/issues/53.\n      if (this.media) {\n        URL.revokeObjectURL(this._objectUrl);\n\n        // clean up video tag src only if it's our own url. some external libraries might\n        // hijack the video tag and change its 'src' without destroying the Hls instance first\n        if (this.media.src === this._objectUrl) {\n          this.media.removeAttribute('src');\n          this.media.load();\n        } else {\n          logger[\"b\" /* logger */].warn('media.src was changed by a third party - skip cleanup');\n        }\n      }\n\n      this.mediaSource = null;\n      this.media = null;\n      this._objectUrl = null;\n      this.pendingTracks = {};\n      this.tracks = {};\n      this.sourceBuffer = {};\n      this.flushRange = [];\n      this.segments = [];\n      this.appended = 0;\n    }\n    this.onmso = this.onmse = this.onmsc = null;\n    this.hls.trigger(events[\"a\" /* default */].MEDIA_DETACHED);\n  };\n\n  BufferController.prototype.onMediaSourceOpen = function onMediaSourceOpen() {\n    logger[\"b\" /* logger */].log('media source opened');\n    this.hls.trigger(events[\"a\" /* default */].MEDIA_ATTACHED, { media: this.media });\n    var mediaSource = this.mediaSource;\n    if (mediaSource) {\n      // once received, don't listen anymore to sourceopen event\n      mediaSource.removeEventListener('sourceopen', this.onmso);\n    }\n    this.checkPendingTracks();\n  };\n\n  BufferController.prototype.checkPendingTracks = function checkPendingTracks() {\n    // if any buffer codecs pending, check if we have enough to create sourceBuffers\n    var pendingTracks = this.pendingTracks,\n        pendingTracksNb = Object.keys(pendingTracks).length;\n    // if any pending tracks and (if nb of pending tracks gt or equal than expected nb or if unknown expected nb)\n    if (pendingTracksNb && (this.sourceBufferNb <= pendingTracksNb || this.sourceBufferNb === 0)) {\n      // ok, let's create them now !\n      this.createSourceBuffers(pendingTracks);\n      this.pendingTracks = {};\n      // append any pending segments now !\n      this.doAppending();\n    }\n  };\n\n  BufferController.prototype.onMediaSourceClose = function onMediaSourceClose() {\n    logger[\"b\" /* logger */].log('media source closed');\n  };\n\n  BufferController.prototype.onMediaSourceEnded = function onMediaSourceEnded() {\n    logger[\"b\" /* logger */].log('media source ended');\n  };\n\n  BufferController.prototype.onSBUpdateEnd = function onSBUpdateEnd() {\n    // update timestampOffset\n    if (this.audioTimestampOffset) {\n      var audioBuffer = this.sourceBuffer.audio;\n      logger[\"b\" /* logger */].warn('change mpeg audio timestamp offset from ' + audioBuffer.timestampOffset + ' to ' + this.audioTimestampOffset);\n      audioBuffer.timestampOffset = this.audioTimestampOffset;\n      delete this.audioTimestampOffset;\n    }\n\n    if (this._needsFlush) this.doFlush();\n\n    if (this._needsEos) this.checkEos();\n\n    this.appending = false;\n    var parent = this.parent;\n    // count nb of pending segments waiting for appending on this sourcebuffer\n    var pending = this.segments.reduce(function (counter, segment) {\n      return segment.parent === parent ? counter + 1 : counter;\n    }, 0);\n\n    // this.sourceBuffer is better to use than media.buffered as it is closer to the PTS data from the fragments\n    var timeRanges = {};\n    var sourceBuffer = this.sourceBuffer;\n    for (var streamType in sourceBuffer) {\n      timeRanges[streamType] = sourceBuffer[streamType].buffered;\n    }this.hls.trigger(events[\"a\" /* default */].BUFFER_APPENDED, { parent: parent, pending: pending, timeRanges: timeRanges });\n    // don't append in flushing mode\n    if (!this._needsFlush) this.doAppending();\n\n    this.updateMediaElementDuration();\n  };\n\n  BufferController.prototype.onSBUpdateError = function onSBUpdateError(event) {\n    logger[\"b\" /* logger */].error('sourceBuffer error:', event);\n    // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error\n    // this error might not always be fatal (it is fatal if decode error is set, in that case\n    // it will be followed by a mediaElement error ...)\n    this.hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].BUFFER_APPENDING_ERROR, fatal: false });\n    // we don't need to do more than that, as accordin to the spec, updateend will be fired just after\n  };\n\n  BufferController.prototype.onBufferReset = function onBufferReset() {\n    var sourceBuffer = this.sourceBuffer;\n    for (var type in sourceBuffer) {\n      var sb = sourceBuffer[type];\n      try {\n        this.mediaSource.removeSourceBuffer(sb);\n        sb.removeEventListener('updateend', this.onsbue);\n        sb.removeEventListener('error', this.onsbe);\n      } catch (err) {}\n    }\n    this.sourceBuffer = {};\n    this.flushRange = [];\n    this.segments = [];\n    this.appended = 0;\n  };\n\n  BufferController.prototype.onBufferCodecs = function onBufferCodecs(tracks) {\n    // if source buffer(s) not created yet, appended buffer tracks in this.pendingTracks\n    // if sourcebuffers already created, do nothing ...\n    if (Object.keys(this.sourceBuffer).length === 0) {\n      for (var trackName in tracks) {\n        this.pendingTracks[trackName] = tracks[trackName];\n      }var mediaSource = this.mediaSource;\n      if (mediaSource && mediaSource.readyState === 'open') {\n        // try to create sourcebuffers if mediasource opened\n        this.checkPendingTracks();\n      }\n    }\n  };\n\n  BufferController.prototype.createSourceBuffers = function createSourceBuffers(tracks) {\n    var sourceBuffer = this.sourceBuffer,\n        mediaSource = this.mediaSource;\n\n    for (var trackName in tracks) {\n      if (!sourceBuffer[trackName]) {\n        var track = tracks[trackName];\n        // use levelCodec as first priority\n        var codec = track.levelCodec || track.codec;\n        var mimeType = track.container + ';codecs=' + codec;\n        logger[\"b\" /* logger */].log('creating sourceBuffer(' + mimeType + ')');\n        try {\n          var sb = sourceBuffer[trackName] = mediaSource.addSourceBuffer(mimeType);\n          sb.addEventListener('updateend', this.onsbue);\n          sb.addEventListener('error', this.onsbe);\n          this.tracks[trackName] = { codec: codec, container: track.container };\n          track.buffer = sb;\n        } catch (err) {\n          logger[\"b\" /* logger */].error('error while trying to add sourceBuffer:' + err.message);\n          this.hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].BUFFER_ADD_CODEC_ERROR, fatal: false, err: err, mimeType: mimeType });\n        }\n      }\n    }\n    this.hls.trigger(events[\"a\" /* default */].BUFFER_CREATED, { tracks: tracks });\n  };\n\n  BufferController.prototype.onBufferAppending = function onBufferAppending(data) {\n    if (!this._needsFlush) {\n      if (!this.segments) this.segments = [data];else this.segments.push(data);\n\n      this.doAppending();\n    }\n  };\n\n  BufferController.prototype.onBufferAppendFail = function onBufferAppendFail(data) {\n    logger[\"b\" /* logger */].error('sourceBuffer error:', data.event);\n    // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error\n    // this error might not always be fatal (it is fatal if decode error is set, in that case\n    // it will be followed by a mediaElement error ...)\n    this.hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: errors[\"a\" /* ErrorDetails */].BUFFER_APPENDING_ERROR, fatal: false });\n  };\n\n  // on BUFFER_EOS mark matching sourcebuffer(s) as ended and trigger checkEos()\n\n\n  BufferController.prototype.onBufferEos = function onBufferEos(data) {\n    var sb = this.sourceBuffer;\n    var dataType = data.type;\n    for (var type in sb) {\n      if (!dataType || type === dataType) {\n        if (!sb[type].ended) {\n          sb[type].ended = true;\n          logger[\"b\" /* logger */].log(type + ' sourceBuffer now EOS');\n        }\n      }\n    }\n    this.checkEos();\n  };\n\n  // if all source buffers are marked as ended, signal endOfStream() to MediaSource.\n\n\n  BufferController.prototype.checkEos = function checkEos() {\n    var sb = this.sourceBuffer,\n        mediaSource = this.mediaSource;\n    if (!mediaSource || mediaSource.readyState !== 'open') {\n      this._needsEos = false;\n      return;\n    }\n    for (var type in sb) {\n      var sbobj = sb[type];\n      if (!sbobj.ended) return;\n\n      if (sbobj.updating) {\n        this._needsEos = true;\n        return;\n      }\n    }\n    logger[\"b\" /* logger */].log('all media data available, signal endOfStream() to MediaSource and stop loading fragment');\n    // Notify the media element that it now has all of the media data\n    try {\n      mediaSource.endOfStream();\n    } catch (e) {\n      logger[\"b\" /* logger */].warn('exception while calling mediaSource.endOfStream()');\n    }\n    this._needsEos = false;\n  };\n\n  BufferController.prototype.onBufferFlushing = function onBufferFlushing(data) {\n    this.flushRange.push({ start: data.startOffset, end: data.endOffset, type: data.type });\n    // attempt flush immediately\n    this.flushBufferCounter = 0;\n    this.doFlush();\n  };\n\n  BufferController.prototype.onLevelUpdated = function onLevelUpdated(_ref) {\n    var details = _ref.details;\n\n    if (details.fragments.length > 0) {\n      this._levelDuration = details.totalduration + details.fragments[0].start;\n      this._live = details.live;\n      this.updateMediaElementDuration();\n    }\n  };\n\n  /**\n   * Update Media Source duration to current level duration or override to Infinity if configuration parameter\n   * 'liveDurationInfinity` is set to `true`\n   * More details: https://github.com/video-dev/hls.js/issues/355\n   */\n\n\n  BufferController.prototype.updateMediaElementDuration = function updateMediaElementDuration() {\n    var config = this.hls.config;\n\n    var duration = void 0;\n\n    if (this._levelDuration === null || !this.media || !this.mediaSource || !this.sourceBuffer || this.media.readyState === 0 || this.mediaSource.readyState !== 'open') return;\n\n    for (var type in this.sourceBuffer) {\n      if (this.sourceBuffer[type].updating === true) {\n        // can't set duration whilst a buffer is updating\n        return;\n      }\n    }\n\n    duration = this.media.duration;\n    // initialise to the value that the media source is reporting\n    if (this._msDuration === null) this._msDuration = this.mediaSource.duration;\n\n    if (this._live === true && config.liveDurationInfinity === true) {\n      // Override duration to Infinity\n      logger[\"b\" /* logger */].log('Media Source duration is set to Infinity');\n      this._msDuration = this.mediaSource.duration = Infinity;\n    } else if (this._levelDuration > this._msDuration && this._levelDuration > duration || duration === Infinity || isNaN(duration)) {\n      // levelDuration was the last value we set.\n      // not using mediaSource.duration as the browser may tweak this value\n      // only update Media Source duration if its value increase, this is to avoid\n      // flushing already buffered portion when switching between quality level\n      logger[\"b\" /* logger */].log('Updating Media Source duration to ' + this._levelDuration.toFixed(3));\n      this._msDuration = this.mediaSource.duration = this._levelDuration;\n    }\n  };\n\n  BufferController.prototype.doFlush = function doFlush() {\n    // loop through all buffer ranges to flush\n    while (this.flushRange.length) {\n      var range = this.flushRange[0];\n      // flushBuffer will abort any buffer append in progress and flush Audio/Video Buffer\n      if (this.flushBuffer(range.start, range.end, range.type)) {\n        // range flushed, remove from flush array\n        this.flushRange.shift();\n        this.flushBufferCounter = 0;\n      } else {\n        this._needsFlush = true;\n        // avoid looping, wait for SB update end to retrigger a flush\n        return;\n      }\n    }\n    if (this.flushRange.length === 0) {\n      // everything flushed\n      this._needsFlush = false;\n\n      // let's recompute this.appended, which is used to avoid flush looping\n      var appended = 0;\n      var sourceBuffer = this.sourceBuffer;\n      try {\n        for (var type in sourceBuffer) {\n          appended += sourceBuffer[type].buffered.length;\n        }\n      } catch (error) {\n        // error could be thrown while accessing buffered, in case sourcebuffer has already been removed from MediaSource\n        // this is harmess at this stage, catch this to avoid reporting an internal exception\n        logger[\"b\" /* logger */].error('error while accessing sourceBuffer.buffered');\n      }\n      this.appended = appended;\n      this.hls.trigger(events[\"a\" /* default */].BUFFER_FLUSHED);\n    }\n  };\n\n  BufferController.prototype.doAppending = function doAppending() {\n    var hls = this.hls,\n        sourceBuffer = this.sourceBuffer,\n        segments = this.segments;\n    if (Object.keys(sourceBuffer).length) {\n      if (this.media.error) {\n        this.segments = [];\n        logger[\"b\" /* logger */].error('trying to append although a media error occured, flush segment and abort');\n        return;\n      }\n      if (this.appending) {\n        // logger.log(`sb appending in progress`);\n        return;\n      }\n      if (segments && segments.length) {\n        var segment = segments.shift();\n        try {\n          var type = segment.type,\n              sb = sourceBuffer[type];\n          if (sb) {\n            if (!sb.updating) {\n              // reset sourceBuffer ended flag before appending segment\n              sb.ended = false;\n              // logger.log(`appending ${segment.content} ${type} SB, size:${segment.data.length}, ${segment.parent}`);\n              this.parent = segment.parent;\n              sb.appendBuffer(segment.data);\n              this.appendError = 0;\n              this.appended++;\n              this.appending = true;\n            } else {\n              segments.unshift(segment);\n            }\n          } else {\n            // in case we don't have any source buffer matching with this segment type,\n            // it means that Mediasource fails to create sourcebuffer\n            // discard this segment, and trigger update end\n            this.onSBUpdateEnd();\n          }\n        } catch (err) {\n          // in case any error occured while appending, put back segment in segments table\n          logger[\"b\" /* logger */].error('error while trying to append buffer:' + err.message);\n          segments.unshift(segment);\n          var event = { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, parent: segment.parent };\n          if (err.code !== 22) {\n            if (this.appendError) this.appendError++;else this.appendError = 1;\n\n            event.details = errors[\"a\" /* ErrorDetails */].BUFFER_APPEND_ERROR;\n            /* with UHD content, we could get loop of quota exceeded error until\n              browser is able to evict some data from sourcebuffer. retrying help recovering this\n            */\n            if (this.appendError > hls.config.appendErrorMaxRetry) {\n              logger[\"b\" /* logger */].log('fail ' + hls.config.appendErrorMaxRetry + ' times to append segment in sourceBuffer');\n              segments = [];\n              event.fatal = true;\n              hls.trigger(events[\"a\" /* default */].ERROR, event);\n            } else {\n              event.fatal = false;\n              hls.trigger(events[\"a\" /* default */].ERROR, event);\n            }\n          } else {\n            // QuotaExceededError: http://www.w3.org/TR/html5/infrastructure.html#quotaexceedederror\n            // let's stop appending any segments, and report BUFFER_FULL_ERROR error\n            this.segments = [];\n            event.details = errors[\"a\" /* ErrorDetails */].BUFFER_FULL_ERROR;\n            event.fatal = false;\n            hls.trigger(events[\"a\" /* default */].ERROR, event);\n          }\n        }\n      }\n    }\n  };\n\n  /*\n    flush specified buffered range,\n    return true once range has been flushed.\n    as sourceBuffer.remove() is asynchronous, flushBuffer will be retriggered on sourceBuffer update end\n  */\n\n\n  BufferController.prototype.flushBuffer = function flushBuffer(startOffset, endOffset, typeIn) {\n    var sb = void 0,\n        i = void 0,\n        bufStart = void 0,\n        bufEnd = void 0,\n        flushStart = void 0,\n        flushEnd = void 0,\n        sourceBuffer = this.sourceBuffer;\n    if (Object.keys(sourceBuffer).length) {\n      logger[\"b\" /* logger */].log('flushBuffer,pos/start/end: ' + this.media.currentTime.toFixed(3) + '/' + startOffset + '/' + endOffset);\n      // safeguard to avoid infinite looping : don't try to flush more than the nb of appended segments\n      if (this.flushBufferCounter < this.appended) {\n        for (var type in sourceBuffer) {\n          // check if sourcebuffer type is defined (typeIn): if yes, let's only flush this one\n          // if no, let's flush all sourcebuffers\n          if (typeIn && type !== typeIn) continue;\n\n          sb = sourceBuffer[type];\n          // we are going to flush buffer, mark source buffer as 'not ended'\n          sb.ended = false;\n          if (!sb.updating) {\n            try {\n              for (i = 0; i < sb.buffered.length; i++) {\n                bufStart = sb.buffered.start(i);\n                bufEnd = sb.buffered.end(i);\n                // workaround firefox not able to properly flush multiple buffered range.\n                if (navigator.userAgent.toLowerCase().indexOf('firefox') !== -1 && endOffset === Number.POSITIVE_INFINITY) {\n                  flushStart = startOffset;\n                  flushEnd = endOffset;\n                } else {\n                  flushStart = Math.max(bufStart, startOffset);\n                  flushEnd = Math.min(bufEnd, endOffset);\n                }\n                /* sometimes sourcebuffer.remove() does not flush\n                   the exact expected time range.\n                   to avoid rounding issues/infinite loop,\n                   only flush buffer range of length greater than 500ms.\n                */\n                if (Math.min(flushEnd, bufEnd) - flushStart > 0.5) {\n                  this.flushBufferCounter++;\n                  logger[\"b\" /* logger */].log('flush ' + type + ' [' + flushStart + ',' + flushEnd + '], of [' + bufStart + ',' + bufEnd + '], pos:' + this.media.currentTime);\n                  sb.remove(flushStart, flushEnd);\n                  return false;\n                }\n              }\n            } catch (e) {\n              logger[\"b\" /* logger */].warn('exception while accessing sourcebuffer, it might have been removed from MediaSource');\n            }\n          } else {\n            // logger.log('abort ' + type + ' append in progress');\n            // this will abort any appending in progress\n            // sb.abort();\n            logger[\"b\" /* logger */].warn('cannot flush, sb updating in progress');\n            return false;\n          }\n        }\n      } else {\n        logger[\"b\" /* logger */].warn('abort flushing too many retries');\n      }\n      logger[\"b\" /* logger */].log('buffer flushed');\n    }\n    // everything flushed !\n    return true;\n  };\n\n  return BufferController;\n}(event_handler);\n\n/* harmony default export */ var buffer_controller = (buffer_controller_BufferController);\n// CONCATENATED MODULE: ./src/controller/cap-level-controller.js\nvar cap_level_controller__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction cap_level_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction cap_level_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction cap_level_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * cap stream level to media size dimension controller\n*/\n\n\n\n\nvar cap_level_controller_CapLevelController = function (_EventHandler) {\n  cap_level_controller__inherits(CapLevelController, _EventHandler);\n\n  function CapLevelController(hls) {\n    cap_level_controller__classCallCheck(this, CapLevelController);\n\n    return cap_level_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].FPS_DROP_LEVEL_CAPPING, events[\"a\" /* default */].MEDIA_ATTACHING, events[\"a\" /* default */].MANIFEST_PARSED));\n  }\n\n  CapLevelController.prototype.destroy = function destroy() {\n    if (this.hls.config.capLevelToPlayerSize) {\n      this.media = this.restrictedLevels = null;\n      this.autoLevelCapping = Number.POSITIVE_INFINITY;\n      if (this.timer) this.timer = clearInterval(this.timer);\n    }\n  };\n\n  CapLevelController.prototype.onFpsDropLevelCapping = function onFpsDropLevelCapping(data) {\n    // Don't add a restricted level more than once\n    if (CapLevelController.isLevelAllowed(data.droppedLevel, this.restrictedLevels)) this.restrictedLevels.push(data.droppedLevel);\n  };\n\n  CapLevelController.prototype.onMediaAttaching = function onMediaAttaching(data) {\n    this.media = data.media instanceof HTMLVideoElement ? data.media : null;\n  };\n\n  CapLevelController.prototype.onManifestParsed = function onManifestParsed(data) {\n    var hls = this.hls;\n    this.restrictedLevels = [];\n    if (hls.config.capLevelToPlayerSize) {\n      this.autoLevelCapping = Number.POSITIVE_INFINITY;\n      this.levels = data.levels;\n      hls.firstLevel = this.getMaxLevel(data.firstLevel);\n      clearInterval(this.timer);\n      this.timer = setInterval(this.detectPlayerSize.bind(this), 1000);\n      this.detectPlayerSize();\n    }\n  };\n\n  CapLevelController.prototype.detectPlayerSize = function detectPlayerSize() {\n    if (this.media) {\n      var levelsLength = this.levels ? this.levels.length : 0;\n      if (levelsLength) {\n        var hls = this.hls;\n        hls.autoLevelCapping = this.getMaxLevel(levelsLength - 1);\n        if (hls.autoLevelCapping > this.autoLevelCapping) {\n          // if auto level capping has a higher value for the previous one, flush the buffer using nextLevelSwitch\n          // usually happen when the user go to the fullscreen mode.\n          hls.streamController.nextLevelSwitch();\n        }\n        this.autoLevelCapping = hls.autoLevelCapping;\n      }\n    }\n  };\n\n  /*\n  * returns level should be the one with the dimensions equal or greater than the media (player) dimensions (so the video will be downscaled)\n  */\n\n\n  CapLevelController.prototype.getMaxLevel = function getMaxLevel(capLevelIndex) {\n    var _this2 = this;\n\n    if (!this.levels) return -1;\n\n    var validLevels = this.levels.filter(function (level, index) {\n      return CapLevelController.isLevelAllowed(index, _this2.restrictedLevels) && index <= capLevelIndex;\n    });\n\n    return CapLevelController.getMaxLevelByMediaSize(validLevels, this.mediaWidth, this.mediaHeight);\n  };\n\n  CapLevelController.isLevelAllowed = function isLevelAllowed(level) {\n    var restrictedLevels = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n\n    return restrictedLevels.indexOf(level) === -1;\n  };\n\n  CapLevelController.getMaxLevelByMediaSize = function getMaxLevelByMediaSize(levels, width, height) {\n    if (!levels || levels && !levels.length) return -1;\n\n    // Levels can have the same dimensions but differing bandwidths - since levels are ordered, we can look to the next\n    // to determine whether we've chosen the greatest bandwidth for the media's dimensions\n    var atGreatestBandiwdth = function atGreatestBandiwdth(curLevel, nextLevel) {\n      if (!nextLevel) return true;\n\n      return curLevel.width !== nextLevel.width || curLevel.height !== nextLevel.height;\n    };\n\n    // If we run through the loop without breaking, the media's dimensions are greater than every level, so default to\n    // the max level\n    var maxLevelIndex = levels.length - 1;\n\n    for (var i = 0; i < levels.length; i += 1) {\n      var level = levels[i];\n      if ((level.width >= width || level.height >= height) && atGreatestBandiwdth(level, levels[i + 1])) {\n        maxLevelIndex = i;\n        break;\n      }\n    }\n\n    return maxLevelIndex;\n  };\n\n  cap_level_controller__createClass(CapLevelController, [{\n    key: 'mediaWidth',\n    get: function get() {\n      var width = void 0;\n      var media = this.media;\n      if (media) {\n        width = media.width || media.clientWidth || media.offsetWidth;\n        width *= CapLevelController.contentScaleFactor;\n      }\n      return width;\n    }\n  }, {\n    key: 'mediaHeight',\n    get: function get() {\n      var height = void 0;\n      var media = this.media;\n      if (media) {\n        height = media.height || media.clientHeight || media.offsetHeight;\n        height *= CapLevelController.contentScaleFactor;\n      }\n      return height;\n    }\n  }], [{\n    key: 'contentScaleFactor',\n    get: function get() {\n      var pixelRatio = 1;\n      try {\n        pixelRatio = window.devicePixelRatio;\n      } catch (e) {}\n      return pixelRatio;\n    }\n  }]);\n\n  return CapLevelController;\n}(event_handler);\n\n/* harmony default export */ var cap_level_controller = (cap_level_controller_CapLevelController);\n// CONCATENATED MODULE: ./src/controller/fps-controller.js\nfunction fps_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction fps_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction fps_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * FPS Controller\n*/\n\n\n\n\n\nvar fps_controller_FPSController = function (_EventHandler) {\n  fps_controller__inherits(FPSController, _EventHandler);\n\n  function FPSController(hls) {\n    fps_controller__classCallCheck(this, FPSController);\n\n    return fps_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHING));\n  }\n\n  FPSController.prototype.destroy = function destroy() {\n    if (this.timer) clearInterval(this.timer);\n\n    this.isVideoPlaybackQualityAvailable = false;\n  };\n\n  FPSController.prototype.onMediaAttaching = function onMediaAttaching(data) {\n    var config = this.hls.config;\n    if (config.capLevelOnFPSDrop) {\n      var video = this.video = data.media instanceof HTMLVideoElement ? data.media : null;\n      if (typeof video.getVideoPlaybackQuality === 'function') this.isVideoPlaybackQualityAvailable = true;\n\n      clearInterval(this.timer);\n      this.timer = setInterval(this.checkFPSInterval.bind(this), config.fpsDroppedMonitoringPeriod);\n    }\n  };\n\n  FPSController.prototype.checkFPS = function checkFPS(video, decodedFrames, droppedFrames) {\n    var currentTime = performance.now();\n    if (decodedFrames) {\n      if (this.lastTime) {\n        var currentPeriod = currentTime - this.lastTime,\n            currentDropped = droppedFrames - this.lastDroppedFrames,\n            currentDecoded = decodedFrames - this.lastDecodedFrames,\n            droppedFPS = 1000 * currentDropped / currentPeriod,\n            hls = this.hls;\n        hls.trigger(events[\"a\" /* default */].FPS_DROP, { currentDropped: currentDropped, currentDecoded: currentDecoded, totalDroppedFrames: droppedFrames });\n        if (droppedFPS > 0) {\n          // logger.log('checkFPS : droppedFPS/decodedFPS:' + droppedFPS/(1000 * currentDecoded / currentPeriod));\n          if (currentDropped > hls.config.fpsDroppedMonitoringThreshold * currentDecoded) {\n            var currentLevel = hls.currentLevel;\n            logger[\"b\" /* logger */].warn('drop FPS ratio greater than max allowed value for currentLevel: ' + currentLevel);\n            if (currentLevel > 0 && (hls.autoLevelCapping === -1 || hls.autoLevelCapping >= currentLevel)) {\n              currentLevel = currentLevel - 1;\n              hls.trigger(events[\"a\" /* default */].FPS_DROP_LEVEL_CAPPING, { level: currentLevel, droppedLevel: hls.currentLevel });\n              hls.autoLevelCapping = currentLevel;\n              hls.streamController.nextLevelSwitch();\n            }\n          }\n        }\n      }\n      this.lastTime = currentTime;\n      this.lastDroppedFrames = droppedFrames;\n      this.lastDecodedFrames = decodedFrames;\n    }\n  };\n\n  FPSController.prototype.checkFPSInterval = function checkFPSInterval() {\n    var video = this.video;\n    if (video) {\n      if (this.isVideoPlaybackQualityAvailable) {\n        var videoPlaybackQuality = video.getVideoPlaybackQuality();\n        this.checkFPS(video, videoPlaybackQuality.totalVideoFrames, videoPlaybackQuality.droppedVideoFrames);\n      } else {\n        this.checkFPS(video, video.webkitDecodedFrameCount, video.webkitDroppedFrameCount);\n      }\n    }\n  };\n\n  return FPSController;\n}(event_handler);\n\n/* harmony default export */ var fps_controller = (fps_controller_FPSController);\n// CONCATENATED MODULE: ./src/utils/xhr-loader.js\nfunction xhr_loader__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * XHR based logger\n*/\n\n\n\nvar xhr_loader_XhrLoader = function () {\n  function XhrLoader(config) {\n    xhr_loader__classCallCheck(this, XhrLoader);\n\n    if (config && config.xhrSetup) this.xhrSetup = config.xhrSetup;\n  }\n\n  XhrLoader.prototype.destroy = function destroy() {\n    this.abort();\n    this.loader = null;\n  };\n\n  XhrLoader.prototype.abort = function abort() {\n    var loader = this.loader;\n    if (loader && loader.readyState !== 4) {\n      this.stats.aborted = true;\n      loader.abort();\n    }\n\n    window.clearTimeout(this.requestTimeout);\n    this.requestTimeout = null;\n    window.clearTimeout(this.retryTimeout);\n    this.retryTimeout = null;\n  };\n\n  XhrLoader.prototype.load = function load(context, config, callbacks) {\n    this.context = context;\n    this.config = config;\n    this.callbacks = callbacks;\n    this.stats = { trequest: performance.now(), retry: 0 };\n    this.retryDelay = config.retryDelay;\n    this.loadInternal();\n  };\n\n  XhrLoader.prototype.loadInternal = function loadInternal() {\n    var xhr = void 0,\n        context = this.context;\n    xhr = this.loader = new XMLHttpRequest();\n\n    var stats = this.stats;\n    stats.tfirst = 0;\n    stats.loaded = 0;\n    var xhrSetup = this.xhrSetup;\n\n    try {\n      if (xhrSetup) {\n        try {\n          xhrSetup(xhr, context.url);\n        } catch (e) {\n          // fix xhrSetup: (xhr, url) => {xhr.setRequestHeader(\"Content-Language\", \"test\");}\n          // not working, as xhr.setRequestHeader expects xhr.readyState === OPEN\n          xhr.open('GET', context.url, true);\n          xhrSetup(xhr, context.url);\n        }\n      }\n      if (!xhr.readyState) xhr.open('GET', context.url, true);\n    } catch (e) {\n      // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS\n      this.callbacks.onError({ code: xhr.status, text: e.message }, context, xhr);\n      return;\n    }\n\n    if (context.rangeEnd) xhr.setRequestHeader('Range', 'bytes=' + context.rangeStart + '-' + (context.rangeEnd - 1));\n\n    xhr.onreadystatechange = this.readystatechange.bind(this);\n    xhr.onprogress = this.loadprogress.bind(this);\n    xhr.responseType = context.responseType;\n\n    // setup timeout before we perform request\n    this.requestTimeout = window.setTimeout(this.loadtimeout.bind(this), this.config.timeout);\n    xhr.send();\n  };\n\n  XhrLoader.prototype.readystatechange = function readystatechange(event) {\n    var xhr = event.currentTarget,\n        readyState = xhr.readyState,\n        stats = this.stats,\n        context = this.context,\n        config = this.config;\n\n    // don't proceed if xhr has been aborted\n    if (stats.aborted) return;\n\n    // >= HEADERS_RECEIVED\n    if (readyState >= 2) {\n      // clear xhr timeout and rearm it if readyState less than 4\n      window.clearTimeout(this.requestTimeout);\n      if (stats.tfirst === 0) stats.tfirst = Math.max(performance.now(), stats.trequest);\n\n      if (readyState === 4) {\n        var status = xhr.status;\n        // http status between 200 to 299 are all successful\n        if (status >= 200 && status < 300) {\n          stats.tload = Math.max(stats.tfirst, performance.now());\n          var data = void 0,\n              len = void 0;\n          if (context.responseType === 'arraybuffer') {\n            data = xhr.response;\n            len = data.byteLength;\n          } else {\n            data = xhr.responseText;\n            len = data.length;\n          }\n          stats.loaded = stats.total = len;\n          var response = { url: xhr.responseURL, data: data };\n          this.callbacks.onSuccess(response, stats, context, xhr);\n        } else {\n          // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error\n          if (stats.retry >= config.maxRetry || status >= 400 && status < 499) {\n            logger[\"b\" /* logger */].error(status + ' while loading ' + context.url);\n            this.callbacks.onError({ code: status, text: xhr.statusText }, context, xhr);\n          } else {\n            // retry\n            logger[\"b\" /* logger */].warn(status + ' while loading ' + context.url + ', retrying in ' + this.retryDelay + '...');\n            // aborts and resets internal state\n            this.destroy();\n            // schedule retry\n            this.retryTimeout = window.setTimeout(this.loadInternal.bind(this), this.retryDelay);\n            // set exponential backoff\n            this.retryDelay = Math.min(2 * this.retryDelay, config.maxRetryDelay);\n            stats.retry++;\n          }\n        }\n      } else {\n        // readyState >= 2 AND readyState !==4 (readyState = HEADERS_RECEIVED || LOADING) rearm timeout as xhr not finished yet\n        this.requestTimeout = window.setTimeout(this.loadtimeout.bind(this), config.timeout);\n      }\n    }\n  };\n\n  XhrLoader.prototype.loadtimeout = function loadtimeout() {\n    logger[\"b\" /* logger */].warn('timeout while loading ' + this.context.url);\n    this.callbacks.onTimeout(this.stats, this.context, null);\n  };\n\n  XhrLoader.prototype.loadprogress = function loadprogress(event) {\n    var xhr = event.currentTarget,\n        stats = this.stats;\n\n    stats.loaded = event.loaded;\n    if (event.lengthComputable) stats.total = event.total;\n\n    var onProgress = this.callbacks.onProgress;\n    if (onProgress) {\n      // third arg is to provide on progress data\n      onProgress(stats, this.context, null, xhr);\n    }\n  };\n\n  return XhrLoader;\n}();\n\n/* harmony default export */ var xhr_loader = (xhr_loader_XhrLoader);\n// CONCATENATED MODULE: ./src/controller/audio-track-controller.js\nvar audio_track_controller__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction audio_track_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction audio_track_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction audio_track_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * audio track controller\n*/\n\n\n\n\n\n\nvar audio_track_controller_AudioTrackController = function (_EventHandler) {\n  audio_track_controller__inherits(AudioTrackController, _EventHandler);\n\n  function AudioTrackController(hls) {\n    audio_track_controller__classCallCheck(this, AudioTrackController);\n\n    var _this = audio_track_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MANIFEST_LOADING, events[\"a\" /* default */].MANIFEST_PARSED, events[\"a\" /* default */].AUDIO_TRACK_LOADED, events[\"a\" /* default */].ERROR));\n\n    _this.ticks = 0;\n    _this.ontick = _this.tick.bind(_this);\n    return _this;\n  }\n\n  AudioTrackController.prototype.destroy = function destroy() {\n    this.cleanTimer();\n    event_handler.prototype.destroy.call(this);\n  };\n\n  AudioTrackController.prototype.cleanTimer = function cleanTimer() {\n    if (this.timer) {\n      clearTimeout(this.timer);\n      this.timer = null;\n    }\n  };\n\n  AudioTrackController.prototype.tick = function tick() {\n    this.ticks++;\n    if (this.ticks === 1) {\n      this.doTick();\n      if (this.ticks > 1) setTimeout(this.tick, 1);\n\n      this.ticks = 0;\n    }\n  };\n\n  AudioTrackController.prototype.doTick = function doTick() {\n    this.updateTrack(this.trackId);\n  };\n\n  AudioTrackController.prototype.onError = function onError(data) {\n    if (data.fatal && data.type === errors[\"b\" /* ErrorTypes */].NETWORK_ERROR) this.cleanTimer();\n  };\n\n  AudioTrackController.prototype.onManifestLoading = function onManifestLoading() {\n    // reset audio tracks on manifest loading\n    this.tracks = [];\n    this.trackId = -1;\n  };\n\n  AudioTrackController.prototype.onManifestParsed = function onManifestParsed(data) {\n    var _this2 = this;\n\n    var tracks = data.audioTracks || [];\n    var defaultFound = false;\n    this.tracks = tracks;\n    this.hls.trigger(events[\"a\" /* default */].AUDIO_TRACKS_UPDATED, { audioTracks: tracks });\n    // loop through available audio tracks and autoselect default if needed\n    var id = 0;\n    tracks.forEach(function (track) {\n      if (track.default && !defaultFound) {\n        _this2.audioTrack = id;\n        defaultFound = true;\n        return;\n      }\n      id++;\n    });\n    if (defaultFound === false && tracks.length) {\n      logger[\"b\" /* logger */].log('no default audio track defined, use first audio track as default');\n      this.audioTrack = 0;\n    }\n  };\n\n  AudioTrackController.prototype.onAudioTrackLoaded = function onAudioTrackLoaded(data) {\n    if (data.id < this.tracks.length) {\n      logger[\"b\" /* logger */].log('audioTrack ' + data.id + ' loaded');\n      this.tracks[data.id].details = data.details;\n      // check if current playlist is a live playlist\n      if (data.details.live && !this.timer) {\n        // if live playlist we will have to reload it periodically\n        // set reload period to playlist target duration\n        this.timer = setInterval(this.ontick, 1000 * data.details.targetduration);\n      }\n      if (!data.details.live && this.timer) {\n        // playlist is not live and timer is armed : stopping it\n        this.cleanTimer();\n      }\n    }\n  };\n\n  /** get alternate audio tracks list from playlist **/\n\n\n  AudioTrackController.prototype.setAudioTrackInternal = function setAudioTrackInternal(newId) {\n    // check if level idx is valid\n    if (newId >= 0 && newId < this.tracks.length) {\n      // stopping live reloading timer if any\n      this.cleanTimer();\n      this.trackId = newId;\n      logger[\"b\" /* logger */].log('switching to audioTrack ' + newId);\n      var audioTrack = this.tracks[newId],\n          hls = this.hls,\n          type = audioTrack.type,\n          url = audioTrack.url,\n          eventObj = { id: newId, type: type, url: url };\n      hls.trigger(events[\"a\" /* default */].AUDIO_TRACK_SWITCHING, eventObj);\n      // check if we need to load playlist for this audio Track\n      var details = audioTrack.details;\n      if (url && (details === undefined || details.live === true)) {\n        // track not retrieved yet, or live playlist we need to (re)load it\n        logger[\"b\" /* logger */].log('(re)loading playlist for audioTrack ' + newId);\n        hls.trigger(events[\"a\" /* default */].AUDIO_TRACK_LOADING, { url: url, id: newId });\n      }\n    }\n  };\n\n  AudioTrackController.prototype.updateTrack = function updateTrack(newId) {\n    // check if level idx is valid\n    if (newId >= 0 && newId < this.tracks.length) {\n      // stopping live reloading timer if any\n      this.cleanTimer();\n      this.trackId = newId;\n      logger[\"b\" /* logger */].log('updating audioTrack ' + newId);\n      var audioTrack = this.tracks[newId],\n          url = audioTrack.url;\n      // check if we need to load playlist for this audio Track\n      var details = audioTrack.details;\n      if (url && (details === undefined || details.live === true)) {\n        // track not retrieved yet, or live playlist we need to (re)load it\n        logger[\"b\" /* logger */].log('(re)loading playlist for audioTrack ' + newId);\n        this.hls.trigger(events[\"a\" /* default */].AUDIO_TRACK_LOADING, { url: url, id: newId });\n      }\n    }\n  };\n\n  audio_track_controller__createClass(AudioTrackController, [{\n    key: 'audioTracks',\n    get: function get() {\n      return this.tracks;\n    }\n\n    /** get index of the selected audio track (index in audio track lists) **/\n\n  }, {\n    key: 'audioTrack',\n    get: function get() {\n      return this.trackId;\n    }\n\n    /** select an audio track, based on its index in audio track lists**/\n    ,\n    set: function set(audioTrackId) {\n      if (this.trackId !== audioTrackId || this.tracks[audioTrackId].details === undefined) this.setAudioTrackInternal(audioTrackId);\n    }\n  }]);\n\n  return AudioTrackController;\n}(event_handler);\n\n/* harmony default export */ var audio_track_controller = (audio_track_controller_AudioTrackController);\n// CONCATENATED MODULE: ./src/controller/audio-stream-controller.js\nvar audio_stream_controller__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction audio_stream_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction audio_stream_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction audio_stream_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * Audio Stream Controller\n*/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar audio_stream_controller_State = {\n  STOPPED: 'STOPPED',\n  STARTING: 'STARTING',\n  IDLE: 'IDLE',\n  PAUSED: 'PAUSED',\n  KEY_LOADING: 'KEY_LOADING',\n  FRAG_LOADING: 'FRAG_LOADING',\n  FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',\n  WAITING_TRACK: 'WAITING_TRACK',\n  PARSING: 'PARSING',\n  PARSED: 'PARSED',\n  BUFFER_FLUSHING: 'BUFFER_FLUSHING',\n  ENDED: 'ENDED',\n  ERROR: 'ERROR',\n  WAITING_INIT_PTS: 'WAITING_INIT_PTS'\n};\n\nvar audio_stream_controller_AudioStreamController = function (_TaskLoop) {\n  audio_stream_controller__inherits(AudioStreamController, _TaskLoop);\n\n  function AudioStreamController(hls, fragmentTracker) {\n    audio_stream_controller__classCallCheck(this, AudioStreamController);\n\n    var _this = audio_stream_controller__possibleConstructorReturn(this, _TaskLoop.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHED, events[\"a\" /* default */].MEDIA_DETACHING, events[\"a\" /* default */].AUDIO_TRACKS_UPDATED, events[\"a\" /* default */].AUDIO_TRACK_SWITCHING, events[\"a\" /* default */].AUDIO_TRACK_LOADED, events[\"a\" /* default */].KEY_LOADED, events[\"a\" /* default */].FRAG_LOADED, events[\"a\" /* default */].FRAG_PARSING_INIT_SEGMENT, events[\"a\" /* default */].FRAG_PARSING_DATA, events[\"a\" /* default */].FRAG_PARSED, events[\"a\" /* default */].ERROR, events[\"a\" /* default */].BUFFER_RESET, events[\"a\" /* default */].BUFFER_CREATED, events[\"a\" /* default */].BUFFER_APPENDED, events[\"a\" /* default */].BUFFER_FLUSHED, events[\"a\" /* default */].INIT_PTS_FOUND));\n\n    _this.fragmentTracker = fragmentTracker;\n    _this.config = hls.config;\n    _this.audioCodecSwap = false;\n    _this._state = audio_stream_controller_State.STOPPED;\n    _this.initPTS = [];\n    _this.waitingFragment = null;\n    _this.videoTrackCC = null;\n    return _this;\n  }\n\n  AudioStreamController.prototype.onHandlerDestroying = function onHandlerDestroying() {\n    this.stopLoad();\n  };\n\n  AudioStreamController.prototype.onHandlerDestroyed = function onHandlerDestroyed() {\n    this.state = audio_stream_controller_State.STOPPED;\n    this.fragmentTracker = null;\n  };\n\n  // Signal that video PTS was found\n\n\n  AudioStreamController.prototype.onInitPtsFound = function onInitPtsFound(data) {\n    var demuxerId = data.id,\n        cc = data.frag.cc,\n        initPTS = data.initPTS;\n    if (demuxerId === 'main') {\n      // Always update the new INIT PTS\n      // Can change due level switch\n      this.initPTS[cc] = initPTS;\n      this.videoTrackCC = cc;\n      logger[\"b\" /* logger */].log('InitPTS for cc: ' + cc + ' found from video track: ' + initPTS);\n\n      // If we are waiting we need to demux/remux the waiting frag\n      // With the new initPTS\n      if (this.state === audio_stream_controller_State.WAITING_INIT_PTS) this.tick();\n    }\n  };\n\n  AudioStreamController.prototype.startLoad = function startLoad(startPosition) {\n    if (this.tracks) {\n      var lastCurrentTime = this.lastCurrentTime;\n      this.stopLoad();\n      this.setInterval(100);\n      this.fragLoadError = 0;\n      if (lastCurrentTime > 0 && startPosition === -1) {\n        logger[\"b\" /* logger */].log('audio:override startPosition with lastCurrentTime @' + lastCurrentTime.toFixed(3));\n        this.state = audio_stream_controller_State.IDLE;\n      } else {\n        this.lastCurrentTime = this.startPosition ? this.startPosition : startPosition;\n        this.state = audio_stream_controller_State.STARTING;\n      }\n      this.nextLoadPosition = this.startPosition = this.lastCurrentTime;\n      this.tick();\n    } else {\n      this.startPosition = startPosition;\n      this.state = audio_stream_controller_State.STOPPED;\n    }\n  };\n\n  AudioStreamController.prototype.stopLoad = function stopLoad() {\n    var frag = this.fragCurrent;\n    if (frag) {\n      if (frag.loader) frag.loader.abort();\n\n      this.fragmentTracker.removeFragment(frag);\n      this.fragCurrent = null;\n    }\n    this.fragPrevious = null;\n    if (this.demuxer) {\n      this.demuxer.destroy();\n      this.demuxer = null;\n    }\n    this.state = audio_stream_controller_State.STOPPED;\n  };\n\n  AudioStreamController.prototype.doTick = function doTick() {\n    var pos = void 0,\n        track = void 0,\n        trackDetails = void 0,\n        hls = this.hls,\n        config = hls.config;\n    // logger.log('audioStream:' + this.state);\n    switch (this.state) {\n      case audio_stream_controller_State.ERROR:\n      // don't do anything in error state to avoid breaking further ...\n      case audio_stream_controller_State.PAUSED:\n      // don't do anything in paused state either ...\n      case audio_stream_controller_State.BUFFER_FLUSHING:\n        break;\n      case audio_stream_controller_State.STARTING:\n        this.state = audio_stream_controller_State.WAITING_TRACK;\n        this.loadedmetadata = false;\n        break;\n      case audio_stream_controller_State.IDLE:\n        var tracks = this.tracks;\n        // audio tracks not received => exit loop\n        if (!tracks) break;\n\n        // if video not attached AND\n        // start fragment already requested OR start frag prefetch disable\n        // exit loop\n        // => if media not attached but start frag prefetch is enabled and start frag not requested yet, we will not exit loop\n        if (!this.media && (this.startFragRequested || !config.startFragPrefetch)) break;\n\n        // determine next candidate fragment to be loaded, based on current position and\n        //  end of buffer position\n        // if we have not yet loaded any fragment, start loading from start position\n        if (this.loadedmetadata) {\n          pos = this.media.currentTime;\n        } else {\n          pos = this.nextLoadPosition;\n          if (pos === undefined) break;\n        }\n        var media = this.mediaBuffer ? this.mediaBuffer : this.media,\n            videoBuffer = this.videoBuffer ? this.videoBuffer : this.media,\n            bufferInfo = buffer_helper.bufferInfo(media, pos, config.maxBufferHole),\n            mainBufferInfo = buffer_helper.bufferInfo(videoBuffer, pos, config.maxBufferHole),\n            bufferLen = bufferInfo.len,\n            bufferEnd = bufferInfo.end,\n            fragPrevious = this.fragPrevious,\n\n        // ensure we buffer at least config.maxBufferLength (default 30s) or config.maxMaxBufferLength (default: 600s)\n        // whichever is smaller.\n        // once we reach that threshold, don't buffer more than video (mainBufferInfo.len)\n        maxConfigBuffer = Math.min(config.maxBufferLength, config.maxMaxBufferLength),\n            maxBufLen = Math.max(maxConfigBuffer, mainBufferInfo.len),\n            audioSwitch = this.audioSwitch,\n            trackId = this.trackId;\n\n        // if buffer length is less than maxBufLen try to load a new fragment\n        if ((bufferLen < maxBufLen || audioSwitch) && trackId < tracks.length) {\n          trackDetails = tracks[trackId].details;\n          // if track info not retrieved yet, switch state and wait for track retrieval\n          if (typeof trackDetails === 'undefined') {\n            this.state = audio_stream_controller_State.WAITING_TRACK;\n            break;\n          }\n\n          // check if we need to finalize media stream\n          // we just got done loading the final fragment and there is no other buffered range after ...\n          // rationale is that in case there are any buffered ranges after, it means that there are unbuffered portion in between\n          // so we should not switch to ENDED in that case, to be able to buffer them\n          if (!audioSwitch && !trackDetails.live && fragPrevious && fragPrevious.sn === trackDetails.endSN && !bufferInfo.nextStart) {\n            // if we are not seeking or if we are seeking but everything (almost) til the end is buffered, let's signal eos\n            // we don't compare exactly media.duration === bufferInfo.end as there could be some subtle media duration difference when switching\n            // between different renditions. using half frag duration should help cope with these cases.\n            if (!this.media.seeking || this.media.duration - bufferEnd < fragPrevious.duration / 2) {\n              // Finalize the media stream\n              this.hls.trigger(events[\"a\" /* default */].BUFFER_EOS, { type: 'audio' });\n              this.state = audio_stream_controller_State.ENDED;\n              break;\n            }\n          }\n\n          // find fragment index, contiguous with end of buffer position\n          var fragments = trackDetails.fragments,\n              fragLen = fragments.length,\n              start = fragments[0].start,\n              end = fragments[fragLen - 1].start + fragments[fragLen - 1].duration,\n              frag = void 0;\n\n          // When switching audio track, reload audio as close as possible to currentTime\n          if (audioSwitch) {\n            if (trackDetails.live && !trackDetails.PTSKnown) {\n              logger[\"b\" /* logger */].log('switching audiotrack, live stream, unknown PTS,load first fragment');\n              bufferEnd = 0;\n            } else {\n              bufferEnd = pos;\n              // if currentTime (pos) is less than alt audio playlist start time, it means that alt audio is ahead of currentTime\n              if (trackDetails.PTSKnown && pos < start) {\n                // if everything is buffered from pos to start or if audio buffer upfront, let's seek to start\n                if (bufferInfo.end > start || bufferInfo.nextStart) {\n                  logger[\"b\" /* logger */].log('alt audio track ahead of main track, seek to start of alt audio track');\n                  this.media.currentTime = start + 0.05;\n                } else {\n                  return;\n                }\n              }\n            }\n          }\n          if (trackDetails.initSegment && !trackDetails.initSegment.data) {\n            frag = trackDetails.initSegment;\n          } // eslint-disable-line brace-style\n          // if bufferEnd before start of playlist, load first fragment\n          else if (bufferEnd <= start) {\n              frag = fragments[0];\n              if (this.videoTrackCC !== null && frag.cc !== this.videoTrackCC) {\n                // Ensure we find a fragment which matches the continuity of the video track\n                frag = findFragWithCC(fragments, this.videoTrackCC);\n              }\n              if (trackDetails.live && frag.loadIdx && frag.loadIdx === this.fragLoadIdx) {\n                // we just loaded this first fragment, and we are still lagging behind the start of the live playlist\n                // let's force seek to start\n                var nextBuffered = bufferInfo.nextStart ? bufferInfo.nextStart : start;\n                logger[\"b\" /* logger */].log('no alt audio available @currentTime:' + this.media.currentTime + ', seeking @' + (nextBuffered + 0.05));\n                this.media.currentTime = nextBuffered + 0.05;\n                return;\n              }\n            } else {\n              var foundFrag = void 0;\n              var maxFragLookUpTolerance = config.maxFragLookUpTolerance;\n              var fragNext = fragPrevious ? fragments[fragPrevious.sn - fragments[0].sn + 1] : undefined;\n              var fragmentWithinToleranceTest = function fragmentWithinToleranceTest(candidate) {\n                // offset should be within fragment boundary - config.maxFragLookUpTolerance\n                // this is to cope with situations like\n                // bufferEnd = 9.991\n                // frag[Ø] : [0,10]\n                // frag[1] : [10,20]\n                // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here\n                //              frag start               frag start+duration\n                //                  |-----------------------------|\n                //              <--->                         <--->\n                //  ...--------><-----------------------------><---------....\n                // previous frag         matching fragment         next frag\n                //  return -1             return 0                 return 1\n                // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);\n                // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments\n                var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration);\n                if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) return 1;\n                // if maxFragLookUpTolerance will have negative value then don't return -1 for first element\n                else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) return -1;\n\n                return 0;\n              };\n\n              if (bufferEnd < end) {\n                if (bufferEnd > end - maxFragLookUpTolerance) maxFragLookUpTolerance = 0;\n\n                // Prefer the next fragment if it's within tolerance\n                if (fragNext && !fragmentWithinToleranceTest(fragNext)) foundFrag = fragNext;else foundFrag = binary_search.search(fragments, fragmentWithinToleranceTest);\n              } else {\n                // reach end of playlist\n                foundFrag = fragments[fragLen - 1];\n              }\n              if (foundFrag) {\n                frag = foundFrag;\n                start = foundFrag.start;\n                // logger.log('find SN matching with pos:' +  bufferEnd + ':' + frag.sn);\n                if (fragPrevious && frag.level === fragPrevious.level && frag.sn === fragPrevious.sn) {\n                  if (frag.sn < trackDetails.endSN) {\n                    frag = fragments[frag.sn + 1 - trackDetails.startSN];\n                    logger[\"b\" /* logger */].log('SN just loaded, load next one: ' + frag.sn);\n                  } else {\n                    frag = null;\n                  }\n                }\n              }\n            }\n          if (frag) {\n            // logger.log('      loading frag ' + i +',pos/bufEnd:' + pos.toFixed(3) + '/' + bufferEnd.toFixed(3));\n            if (frag.decryptdata && frag.decryptdata.uri != null && frag.decryptdata.key == null) {\n              logger[\"b\" /* logger */].log('Loading key for ' + frag.sn + ' of [' + trackDetails.startSN + ' ,' + trackDetails.endSN + '],track ' + trackId);\n              this.state = audio_stream_controller_State.KEY_LOADING;\n              hls.trigger(events[\"a\" /* default */].KEY_LOADING, { frag: frag });\n            } else {\n              logger[\"b\" /* logger */].log('Loading ' + frag.sn + ', cc: ' + frag.cc + ' of [' + trackDetails.startSN + ' ,' + trackDetails.endSN + '],track ' + trackId + ', currentTime:' + pos + ',bufferEnd:' + bufferEnd.toFixed(3));\n              // Check if fragment is not loaded\n              if (this.fragmentTracker.getState(frag) === FragmentState.NOT_LOADED) {\n                this.fragCurrent = frag;\n                this.startFragRequested = true;\n                if (!isNaN(frag.sn)) this.nextLoadPosition = frag.start + frag.duration;\n\n                hls.trigger(events[\"a\" /* default */].FRAG_LOADING, { frag: frag });\n                this.state = audio_stream_controller_State.FRAG_LOADING;\n              }\n            }\n          }\n        }\n        break;\n      case audio_stream_controller_State.WAITING_TRACK:\n        track = this.tracks[this.trackId];\n        // check if playlist is already loaded\n        if (track && track.details) this.state = audio_stream_controller_State.IDLE;\n\n        break;\n      case audio_stream_controller_State.FRAG_LOADING_WAITING_RETRY:\n        var now = performance.now();\n        var retryDate = this.retryDate;\n        media = this.media;\n        var isSeeking = media && media.seeking;\n        // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\n        if (!retryDate || now >= retryDate || isSeeking) {\n          logger[\"b\" /* logger */].log('audioStreamController: retryDate reached, switch back to IDLE state');\n          this.state = audio_stream_controller_State.IDLE;\n        }\n        break;\n      case audio_stream_controller_State.WAITING_INIT_PTS:\n        var videoTrackCC = this.videoTrackCC;\n        if (this.initPTS[videoTrackCC] === undefined) break;\n\n        // Ensure we don't get stuck in the WAITING_INIT_PTS state if the waiting frag CC doesn't match any initPTS\n        var waitingFrag = this.waitingFragment;\n        if (waitingFrag) {\n          var waitingFragCC = waitingFrag.frag.cc;\n          if (videoTrackCC !== waitingFragCC) {\n            track = this.tracks[this.trackId];\n            if (track.details && track.details.live) {\n              logger[\"b\" /* logger */].warn('Waiting fragment CC (' + waitingFragCC + ') does not match video track CC (' + videoTrackCC + ')');\n              this.waitingFragment = null;\n              this.state = audio_stream_controller_State.IDLE;\n            }\n          } else {\n            this.state = audio_stream_controller_State.FRAG_LOADING;\n            this.onFragLoaded(this.waitingFragment);\n            this.waitingFragment = null;\n          }\n        } else {\n          this.state = audio_stream_controller_State.IDLE;\n        }\n\n        break;\n      case audio_stream_controller_State.STOPPED:\n      case audio_stream_controller_State.FRAG_LOADING:\n      case audio_stream_controller_State.PARSING:\n      case audio_stream_controller_State.PARSED:\n      case audio_stream_controller_State.ENDED:\n        break;\n      default:\n        break;\n    }\n  };\n\n  AudioStreamController.prototype.onMediaAttached = function onMediaAttached(data) {\n    var media = this.media = this.mediaBuffer = data.media;\n    this.onvseeking = this.onMediaSeeking.bind(this);\n    this.onvended = this.onMediaEnded.bind(this);\n    media.addEventListener('seeking', this.onvseeking);\n    media.addEventListener('ended', this.onvended);\n    var config = this.config;\n    if (this.tracks && config.autoStartLoad) this.startLoad(config.startPosition);\n  };\n\n  AudioStreamController.prototype.onMediaDetaching = function onMediaDetaching() {\n    var media = this.media;\n    if (media && media.ended) {\n      logger[\"b\" /* logger */].log('MSE detaching and video ended, reset startPosition');\n      this.startPosition = this.lastCurrentTime = 0;\n    }\n\n    // remove video listeners\n    if (media) {\n      media.removeEventListener('seeking', this.onvseeking);\n      media.removeEventListener('ended', this.onvended);\n      this.onvseeking = this.onvseeked = this.onvended = null;\n    }\n    this.media = this.mediaBuffer = this.videoBuffer = null;\n    this.loadedmetadata = false;\n    this.stopLoad();\n  };\n\n  AudioStreamController.prototype.onMediaSeeking = function onMediaSeeking() {\n    if (this.state === audio_stream_controller_State.ENDED) {\n      // switch to IDLE state to check for potential new fragment\n      this.state = audio_stream_controller_State.IDLE;\n    }\n    if (this.media) this.lastCurrentTime = this.media.currentTime;\n\n    // tick to speed up processing\n    this.tick();\n  };\n\n  AudioStreamController.prototype.onMediaEnded = function onMediaEnded() {\n    // reset startPosition and lastCurrentTime to restart playback @ stream beginning\n    this.startPosition = this.lastCurrentTime = 0;\n  };\n\n  AudioStreamController.prototype.onAudioTracksUpdated = function onAudioTracksUpdated(data) {\n    logger[\"b\" /* logger */].log('audio tracks updated');\n    this.tracks = data.audioTracks;\n  };\n\n  AudioStreamController.prototype.onAudioTrackSwitching = function onAudioTrackSwitching(data) {\n    // if any URL found on new audio track, it is an alternate audio track\n    var altAudio = !!data.url;\n    this.trackId = data.id;\n\n    this.fragCurrent = null;\n    this.state = audio_stream_controller_State.PAUSED;\n    this.waitingFragment = null;\n    // destroy useless demuxer when switching audio to main\n    if (!altAudio) {\n      if (this.demuxer) {\n        this.demuxer.destroy();\n        this.demuxer = null;\n      }\n    } else {\n      // switching to audio track, start timer if not already started\n      this.setInterval(100);\n    }\n\n    // should we switch tracks ?\n    if (altAudio) {\n      this.audioSwitch = true;\n      // main audio track are handled by stream-controller, just do something if switching to alt audio track\n      this.state = audio_stream_controller_State.IDLE;\n    }\n    this.tick();\n  };\n\n  AudioStreamController.prototype.onAudioTrackLoaded = function onAudioTrackLoaded(data) {\n    var newDetails = data.details,\n        trackId = data.id,\n        track = this.tracks[trackId],\n        duration = newDetails.totalduration,\n        sliding = 0;\n\n    logger[\"b\" /* logger */].log('track ' + trackId + ' loaded [' + newDetails.startSN + ',' + newDetails.endSN + '],duration:' + duration);\n\n    if (newDetails.live) {\n      var curDetails = track.details;\n      if (curDetails && newDetails.fragments.length > 0) {\n        // we already have details for that level, merge them\n        mergeDetails(curDetails, newDetails);\n        sliding = newDetails.fragments[0].start;\n        // TODO\n        // this.liveSyncPosition = this.computeLivePosition(sliding, curDetails);\n        if (newDetails.PTSKnown) logger[\"b\" /* logger */].log('live audio playlist sliding:' + sliding.toFixed(3));else logger[\"b\" /* logger */].log('live audio playlist - outdated PTS, unknown sliding');\n      } else {\n        newDetails.PTSKnown = false;\n        logger[\"b\" /* logger */].log('live audio playlist - first load, unknown sliding');\n      }\n    } else {\n      newDetails.PTSKnown = false;\n    }\n    track.details = newDetails;\n\n    // compute start position\n    if (!this.startFragRequested) {\n      // compute start position if set to -1. use it straight away if value is defined\n      if (this.startPosition === -1) {\n        // first, check if start time offset has been set in playlist, if yes, use this value\n        var startTimeOffset = newDetails.startTimeOffset;\n        if (!isNaN(startTimeOffset)) {\n          logger[\"b\" /* logger */].log('start time offset found in playlist, adjust startPosition to ' + startTimeOffset);\n          this.startPosition = startTimeOffset;\n        } else {\n          this.startPosition = 0;\n        }\n      }\n      this.nextLoadPosition = this.startPosition;\n    }\n    // only switch batck to IDLE state if we were waiting for track to start downloading a new fragment\n    if (this.state === audio_stream_controller_State.WAITING_TRACK) this.state = audio_stream_controller_State.IDLE;\n\n    // trigger handler right now\n    this.tick();\n  };\n\n  AudioStreamController.prototype.onKeyLoaded = function onKeyLoaded() {\n    if (this.state === audio_stream_controller_State.KEY_LOADING) {\n      this.state = audio_stream_controller_State.IDLE;\n      this.tick();\n    }\n  };\n\n  AudioStreamController.prototype.onFragLoaded = function onFragLoaded(data) {\n    var fragCurrent = this.fragCurrent,\n        fragLoaded = data.frag;\n    if (this.state === audio_stream_controller_State.FRAG_LOADING && fragCurrent && fragLoaded.type === 'audio' && fragLoaded.level === fragCurrent.level && fragLoaded.sn === fragCurrent.sn) {\n      var track = this.tracks[this.trackId],\n          details = track.details,\n          duration = details.totalduration,\n          trackId = fragCurrent.level,\n          sn = fragCurrent.sn,\n          cc = fragCurrent.cc,\n          audioCodec = this.config.defaultAudioCodec || track.audioCodec || 'mp4a.40.2',\n          stats = this.stats = data.stats;\n      if (sn === 'initSegment') {\n        this.state = audio_stream_controller_State.IDLE;\n\n        stats.tparsed = stats.tbuffered = performance.now();\n        details.initSegment.data = data.payload;\n        this.hls.trigger(events[\"a\" /* default */].FRAG_BUFFERED, { stats: stats, frag: fragCurrent, id: 'audio' });\n        this.tick();\n      } else {\n        this.state = audio_stream_controller_State.PARSING;\n        // transmux the MPEG-TS data to ISO-BMFF segments\n        this.appended = false;\n        if (!this.demuxer) this.demuxer = new demux_demuxer(this.hls, 'audio');\n\n        // Check if we have video initPTS\n        // If not we need to wait for it\n        var initPTS = this.initPTS[cc];\n        var initSegmentData = details.initSegment ? details.initSegment.data : [];\n        if (details.initSegment || initPTS !== undefined) {\n          this.pendingBuffering = true;\n          logger[\"b\" /* logger */].log('Demuxing ' + sn + ' of [' + details.startSN + ' ,' + details.endSN + '],track ' + trackId);\n          // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)\n          var accurateTimeOffset = false; // details.PTSKnown || !details.live;\n          this.demuxer.push(data.payload, initSegmentData, audioCodec, null, fragCurrent, duration, accurateTimeOffset, initPTS);\n        } else {\n          logger[\"b\" /* logger */].log('unknown video PTS for continuity counter ' + cc + ', waiting for video PTS before demuxing audio frag ' + sn + ' of [' + details.startSN + ' ,' + details.endSN + '],track ' + trackId);\n          this.waitingFragment = data;\n          this.state = audio_stream_controller_State.WAITING_INIT_PTS;\n        }\n      }\n    }\n    this.fragLoadError = 0;\n  };\n\n  AudioStreamController.prototype.onFragParsingInitSegment = function onFragParsingInitSegment(data) {\n    var fragCurrent = this.fragCurrent;\n    var fragNew = data.frag;\n    if (fragCurrent && data.id === 'audio' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === audio_stream_controller_State.PARSING) {\n      var tracks = data.tracks,\n          track = void 0;\n\n      // delete any video track found on audio demuxer\n      if (tracks.video) delete tracks.video;\n\n      // include levelCodec in audio and video tracks\n      track = tracks.audio;\n      if (track) {\n        track.levelCodec = track.codec;\n        track.id = data.id;\n        this.hls.trigger(events[\"a\" /* default */].BUFFER_CODECS, tracks);\n        logger[\"b\" /* logger */].log('audio track:audio,container:' + track.container + ',codecs[level/parsed]=[' + track.levelCodec + '/' + track.codec + ']');\n        var initSegment = track.initSegment;\n        if (initSegment) {\n          var appendObj = { type: 'audio', data: initSegment, parent: 'audio', content: 'initSegment' };\n          if (this.audioSwitch) {\n            this.pendingData = [appendObj];\n          } else {\n            this.appended = true;\n            // arm pending Buffering flag before appending a segment\n            this.pendingBuffering = true;\n            this.hls.trigger(events[\"a\" /* default */].BUFFER_APPENDING, appendObj);\n          }\n        }\n        // trigger handler right now\n        this.tick();\n      }\n    }\n  };\n\n  AudioStreamController.prototype.onFragParsingData = function onFragParsingData(data) {\n    var _this2 = this;\n\n    var fragCurrent = this.fragCurrent;\n    var fragNew = data.frag;\n    if (fragCurrent && data.id === 'audio' && data.type === 'audio' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === audio_stream_controller_State.PARSING) {\n      var trackId = this.trackId,\n          track = this.tracks[trackId],\n          hls = this.hls;\n\n      if (isNaN(data.endPTS)) {\n        data.endPTS = data.startPTS + fragCurrent.duration;\n        data.endDTS = data.startDTS + fragCurrent.duration;\n      }\n\n      fragCurrent.addElementaryStream(loader_fragment.ElementaryStreamTypes.AUDIO);\n\n      logger[\"b\" /* logger */].log('parsed ' + data.type + ',PTS:[' + data.startPTS.toFixed(3) + ',' + data.endPTS.toFixed(3) + '],DTS:[' + data.startDTS.toFixed(3) + '/' + data.endDTS.toFixed(3) + '],nb:' + data.nb);\n      updateFragPTSDTS(track.details, fragCurrent, data.startPTS, data.endPTS);\n\n      var audioSwitch = this.audioSwitch,\n          media = this.media,\n          appendOnBufferFlush = false;\n      // Only flush audio from old audio tracks when PTS is known on new audio track\n      if (audioSwitch && media) {\n        if (media.readyState) {\n          var currentTime = media.currentTime;\n          logger[\"b\" /* logger */].log('switching audio track : currentTime:' + currentTime);\n          if (currentTime >= data.startPTS) {\n            logger[\"b\" /* logger */].log('switching audio track : flushing all audio');\n            this.state = audio_stream_controller_State.BUFFER_FLUSHING;\n            hls.trigger(events[\"a\" /* default */].BUFFER_FLUSHING, { startOffset: 0, endOffset: Number.POSITIVE_INFINITY, type: 'audio' });\n            appendOnBufferFlush = true;\n            // Lets announce that the initial audio track switch flush occur\n            this.audioSwitch = false;\n            hls.trigger(events[\"a\" /* default */].AUDIO_TRACK_SWITCHED, { id: trackId });\n          }\n        } else {\n          // Lets announce that the initial audio track switch flush occur\n          this.audioSwitch = false;\n          hls.trigger(events[\"a\" /* default */].AUDIO_TRACK_SWITCHED, { id: trackId });\n        }\n      }\n\n      var pendingData = this.pendingData;\n\n      if (!pendingData) {\n        console.warn('Apparently attempt to enqueue media payload without codec initialization data upfront');\n        hls.trigger(events[\"a\" /* default */].ERROR, { type: errors[\"b\" /* ErrorTypes */].MEDIA_ERROR, details: null, fatal: true });\n        return;\n      }\n\n      if (!this.audioSwitch) {\n        [data.data1, data.data2].forEach(function (buffer) {\n          if (buffer && buffer.length) pendingData.push({ type: data.type, data: buffer, parent: 'audio', content: 'data' });\n        });\n        if (!appendOnBufferFlush && pendingData.length) {\n          pendingData.forEach(function (appendObj) {\n            // only append in PARSING state (rationale is that an appending error could happen synchronously on first segment appending)\n            // in that case it is useless to append following segments\n            if (_this2.state === audio_stream_controller_State.PARSING) {\n              // arm pending Buffering flag before appending a segment\n              _this2.pendingBuffering = true;\n              _this2.hls.trigger(events[\"a\" /* default */].BUFFER_APPENDING, appendObj);\n            }\n          });\n          this.pendingData = [];\n          this.appended = true;\n        }\n      }\n      // trigger handler right now\n      this.tick();\n    }\n  };\n\n  AudioStreamController.prototype.onFragParsed = function onFragParsed(data) {\n    var fragCurrent = this.fragCurrent;\n    var fragNew = data.frag;\n    if (fragCurrent && data.id === 'audio' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === audio_stream_controller_State.PARSING) {\n      this.stats.tparsed = performance.now();\n      this.state = audio_stream_controller_State.PARSED;\n      this._checkAppendedParsed();\n    }\n  };\n\n  AudioStreamController.prototype.onBufferReset = function onBufferReset() {\n    // reset reference to sourcebuffers\n    this.mediaBuffer = this.videoBuffer = null;\n    this.loadedmetadata = false;\n  };\n\n  AudioStreamController.prototype.onBufferCreated = function onBufferCreated(data) {\n    var audioTrack = data.tracks.audio;\n    if (audioTrack) {\n      this.mediaBuffer = audioTrack.buffer;\n      this.loadedmetadata = true;\n    }\n    if (data.tracks.video) this.videoBuffer = data.tracks.video.buffer;\n  };\n\n  AudioStreamController.prototype.onBufferAppended = function onBufferAppended(data) {\n    if (data.parent === 'audio') {\n      var state = this.state;\n      if (state === audio_stream_controller_State.PARSING || state === audio_stream_controller_State.PARSED) {\n        // check if all buffers have been appended\n        this.pendingBuffering = data.pending > 0;\n        this._checkAppendedParsed();\n      }\n    }\n  };\n\n  AudioStreamController.prototype._checkAppendedParsed = function _checkAppendedParsed() {\n    // trigger handler right now\n    if (this.state === audio_stream_controller_State.PARSED && (!this.appended || !this.pendingBuffering)) {\n      var frag = this.fragCurrent,\n          stats = this.stats,\n          hls = this.hls;\n      if (frag) {\n        this.fragPrevious = frag;\n        stats.tbuffered = performance.now();\n        hls.trigger(events[\"a\" /* default */].FRAG_BUFFERED, { stats: stats, frag: frag, id: 'audio' });\n        var media = this.mediaBuffer ? this.mediaBuffer : this.media;\n        logger[\"b\" /* logger */].log('audio buffered : ' + time_ranges.toString(media.buffered));\n        if (this.audioSwitch && this.appended) {\n          this.audioSwitch = false;\n          hls.trigger(events[\"a\" /* default */].AUDIO_TRACK_SWITCHED, { id: this.trackId });\n        }\n        this.state = audio_stream_controller_State.IDLE;\n      }\n      this.tick();\n    }\n  };\n\n  AudioStreamController.prototype.onError = function onError(data) {\n    var frag = data.frag;\n    // don't handle frag error not related to audio fragment\n    if (frag && frag.type !== 'audio') return;\n\n    switch (data.details) {\n      case errors[\"a\" /* ErrorDetails */].FRAG_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].FRAG_LOAD_TIMEOUT:\n        if (!data.fatal) {\n          var loadError = this.fragLoadError;\n          if (loadError) loadError++;else loadError = 1;\n\n          var config = this.config;\n          if (loadError <= config.fragLoadingMaxRetry) {\n            this.fragLoadError = loadError;\n            // exponential backoff capped to config.fragLoadingMaxRetryTimeout\n            var delay = Math.min(Math.pow(2, loadError - 1) * config.fragLoadingRetryDelay, config.fragLoadingMaxRetryTimeout);\n            logger[\"b\" /* logger */].warn('audioStreamController: frag loading failed, retry in ' + delay + ' ms');\n            this.retryDate = performance.now() + delay;\n            // retry loading state\n            this.state = audio_stream_controller_State.FRAG_LOADING_WAITING_RETRY;\n          } else {\n            logger[\"b\" /* logger */].error('audioStreamController: ' + data.details + ' reaches max retry, redispatch as fatal ...');\n            // switch error to fatal\n            data.fatal = true;\n            this.state = audio_stream_controller_State.ERROR;\n          }\n        }\n        break;\n      case errors[\"a\" /* ErrorDetails */].AUDIO_TRACK_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].AUDIO_TRACK_LOAD_TIMEOUT:\n      case errors[\"a\" /* ErrorDetails */].KEY_LOAD_ERROR:\n      case errors[\"a\" /* ErrorDetails */].KEY_LOAD_TIMEOUT:\n        //  when in ERROR state, don't switch back to IDLE state in case a non-fatal error is received\n        if (this.state !== audio_stream_controller_State.ERROR) {\n          // if fatal error, stop processing, otherwise move to IDLE to retry loading\n          this.state = data.fatal ? audio_stream_controller_State.ERROR : audio_stream_controller_State.IDLE;\n          logger[\"b\" /* logger */].warn('audioStreamController: ' + data.details + ' while loading frag,switch to ' + this.state + ' state ...');\n        }\n        break;\n      case errors[\"a\" /* ErrorDetails */].BUFFER_FULL_ERROR:\n        // if in appending state\n        if (data.parent === 'audio' && (this.state === audio_stream_controller_State.PARSING || this.state === audio_stream_controller_State.PARSED)) {\n          var media = this.mediaBuffer,\n              currentTime = this.media.currentTime,\n              mediaBuffered = media && buffer_helper.isBuffered(media, currentTime) && buffer_helper.isBuffered(media, currentTime + 0.5);\n          // reduce max buf len if current position is buffered\n          if (mediaBuffered) {\n            var _config = this.config;\n            if (_config.maxMaxBufferLength >= _config.maxBufferLength) {\n              // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...\n              _config.maxMaxBufferLength /= 2;\n              logger[\"b\" /* logger */].warn('audio:reduce max buffer length to ' + _config.maxMaxBufferLength + 's');\n            }\n            this.state = audio_stream_controller_State.IDLE;\n          } else {\n            // current position is not buffered, but browser is still complaining about buffer full error\n            // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708\n            // in that case flush the whole audio buffer to recover\n            logger[\"b\" /* logger */].warn('buffer full error also media.currentTime is not buffered, flush audio buffer');\n            this.fragCurrent = null;\n            // flush everything\n            this.state = audio_stream_controller_State.BUFFER_FLUSHING;\n            this.hls.trigger(events[\"a\" /* default */].BUFFER_FLUSHING, { startOffset: 0, endOffset: Number.POSITIVE_INFINITY, type: 'audio' });\n          }\n        }\n        break;\n      default:\n        break;\n    }\n  };\n\n  AudioStreamController.prototype.onBufferFlushed = function onBufferFlushed() {\n    var _this3 = this;\n\n    var pendingData = this.pendingData;\n    if (pendingData && pendingData.length) {\n      logger[\"b\" /* logger */].log('appending pending audio data on Buffer Flushed');\n      pendingData.forEach(function (appendObj) {\n        _this3.hls.trigger(events[\"a\" /* default */].BUFFER_APPENDING, appendObj);\n      });\n      this.appended = true;\n      this.pendingData = [];\n      this.state = audio_stream_controller_State.PARSED;\n    } else {\n      // move to IDLE once flush complete. this should trigger new fragment loading\n      this.state = audio_stream_controller_State.IDLE;\n      // reset reference to frag\n      this.fragPrevious = null;\n      this.tick();\n    }\n  };\n\n  audio_stream_controller__createClass(AudioStreamController, [{\n    key: 'state',\n    set: function set(nextState) {\n      if (this.state !== nextState) {\n        var previousState = this.state;\n        this._state = nextState;\n        logger[\"b\" /* logger */].log('audio stream:' + previousState + '->' + nextState);\n      }\n    },\n    get: function get() {\n      return this._state;\n    }\n  }]);\n\n  return AudioStreamController;\n}(task_loop);\n\n/* harmony default export */ var audio_stream_controller = (audio_stream_controller_AudioStreamController);\n// CONCATENATED MODULE: ./src/utils/vttcue.js\n/**\n * Copyright 2013 vtt.js Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/* harmony default export */ var vttcue = ((function () {\n  if (typeof window !== 'undefined' && window.VTTCue) return window.VTTCue;\n\n  var autoKeyword = 'auto';\n  var directionSetting = {\n    '': true,\n    lr: true,\n    rl: true\n  };\n  var alignSetting = {\n    start: true,\n    middle: true,\n    end: true,\n    left: true,\n    right: true\n  };\n\n  function findDirectionSetting(value) {\n    if (typeof value !== 'string') return false;\n\n    var dir = directionSetting[value.toLowerCase()];\n    return dir ? value.toLowerCase() : false;\n  }\n\n  function findAlignSetting(value) {\n    if (typeof value !== 'string') return false;\n\n    var align = alignSetting[value.toLowerCase()];\n    return align ? value.toLowerCase() : false;\n  }\n\n  function extend(obj) {\n    var i = 1;\n    for (; i < arguments.length; i++) {\n      var cobj = arguments[i];\n      for (var p in cobj) {\n        obj[p] = cobj[p];\n      }\n    }\n\n    return obj;\n  }\n\n  function VTTCue(startTime, endTime, text) {\n    var cue = this;\n    var isIE8 = function () {\n      if (typeof navigator === 'undefined') return;\n\n      return (/MSIE\\s8\\.0/.test(navigator.userAgent)\n      );\n    }();\n    var baseObj = {};\n\n    if (isIE8) cue = document.createElement('custom');else baseObj.enumerable = true;\n\n    /**\n     * Shim implementation specific properties. These properties are not in\n     * the spec.\n     */\n\n    // Lets us know when the VTTCue's data has changed in such a way that we need\n    // to recompute its display state. This lets us compute its display state\n    // lazily.\n    cue.hasBeenReset = false;\n\n    /**\n     * VTTCue and TextTrackCue properties\n     * http://dev.w3.org/html5/webvtt/#vttcue-interface\n     */\n\n    var _id = '';\n    var _pauseOnExit = false;\n    var _startTime = startTime;\n    var _endTime = endTime;\n    var _text = text;\n    var _region = null;\n    var _vertical = '';\n    var _snapToLines = true;\n    var _line = 'auto';\n    var _lineAlign = 'start';\n    var _position = 50;\n    var _positionAlign = 'middle';\n    var _size = 50;\n    var _align = 'middle';\n\n    Object.defineProperty(cue, 'id', extend({}, baseObj, {\n      get: function get() {\n        return _id;\n      },\n      set: function set(value) {\n        _id = '' + value;\n      }\n    }));\n\n    Object.defineProperty(cue, 'pauseOnExit', extend({}, baseObj, {\n      get: function get() {\n        return _pauseOnExit;\n      },\n      set: function set(value) {\n        _pauseOnExit = !!value;\n      }\n    }));\n\n    Object.defineProperty(cue, 'startTime', extend({}, baseObj, {\n      get: function get() {\n        return _startTime;\n      },\n      set: function set(value) {\n        if (typeof value !== 'number') throw new TypeError('Start time must be set to a number.');\n\n        _startTime = value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'endTime', extend({}, baseObj, {\n      get: function get() {\n        return _endTime;\n      },\n      set: function set(value) {\n        if (typeof value !== 'number') throw new TypeError('End time must be set to a number.');\n\n        _endTime = value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'text', extend({}, baseObj, {\n      get: function get() {\n        return _text;\n      },\n      set: function set(value) {\n        _text = '' + value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'region', extend({}, baseObj, {\n      get: function get() {\n        return _region;\n      },\n      set: function set(value) {\n        _region = value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'vertical', extend({}, baseObj, {\n      get: function get() {\n        return _vertical;\n      },\n      set: function set(value) {\n        var setting = findDirectionSetting(value);\n        // Have to check for false because the setting an be an empty string.\n        if (setting === false) throw new SyntaxError('An invalid or illegal string was specified.');\n\n        _vertical = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'snapToLines', extend({}, baseObj, {\n      get: function get() {\n        return _snapToLines;\n      },\n      set: function set(value) {\n        _snapToLines = !!value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'line', extend({}, baseObj, {\n      get: function get() {\n        return _line;\n      },\n      set: function set(value) {\n        if (typeof value !== 'number' && value !== autoKeyword) throw new SyntaxError('An invalid number or illegal string was specified.');\n\n        _line = value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'lineAlign', extend({}, baseObj, {\n      get: function get() {\n        return _lineAlign;\n      },\n      set: function set(value) {\n        var setting = findAlignSetting(value);\n        if (!setting) throw new SyntaxError('An invalid or illegal string was specified.');\n\n        _lineAlign = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'position', extend({}, baseObj, {\n      get: function get() {\n        return _position;\n      },\n      set: function set(value) {\n        if (value < 0 || value > 100) throw new Error('Position must be between 0 and 100.');\n\n        _position = value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'positionAlign', extend({}, baseObj, {\n      get: function get() {\n        return _positionAlign;\n      },\n      set: function set(value) {\n        var setting = findAlignSetting(value);\n        if (!setting) throw new SyntaxError('An invalid or illegal string was specified.');\n\n        _positionAlign = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'size', extend({}, baseObj, {\n      get: function get() {\n        return _size;\n      },\n      set: function set(value) {\n        if (value < 0 || value > 100) throw new Error('Size must be between 0 and 100.');\n\n        _size = value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    Object.defineProperty(cue, 'align', extend({}, baseObj, {\n      get: function get() {\n        return _align;\n      },\n      set: function set(value) {\n        var setting = findAlignSetting(value);\n        if (!setting) throw new SyntaxError('An invalid or illegal string was specified.');\n\n        _align = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    /**\n     * Other <track> spec defined properties\n     */\n\n    // http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#text-track-cue-display-state\n    cue.displayState = undefined;\n\n    if (isIE8) return cue;\n  }\n\n  /**\n   * VTTCue methods\n   */\n\n  VTTCue.prototype.getCueAsHTML = function () {\n    // Assume WebVTT.convertCueToDOMTree is on the global.\n    var WebVTT = window.WebVTT;\n    return WebVTT.convertCueToDOMTree(window, this.text);\n  };\n\n  return VTTCue;\n})());\n// CONCATENATED MODULE: ./src/utils/vttparser.js\n/*\n * Source: https://github.com/mozilla/vtt.js/blob/master/dist/vtt.js#L1716\n */\n\n\n\nvar StringDecoder = function StringDecoder() {\n  return {\n    decode: function decode(data) {\n      if (!data) return '';\n\n      if (typeof data !== 'string') throw new Error('Error - expected string data.');\n\n      return decodeURIComponent(encodeURIComponent(data));\n    }\n  };\n};\n\nfunction VTTParser() {\n  this.window = window;\n  this.state = 'INITIAL';\n  this.buffer = '';\n  this.decoder = new StringDecoder();\n  this.regionList = [];\n}\n\n// Try to parse input as a time stamp.\nfunction parseTimeStamp(input) {\n  function computeSeconds(h, m, s, f) {\n    return (h | 0) * 3600 + (m | 0) * 60 + (s | 0) + (f | 0) / 1000;\n  }\n\n  var m = input.match(/^(\\d+):(\\d{2})(:\\d{2})?\\.(\\d{3})/);\n  if (!m) return null;\n\n  if (m[3]) {\n    // Timestamp takes the form of [hours]:[minutes]:[seconds].[milliseconds]\n    return computeSeconds(m[1], m[2], m[3].replace(':', ''), m[4]);\n  } else if (m[1] > 59) {\n    // Timestamp takes the form of [hours]:[minutes].[milliseconds]\n    // First position is hours as it's over 59.\n    return computeSeconds(m[1], m[2], 0, m[4]);\n  } else {\n    // Timestamp takes the form of [minutes]:[seconds].[milliseconds]\n    return computeSeconds(0, m[1], m[2], m[4]);\n  }\n}\n\n// A settings object holds key/value pairs and will ignore anything but the first\n// assignment to a specific key.\nfunction Settings() {\n  this.values = Object.create(null);\n}\n\nSettings.prototype = {\n  // Only accept the first assignment to any key.\n  set: function set(k, v) {\n    if (!this.get(k) && v !== '') this.values[k] = v;\n  },\n  // Return the value for a key, or a default value.\n  // If 'defaultKey' is passed then 'dflt' is assumed to be an object with\n  // a number of possible default values as properties where 'defaultKey' is\n  // the key of the property that will be chosen; otherwise it's assumed to be\n  // a single value.\n  get: function get(k, dflt, defaultKey) {\n    if (defaultKey) return this.has(k) ? this.values[k] : dflt[defaultKey];\n\n    return this.has(k) ? this.values[k] : dflt;\n  },\n  // Check whether we have a value for a key.\n  has: function has(k) {\n    return k in this.values;\n  },\n  // Accept a setting if its one of the given alternatives.\n  alt: function alt(k, v, a) {\n    for (var n = 0; n < a.length; ++n) {\n      if (v === a[n]) {\n        this.set(k, v);\n        break;\n      }\n    }\n  },\n  // Accept a setting if its a valid (signed) integer.\n  integer: function integer(k, v) {\n    if (/^-?\\d+$/.test(v)) {\n      // integer\n      this.set(k, parseInt(v, 10));\n    }\n  },\n  // Accept a setting if its a valid percentage.\n  percent: function percent(k, v) {\n    var m = void 0;\n    if (m = v.match(/^([\\d]{1,3})(\\.[\\d]*)?%$/)) {\n      v = parseFloat(v);\n      if (v >= 0 && v <= 100) {\n        this.set(k, v);\n        return true;\n      }\n    }\n    return false;\n  }\n};\n\n// Helper function to parse input into groups separated by 'groupDelim', and\n// interprete each group as a key/value pair separated by 'keyValueDelim'.\nfunction parseOptions(input, callback, keyValueDelim, groupDelim) {\n  var groups = groupDelim ? input.split(groupDelim) : [input];\n  for (var i in groups) {\n    if (typeof groups[i] !== 'string') continue;\n\n    var kv = groups[i].split(keyValueDelim);\n    if (kv.length !== 2) continue;\n\n    var k = kv[0];\n    var v = kv[1];\n    callback(k, v);\n  }\n}\n\nvar defaults = new vttcue(0, 0, 0);\n// 'middle' was changed to 'center' in the spec: https://github.com/w3c/webvtt/pull/244\n//  Safari doesn't yet support this change, but FF and Chrome do.\nvar center = defaults.align === 'middle' ? 'middle' : 'center';\n\nfunction parseCue(input, cue, regionList) {\n  // Remember the original input if we need to throw an error.\n  var oInput = input;\n  // 4.1 WebVTT timestamp\n  function consumeTimeStamp() {\n    var ts = parseTimeStamp(input);\n    if (ts === null) throw new Error('Malformed timestamp: ' + oInput);\n\n    // Remove time stamp from input.\n    input = input.replace(/^[^\\sa-zA-Z-]+/, '');\n    return ts;\n  }\n\n  // 4.4.2 WebVTT cue settings\n  function consumeCueSettings(input, cue) {\n    var settings = new Settings();\n\n    parseOptions(input, function (k, v) {\n      switch (k) {\n        case 'region':\n          // Find the last region we parsed with the same region id.\n          for (var i = regionList.length - 1; i >= 0; i--) {\n            if (regionList[i].id === v) {\n              settings.set(k, regionList[i].region);\n              break;\n            }\n          }\n          break;\n        case 'vertical':\n          settings.alt(k, v, ['rl', 'lr']);\n          break;\n        case 'line':\n          var vals = v.split(','),\n              vals0 = vals[0];\n          settings.integer(k, vals0);\n          if (settings.percent(k, vals0)) settings.set('snapToLines', false);\n\n          settings.alt(k, vals0, ['auto']);\n          if (vals.length === 2) settings.alt('lineAlign', vals[1], ['start', center, 'end']);\n\n          break;\n        case 'position':\n          vals = v.split(',');\n          settings.percent(k, vals[0]);\n          if (vals.length === 2) settings.alt('positionAlign', vals[1], ['start', center, 'end', 'line-left', 'line-right', 'auto']);\n\n          break;\n        case 'size':\n          settings.percent(k, v);\n          break;\n        case 'align':\n          settings.alt(k, v, ['start', center, 'end', 'left', 'right']);\n          break;\n      }\n    }, /:/, /\\s/);\n\n    // Apply default values for any missing fields.\n    cue.region = settings.get('region', null);\n    cue.vertical = settings.get('vertical', '');\n    var line = settings.get('line', 'auto');\n    if (line === 'auto' && defaults.line === -1) {\n      // set numeric line number for Safari\n      line = -1;\n    }\n    cue.line = line;\n    cue.lineAlign = settings.get('lineAlign', 'start');\n    cue.snapToLines = settings.get('snapToLines', true);\n    cue.size = settings.get('size', 100);\n    cue.align = settings.get('align', center);\n    var position = settings.get('position', 'auto');\n    if (position === 'auto' && defaults.position === 50) {\n      // set numeric position for Safari\n      position = cue.align === 'start' || cue.align === 'left' ? 0 : cue.align === 'end' || cue.align === 'right' ? 100 : 50;\n    }\n    cue.position = position;\n  }\n\n  function skipWhitespace() {\n    input = input.replace(/^\\s+/, '');\n  }\n\n  // 4.1 WebVTT cue timings.\n  skipWhitespace();\n  cue.startTime = consumeTimeStamp(); // (1) collect cue start time\n  skipWhitespace();\n  if (input.substr(0, 3) !== '-->') {\n    // (3) next characters must match '-->'\n    throw new Error('Malformed time stamp (time stamps must be separated by \\'-->\\'): ' + oInput);\n  }\n  input = input.substr(3);\n  skipWhitespace();\n  cue.endTime = consumeTimeStamp(); // (5) collect cue end time\n\n  // 4.1 WebVTT cue settings list.\n  skipWhitespace();\n  consumeCueSettings(input, cue);\n}\n\nfunction fixLineBreaks(input) {\n  return input.replace(/<br(?: \\/)?>/gi, '\\n');\n}\n\nVTTParser.prototype = {\n  parse: function parse(data) {\n    var self = this;\n\n    // If there is no data then we won't decode it, but will just try to parse\n    // whatever is in buffer already. This may occur in circumstances, for\n    // example when flush() is called.\n    if (data) {\n      // Try to decode the data that we received.\n      self.buffer += self.decoder.decode(data, { stream: true });\n    }\n\n    function collectNextLine() {\n      var buffer = self.buffer;\n      var pos = 0;\n\n      buffer = fixLineBreaks(buffer);\n\n      while (pos < buffer.length && buffer[pos] !== '\\r' && buffer[pos] !== '\\n') {\n        ++pos;\n      }var line = buffer.substr(0, pos);\n      // Advance the buffer early in case we fail below.\n      if (buffer[pos] === '\\r') ++pos;\n\n      if (buffer[pos] === '\\n') ++pos;\n\n      self.buffer = buffer.substr(pos);\n      return line;\n    }\n\n    // 3.2 WebVTT metadata header syntax\n    function parseHeader(input) {\n      parseOptions(input, function (k, v) {\n        switch (k) {\n          case 'Region':\n            // 3.3 WebVTT region metadata header syntax\n            console.log('parse region', v);\n            // parseRegion(v);\n            break;\n        }\n      }, /:/);\n    }\n\n    // 5.1 WebVTT file parsing.\n    try {\n      var line = void 0;\n      if (self.state === 'INITIAL') {\n        // We can't start parsing until we have the first line.\n        if (!/\\r\\n|\\n/.test(self.buffer)) return this;\n\n        line = collectNextLine();\n        // strip of UTF-8 BOM if any\n        // https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8\n        var m = line.match(/^(ï»¿)?WEBVTT([ \\t].*)?$/);\n        if (!m || !m[0]) throw new Error('Malformed WebVTT signature.');\n\n        self.state = 'HEADER';\n      }\n\n      var alreadyCollectedLine = false;\n      while (self.buffer) {\n        // We can't parse a line until we have the full line.\n        if (!/\\r\\n|\\n/.test(self.buffer)) return this;\n\n        if (!alreadyCollectedLine) line = collectNextLine();else alreadyCollectedLine = false;\n\n        switch (self.state) {\n          case 'HEADER':\n            // 13-18 - Allow a header (metadata) under the WEBVTT line.\n            if (/:/.test(line)) {\n              parseHeader(line);\n            } else if (!line) {\n              // An empty line terminates the header and starts the body (cues).\n              self.state = 'ID';\n            }\n            continue;\n          case 'NOTE':\n            // Ignore NOTE blocks.\n            if (!line) self.state = 'ID';\n\n            continue;\n          case 'ID':\n            // Check for the start of NOTE blocks.\n            if (/^NOTE($|[ \\t])/.test(line)) {\n              self.state = 'NOTE';\n              break;\n            }\n            // 19-29 - Allow any number of line terminators, then initialize new cue values.\n            if (!line) continue;\n\n            self.cue = new vttcue(0, 0, '');\n            self.state = 'CUE';\n            // 30-39 - Check if self line contains an optional identifier or timing data.\n            if (line.indexOf('-->') === -1) {\n              self.cue.id = line;\n              continue;\n            }\n          // Process line as start of a cue.\n          /* falls through */\n          case 'CUE':\n            // 40 - Collect cue timings and settings.\n            try {\n              parseCue(line, self.cue, self.regionList);\n            } catch (e) {\n              // In case of an error ignore rest of the cue.\n              self.cue = null;\n              self.state = 'BADCUE';\n              continue;\n            }\n            self.state = 'CUETEXT';\n            continue;\n          case 'CUETEXT':\n            var hasSubstring = line.indexOf('-->') !== -1;\n            // 34 - If we have an empty line then report the cue.\n            // 35 - If we have the special substring '-->' then report the cue,\n            // but do not collect the line as we need to process the current\n            // one as a new cue.\n            if (!line || hasSubstring && (alreadyCollectedLine = true)) {\n              // We are done parsing self cue.\n              if (self.oncue) self.oncue(self.cue);\n\n              self.cue = null;\n              self.state = 'ID';\n              continue;\n            }\n            if (self.cue.text) self.cue.text += '\\n';\n\n            self.cue.text += line;\n            continue;\n          case 'BADCUE':\n            // BADCUE\n            // 54-62 - Collect and discard the remaining cue.\n            if (!line) self.state = 'ID';\n\n            continue;\n        }\n      }\n    } catch (e) {\n      // If we are currently parsing a cue, report what we have.\n      if (self.state === 'CUETEXT' && self.cue && self.oncue) self.oncue(self.cue);\n\n      self.cue = null;\n      // Enter BADWEBVTT state if header was not parsed correctly otherwise\n      // another exception occurred so enter BADCUE state.\n      self.state = self.state === 'INITIAL' ? 'BADWEBVTT' : 'BADCUE';\n    }\n    return this;\n  },\n  flush: function flush() {\n    var self = this;\n    try {\n      // Finish decoding the stream.\n      self.buffer += self.decoder.decode();\n      // Synthesize the end of the current cue or region.\n      if (self.cue || self.state === 'HEADER') {\n        self.buffer += '\\n\\n';\n        self.parse();\n      }\n      // If we've flushed, parsed, and we're still on the INITIAL state then\n      // that means we don't have enough of the stream to parse the first\n      // line.\n      if (self.state === 'INITIAL') throw new Error('Malformed WebVTT signature.');\n    } catch (e) {\n      throw e;\n    }\n    if (self.onflush) self.onflush();\n\n    return this;\n  }\n};\n\n\n\n/* harmony default export */ var vttparser = (VTTParser);\n// CONCATENATED MODULE: ./src/utils/cues.js\n\n\nfunction newCue(track, startTime, endTime, captionScreen) {\n  var row = void 0;\n  var cue = void 0;\n  var indenting = void 0;\n  var indent = void 0;\n  var text = void 0;\n  var VTTCue = window.VTTCue || window.TextTrackCue;\n\n  for (var r = 0; r < captionScreen.rows.length; r++) {\n    row = captionScreen.rows[r];\n    indenting = true;\n    indent = 0;\n    text = '';\n\n    if (!row.isEmpty()) {\n      for (var c = 0; c < row.chars.length; c++) {\n        if (row.chars[c].uchar.match(/\\s/) && indenting) {\n          indent++;\n        } else {\n          text += row.chars[c].uchar;\n          indenting = false;\n        }\n      }\n      // To be used for cleaning-up orphaned roll-up captions\n      row.cueStartTime = startTime;\n\n      // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE\n      if (startTime === endTime) endTime += 0.0001;\n\n      cue = new VTTCue(startTime, endTime, fixLineBreaks(text.trim()));\n\n      if (indent >= 16) indent--;else indent++;\n\n      // VTTCue.line get's flakey when using controls, so let's now include line 13&14\n      // also, drop line 1 since it's to close to the top\n      if (navigator.userAgent.match(/Firefox\\//)) cue.line = r + 1;else cue.line = r > 7 ? r - 2 : r + 1;\n\n      cue.align = 'left';\n      // Clamp the position between 0 and 100 - if out of these bounds, Firefox throws an exception and captions break\n      cue.position = Math.max(0, Math.min(100, 100 * (indent / 32) + (navigator.userAgent.match(/Firefox\\//) ? 50 : 0)));\n      track.addCue(cue);\n    }\n  }\n}\n// CONCATENATED MODULE: ./src/utils/cea-608-parser.js\nfunction cea_608_parser__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n *\n * This code was ported from the dash.js project at:\n *   https://github.com/Dash-Industry-Forum/dash.js/blob/development/externals/cea608-parser.js\n *   https://github.com/Dash-Industry-Forum/dash.js/commit/8269b26a761e0853bb21d78780ed945144ecdd4d#diff-71bc295a2d6b6b7093a1d3290d53a4b2\n *\n * The original copyright appears below:\n *\n * The copyright in this software is being made available under the BSD License,\n * included below. This software may be subject to other third party and contributor\n * rights, including patent rights, and no such rights are granted under this license.\n *\n * Copyright (c) 2015-2016, DASH Industry Forum.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without modification,\n * are permitted provided that the following conditions are met:\n *  1. Redistributions of source code must retain the above copyright notice, this\n *  list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above copyright notice,\n *  this list of conditions and the following disclaimer in the documentation and/or\n *  other materials provided with the distribution.\n *  2. Neither the name of Dash Industry Forum nor the names of its\n *  contributors may be used to endorse or promote products derived from this software\n *  without specific prior written permission.\n *\n *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS AS IS AND ANY\n *  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n *  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\n *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n *  POSSIBILITY OF SUCH DAMAGE.\n */\n/**\n     *  Exceptions from regular ASCII. CodePoints are mapped to UTF-16 codes\n     */\n\nvar specialCea608CharsCodes = {\n  0x2a: 0xe1, // lowercase a, acute accent\n  0x5c: 0xe9, // lowercase e, acute accent\n  0x5e: 0xed, // lowercase i, acute accent\n  0x5f: 0xf3, // lowercase o, acute accent\n  0x60: 0xfa, // lowercase u, acute accent\n  0x7b: 0xe7, // lowercase c with cedilla\n  0x7c: 0xf7, // division symbol\n  0x7d: 0xd1, // uppercase N tilde\n  0x7e: 0xf1, // lowercase n tilde\n  0x7f: 0x2588, // Full block\n  // THIS BLOCK INCLUDES THE 16 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x11 AND LOW BETWEEN 0x30 AND 0x3F\n  // THIS MEANS THAT \\x50 MUST BE ADDED TO THE VALUES\n  0x80: 0xae, // Registered symbol (R)\n  0x81: 0xb0, // degree sign\n  0x82: 0xbd, // 1/2 symbol\n  0x83: 0xbf, // Inverted (open) question mark\n  0x84: 0x2122, // Trademark symbol (TM)\n  0x85: 0xa2, // Cents symbol\n  0x86: 0xa3, // Pounds sterling\n  0x87: 0x266a, // Music 8'th note\n  0x88: 0xe0, // lowercase a, grave accent\n  0x89: 0x20, // transparent space (regular)\n  0x8a: 0xe8, // lowercase e, grave accent\n  0x8b: 0xe2, // lowercase a, circumflex accent\n  0x8c: 0xea, // lowercase e, circumflex accent\n  0x8d: 0xee, // lowercase i, circumflex accent\n  0x8e: 0xf4, // lowercase o, circumflex accent\n  0x8f: 0xfb, // lowercase u, circumflex accent\n  // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x12 AND LOW BETWEEN 0x20 AND 0x3F\n  0x90: 0xc1, // capital letter A with acute\n  0x91: 0xc9, // capital letter E with acute\n  0x92: 0xd3, // capital letter O with acute\n  0x93: 0xda, // capital letter U with acute\n  0x94: 0xdc, // capital letter U with diaresis\n  0x95: 0xfc, // lowercase letter U with diaeresis\n  0x96: 0x2018, // opening single quote\n  0x97: 0xa1, // inverted exclamation mark\n  0x98: 0x2a, // asterisk\n  0x99: 0x2019, // closing single quote\n  0x9a: 0x2501, // box drawings heavy horizontal\n  0x9b: 0xa9, // copyright sign\n  0x9c: 0x2120, // Service mark\n  0x9d: 0x2022, // (round) bullet\n  0x9e: 0x201c, // Left double quotation mark\n  0x9f: 0x201d, // Right double quotation mark\n  0xa0: 0xc0, // uppercase A, grave accent\n  0xa1: 0xc2, // uppercase A, circumflex\n  0xa2: 0xc7, // uppercase C with cedilla\n  0xa3: 0xc8, // uppercase E, grave accent\n  0xa4: 0xca, // uppercase E, circumflex\n  0xa5: 0xcb, // capital letter E with diaresis\n  0xa6: 0xeb, // lowercase letter e with diaresis\n  0xa7: 0xce, // uppercase I, circumflex\n  0xa8: 0xcf, // uppercase I, with diaresis\n  0xa9: 0xef, // lowercase i, with diaresis\n  0xaa: 0xd4, // uppercase O, circumflex\n  0xab: 0xd9, // uppercase U, grave accent\n  0xac: 0xf9, // lowercase u, grave accent\n  0xad: 0xdb, // uppercase U, circumflex\n  0xae: 0xab, // left-pointing double angle quotation mark\n  0xaf: 0xbb, // right-pointing double angle quotation mark\n  // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x13 AND LOW BETWEEN 0x20 AND 0x3F\n  0xb0: 0xc3, // Uppercase A, tilde\n  0xb1: 0xe3, // Lowercase a, tilde\n  0xb2: 0xcd, // Uppercase I, acute accent\n  0xb3: 0xcc, // Uppercase I, grave accent\n  0xb4: 0xec, // Lowercase i, grave accent\n  0xb5: 0xd2, // Uppercase O, grave accent\n  0xb6: 0xf2, // Lowercase o, grave accent\n  0xb7: 0xd5, // Uppercase O, tilde\n  0xb8: 0xf5, // Lowercase o, tilde\n  0xb9: 0x7b, // Open curly brace\n  0xba: 0x7d, // Closing curly brace\n  0xbb: 0x5c, // Backslash\n  0xbc: 0x5e, // Caret\n  0xbd: 0x5f, // Underscore\n  0xbe: 0x7c, // Pipe (vertical line)\n  0xbf: 0x223c, // Tilde operator\n  0xc0: 0xc4, // Uppercase A, umlaut\n  0xc1: 0xe4, // Lowercase A, umlaut\n  0xc2: 0xd6, // Uppercase O, umlaut\n  0xc3: 0xf6, // Lowercase o, umlaut\n  0xc4: 0xdf, // Esszett (sharp S)\n  0xc5: 0xa5, // Yen symbol\n  0xc6: 0xa4, // Generic currency sign\n  0xc7: 0x2503, // Box drawings heavy vertical\n  0xc8: 0xc5, // Uppercase A, ring\n  0xc9: 0xe5, // Lowercase A, ring\n  0xca: 0xd8, // Uppercase O, stroke\n  0xcb: 0xf8, // Lowercase o, strok\n  0xcc: 0x250f, // Box drawings heavy down and right\n  0xcd: 0x2513, // Box drawings heavy down and left\n  0xce: 0x2517, // Box drawings heavy up and right\n  0xcf: 0x251b // Box drawings heavy up and left\n};\n\n/**\n * Utils\n */\nvar getCharForByte = function getCharForByte(byte) {\n  var charCode = byte;\n  if (specialCea608CharsCodes.hasOwnProperty(byte)) charCode = specialCea608CharsCodes[byte];\n\n  return String.fromCharCode(charCode);\n};\n\nvar NR_ROWS = 15,\n    NR_COLS = 100;\n// Tables to look up row from PAC data\nvar rowsLowCh1 = { 0x11: 1, 0x12: 3, 0x15: 5, 0x16: 7, 0x17: 9, 0x10: 11, 0x13: 12, 0x14: 14 };\nvar rowsHighCh1 = { 0x11: 2, 0x12: 4, 0x15: 6, 0x16: 8, 0x17: 10, 0x13: 13, 0x14: 15 };\nvar rowsLowCh2 = { 0x19: 1, 0x1A: 3, 0x1D: 5, 0x1E: 7, 0x1F: 9, 0x18: 11, 0x1B: 12, 0x1C: 14 };\nvar rowsHighCh2 = { 0x19: 2, 0x1A: 4, 0x1D: 6, 0x1E: 8, 0x1F: 10, 0x1B: 13, 0x1C: 15 };\n\nvar backgroundColors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'black', 'transparent'];\n\n/**\n * Simple logger class to be able to write with time-stamps and filter on level.\n */\nvar cea_608_parser_logger = {\n  verboseFilter: { 'DATA': 3, 'DEBUG': 3, 'INFO': 2, 'WARNING': 2, 'TEXT': 1, 'ERROR': 0 },\n  time: null,\n  verboseLevel: 0, // Only write errors\n  setTime: function setTime(newTime) {\n    this.time = newTime;\n  },\n  log: function log(severity, msg) {\n    var minLevel = this.verboseFilter[severity];\n    if (this.verboseLevel >= minLevel) console.log(this.time + ' [' + severity + '] ' + msg);\n  }\n};\n\nvar numArrayToHexArray = function numArrayToHexArray(numArray) {\n  var hexArray = [];\n  for (var j = 0; j < numArray.length; j++) {\n    hexArray.push(numArray[j].toString(16));\n  }return hexArray;\n};\n\nvar PenState = function () {\n  function PenState(foreground, underline, italics, background, flash) {\n    cea_608_parser__classCallCheck(this, PenState);\n\n    this.foreground = foreground || 'white';\n    this.underline = underline || false;\n    this.italics = italics || false;\n    this.background = background || 'black';\n    this.flash = flash || false;\n  }\n\n  PenState.prototype.reset = function reset() {\n    this.foreground = 'white';\n    this.underline = false;\n    this.italics = false;\n    this.background = 'black';\n    this.flash = false;\n  };\n\n  PenState.prototype.setStyles = function setStyles(styles) {\n    var attribs = ['foreground', 'underline', 'italics', 'background', 'flash'];\n    for (var i = 0; i < attribs.length; i++) {\n      var style = attribs[i];\n      if (styles.hasOwnProperty(style)) this[style] = styles[style];\n    }\n  };\n\n  PenState.prototype.isDefault = function isDefault() {\n    return this.foreground === 'white' && !this.underline && !this.italics && this.background === 'black' && !this.flash;\n  };\n\n  PenState.prototype.equals = function equals(other) {\n    return this.foreground === other.foreground && this.underline === other.underline && this.italics === other.italics && this.background === other.background && this.flash === other.flash;\n  };\n\n  PenState.prototype.copy = function copy(newPenState) {\n    this.foreground = newPenState.foreground;\n    this.underline = newPenState.underline;\n    this.italics = newPenState.italics;\n    this.background = newPenState.background;\n    this.flash = newPenState.flash;\n  };\n\n  PenState.prototype.toString = function toString() {\n    return 'color=' + this.foreground + ', underline=' + this.underline + ', italics=' + this.italics + ', background=' + this.background + ', flash=' + this.flash;\n  };\n\n  return PenState;\n}();\n\n/**\n * Unicode character with styling and background.\n * @constructor\n */\n\n\nvar StyledUnicodeChar = function () {\n  function StyledUnicodeChar(uchar, foreground, underline, italics, background, flash) {\n    cea_608_parser__classCallCheck(this, StyledUnicodeChar);\n\n    this.uchar = uchar || ' '; // unicode character\n    this.penState = new PenState(foreground, underline, italics, background, flash);\n  }\n\n  StyledUnicodeChar.prototype.reset = function reset() {\n    this.uchar = ' ';\n    this.penState.reset();\n  };\n\n  StyledUnicodeChar.prototype.setChar = function setChar(uchar, newPenState) {\n    this.uchar = uchar;\n    this.penState.copy(newPenState);\n  };\n\n  StyledUnicodeChar.prototype.setPenState = function setPenState(newPenState) {\n    this.penState.copy(newPenState);\n  };\n\n  StyledUnicodeChar.prototype.equals = function equals(other) {\n    return this.uchar === other.uchar && this.penState.equals(other.penState);\n  };\n\n  StyledUnicodeChar.prototype.copy = function copy(newChar) {\n    this.uchar = newChar.uchar;\n    this.penState.copy(newChar.penState);\n  };\n\n  StyledUnicodeChar.prototype.isEmpty = function isEmpty() {\n    return this.uchar === ' ' && this.penState.isDefault();\n  };\n\n  return StyledUnicodeChar;\n}();\n\n/**\n * CEA-608 row consisting of NR_COLS instances of StyledUnicodeChar.\n * @constructor\n */\n\n\nvar Row = function () {\n  function Row() {\n    cea_608_parser__classCallCheck(this, Row);\n\n    this.chars = [];\n    for (var i = 0; i < NR_COLS; i++) {\n      this.chars.push(new StyledUnicodeChar());\n    }this.pos = 0;\n    this.currPenState = new PenState();\n  }\n\n  Row.prototype.equals = function equals(other) {\n    var equal = true;\n    for (var i = 0; i < NR_COLS; i++) {\n      if (!this.chars[i].equals(other.chars[i])) {\n        equal = false;\n        break;\n      }\n    }\n    return equal;\n  };\n\n  Row.prototype.copy = function copy(other) {\n    for (var i = 0; i < NR_COLS; i++) {\n      this.chars[i].copy(other.chars[i]);\n    }\n  };\n\n  Row.prototype.isEmpty = function isEmpty() {\n    var empty = true;\n    for (var i = 0; i < NR_COLS; i++) {\n      if (!this.chars[i].isEmpty()) {\n        empty = false;\n        break;\n      }\n    }\n    return empty;\n  };\n\n  /**\n     *  Set the cursor to a valid column.\n     */\n\n\n  Row.prototype.setCursor = function setCursor(absPos) {\n    if (this.pos !== absPos) this.pos = absPos;\n\n    if (this.pos < 0) {\n      cea_608_parser_logger.log('ERROR', 'Negative cursor position ' + this.pos);\n      this.pos = 0;\n    } else if (this.pos > NR_COLS) {\n      cea_608_parser_logger.log('ERROR', 'Too large cursor position ' + this.pos);\n      this.pos = NR_COLS;\n    }\n  };\n\n  /**\n     * Move the cursor relative to current position.\n     */\n\n\n  Row.prototype.moveCursor = function moveCursor(relPos) {\n    var newPos = this.pos + relPos;\n    if (relPos > 1) {\n      for (var i = this.pos + 1; i < newPos + 1; i++) {\n        this.chars[i].setPenState(this.currPenState);\n      }\n    }\n    this.setCursor(newPos);\n  };\n\n  /**\n     * Backspace, move one step back and clear character.\n     */\n\n\n  Row.prototype.backSpace = function backSpace() {\n    this.moveCursor(-1);\n    this.chars[this.pos].setChar(' ', this.currPenState);\n  };\n\n  Row.prototype.insertChar = function insertChar(byte) {\n    if (byte >= 0x90) {\n      // Extended char\n      this.backSpace();\n    }\n    var char = getCharForByte(byte);\n    if (this.pos >= NR_COLS) {\n      cea_608_parser_logger.log('ERROR', 'Cannot insert ' + byte.toString(16) + ' (' + char + ') at position ' + this.pos + '. Skipping it!');\n      return;\n    }\n    this.chars[this.pos].setChar(char, this.currPenState);\n    this.moveCursor(1);\n  };\n\n  Row.prototype.clearFromPos = function clearFromPos(startPos) {\n    var i = void 0;\n    for (i = startPos; i < NR_COLS; i++) {\n      this.chars[i].reset();\n    }\n  };\n\n  Row.prototype.clear = function clear() {\n    this.clearFromPos(0);\n    this.pos = 0;\n    this.currPenState.reset();\n  };\n\n  Row.prototype.clearToEndOfRow = function clearToEndOfRow() {\n    this.clearFromPos(this.pos);\n  };\n\n  Row.prototype.getTextString = function getTextString() {\n    var chars = [];\n    var empty = true;\n    for (var i = 0; i < NR_COLS; i++) {\n      var char = this.chars[i].uchar;\n      if (char !== ' ') empty = false;\n\n      chars.push(char);\n    }\n    if (empty) return '';else return chars.join('');\n  };\n\n  Row.prototype.setPenStyles = function setPenStyles(styles) {\n    this.currPenState.setStyles(styles);\n    var currChar = this.chars[this.pos];\n    currChar.setPenState(this.currPenState);\n  };\n\n  return Row;\n}();\n\n/**\n * Keep a CEA-608 screen of 32x15 styled characters\n * @constructor\n*/\n\n\nvar CaptionScreen = function () {\n  function CaptionScreen() {\n    cea_608_parser__classCallCheck(this, CaptionScreen);\n\n    this.rows = [];\n    for (var i = 0; i < NR_ROWS; i++) {\n      this.rows.push(new Row());\n    } // Note that we use zero-based numbering (0-14)\n\n    this.currRow = NR_ROWS - 1;\n    this.nrRollUpRows = null;\n    this.reset();\n  }\n\n  CaptionScreen.prototype.reset = function reset() {\n    for (var i = 0; i < NR_ROWS; i++) {\n      this.rows[i].clear();\n    }this.currRow = NR_ROWS - 1;\n  };\n\n  CaptionScreen.prototype.equals = function equals(other) {\n    var equal = true;\n    for (var i = 0; i < NR_ROWS; i++) {\n      if (!this.rows[i].equals(other.rows[i])) {\n        equal = false;\n        break;\n      }\n    }\n    return equal;\n  };\n\n  CaptionScreen.prototype.copy = function copy(other) {\n    for (var i = 0; i < NR_ROWS; i++) {\n      this.rows[i].copy(other.rows[i]);\n    }\n  };\n\n  CaptionScreen.prototype.isEmpty = function isEmpty() {\n    var empty = true;\n    for (var i = 0; i < NR_ROWS; i++) {\n      if (!this.rows[i].isEmpty()) {\n        empty = false;\n        break;\n      }\n    }\n    return empty;\n  };\n\n  CaptionScreen.prototype.backSpace = function backSpace() {\n    var row = this.rows[this.currRow];\n    row.backSpace();\n  };\n\n  CaptionScreen.prototype.clearToEndOfRow = function clearToEndOfRow() {\n    var row = this.rows[this.currRow];\n    row.clearToEndOfRow();\n  };\n\n  /**\n     * Insert a character (without styling) in the current row.\n     */\n\n\n  CaptionScreen.prototype.insertChar = function insertChar(char) {\n    var row = this.rows[this.currRow];\n    row.insertChar(char);\n  };\n\n  CaptionScreen.prototype.setPen = function setPen(styles) {\n    var row = this.rows[this.currRow];\n    row.setPenStyles(styles);\n  };\n\n  CaptionScreen.prototype.moveCursor = function moveCursor(relPos) {\n    var row = this.rows[this.currRow];\n    row.moveCursor(relPos);\n  };\n\n  CaptionScreen.prototype.setCursor = function setCursor(absPos) {\n    cea_608_parser_logger.log('INFO', 'setCursor: ' + absPos);\n    var row = this.rows[this.currRow];\n    row.setCursor(absPos);\n  };\n\n  CaptionScreen.prototype.setPAC = function setPAC(pacData) {\n    cea_608_parser_logger.log('INFO', 'pacData = ' + JSON.stringify(pacData));\n    var newRow = pacData.row - 1;\n    if (this.nrRollUpRows && newRow < this.nrRollUpRows - 1) newRow = this.nrRollUpRows - 1;\n\n    // Make sure this only affects Roll-up Captions by checking this.nrRollUpRows\n    if (this.nrRollUpRows && this.currRow !== newRow) {\n      // clear all rows first\n      for (var i = 0; i < NR_ROWS; i++) {\n        this.rows[i].clear();\n      } // Copy this.nrRollUpRows rows from lastOutputScreen and place it in the newRow location\n      // topRowIndex - the start of rows to copy (inclusive index)\n      var topRowIndex = this.currRow + 1 - this.nrRollUpRows;\n      // We only copy if the last position was already shown.\n      // We use the cueStartTime value to check this.\n      var lastOutputScreen = this.lastOutputScreen;\n      if (lastOutputScreen) {\n        var prevLineTime = lastOutputScreen.rows[topRowIndex].cueStartTime;\n        if (prevLineTime && prevLineTime < cea_608_parser_logger.time) {\n          for (var _i = 0; _i < this.nrRollUpRows; _i++) {\n            this.rows[newRow - this.nrRollUpRows + _i + 1].copy(lastOutputScreen.rows[topRowIndex + _i]);\n          }\n        }\n      }\n    }\n\n    this.currRow = newRow;\n    var row = this.rows[this.currRow];\n    if (pacData.indent !== null) {\n      var indent = pacData.indent;\n      var prevPos = Math.max(indent - 1, 0);\n      row.setCursor(pacData.indent);\n      pacData.color = row.chars[prevPos].penState.foreground;\n    }\n    var styles = { foreground: pacData.color, underline: pacData.underline, italics: pacData.italics, background: 'black', flash: false };\n    this.setPen(styles);\n  };\n\n  /**\n     * Set background/extra foreground, but first do back_space, and then insert space (backwards compatibility).\n     */\n\n\n  CaptionScreen.prototype.setBkgData = function setBkgData(bkgData) {\n    cea_608_parser_logger.log('INFO', 'bkgData = ' + JSON.stringify(bkgData));\n    this.backSpace();\n    this.setPen(bkgData);\n    this.insertChar(0x20); // Space\n  };\n\n  CaptionScreen.prototype.setRollUpRows = function setRollUpRows(nrRows) {\n    this.nrRollUpRows = nrRows;\n  };\n\n  CaptionScreen.prototype.rollUp = function rollUp() {\n    if (this.nrRollUpRows === null) {\n      cea_608_parser_logger.log('DEBUG', 'roll_up but nrRollUpRows not set yet');\n      return; // Not properly setup\n    }\n    cea_608_parser_logger.log('TEXT', this.getDisplayText());\n    var topRowIndex = this.currRow + 1 - this.nrRollUpRows;\n    var topRow = this.rows.splice(topRowIndex, 1)[0];\n    topRow.clear();\n    this.rows.splice(this.currRow, 0, topRow);\n    cea_608_parser_logger.log('INFO', 'Rolling up');\n    // logger.log('TEXT', this.get_display_text())\n  };\n\n  /**\n    * Get all non-empty rows with as unicode text.\n    */\n\n\n  CaptionScreen.prototype.getDisplayText = function getDisplayText(asOneRow) {\n    asOneRow = asOneRow || false;\n    var displayText = [];\n    var text = '';\n    var rowNr = -1;\n    for (var i = 0; i < NR_ROWS; i++) {\n      var rowText = this.rows[i].getTextString();\n      if (rowText) {\n        rowNr = i + 1;\n        if (asOneRow) displayText.push('Row ' + rowNr + ': \\'' + rowText + '\\'');else displayText.push(rowText.trim());\n      }\n    }\n    if (displayText.length > 0) {\n      if (asOneRow) text = '[' + displayText.join(' | ') + ']';else text = displayText.join('\\n');\n    }\n    return text;\n  };\n\n  CaptionScreen.prototype.getTextAndFormat = function getTextAndFormat() {\n    return this.rows;\n  };\n\n  return CaptionScreen;\n}();\n\n// var modes = ['MODE_ROLL-UP', 'MODE_POP-ON', 'MODE_PAINT-ON', 'MODE_TEXT'];\n\nvar Cea608Channel = function () {\n  function Cea608Channel(channelNumber, outputFilter) {\n    cea_608_parser__classCallCheck(this, Cea608Channel);\n\n    this.chNr = channelNumber;\n    this.outputFilter = outputFilter;\n    this.mode = null;\n    this.verbose = 0;\n    this.displayedMemory = new CaptionScreen();\n    this.nonDisplayedMemory = new CaptionScreen();\n    this.lastOutputScreen = new CaptionScreen();\n    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\n    this.writeScreen = this.displayedMemory;\n    this.mode = null;\n    this.cueStartTime = null; // Keeps track of where a cue started.\n  }\n\n  Cea608Channel.prototype.reset = function reset() {\n    this.mode = null;\n    this.displayedMemory.reset();\n    this.nonDisplayedMemory.reset();\n    this.lastOutputScreen.reset();\n    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\n    this.writeScreen = this.displayedMemory;\n    this.mode = null;\n    this.cueStartTime = null;\n    this.lastCueEndTime = null;\n  };\n\n  Cea608Channel.prototype.getHandler = function getHandler() {\n    return this.outputFilter;\n  };\n\n  Cea608Channel.prototype.setHandler = function setHandler(newHandler) {\n    this.outputFilter = newHandler;\n  };\n\n  Cea608Channel.prototype.setPAC = function setPAC(pacData) {\n    this.writeScreen.setPAC(pacData);\n  };\n\n  Cea608Channel.prototype.setBkgData = function setBkgData(bkgData) {\n    this.writeScreen.setBkgData(bkgData);\n  };\n\n  Cea608Channel.prototype.setMode = function setMode(newMode) {\n    if (newMode === this.mode) return;\n\n    this.mode = newMode;\n    cea_608_parser_logger.log('INFO', 'MODE=' + newMode);\n    if (this.mode === 'MODE_POP-ON') {\n      this.writeScreen = this.nonDisplayedMemory;\n    } else {\n      this.writeScreen = this.displayedMemory;\n      this.writeScreen.reset();\n    }\n    if (this.mode !== 'MODE_ROLL-UP') {\n      this.displayedMemory.nrRollUpRows = null;\n      this.nonDisplayedMemory.nrRollUpRows = null;\n    }\n    this.mode = newMode;\n  };\n\n  Cea608Channel.prototype.insertChars = function insertChars(chars) {\n    for (var i = 0; i < chars.length; i++) {\n      this.writeScreen.insertChar(chars[i]);\n    }var screen = this.writeScreen === this.displayedMemory ? 'DISP' : 'NON_DISP';\n    cea_608_parser_logger.log('INFO', screen + ': ' + this.writeScreen.getDisplayText(true));\n    if (this.mode === 'MODE_PAINT-ON' || this.mode === 'MODE_ROLL-UP') {\n      cea_608_parser_logger.log('TEXT', 'DISPLAYED: ' + this.displayedMemory.getDisplayText(true));\n      this.outputDataUpdate();\n    }\n  };\n\n  Cea608Channel.prototype.ccRCL = function ccRCL() {\n    // Resume Caption Loading (switch mode to Pop On)\n    cea_608_parser_logger.log('INFO', 'RCL - Resume Caption Loading');\n    this.setMode('MODE_POP-ON');\n  };\n\n  Cea608Channel.prototype.ccBS = function ccBS() {\n    // BackSpace\n    cea_608_parser_logger.log('INFO', 'BS - BackSpace');\n    if (this.mode === 'MODE_TEXT') return;\n\n    this.writeScreen.backSpace();\n    if (this.writeScreen === this.displayedMemory) this.outputDataUpdate();\n  };\n\n  Cea608Channel.prototype.ccAOF = function ccAOF() {// Reserved (formerly Alarm Off)\n\n  };\n\n  Cea608Channel.prototype.ccAON = function ccAON() {// Reserved (formerly Alarm On)\n\n  };\n\n  Cea608Channel.prototype.ccDER = function ccDER() {\n    // Delete to End of Row\n    cea_608_parser_logger.log('INFO', 'DER- Delete to End of Row');\n    this.writeScreen.clearToEndOfRow();\n    this.outputDataUpdate();\n  };\n\n  Cea608Channel.prototype.ccRU = function ccRU(nrRows) {\n    // Roll-Up Captions-2,3,or 4 Rows\n    cea_608_parser_logger.log('INFO', 'RU(' + nrRows + ') - Roll Up');\n    this.writeScreen = this.displayedMemory;\n    this.setMode('MODE_ROLL-UP');\n    this.writeScreen.setRollUpRows(nrRows);\n  };\n\n  Cea608Channel.prototype.ccFON = function ccFON() {\n    // Flash On\n    cea_608_parser_logger.log('INFO', 'FON - Flash On');\n    this.writeScreen.setPen({ flash: true });\n  };\n\n  Cea608Channel.prototype.ccRDC = function ccRDC() {\n    // Resume Direct Captioning (switch mode to PaintOn)\n    cea_608_parser_logger.log('INFO', 'RDC - Resume Direct Captioning');\n    this.setMode('MODE_PAINT-ON');\n  };\n\n  Cea608Channel.prototype.ccTR = function ccTR() {\n    // Text Restart in text mode (not supported, however)\n    cea_608_parser_logger.log('INFO', 'TR');\n    this.setMode('MODE_TEXT');\n  };\n\n  Cea608Channel.prototype.ccRTD = function ccRTD() {\n    // Resume Text Display in Text mode (not supported, however)\n    cea_608_parser_logger.log('INFO', 'RTD');\n    this.setMode('MODE_TEXT');\n  };\n\n  Cea608Channel.prototype.ccEDM = function ccEDM() {\n    // Erase Displayed Memory\n    cea_608_parser_logger.log('INFO', 'EDM - Erase Displayed Memory');\n    this.displayedMemory.reset();\n    this.outputDataUpdate(true);\n  };\n\n  Cea608Channel.prototype.ccCR = function ccCR() {\n    // Carriage Return\n    cea_608_parser_logger.log('CR - Carriage Return');\n    this.writeScreen.rollUp();\n    this.outputDataUpdate(true);\n  };\n\n  Cea608Channel.prototype.ccENM = function ccENM() {\n    // Erase Non-Displayed Memory\n    cea_608_parser_logger.log('INFO', 'ENM - Erase Non-displayed Memory');\n    this.nonDisplayedMemory.reset();\n  };\n\n  Cea608Channel.prototype.ccEOC = function ccEOC() {\n    // End of Caption (Flip Memories)\n    cea_608_parser_logger.log('INFO', 'EOC - End Of Caption');\n    if (this.mode === 'MODE_POP-ON') {\n      var tmp = this.displayedMemory;\n      this.displayedMemory = this.nonDisplayedMemory;\n      this.nonDisplayedMemory = tmp;\n      this.writeScreen = this.nonDisplayedMemory;\n      cea_608_parser_logger.log('TEXT', 'DISP: ' + this.displayedMemory.getDisplayText());\n    }\n    this.outputDataUpdate(true);\n  };\n\n  Cea608Channel.prototype.ccTO = function ccTO(nrCols) {\n    // Tab Offset 1,2, or 3 columns\n    cea_608_parser_logger.log('INFO', 'TO(' + nrCols + ') - Tab Offset');\n    this.writeScreen.moveCursor(nrCols);\n  };\n\n  Cea608Channel.prototype.ccMIDROW = function ccMIDROW(secondByte) {\n    // Parse MIDROW command\n    var styles = { flash: false };\n    styles.underline = secondByte % 2 === 1;\n    styles.italics = secondByte >= 0x2e;\n    if (!styles.italics) {\n      var colorIndex = Math.floor(secondByte / 2) - 0x10;\n      var colors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta'];\n      styles.foreground = colors[colorIndex];\n    } else {\n      styles.foreground = 'white';\n    }\n    cea_608_parser_logger.log('INFO', 'MIDROW: ' + JSON.stringify(styles));\n    this.writeScreen.setPen(styles);\n  };\n\n  Cea608Channel.prototype.outputDataUpdate = function outputDataUpdate() {\n    var dispatch = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n\n    var t = cea_608_parser_logger.time;\n    if (t === null) return;\n\n    if (this.outputFilter) {\n      if (this.cueStartTime === null && !this.displayedMemory.isEmpty()) {\n        // Start of a new cue\n        this.cueStartTime = t;\n      } else {\n        if (!this.displayedMemory.equals(this.lastOutputScreen)) {\n          if (this.outputFilter.newCue) {\n            this.outputFilter.newCue(this.cueStartTime, t, this.lastOutputScreen);\n            if (dispatch === true && this.outputFilter.dispatchCue) this.outputFilter.dispatchCue();\n          }\n          this.cueStartTime = this.displayedMemory.isEmpty() ? null : t;\n        }\n      }\n      this.lastOutputScreen.copy(this.displayedMemory);\n    }\n  };\n\n  Cea608Channel.prototype.cueSplitAtTime = function cueSplitAtTime(t) {\n    if (this.outputFilter) {\n      if (!this.displayedMemory.isEmpty()) {\n        if (this.outputFilter.newCue) this.outputFilter.newCue(this.cueStartTime, t, this.displayedMemory);\n\n        this.cueStartTime = t;\n      }\n    }\n  };\n\n  return Cea608Channel;\n}();\n\nvar Cea608Parser = function () {\n  function Cea608Parser(field, out1, out2) {\n    cea_608_parser__classCallCheck(this, Cea608Parser);\n\n    this.field = field || 1;\n    this.outputs = [out1, out2];\n    this.channels = [new Cea608Channel(1, out1), new Cea608Channel(2, out2)];\n    this.currChNr = -1; // Will be 1 or 2\n    this.lastCmdA = null; // First byte of last command\n    this.lastCmdB = null; // Second byte of last command\n    this.bufferedData = [];\n    this.startTime = null;\n    this.lastTime = null;\n    this.dataCounters = { 'padding': 0, 'char': 0, 'cmd': 0, 'other': 0 };\n  }\n\n  Cea608Parser.prototype.getHandler = function getHandler(index) {\n    return this.channels[index].getHandler();\n  };\n\n  Cea608Parser.prototype.setHandler = function setHandler(index, newHandler) {\n    this.channels[index].setHandler(newHandler);\n  };\n\n  /**\n     * Add data for time t in forms of list of bytes (unsigned ints). The bytes are treated as pairs.\n     */\n\n\n  Cea608Parser.prototype.addData = function addData(t, byteList) {\n    var cmdFound = void 0,\n        a = void 0,\n        b = void 0,\n        charsFound = false;\n\n    this.lastTime = t;\n    cea_608_parser_logger.setTime(t);\n\n    for (var i = 0; i < byteList.length; i += 2) {\n      a = byteList[i] & 0x7f;\n      b = byteList[i + 1] & 0x7f;\n      if (a === 0 && b === 0) {\n        this.dataCounters.padding += 2;\n        continue;\n      } else {\n        cea_608_parser_logger.log('DATA', '[' + numArrayToHexArray([byteList[i], byteList[i + 1]]) + '] -> (' + numArrayToHexArray([a, b]) + ')');\n      }\n      cmdFound = this.parseCmd(a, b);\n      if (!cmdFound) cmdFound = this.parseMidrow(a, b);\n\n      if (!cmdFound) cmdFound = this.parsePAC(a, b);\n\n      if (!cmdFound) cmdFound = this.parseBackgroundAttributes(a, b);\n\n      if (!cmdFound) {\n        charsFound = this.parseChars(a, b);\n        if (charsFound) {\n          if (this.currChNr && this.currChNr >= 0) {\n            var channel = this.channels[this.currChNr - 1];\n            channel.insertChars(charsFound);\n          } else {\n            cea_608_parser_logger.log('WARNING', 'No channel found yet. TEXT-MODE?');\n          }\n        }\n      }\n      if (cmdFound) {\n        this.dataCounters.cmd += 2;\n      } else if (charsFound) {\n        this.dataCounters.char += 2;\n      } else {\n        this.dataCounters.other += 2;\n        cea_608_parser_logger.log('WARNING', 'Couldn\\'t parse cleaned data ' + numArrayToHexArray([a, b]) + ' orig: ' + numArrayToHexArray([byteList[i], byteList[i + 1]]));\n      }\n    }\n  };\n\n  /**\n     * Parse Command.\n     * @returns {Boolean} Tells if a command was found\n     */\n\n\n  Cea608Parser.prototype.parseCmd = function parseCmd(a, b) {\n    var chNr = null;\n\n    var cond1 = (a === 0x14 || a === 0x1C) && b >= 0x20 && b <= 0x2F;\n    var cond2 = (a === 0x17 || a === 0x1F) && b >= 0x21 && b <= 0x23;\n    if (!(cond1 || cond2)) return false;\n\n    if (a === this.lastCmdA && b === this.lastCmdB) {\n      this.lastCmdA = null;\n      this.lastCmdB = null; // Repeated commands are dropped (once)\n      cea_608_parser_logger.log('DEBUG', 'Repeated command (' + numArrayToHexArray([a, b]) + ') is dropped');\n      return true;\n    }\n\n    if (a === 0x14 || a === 0x17) chNr = 1;else chNr = 2; // (a === 0x1C || a=== 0x1f)\n\n    var channel = this.channels[chNr - 1];\n\n    if (a === 0x14 || a === 0x1C) {\n      if (b === 0x20) channel.ccRCL();else if (b === 0x21) channel.ccBS();else if (b === 0x22) channel.ccAOF();else if (b === 0x23) channel.ccAON();else if (b === 0x24) channel.ccDER();else if (b === 0x25) channel.ccRU(2);else if (b === 0x26) channel.ccRU(3);else if (b === 0x27) channel.ccRU(4);else if (b === 0x28) channel.ccFON();else if (b === 0x29) channel.ccRDC();else if (b === 0x2A) channel.ccTR();else if (b === 0x2B) channel.ccRTD();else if (b === 0x2C) channel.ccEDM();else if (b === 0x2D) channel.ccCR();else if (b === 0x2E) channel.ccENM();else if (b === 0x2F) channel.ccEOC();\n    } else {\n      // a == 0x17 || a == 0x1F\n      channel.ccTO(b - 0x20);\n    }\n    this.lastCmdA = a;\n    this.lastCmdB = b;\n    this.currChNr = chNr;\n    return true;\n  };\n\n  /**\n     * Parse midrow styling command\n     * @returns {Boolean}\n     */\n\n\n  Cea608Parser.prototype.parseMidrow = function parseMidrow(a, b) {\n    var chNr = null;\n\n    if ((a === 0x11 || a === 0x19) && b >= 0x20 && b <= 0x2f) {\n      if (a === 0x11) chNr = 1;else chNr = 2;\n\n      if (chNr !== this.currChNr) {\n        cea_608_parser_logger.log('ERROR', 'Mismatch channel in midrow parsing');\n        return false;\n      }\n      var channel = this.channels[chNr - 1];\n      channel.ccMIDROW(b);\n      cea_608_parser_logger.log('DEBUG', 'MIDROW (' + numArrayToHexArray([a, b]) + ')');\n      return true;\n    }\n    return false;\n  };\n  /**\n     * Parse Preable Access Codes (Table 53).\n     * @returns {Boolean} Tells if PAC found\n     */\n\n\n  Cea608Parser.prototype.parsePAC = function parsePAC(a, b) {\n    var chNr = null;\n    var row = null;\n\n    var case1 = (a >= 0x11 && a <= 0x17 || a >= 0x19 && a <= 0x1F) && b >= 0x40 && b <= 0x7F;\n    var case2 = (a === 0x10 || a === 0x18) && b >= 0x40 && b <= 0x5F;\n    if (!(case1 || case2)) return false;\n\n    if (a === this.lastCmdA && b === this.lastCmdB) {\n      this.lastCmdA = null;\n      this.lastCmdB = null;\n      return true; // Repeated commands are dropped (once)\n    }\n\n    chNr = a <= 0x17 ? 1 : 2;\n\n    if (b >= 0x40 && b <= 0x5F) {\n      row = chNr === 1 ? rowsLowCh1[a] : rowsLowCh2[a];\n    } else {\n      // 0x60 <= b <= 0x7F\n      row = chNr === 1 ? rowsHighCh1[a] : rowsHighCh2[a];\n    }\n    var pacData = this.interpretPAC(row, b);\n    var channel = this.channels[chNr - 1];\n    channel.setPAC(pacData);\n    this.lastCmdA = a;\n    this.lastCmdB = b;\n    this.currChNr = chNr;\n    return true;\n  };\n\n  /**\n     * Interpret the second byte of the pac, and return the information.\n     * @returns {Object} pacData with style parameters.\n     */\n\n\n  Cea608Parser.prototype.interpretPAC = function interpretPAC(row, byte) {\n    var pacIndex = byte;\n    var pacData = { color: null, italics: false, indent: null, underline: false, row: row };\n\n    if (byte > 0x5F) pacIndex = byte - 0x60;else pacIndex = byte - 0x40;\n\n    pacData.underline = (pacIndex & 1) === 1;\n    if (pacIndex <= 0xd) {\n      pacData.color = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'white'][Math.floor(pacIndex / 2)];\n    } else if (pacIndex <= 0xf) {\n      pacData.italics = true;\n      pacData.color = 'white';\n    } else {\n      pacData.indent = Math.floor((pacIndex - 0x10) / 2) * 4;\n    }\n    return pacData; // Note that row has zero offset. The spec uses 1.\n  };\n\n  /**\n     * Parse characters.\n     * @returns An array with 1 to 2 codes corresponding to chars, if found. null otherwise.\n     */\n\n\n  Cea608Parser.prototype.parseChars = function parseChars(a, b) {\n    var channelNr = null,\n        charCodes = null,\n        charCode1 = null;\n\n    if (a >= 0x19) {\n      channelNr = 2;\n      charCode1 = a - 8;\n    } else {\n      channelNr = 1;\n      charCode1 = a;\n    }\n    if (charCode1 >= 0x11 && charCode1 <= 0x13) {\n      // Special character\n      var oneCode = b;\n      if (charCode1 === 0x11) oneCode = b + 0x50;else if (charCode1 === 0x12) oneCode = b + 0x70;else oneCode = b + 0x90;\n\n      cea_608_parser_logger.log('INFO', 'Special char \\'' + getCharForByte(oneCode) + '\\' in channel ' + channelNr);\n      charCodes = [oneCode];\n    } else if (a >= 0x20 && a <= 0x7f) {\n      charCodes = b === 0 ? [a] : [a, b];\n    }\n    if (charCodes) {\n      var hexCodes = numArrayToHexArray(charCodes);\n      cea_608_parser_logger.log('DEBUG', 'Char codes =  ' + hexCodes.join(','));\n      this.lastCmdA = null;\n      this.lastCmdB = null;\n    }\n    return charCodes;\n  };\n\n  /**\n    * Parse extended background attributes as well as new foreground color black.\n    * @returns{Boolean} Tells if background attributes are found\n    */\n\n\n  Cea608Parser.prototype.parseBackgroundAttributes = function parseBackgroundAttributes(a, b) {\n    var bkgData = void 0,\n        index = void 0,\n        chNr = void 0,\n        channel = void 0;\n\n    var case1 = (a === 0x10 || a === 0x18) && b >= 0x20 && b <= 0x2f;\n    var case2 = (a === 0x17 || a === 0x1f) && b >= 0x2d && b <= 0x2f;\n    if (!(case1 || case2)) return false;\n\n    bkgData = {};\n    if (a === 0x10 || a === 0x18) {\n      index = Math.floor((b - 0x20) / 2);\n      bkgData.background = backgroundColors[index];\n      if (b % 2 === 1) bkgData.background = bkgData.background + '_semi';\n    } else if (b === 0x2d) {\n      bkgData.background = 'transparent';\n    } else {\n      bkgData.foreground = 'black';\n      if (b === 0x2f) bkgData.underline = true;\n    }\n    chNr = a < 0x18 ? 1 : 2;\n    channel = this.channels[chNr - 1];\n    channel.setBkgData(bkgData);\n    this.lastCmdA = null;\n    this.lastCmdB = null;\n    return true;\n  };\n\n  /**\n     * Reset state of parser and its channels.\n     */\n\n\n  Cea608Parser.prototype.reset = function reset() {\n    for (var i = 0; i < this.channels.length; i++) {\n      if (this.channels[i]) this.channels[i].reset();\n    }\n    this.lastCmdA = null;\n    this.lastCmdB = null;\n  };\n\n  /**\n     * Trigger the generation of a cue, and the start of a new one if displayScreens are not empty.\n     */\n\n\n  Cea608Parser.prototype.cueSplitAtTime = function cueSplitAtTime(t) {\n    for (var i = 0; i < this.channels.length; i++) {\n      if (this.channels[i]) this.channels[i].cueSplitAtTime(t);\n    }\n  };\n\n  return Cea608Parser;\n}();\n\n/* harmony default export */ var cea_608_parser = (Cea608Parser);\n// CONCATENATED MODULE: ./src/utils/output-filter.js\nfunction output_filter__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar OutputFilter = function () {\n  function OutputFilter(timelineController, track) {\n    output_filter__classCallCheck(this, OutputFilter);\n\n    this.timelineController = timelineController;\n    this.track = track;\n    this.startTime = null;\n    this.endTime = null;\n    this.screen = null;\n  }\n\n  OutputFilter.prototype.dispatchCue = function dispatchCue() {\n    if (this.startTime === null) return;\n\n    this.timelineController.addCues('textTrack' + this.track, this.startTime, this.endTime, this.screen);\n    this.startTime = null;\n  };\n\n  OutputFilter.prototype.newCue = function newCue(startTime, endTime, screen) {\n    if (this.startTime === null || this.startTime > startTime) this.startTime = startTime;\n\n    this.endTime = endTime;\n    this.screen = screen;\n    this.timelineController.createCaptionsTrack(this.track);\n  };\n\n  return OutputFilter;\n}();\n\n/* harmony default export */ var output_filter = (OutputFilter);\n// CONCATENATED MODULE: ./src/utils/webvtt-parser.js\n\n\n\n// String.prototype.startsWith is not supported in IE11\nvar startsWith = function startsWith(inputString, searchString, position) {\n  return inputString.substr(position || 0, searchString.length) === searchString;\n};\n\nvar cueString2millis = function cueString2millis(timeString) {\n  var ts = parseInt(timeString.substr(-3));\n  var secs = parseInt(timeString.substr(-6, 2));\n  var mins = parseInt(timeString.substr(-9, 2));\n  var hours = timeString.length > 9 ? parseInt(timeString.substr(0, timeString.indexOf(':'))) : 0;\n\n  if (isNaN(ts) || isNaN(secs) || isNaN(mins) || isNaN(hours)) return -1;\n\n  ts += 1000 * secs;\n  ts += 60 * 1000 * mins;\n  ts += 60 * 60 * 1000 * hours;\n\n  return ts;\n};\n\n// From https://github.com/darkskyapp/string-hash\nvar hash = function hash(text) {\n  var hash = 5381;\n  var i = text.length;\n  while (i) {\n    hash = hash * 33 ^ text.charCodeAt(--i);\n  }return (hash >>> 0).toString();\n};\n\nvar calculateOffset = function calculateOffset(vttCCs, cc, presentationTime) {\n  var currCC = vttCCs[cc];\n  var prevCC = vttCCs[currCC.prevCC];\n\n  // This is the first discontinuity or cues have been processed since the last discontinuity\n  // Offset = current discontinuity time\n  if (!prevCC || !prevCC.new && currCC.new) {\n    vttCCs.ccOffset = vttCCs.presentationOffset = currCC.start;\n    currCC.new = false;\n    return;\n  }\n\n  // There have been discontinuities since cues were last parsed.\n  // Offset = time elapsed\n  while (prevCC && prevCC.new) {\n    vttCCs.ccOffset += currCC.start - prevCC.start;\n    currCC.new = false;\n    currCC = prevCC;\n    prevCC = vttCCs[currCC.prevCC];\n  }\n\n  vttCCs.presentationOffset = presentationTime;\n};\n\nvar WebVTTParser = {\n  parse: function parse(vttByteArray, syncPTS, vttCCs, cc, callBack, errorCallBack) {\n    // Convert byteArray into string, replacing any somewhat exotic linefeeds with \"\\n\", then split on that character.\n    var re = /\\r\\n|\\n\\r|\\n|\\r/g;\n    // Uint8Array.prototype.reduce is not implemented in IE11\n    var vttLines = Object(id3[\"b\" /* utf8ArrayToStr */])(new Uint8Array(vttByteArray)).trim().replace(re, '\\n').split('\\n');\n\n    var cueTime = '00:00.000';\n    var mpegTs = 0;\n    var localTime = 0;\n    var presentationTime = 0;\n    var cues = [];\n    var parsingError = void 0;\n    var inHeader = true;\n    // let VTTCue = VTTCue || window.TextTrackCue;\n\n    // Create parser object using VTTCue with TextTrackCue fallback on certain browsers.\n    var parser = new vttparser();\n\n    parser.oncue = function (cue) {\n      // Adjust cue timing; clamp cues to start no earlier than - and drop cues that don't end after - 0 on timeline.\n      var currCC = vttCCs[cc];\n      var cueOffset = vttCCs.ccOffset;\n\n      // Update offsets for new discontinuities\n      if (currCC && currCC.new) {\n        if (localTime !== undefined) {\n          // When local time is provided, offset = discontinuity start time - local time\n          cueOffset = vttCCs.ccOffset = currCC.start;\n        } else {\n          calculateOffset(vttCCs, cc, presentationTime);\n        }\n      }\n\n      if (presentationTime) {\n        // If we have MPEGTS, offset = presentation time + discontinuity offset\n        cueOffset = presentationTime + vttCCs.ccOffset - vttCCs.presentationOffset;\n      }\n\n      cue.startTime += cueOffset - localTime;\n      cue.endTime += cueOffset - localTime;\n\n      // Create a unique hash id for a cue based on start/end times and text.\n      // This helps timeline-controller to avoid showing repeated captions.\n      cue.id = hash(cue.startTime.toString()) + hash(cue.endTime.toString()) + hash(cue.text);\n\n      // Fix encoding of special characters. TODO: Test with all sorts of weird characters.\n      cue.text = decodeURIComponent(encodeURIComponent(cue.text));\n      if (cue.endTime > 0) cues.push(cue);\n    };\n\n    parser.onparsingerror = function (e) {\n      parsingError = e;\n    };\n\n    parser.onflush = function () {\n      if (parsingError && errorCallBack) {\n        errorCallBack(parsingError);\n        return;\n      }\n      callBack(cues);\n    };\n\n    // Go through contents line by line.\n    vttLines.forEach(function (line) {\n      if (inHeader) {\n        // Look for X-TIMESTAMP-MAP in header.\n        if (startsWith(line, 'X-TIMESTAMP-MAP=')) {\n          // Once found, no more are allowed anyway, so stop searching.\n          inHeader = false;\n          // Extract LOCAL and MPEGTS.\n          line.substr(16).split(',').forEach(function (timestamp) {\n            if (startsWith(timestamp, 'LOCAL:')) cueTime = timestamp.substr(6);else if (startsWith(timestamp, 'MPEGTS:')) mpegTs = parseInt(timestamp.substr(7));\n          });\n          try {\n            // Calculate subtitle offset in milliseconds.\n            // If sync PTS is less than zero, we have a 33-bit wraparound, which is fixed by adding 2^33 = 8589934592.\n            syncPTS = syncPTS < 0 ? syncPTS + 8589934592 : syncPTS;\n            // Adjust MPEGTS by sync PTS.\n            mpegTs -= syncPTS;\n            // Convert cue time to seconds\n            localTime = cueString2millis(cueTime) / 1000;\n            // Convert MPEGTS to seconds from 90kHz.\n            presentationTime = mpegTs / 90000;\n\n            if (localTime === -1) parsingError = new Error('Malformed X-TIMESTAMP-MAP: ' + line);\n          } catch (e) {\n            parsingError = new Error('Malformed X-TIMESTAMP-MAP: ' + line);\n          }\n          // Return without parsing X-TIMESTAMP-MAP line.\n          return;\n        } else if (line === '') {\n          inHeader = false;\n        }\n      }\n      // Parse line by default.\n      parser.parse(line + '\\n');\n    });\n\n    parser.flush();\n  }\n};\n\n/* harmony default export */ var webvtt_parser = (WebVTTParser);\n// CONCATENATED MODULE: ./src/controller/timeline-controller.js\nfunction timeline_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction timeline_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction timeline_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * Timeline Controller\n*/\n\n\n\n\n\n\n\n\n\nfunction reuseVttTextTrack(inUseTrack, manifestTrack) {\n  return inUseTrack && inUseTrack.label === manifestTrack.name && !(inUseTrack.textTrack1 || inUseTrack.textTrack2);\n}\n\nfunction intersection(x1, x2, y1, y2) {\n  return Math.min(x2, y2) - Math.max(x1, y1);\n}\n\nvar timeline_controller_TimelineController = function (_EventHandler) {\n  timeline_controller__inherits(TimelineController, _EventHandler);\n\n  function TimelineController(hls) {\n    timeline_controller__classCallCheck(this, TimelineController);\n\n    var _this = timeline_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHING, events[\"a\" /* default */].MEDIA_DETACHING, events[\"a\" /* default */].FRAG_PARSING_USERDATA, events[\"a\" /* default */].FRAG_DECRYPTED, events[\"a\" /* default */].MANIFEST_LOADING, events[\"a\" /* default */].MANIFEST_LOADED, events[\"a\" /* default */].FRAG_LOADED, events[\"a\" /* default */].LEVEL_SWITCHING, events[\"a\" /* default */].INIT_PTS_FOUND));\n\n    _this.hls = hls;\n    _this.config = hls.config;\n    _this.enabled = true;\n    _this.Cues = hls.config.cueHandler;\n    _this.textTracks = [];\n    _this.tracks = [];\n    _this.unparsedVttFrags = [];\n    _this.initPTS = undefined;\n    _this.cueRanges = [];\n\n    if (_this.config.enableCEA708Captions) {\n      var channel1 = new output_filter(_this, 1);\n      var channel2 = new output_filter(_this, 2);\n\n      _this.cea608Parser = new cea_608_parser(0, channel1, channel2);\n    }\n    return _this;\n  }\n\n  TimelineController.prototype.addCues = function addCues(channel, startTime, endTime, screen) {\n    // skip cues which overlap more than 50% with previously parsed time ranges\n    var ranges = this.cueRanges;\n    var merged = false;\n    for (var i = ranges.length; i--;) {\n      var cueRange = ranges[i];\n      var overlap = intersection(cueRange[0], cueRange[1], startTime, endTime);\n      if (overlap >= 0) {\n        cueRange[0] = Math.min(cueRange[0], startTime);\n        cueRange[1] = Math.max(cueRange[1], endTime);\n        merged = true;\n        if (overlap / (endTime - startTime) > 0.5) return;\n      }\n    }\n    if (!merged) ranges.push([startTime, endTime]);\n\n    this.Cues.newCue(this[channel], startTime, endTime, screen);\n  };\n\n  // Triggered when an initial PTS is found; used for synchronisation of WebVTT.\n\n\n  TimelineController.prototype.onInitPtsFound = function onInitPtsFound(data) {\n    var _this2 = this;\n\n    if (typeof this.initPTS === 'undefined') this.initPTS = data.initPTS;\n\n    // Due to asynchrony, initial PTS may arrive later than the first VTT fragments are loaded.\n    // Parse any unparsed fragments upon receiving the initial PTS.\n    if (this.unparsedVttFrags.length) {\n      this.unparsedVttFrags.forEach(function (frag) {\n        _this2.onFragLoaded(frag);\n      });\n      this.unparsedVttFrags = [];\n    }\n  };\n\n  TimelineController.prototype.getExistingTrack = function getExistingTrack(channelNumber) {\n    var media = this.media;\n    if (media) {\n      for (var i = 0; i < media.textTracks.length; i++) {\n        var textTrack = media.textTracks[i];\n        var propName = 'textTrack' + channelNumber;\n        if (textTrack[propName] === true) return textTrack;\n      }\n    }\n    return null;\n  };\n\n  TimelineController.prototype.createCaptionsTrack = function createCaptionsTrack(track) {\n    var trackVar = 'textTrack' + track;\n    if (!this[trackVar]) {\n      // Enable reuse of existing text track.\n      var existingTrack = this.getExistingTrack(track);\n      if (!existingTrack) {\n        var textTrack = this.createTextTrack('captions', this.config['captionsTextTrack' + track + 'Label'], this.config['captionsTextTrack' + track + 'LanguageCode']);\n        if (textTrack) {\n          textTrack[trackVar] = true;\n          this[trackVar] = textTrack;\n        }\n      } else {\n        this[trackVar] = existingTrack;\n        clearCurrentCues(this[trackVar]);\n\n        sendAddTrackEvent(this[trackVar], this.media);\n      }\n    }\n  };\n\n  TimelineController.prototype.createTextTrack = function createTextTrack(kind, label, lang) {\n    var media = this.media;\n    if (media) return media.addTextTrack(kind, label, lang);\n  };\n\n  TimelineController.prototype.destroy = function destroy() {\n    event_handler.prototype.destroy.call(this);\n  };\n\n  TimelineController.prototype.onMediaAttaching = function onMediaAttaching(data) {\n    this.media = data.media;\n    this._cleanTracks();\n  };\n\n  TimelineController.prototype.onMediaDetaching = function onMediaDetaching() {\n    clearCurrentCues(this.textTrack1);\n    clearCurrentCues(this.textTrack2);\n  };\n\n  TimelineController.prototype.onManifestLoading = function onManifestLoading() {\n    this.lastSn = -1; // Detect discontiguity in fragment parsing\n    this.prevCC = -1;\n    this.vttCCs = { ccOffset: 0, presentationOffset: 0 }; // Detect discontinuity in subtitle manifests\n    this._cleanTracks();\n  };\n\n  TimelineController.prototype._cleanTracks = function _cleanTracks() {\n    // clear outdated subtitles\n    var media = this.media;\n    if (media) {\n      var textTracks = media.textTracks;\n      if (textTracks) {\n        for (var i = 0; i < textTracks.length; i++) {\n          clearCurrentCues(textTracks[i]);\n        }\n      }\n    }\n  };\n\n  TimelineController.prototype.onManifestLoaded = function onManifestLoaded(data) {\n    var _this3 = this;\n\n    this.textTracks = [];\n    this.unparsedVttFrags = this.unparsedVttFrags || [];\n    this.initPTS = undefined;\n    this.cueRanges = [];\n\n    if (this.config.enableWebVTT) {\n      this.tracks = data.subtitles || [];\n      var inUseTracks = this.media ? this.media.textTracks : [];\n\n      this.tracks.forEach(function (track, index) {\n        var textTrack = void 0;\n        if (index < inUseTracks.length) {\n          var inUseTrack = inUseTracks[index];\n          // Reuse tracks with the same label, but do not reuse 608/708 tracks\n          if (reuseVttTextTrack(inUseTrack, track)) textTrack = inUseTrack;\n        }\n        if (!textTrack) textTrack = _this3.createTextTrack('subtitles', track.name, track.lang);\n\n        if (track.default) textTrack.mode = _this3.hls.subtitleDisplay ? 'showing' : 'hidden';else textTrack.mode = 'disabled';\n\n        _this3.textTracks.push(textTrack);\n      });\n    }\n  };\n\n  TimelineController.prototype.onLevelSwitching = function onLevelSwitching() {\n    this.enabled = this.hls.currentLevel.closedCaptions !== 'NONE';\n  };\n\n  TimelineController.prototype.onFragLoaded = function onFragLoaded(data) {\n    var frag = data.frag,\n        payload = data.payload;\n    if (frag.type === 'main') {\n      var sn = frag.sn;\n      // if this frag isn't contiguous, clear the parser so cues with bad start/end times aren't added to the textTrack\n      if (sn !== this.lastSn + 1) {\n        var cea608Parser = this.cea608Parser;\n        if (cea608Parser) cea608Parser.reset();\n      }\n      this.lastSn = sn;\n    } // eslint-disable-line brace-style\n    // If fragment is subtitle type, parse as WebVTT.\n    else if (frag.type === 'subtitle') {\n        if (payload.byteLength) {\n          // We need an initial synchronisation PTS. Store fragments as long as none has arrived.\n          if (typeof this.initPTS === 'undefined') {\n            this.unparsedVttFrags.push(data);\n            return;\n          }\n\n          var decryptData = frag.decryptdata;\n          // If the subtitles are not encrypted, parse VTTs now. Otherwise, we need to wait.\n          if (decryptData == null || decryptData.key == null || decryptData.method !== 'AES-128') this._parseVTTs(frag, payload);\n        } else {\n          // In case there is no payload, finish unsuccessfully.\n          this.hls.trigger(events[\"a\" /* default */].SUBTITLE_FRAG_PROCESSED, { success: false, frag: frag });\n        }\n      }\n  };\n\n  TimelineController.prototype._parseVTTs = function _parseVTTs(frag, payload) {\n    var vttCCs = this.vttCCs;\n    if (!vttCCs[frag.cc]) {\n      vttCCs[frag.cc] = { start: frag.start, prevCC: this.prevCC, new: true };\n      this.prevCC = frag.cc;\n    }\n    var textTracks = this.textTracks,\n        hls = this.hls;\n\n    // Parse the WebVTT file contents.\n    webvtt_parser.parse(payload, this.initPTS, vttCCs, frag.cc, function (cues) {\n      var currentTrack = textTracks[frag.trackId];\n      // WebVTTParser.parse is an async method and if the currently selected text track mode is set to \"disabled\"\n      // before parsing is done then don't try to access currentTrack.cues.getCueById as cues will be null\n      // and trying to access getCueById method of cues will throw an exception\n      if (currentTrack.mode === 'disabled') {\n        hls.trigger(events[\"a\" /* default */].SUBTITLE_FRAG_PROCESSED, { success: false, frag: frag });\n        return;\n      }\n      // Add cues and trigger event with success true.\n      cues.forEach(function (cue) {\n        // Sometimes there are cue overlaps on segmented vtts so the same\n        // cue can appear more than once in different vtt files.\n        // This avoid showing duplicated cues with same timecode and text.\n        if (!currentTrack.cues.getCueById(cue.id)) {\n          try {\n            currentTrack.addCue(cue);\n          } catch (err) {\n            var textTrackCue = new window.TextTrackCue(cue.startTime, cue.endTime, cue.text);\n            textTrackCue.id = cue.id;\n            currentTrack.addCue(textTrackCue);\n          }\n        }\n      });\n      hls.trigger(events[\"a\" /* default */].SUBTITLE_FRAG_PROCESSED, { success: true, frag: frag });\n    }, function (e) {\n      // Something went wrong while parsing. Trigger event with success false.\n      logger[\"b\" /* logger */].log('Failed to parse VTT cue: ' + e);\n      hls.trigger(events[\"a\" /* default */].SUBTITLE_FRAG_PROCESSED, { success: false, frag: frag });\n    });\n  };\n\n  TimelineController.prototype.onFragDecrypted = function onFragDecrypted(data) {\n    var decryptedData = data.payload,\n        frag = data.frag;\n\n    if (frag.type === 'subtitle') {\n      if (typeof this.initPTS === 'undefined') {\n        this.unparsedVttFrags.push(data);\n        return;\n      }\n\n      this._parseVTTs(frag, decryptedData);\n    }\n  };\n\n  TimelineController.prototype.onFragParsingUserdata = function onFragParsingUserdata(data) {\n    // push all of the CEA-708 messages into the interpreter\n    // immediately. It will create the proper timestamps based on our PTS value\n    if (this.enabled && this.config.enableCEA708Captions) {\n      for (var i = 0; i < data.samples.length; i++) {\n        var ccdatas = this.extractCea608Data(data.samples[i].bytes);\n        this.cea608Parser.addData(data.samples[i].pts, ccdatas);\n      }\n    }\n  };\n\n  TimelineController.prototype.extractCea608Data = function extractCea608Data(byteArray) {\n    var count = byteArray[0] & 31;\n    var position = 2;\n    var tmpByte = void 0,\n        ccbyte1 = void 0,\n        ccbyte2 = void 0,\n        ccValid = void 0,\n        ccType = void 0;\n    var actualCCBytes = [];\n\n    for (var j = 0; j < count; j++) {\n      tmpByte = byteArray[position++];\n      ccbyte1 = 0x7F & byteArray[position++];\n      ccbyte2 = 0x7F & byteArray[position++];\n      ccValid = (4 & tmpByte) !== 0;\n      ccType = 3 & tmpByte;\n\n      if (ccbyte1 === 0 && ccbyte2 === 0) continue;\n\n      if (ccValid) {\n        if (ccType === 0) {\n          // || ccType === 1\n          actualCCBytes.push(ccbyte1);\n          actualCCBytes.push(ccbyte2);\n        }\n      }\n    }\n    return actualCCBytes;\n  };\n\n  return TimelineController;\n}(event_handler);\n\n/* harmony default export */ var timeline_controller = (timeline_controller_TimelineController);\n// CONCATENATED MODULE: ./src/controller/subtitle-track-controller.js\nvar subtitle_track_controller__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction subtitle_track_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction subtitle_track_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction subtitle_track_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * subtitle track controller\n*/\n\n\n\n\n\nfunction filterSubtitleTracks(textTrackList) {\n  var tracks = [];\n  for (var i = 0; i < textTrackList.length; i++) {\n    if (textTrackList[i].kind === 'subtitles') tracks.push(textTrackList[i]);\n  }\n  return tracks;\n}\n\nvar subtitle_track_controller_SubtitleTrackController = function (_EventHandler) {\n  subtitle_track_controller__inherits(SubtitleTrackController, _EventHandler);\n\n  function SubtitleTrackController(hls) {\n    subtitle_track_controller__classCallCheck(this, SubtitleTrackController);\n\n    var _this = subtitle_track_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHED, events[\"a\" /* default */].MEDIA_DETACHING, events[\"a\" /* default */].MANIFEST_LOADING, events[\"a\" /* default */].MANIFEST_LOADED, events[\"a\" /* default */].SUBTITLE_TRACK_LOADED));\n\n    _this.tracks = [];\n    _this.trackId = -1;\n    _this.media = undefined;\n\n    /**\n     * @member {boolean} subtitleDisplay Enable/disable subtitle display rendering\n     */\n    _this.subtitleDisplay = false;\n    return _this;\n  }\n\n  SubtitleTrackController.prototype._onTextTracksChanged = function _onTextTracksChanged() {\n    // Media is undefined when switching streams via loadSource()\n    if (!this.media) return;\n\n    var trackId = -1;\n    var tracks = filterSubtitleTracks(this.media.textTracks);\n    for (var id = 0; id < tracks.length; id++) {\n      if (tracks[id].mode === 'hidden') {\n        // Do not break in case there is a following track with showing.\n        trackId = id;\n      } else if (tracks[id].mode === 'showing') {\n        trackId = id;\n        break;\n      }\n    }\n\n    // Setting current subtitleTrack will invoke code.\n    this.subtitleTrack = trackId;\n  };\n\n  SubtitleTrackController.prototype.destroy = function destroy() {\n    event_handler.prototype.destroy.call(this);\n  };\n\n  // Listen for subtitle track change, then extract the current track ID.\n\n\n  SubtitleTrackController.prototype.onMediaAttached = function onMediaAttached(data) {\n    var _this2 = this;\n\n    this.media = data.media;\n    if (!this.media) return;\n\n    if (this.queuedDefaultTrack !== undefined) {\n      this.subtitleTrack = this.queuedDefaultTrack;\n      delete this.queuedDefaultTrack;\n    }\n\n    this.trackChangeListener = this._onTextTracksChanged.bind(this);\n\n    this.useTextTrackPolling = !(this.media.textTracks && 'onchange' in this.media.textTracks);\n    if (this.useTextTrackPolling) {\n      this.subtitlePollingInterval = setInterval(function () {\n        _this2.trackChangeListener();\n      }, 500);\n    } else {\n      this.media.textTracks.addEventListener('change', this.trackChangeListener);\n    }\n  };\n\n  SubtitleTrackController.prototype.onMediaDetaching = function onMediaDetaching() {\n    if (!this.media) return;\n\n    if (this.useTextTrackPolling) clearInterval(this.subtitlePollingInterval);else this.media.textTracks.removeEventListener('change', this.trackChangeListener);\n\n    this.media = undefined;\n  };\n\n  // Reset subtitle tracks on manifest loading\n\n\n  SubtitleTrackController.prototype.onManifestLoading = function onManifestLoading() {\n    this.tracks = [];\n    this.trackId = -1;\n  };\n\n  // Fired whenever a new manifest is loaded.\n\n\n  SubtitleTrackController.prototype.onManifestLoaded = function onManifestLoaded(data) {\n    var _this3 = this;\n\n    var tracks = data.subtitles || [];\n    this.tracks = tracks;\n    this.trackId = -1;\n    this.hls.trigger(events[\"a\" /* default */].SUBTITLE_TRACKS_UPDATED, { subtitleTracks: tracks });\n\n    // loop through available subtitle tracks and autoselect default if needed\n    // TODO: improve selection logic to handle forced, etc\n    tracks.forEach(function (track) {\n      if (track.default) {\n        // setting this.subtitleTrack will trigger internal logic\n        // if media has not been attached yet, it will fail\n        // we keep a reference to the default track id\n        // and we'll set subtitleTrack when onMediaAttached is triggered\n        if (_this3.media) _this3.subtitleTrack = track.id;else _this3.queuedDefaultTrack = track.id;\n      }\n    });\n  };\n\n  // Trigger subtitle track playlist reload.\n\n\n  SubtitleTrackController.prototype.onTick = function onTick() {\n    var trackId = this.trackId;\n    var subtitleTrack = this.tracks[trackId];\n    if (!subtitleTrack) return;\n\n    var details = subtitleTrack.details;\n    // check if we need to load playlist for this subtitle Track\n    if (details === undefined || details.live === true) {\n      // track not retrieved yet, or live playlist we need to (re)load it\n      logger[\"b\" /* logger */].log('(re)loading playlist for subtitle track ' + trackId);\n      this.hls.trigger(events[\"a\" /* default */].SUBTITLE_TRACK_LOADING, { url: subtitleTrack.url, id: trackId });\n    }\n  };\n\n  SubtitleTrackController.prototype.onSubtitleTrackLoaded = function onSubtitleTrackLoaded(data) {\n    var _this4 = this;\n\n    if (data.id < this.tracks.length) {\n      logger[\"b\" /* logger */].log('subtitle track ' + data.id + ' loaded');\n      this.tracks[data.id].details = data.details;\n      // check if current playlist is a live playlist\n      if (data.details.live && !this.timer) {\n        // if live playlist we will have to reload it periodically\n        // set reload period to playlist target duration\n        this.timer = setInterval(function () {\n          _this4.onTick();\n        }, 1000 * data.details.targetduration, this);\n      }\n      if (!data.details.live && this.timer) {\n        // playlist is not live and timer is armed : stopping it\n        clearInterval(this.timer);\n        this.timer = null;\n      }\n    }\n  };\n\n  /** get alternate subtitle tracks list from playlist **/\n\n\n  SubtitleTrackController.prototype.setSubtitleTrackInternal = function setSubtitleTrackInternal(newId) {\n    // check if level idx is valid\n    if (newId < -1 || newId >= this.tracks.length) return;\n\n    // stopping live reloading timer if any\n    if (this.timer) {\n      clearInterval(this.timer);\n      this.timer = null;\n    }\n\n    var textTracks = filterSubtitleTracks(this.media.textTracks);\n\n    // hide currently enabled subtitle track\n    if (this.trackId !== -1) textTracks[this.trackId].mode = 'disabled';\n\n    this.trackId = newId;\n    logger[\"b\" /* logger */].log('switching to subtitle track ' + newId);\n    this.hls.trigger(events[\"a\" /* default */].SUBTITLE_TRACK_SWITCH, { id: newId });\n\n    if (newId === -1) return;\n\n    var subtitleTrack = this.tracks[newId];\n    if (newId < textTracks.length) textTracks[newId].mode = this.subtitleDisplay ? 'showing' : 'hidden';\n\n    // check if we need to load playlist for this subtitle Track\n    var details = subtitleTrack.details;\n    if (details === undefined || details.live === true) {\n      // track not retrieved yet, or live playlist we need to (re)load it\n      logger[\"b\" /* logger */].log('(re)loading playlist for subtitle track ' + newId);\n      this.hls.trigger(events[\"a\" /* default */].SUBTITLE_TRACK_LOADING, { url: subtitleTrack.url, id: newId });\n    }\n  };\n\n  subtitle_track_controller__createClass(SubtitleTrackController, [{\n    key: 'subtitleTracks',\n    get: function get() {\n      return this.tracks;\n    }\n\n    /** get index of the selected subtitle track (index in subtitle track lists) **/\n\n  }, {\n    key: 'subtitleTrack',\n    get: function get() {\n      return this.trackId;\n    }\n\n    /** select a subtitle track, based on its index in subtitle track lists**/\n    ,\n    set: function set(subtitleTrackId) {\n      if (this.trackId !== subtitleTrackId) {\n        // || this.tracks[subtitleTrackId].details === undefined) {\n        this.setSubtitleTrackInternal(subtitleTrackId);\n      }\n    }\n  }]);\n\n  return SubtitleTrackController;\n}(event_handler);\n\n/* harmony default export */ var subtitle_track_controller = (subtitle_track_controller_SubtitleTrackController);\n// EXTERNAL MODULE: ./src/crypt/decrypter.js + 3 modules\nvar decrypter = __webpack_require__(5);\n\n// CONCATENATED MODULE: ./src/controller/subtitle-stream-controller.js\nfunction subtitle_stream_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction subtitle_stream_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction subtitle_stream_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/*\n * Subtitle Stream Controller\n*/\n\n\n\n\n\n\nvar subtitle_stream_controller_State = {\n  STOPPED: 'STOPPED',\n  IDLE: 'IDLE',\n  KEY_LOADING: 'KEY_LOADING',\n  FRAG_LOADING: 'FRAG_LOADING'\n};\n\nvar subtitle_stream_controller_SubtitleStreamController = function (_TaskLoop) {\n  subtitle_stream_controller__inherits(SubtitleStreamController, _TaskLoop);\n\n  function SubtitleStreamController(hls) {\n    subtitle_stream_controller__classCallCheck(this, SubtitleStreamController);\n\n    var _this = subtitle_stream_controller__possibleConstructorReturn(this, _TaskLoop.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHED, events[\"a\" /* default */].ERROR, events[\"a\" /* default */].KEY_LOADED, events[\"a\" /* default */].FRAG_LOADED, events[\"a\" /* default */].SUBTITLE_TRACKS_UPDATED, events[\"a\" /* default */].SUBTITLE_TRACK_SWITCH, events[\"a\" /* default */].SUBTITLE_TRACK_LOADED, events[\"a\" /* default */].SUBTITLE_FRAG_PROCESSED));\n\n    _this.config = hls.config;\n    _this.vttFragSNsProcessed = {};\n    _this.vttFragQueues = undefined;\n    _this.currentlyProcessing = null;\n    _this.state = subtitle_stream_controller_State.STOPPED;\n    _this.currentTrackId = -1;\n    _this.decrypter = new decrypter[\"a\" /* default */](hls.observer, hls.config);\n    return _this;\n  }\n\n  SubtitleStreamController.prototype.onHandlerDestroyed = function onHandlerDestroyed() {\n    this.state = subtitle_stream_controller_State.STOPPED;\n  };\n\n  // Remove all queued items and create a new, empty queue for each track.\n\n\n  SubtitleStreamController.prototype.clearVttFragQueues = function clearVttFragQueues() {\n    var _this2 = this;\n\n    this.vttFragQueues = {};\n    this.tracks.forEach(function (track) {\n      _this2.vttFragQueues[track.id] = [];\n    });\n  };\n\n  // If no frag is being processed and queue isn't empty, initiate processing of next frag in line.\n\n\n  SubtitleStreamController.prototype.nextFrag = function nextFrag() {\n    if (this.currentlyProcessing === null && this.currentTrackId > -1 && this.vttFragQueues[this.currentTrackId].length) {\n      var frag = this.currentlyProcessing = this.vttFragQueues[this.currentTrackId].shift();\n      this.fragCurrent = frag;\n      this.hls.trigger(events[\"a\" /* default */].FRAG_LOADING, { frag: frag });\n      this.state = subtitle_stream_controller_State.FRAG_LOADING;\n    }\n  };\n\n  // When fragment has finished processing, add sn to list of completed if successful.\n\n\n  SubtitleStreamController.prototype.onSubtitleFragProcessed = function onSubtitleFragProcessed(data) {\n    if (data.success) this.vttFragSNsProcessed[data.frag.trackId].push(data.frag.sn);\n\n    this.currentlyProcessing = null;\n    this.state = subtitle_stream_controller_State.IDLE;\n    this.nextFrag();\n  };\n\n  SubtitleStreamController.prototype.onMediaAttached = function onMediaAttached() {\n    this.state = subtitle_stream_controller_State.IDLE;\n  };\n\n  // If something goes wrong, procede to next frag, if we were processing one.\n\n\n  SubtitleStreamController.prototype.onError = function onError(data) {\n    var frag = data.frag;\n    // don't handle frag error not related to subtitle fragment\n    if (frag && frag.type !== 'subtitle') return;\n\n    if (this.currentlyProcessing) {\n      this.currentlyProcessing = null;\n      this.nextFrag();\n    }\n  };\n\n  SubtitleStreamController.prototype.doTick = function doTick() {\n    var _this3 = this;\n\n    switch (this.state) {\n      case subtitle_stream_controller_State.IDLE:\n        var tracks = this.tracks;\n        var trackId = this.currentTrackId;\n\n        var processedFragSNs = this.vttFragSNsProcessed[trackId],\n            fragQueue = this.vttFragQueues[trackId],\n            currentFragSN = this.currentlyProcessing ? this.currentlyProcessing.sn : -1;\n\n        var alreadyProcessed = function alreadyProcessed(frag) {\n          return processedFragSNs.indexOf(frag.sn) > -1;\n        };\n\n        var alreadyInQueue = function alreadyInQueue(frag) {\n          return fragQueue.some(function (fragInQueue) {\n            return fragInQueue.sn === frag.sn;\n          });\n        };\n\n        // exit if tracks don't exist\n        if (!tracks) break;\n\n        var trackDetails;\n\n        if (trackId < tracks.length) trackDetails = tracks[trackId].details;\n\n        if (typeof trackDetails === 'undefined') break;\n\n        // Add all fragments that haven't been, aren't currently being and aren't waiting to be processed, to queue.\n        trackDetails.fragments.forEach(function (frag) {\n          if (!(alreadyProcessed(frag) || frag.sn === currentFragSN || alreadyInQueue(frag))) {\n            // Load key if subtitles are encrypted\n            if (frag.decryptdata && frag.decryptdata.uri != null && frag.decryptdata.key == null) {\n              logger[\"b\" /* logger */].log('Loading key for ' + frag.sn);\n              _this3.state = subtitle_stream_controller_State.KEY_LOADING;\n              _this3.hls.trigger(events[\"a\" /* default */].KEY_LOADING, { frag: frag });\n            } else {\n              // Frags don't know their subtitle track ID, so let's just add that...\n              frag.trackId = trackId;\n              fragQueue.push(frag);\n              _this3.nextFrag();\n            }\n          }\n        });\n    }\n  };\n\n  // Got all new subtitle tracks.\n\n\n  SubtitleStreamController.prototype.onSubtitleTracksUpdated = function onSubtitleTracksUpdated(data) {\n    var _this4 = this;\n\n    logger[\"b\" /* logger */].log('subtitle tracks updated');\n    this.tracks = data.subtitleTracks;\n    this.clearVttFragQueues();\n    this.vttFragSNsProcessed = {};\n    this.tracks.forEach(function (track) {\n      _this4.vttFragSNsProcessed[track.id] = [];\n    });\n  };\n\n  SubtitleStreamController.prototype.onSubtitleTrackSwitch = function onSubtitleTrackSwitch(data) {\n    this.currentTrackId = data.id;\n    if (this.currentTrackId === -1) return;\n\n    // Check if track was already loaded and if so make sure we finish\n    // downloading its frags, if not all have been downloaded yet\n    var currentTrack = this.tracks[this.currentTrackId];\n    var details = currentTrack.details;\n    if (details !== undefined) this.tick();\n  };\n\n  // Got a new set of subtitle fragments.\n\n\n  SubtitleStreamController.prototype.onSubtitleTrackLoaded = function onSubtitleTrackLoaded() {\n    this.tick();\n  };\n\n  SubtitleStreamController.prototype.onKeyLoaded = function onKeyLoaded() {\n    if (this.state === subtitle_stream_controller_State.KEY_LOADING) {\n      this.state = subtitle_stream_controller_State.IDLE;\n      this.tick();\n    }\n  };\n\n  SubtitleStreamController.prototype.onFragLoaded = function onFragLoaded(data) {\n    var fragCurrent = this.fragCurrent,\n        decryptData = data.frag.decryptdata;\n    var fragLoaded = data.frag,\n        hls = this.hls;\n    if (this.state === subtitle_stream_controller_State.FRAG_LOADING && fragCurrent && data.frag.type === 'subtitle' && fragCurrent.sn === data.frag.sn) {\n      // check to see if the payload needs to be decrypted\n      if (data.payload.byteLength > 0 && decryptData != null && decryptData.key != null && decryptData.method === 'AES-128') {\n        var startTime = void 0;\n        try {\n          startTime = performance.now();\n        } catch (error) {\n          startTime = Date.now();\n        }\n        // decrypt the subtitles\n        this.decrypter.decrypt(data.payload, decryptData.key.buffer, decryptData.iv.buffer, function (decryptedData) {\n          var endTime = void 0;\n          try {\n            endTime = performance.now();\n          } catch (error) {\n            endTime = Date.now();\n          }\n          hls.trigger(events[\"a\" /* default */].FRAG_DECRYPTED, { frag: fragLoaded, payload: decryptedData, stats: { tstart: startTime, tdecrypt: endTime } });\n        });\n      }\n    }\n  };\n\n  return SubtitleStreamController;\n}(task_loop);\n\n/* harmony default export */ var subtitle_stream_controller = (subtitle_stream_controller_SubtitleStreamController);\n// CONCATENATED MODULE: ./src/controller/eme-controller.js\nvar eme_controller__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction eme_controller__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction eme_controller__possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction eme_controller__inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n/**\n * @author Stephan Hesse <disparat@gmail.com> | <tchakabam@gmail.com>\n *\n * DRM support for Hls.js\n */\n\n\n\n\n\n\n\nvar MAX_LICENSE_REQUEST_FAILURES = 3;\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess\n */\nvar KeySystems = {\n  WIDEVINE: 'com.widevine.alpha',\n  PLAYREADY: 'com.microsoft.playready'\n};\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration\n * @param {Array<string>} audioCodecs List of required audio codecs to support\n * @param {Array<string>} videoCodecs List of required video codecs to support\n * @param {object} drmSystemOptions Optional parameters/requirements for the key-system\n * @returns {Array<MediaSystemConfiguration>} An array of supported configurations\n */\n\nvar createWidevineMediaKeySystemConfigurations = function createWidevineMediaKeySystemConfigurations(audioCodecs, videoCodecs, drmSystemOptions) {\n  /* jshint ignore:line */\n  var baseConfig = {\n    // initDataTypes: ['keyids', 'mp4'],\n    // label: \"\",\n    // persistentState: \"not-allowed\", // or \"required\" ?\n    // distinctiveIdentifier: \"not-allowed\", // or \"required\" ?\n    // sessionTypes: ['temporary'],\n    videoCapabilities: [\n      // { contentType: 'video/mp4; codecs=\"avc1.42E01E\"' }\n    ]\n  };\n\n  videoCodecs.forEach(function (codec) {\n    baseConfig.videoCapabilities.push({\n      contentType: 'video/mp4; codecs=\"' + codec + '\"'\n    });\n  });\n\n  return [baseConfig];\n};\n\n/**\n * The idea here is to handle key-system (and their respective platforms) specific configuration differences\n * in order to work with the local requestMediaKeySystemAccess method.\n *\n * We can also rule-out platform-related key-system support at this point by throwing an error or returning null.\n *\n * @param {string} keySystem Identifier for the key-system, see `KeySystems` enum\n * @param {Array<string>} audioCodecs List of required audio codecs to support\n * @param {Array<string>} videoCodecs List of required video codecs to support\n * @returns {Array<MediaSystemConfiguration> | null} A non-empty Array of MediaKeySystemConfiguration objects or `null`\n */\nvar getSupportedMediaKeySystemConfigurations = function getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs) {\n  switch (keySystem) {\n    case KeySystems.WIDEVINE:\n      return createWidevineMediaKeySystemConfigurations(audioCodecs, videoCodecs);\n    default:\n      throw Error('Unknown key-system: ' + keySystem);\n  }\n};\n\n/**\n * Controller to deal with encrypted media extensions (EME)\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API\n *\n * @class\n * @constructor\n */\n\nvar eme_controller_EMEController = function (_EventHandler) {\n  eme_controller__inherits(EMEController, _EventHandler);\n\n  /**\n     * @constructs\n     * @param {Hls} hls Our Hls.js instance\n     */\n  function EMEController(hls) {\n    eme_controller__classCallCheck(this, EMEController);\n\n    var _this = eme_controller__possibleConstructorReturn(this, _EventHandler.call(this, hls, events[\"a\" /* default */].MEDIA_ATTACHED, events[\"a\" /* default */].MANIFEST_PARSED));\n\n    _this._widevineLicenseUrl = hls.config.widevineLicenseUrl;\n    _this._licenseXhrSetup = hls.config.licenseXhrSetup;\n    _this._emeEnabled = hls.config.emeEnabled;\n\n    _this._requestMediaKeySystemAccess = hls.config.requestMediaKeySystemAccessFunc;\n\n    _this._mediaKeysList = [];\n    _this._media = null;\n\n    _this._hasSetMediaKeys = false;\n    _this._isMediaEncrypted = false;\n\n    _this._requestLicenseFailureCount = 0;\n    return _this;\n  }\n\n  /**\n     *\n     * @param {string} keySystem Identifier for the key-system, see `KeySystems` enum\n     * @returns {string} License server URL for key-system (if any configured, otherwise causes error)\n     */\n\n\n  EMEController.prototype.getLicenseServerUrl = function getLicenseServerUrl(keySystem) {\n    var url = void 0;\n    switch (keySystem) {\n      case KeySystems.WIDEVINE:\n        url = this._widevineLicenseUrl;\n        break;\n      default:\n        url = null;\n        break;\n    }\n\n    if (!url) {\n      logger[\"b\" /* logger */].error('No license server URL configured for key-system \"' + keySystem + '\"');\n      this.hls.trigger(events[\"a\" /* default */].ERROR, {\n        type: errors[\"b\" /* ErrorTypes */].KEY_SYSTEM_ERROR,\n        details: errors[\"a\" /* ErrorDetails */].KEY_SYSTEM_LICENSE_REQUEST_FAILED,\n        fatal: true\n      });\n    }\n\n    return url;\n  };\n\n  /**\n     * Requests access object and adds it to our list upon success\n     * @private\n     * @param {string} keySystem System ID (see `KeySystems`)\n     * @param {Array<string>} audioCodecs List of required audio codecs to support\n     * @param {Array<string>} videoCodecs List of required video codecs to support\n     */\n\n\n  EMEController.prototype._attemptKeySystemAccess = function _attemptKeySystemAccess(keySystem, audioCodecs, videoCodecs) {\n    var _this2 = this;\n\n    // TODO: add other DRM \"options\"\n\n    var mediaKeySystemConfigs = getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs);\n\n    if (!mediaKeySystemConfigs) {\n      logger[\"b\" /* logger */].warn('Can not create config for key-system (maybe because platform is not supported):', keySystem);\n      return;\n    }\n\n    logger[\"b\" /* logger */].log('Requesting encrypted media key-system access');\n\n    // expecting interface like window.navigator.requestMediaKeySystemAccess\n    this.requestMediaKeySystemAccess(keySystem, mediaKeySystemConfigs).then(function (mediaKeySystemAccess) {\n      _this2._onMediaKeySystemAccessObtained(keySystem, mediaKeySystemAccess);\n    }).catch(function (err) {\n      logger[\"b\" /* logger */].error('Failed to obtain key-system \"' + keySystem + '\" access:', err);\n    });\n  };\n\n  /**\n     * Handles obtaining access to a key-system\n     *\n     * @param {string} keySystem\n     * @param {MediaKeySystemAccess} mediaKeySystemAccess https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemAccess\n     */\n  EMEController.prototype._onMediaKeySystemAccessObtained = function _onMediaKeySystemAccessObtained(keySystem, mediaKeySystemAccess) {\n    var _this3 = this;\n\n    logger[\"b\" /* logger */].log('Access for key-system \"' + keySystem + '\" obtained');\n\n    var mediaKeysListItem = {\n      mediaKeys: null,\n      mediaKeysSession: null,\n      mediaKeysSessionInitialized: false,\n      mediaKeySystemAccess: mediaKeySystemAccess,\n      mediaKeySystemDomain: keySystem\n    };\n\n    this._mediaKeysList.push(mediaKeysListItem);\n\n    mediaKeySystemAccess.createMediaKeys().then(function (mediaKeys) {\n      mediaKeysListItem.mediaKeys = mediaKeys;\n\n      logger[\"b\" /* logger */].log('Media-keys created for key-system \"' + keySystem + '\"');\n\n      _this3._onMediaKeysCreated();\n    }).catch(function (err) {\n      logger[\"b\" /* logger */].error('Failed to create media-keys:', err);\n    });\n  };\n\n  /**\n     * Handles key-creation (represents access to CDM). We are going to create key-sessions upon this\n     * for all existing keys where no session exists yet.\n     */\n\n\n  EMEController.prototype._onMediaKeysCreated = function _onMediaKeysCreated() {\n    var _this4 = this;\n\n    // check for all key-list items if a session exists, otherwise, create one\n    this._mediaKeysList.forEach(function (mediaKeysListItem) {\n      if (!mediaKeysListItem.mediaKeysSession) {\n        mediaKeysListItem.mediaKeysSession = mediaKeysListItem.mediaKeys.createSession();\n        _this4._onNewMediaKeySession(mediaKeysListItem.mediaKeysSession);\n      }\n    });\n  };\n\n  /**\n     *\n     * @param {*} keySession\n     */\n\n\n  EMEController.prototype._onNewMediaKeySession = function _onNewMediaKeySession(keySession) {\n    var _this5 = this;\n\n    logger[\"b\" /* logger */].log('New key-system session ' + keySession.sessionId);\n\n    keySession.addEventListener('message', function (event) {\n      _this5._onKeySessionMessage(keySession, event.message);\n    }, false);\n  };\n\n  EMEController.prototype._onKeySessionMessage = function _onKeySessionMessage(keySession, message) {\n    logger[\"b\" /* logger */].log('Got EME message event, creating license request');\n\n    this._requestLicense(message, function (data) {\n      logger[\"b\" /* logger */].log('Received license data, updating key-session');\n      keySession.update(data);\n    });\n  };\n\n  EMEController.prototype._onMediaEncrypted = function _onMediaEncrypted(initDataType, initData) {\n    logger[\"b\" /* logger */].log('Media is encrypted using \"' + initDataType + '\" init data type');\n\n    this._isMediaEncrypted = true;\n    this._mediaEncryptionInitDataType = initDataType;\n    this._mediaEncryptionInitData = initData;\n\n    this._attemptSetMediaKeys();\n    this._generateRequestWithPreferredKeySession();\n  };\n\n  EMEController.prototype._attemptSetMediaKeys = function _attemptSetMediaKeys() {\n    if (!this._hasSetMediaKeys) {\n      // FIXME: see if we can/want/need-to really to deal with several potential key-sessions?\n      var keysListItem = this._mediaKeysList[0];\n      if (!keysListItem || !keysListItem.mediaKeys) {\n        logger[\"b\" /* logger */].error('Fatal: Media is encrypted but no CDM access or no keys have been obtained yet');\n        this.hls.trigger(events[\"a\" /* default */].ERROR, {\n          type: errors[\"b\" /* ErrorTypes */].KEY_SYSTEM_ERROR,\n          details: errors[\"a\" /* ErrorDetails */].KEY_SYSTEM_NO_KEYS,\n          fatal: true\n        });\n        return;\n      }\n\n      logger[\"b\" /* logger */].log('Setting keys for encrypted media');\n\n      this._media.setMediaKeys(keysListItem.mediaKeys);\n      this._hasSetMediaKeys = true;\n    }\n  };\n\n  EMEController.prototype._generateRequestWithPreferredKeySession = function _generateRequestWithPreferredKeySession() {\n    var _this6 = this;\n\n    // FIXME: see if we can/want/need-to really to deal with several potential key-sessions?\n    var keysListItem = this._mediaKeysList[0];\n    if (!keysListItem) {\n      logger[\"b\" /* logger */].error('Fatal: Media is encrypted but not any key-system access has been obtained yet');\n      this.hls.trigger(events[\"a\" /* default */].ERROR, {\n        type: errors[\"b\" /* ErrorTypes */].KEY_SYSTEM_ERROR,\n        details: errors[\"a\" /* ErrorDetails */].KEY_SYSTEM_NO_ACCESS,\n        fatal: true\n      });\n      return;\n    }\n\n    if (keysListItem.mediaKeysSessionInitialized) {\n      logger[\"b\" /* logger */].warn('Key-Session already initialized but requested again');\n      return;\n    }\n\n    var keySession = keysListItem.mediaKeysSession;\n    if (!keySession) {\n      logger[\"b\" /* logger */].error('Fatal: Media is encrypted but no key-session existing');\n      this.hls.trigger(events[\"a\" /* default */].ERROR, {\n        type: errors[\"b\" /* ErrorTypes */].KEY_SYSTEM_ERROR,\n        details: errors[\"a\" /* ErrorDetails */].KEY_SYSTEM_NO_SESSION,\n        fatal: true\n      });\n    }\n\n    var initDataType = this._mediaEncryptionInitDataType;\n    var initData = this._mediaEncryptionInitData;\n\n    logger[\"b\" /* logger */].log('Generating key-session request for \"' + initDataType + '\" init data type');\n\n    keysListItem.mediaKeysSessionInitialized = true;\n\n    keySession.generateRequest(initDataType, initData).then(function () {\n      logger[\"b\" /* logger */].debug('Key-session generation succeeded');\n    }).catch(function (err) {\n      logger[\"b\" /* logger */].error('Error generating key-session request:', err);\n      _this6.hls.trigger(events[\"a\" /* default */].ERROR, {\n        type: errors[\"b\" /* ErrorTypes */].KEY_SYSTEM_ERROR,\n        details: errors[\"a\" /* ErrorDetails */].KEY_SYSTEM_NO_SESSION,\n        fatal: false\n      });\n    });\n  };\n\n  /**\n     * @param {string} url License server URL\n     * @param {ArrayBuffer} keyMessage Message data issued by key-system\n     * @param {function} callback Called when XHR has succeeded\n     * @returns {XMLHttpRequest} Unsent (but opened state) XHR object\n     */\n\n\n  EMEController.prototype._createLicenseXhr = function _createLicenseXhr(url, keyMessage, callback) {\n    var xhr = new XMLHttpRequest();\n    var licenseXhrSetup = this._licenseXhrSetup;\n\n    try {\n      if (licenseXhrSetup) {\n        try {\n          licenseXhrSetup(xhr, url);\n        } catch (e) {\n          // let's try to open before running setup\n          xhr.open('POST', url, true);\n          licenseXhrSetup(xhr, url);\n        }\n      }\n      // if licenseXhrSetup did not yet call open, let's do it now\n      if (!xhr.readyState) xhr.open('POST', url, true);\n    } catch (e) {\n      // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS\n      logger[\"b\" /* logger */].error('Error setting up key-system license XHR', e);\n      this.hls.trigger(events[\"a\" /* default */].ERROR, {\n        type: errors[\"b\" /* ErrorTypes */].KEY_SYSTEM_ERROR,\n        details: errors[\"a\" /* ErrorDetails */].KEY_SYSTEM_LICENSE_REQUEST_FAILED,\n        fatal: true\n      });\n      return;\n    }\n\n    xhr.responseType = 'arraybuffer';\n    xhr.onreadystatechange = this._onLicenseRequestReadyStageChange.bind(this, xhr, url, keyMessage, callback);\n    return xhr;\n  };\n\n  /**\n     * @param {XMLHttpRequest} xhr\n     * @param {string} url License server URL\n     * @param {ArrayBuffer} keyMessage Message data issued by key-system\n     * @param {function} callback Called when XHR has succeeded\n     *\n     */\n\n\n  EMEController.prototype._onLicenseRequestReadyStageChange = function _onLicenseRequestReadyStageChange(xhr, url, keyMessage, callback) {\n    switch (xhr.readyState) {\n      case 4:\n        if (xhr.status === 200) {\n          this._requestLicenseFailureCount = 0;\n          logger[\"b\" /* logger */].log('License request succeeded');\n          callback(xhr.response);\n        } else {\n          logger[\"b\" /* logger */].error('License Request XHR failed (' + url + '). Status: ' + xhr.status + ' (' + xhr.statusText + ')');\n\n          this._requestLicenseFailureCount++;\n          if (this._requestLicenseFailureCount <= MAX_LICENSE_REQUEST_FAILURES) {\n            var attemptsLeft = MAX_LICENSE_REQUEST_FAILURES - this._requestLicenseFailureCount + 1;\n            logger[\"b\" /* logger */].warn('Retrying license request, ' + attemptsLeft + ' attempts left');\n            this._requestLicense(keyMessage, callback);\n            return;\n          }\n\n          this.hls.trigger(events[\"a\" /* default */].ERROR, {\n            type: errors[\"b\" /* ErrorTypes */].KEY_SYSTEM_ERROR,\n            details: errors[\"a\" /* ErrorDetails */].KEY_SYSTEM_LICENSE_REQUEST_FAILED,\n            fatal: true\n          });\n        }\n        break;\n    }\n  };\n\n  /**\n     * @param {object} keysListItem\n     * @param {ArrayBuffer} keyMessage\n     * @returns {ArrayBuffer} Challenge data posted to license server\n     */\n\n\n  EMEController.prototype._generateLicenseRequestChallenge = function _generateLicenseRequestChallenge(keysListItem, keyMessage) {\n    var challenge = void 0;\n\n    if (keysListItem.mediaKeySystemDomain === KeySystems.PLAYREADY) {\n      logger[\"b\" /* logger */].error('PlayReady is not supported (yet)');\n\n      // from https://github.com/MicrosoftEdge/Demos/blob/master/eme/scripts/demo.js\n      /*\n        if (this.licenseType !== this.LICENSE_TYPE_WIDEVINE) {\n            // For PlayReady CDMs, we need to dig the Challenge out of the XML.\n            var keyMessageXml = new DOMParser().parseFromString(String.fromCharCode.apply(null, new Uint16Array(keyMessage)), 'application/xml');\n            if (keyMessageXml.getElementsByTagName('Challenge')[0]) {\n                challenge = atob(keyMessageXml.getElementsByTagName('Challenge')[0].childNodes[0].nodeValue);\n            } else {\n                throw 'Cannot find <Challenge> in key message';\n            }\n            var headerNames = keyMessageXml.getElementsByTagName('name');\n            var headerValues = keyMessageXml.getElementsByTagName('value');\n            if (headerNames.length !== headerValues.length) {\n                throw 'Mismatched header <name>/<value> pair in key message';\n            }\n            for (var i = 0; i < headerNames.length; i++) {\n                xhr.setRequestHeader(headerNames[i].childNodes[0].nodeValue, headerValues[i].childNodes[0].nodeValue);\n            }\n        }\n        */\n    } else if (keysListItem.mediaKeySystemDomain === KeySystems.WIDEVINE) {\n      // For Widevine CDMs, the challenge is the keyMessage.\n      challenge = keyMessage;\n    } else {\n      logger[\"b\" /* logger */].error('Unsupported key-system:', keysListItem.mediaKeySystemDomain);\n    }\n\n    return challenge;\n  };\n\n  EMEController.prototype._requestLicense = function _requestLicense(keyMessage, callback) {\n    logger[\"b\" /* logger */].log('Requesting content license for key-system');\n\n    var keysListItem = this._mediaKeysList[0];\n    if (!keysListItem) {\n      logger[\"b\" /* logger */].error('Fatal error: Media is encrypted but no key-system access has been obtained yet');\n      this.hls.trigger(events[\"a\" /* default */].ERROR, {\n        type: errors[\"b\" /* ErrorTypes */].KEY_SYSTEM_ERROR,\n        details: errors[\"a\" /* ErrorDetails */].KEY_SYSTEM_NO_ACCESS,\n        fatal: true\n      });\n      return;\n    }\n\n    var url = this.getLicenseServerUrl(keysListItem.mediaKeySystemDomain);\n    var xhr = this._createLicenseXhr(url, keyMessage, callback);\n\n    logger[\"b\" /* logger */].log('Sending license request to URL: ' + url);\n\n    xhr.send(this._generateLicenseRequestChallenge(keysListItem, keyMessage));\n  };\n\n  EMEController.prototype.onMediaAttached = function onMediaAttached(data) {\n    var _this7 = this;\n\n    if (!this._emeEnabled) return;\n\n    var media = data.media;\n\n    // keep reference of media\n    this._media = media;\n\n    // FIXME: also handle detaching media !\n\n    media.addEventListener('encrypted', function (e) {\n      _this7._onMediaEncrypted(e.initDataType, e.initData);\n    });\n  };\n\n  EMEController.prototype.onManifestParsed = function onManifestParsed(data) {\n    if (!this._emeEnabled) return;\n\n    var audioCodecs = data.levels.map(function (level) {\n      return level.audioCodec;\n    });\n    var videoCodecs = data.levels.map(function (level) {\n      return level.videoCodec;\n    });\n\n    this._attemptKeySystemAccess(KeySystems.WIDEVINE, audioCodecs, videoCodecs);\n  };\n\n  eme_controller__createClass(EMEController, [{\n    key: 'requestMediaKeySystemAccess',\n    get: function get() {\n      if (!this._requestMediaKeySystemAccess) throw new Error('No requestMediaKeySystemAccess function configured');\n\n      return this._requestMediaKeySystemAccess;\n    }\n  }]);\n\n  return EMEController;\n}(event_handler);\n\n/* harmony default export */ var eme_controller = (eme_controller_EMEController);\n// CONCATENATED MODULE: ./src/helper/mediakeys-helper.js\nvar requestMediaKeySystemAccess = function () {\n  if (window.navigator && window.navigator.requestMediaKeySystemAccess) return window.navigator.requestMediaKeySystemAccess.bind(window.navigator);else return null;\n}();\n\n\n// CONCATENATED MODULE: ./src/config.js\n/**\n * HLS config\n */\n\n\n\n\n\n\n// import FetchLoader from './utils/fetch-loader';\n\n\n\n\n\n\n\n\n\n\n\n\nvar hlsDefaultConfig = {\n  autoStartLoad: true, // used by stream-controller\n  startPosition: -1, // used by stream-controller\n  defaultAudioCodec: undefined, // used by stream-controller\n  debug: false, // used by logger\n  capLevelOnFPSDrop: false, // used by fps-controller\n  capLevelToPlayerSize: false, // used by cap-level-controller\n  initialLiveManifestSize: 1, // used by stream-controller\n  maxBufferLength: 30, // used by stream-controller\n  maxBufferSize: 60 * 1000 * 1000, // used by stream-controller\n  maxBufferHole: 0.5, // used by stream-controller\n\n  lowBufferWatchdogPeriod: 0.5, // used by stream-controller\n  highBufferWatchdogPeriod: 3, // used by stream-controller\n  nudgeOffset: 0.1, // used by stream-controller\n  nudgeMaxRetry: 3, // used by stream-controller\n  maxFragLookUpTolerance: 0.25, // used by stream-controller\n  liveSyncDurationCount: 3, // used by stream-controller\n  liveMaxLatencyDurationCount: Infinity, // used by stream-controller\n  liveSyncDuration: undefined, // used by stream-controller\n  liveMaxLatencyDuration: undefined, // used by stream-controller\n  liveDurationInfinity: false, // used by buffer-controller\n  maxMaxBufferLength: 600, // used by stream-controller\n  enableWorker: true, // used by demuxer\n  enableSoftwareAES: true, // used by decrypter\n  manifestLoadingTimeOut: 10000, // used by playlist-loader\n  manifestLoadingMaxRetry: 1, // used by playlist-loader\n  manifestLoadingRetryDelay: 1000, // used by playlist-loader\n  manifestLoadingMaxRetryTimeout: 64000, // used by playlist-loader\n  startLevel: undefined, // used by level-controller\n  levelLoadingTimeOut: 10000, // used by playlist-loader\n  levelLoadingMaxRetry: 4, // used by playlist-loader\n  levelLoadingRetryDelay: 1000, // used by playlist-loader\n  levelLoadingMaxRetryTimeout: 64000, // used by playlist-loader\n  fragLoadingTimeOut: 20000, // used by fragment-loader\n  fragLoadingMaxRetry: 6, // used by fragment-loader\n  fragLoadingRetryDelay: 1000, // used by fragment-loader\n  fragLoadingMaxRetryTimeout: 64000, // used by fragment-loader\n  startFragPrefetch: false, // used by stream-controller\n  fpsDroppedMonitoringPeriod: 5000, // used by fps-controller\n  fpsDroppedMonitoringThreshold: 0.2, // used by fps-controller\n  appendErrorMaxRetry: 3, // used by buffer-controller\n  loader: xhr_loader,\n  // loader: FetchLoader,\n  fLoader: undefined, // used by fragment-loader\n  pLoader: undefined, // used by playlist-loader\n  xhrSetup: undefined, // used by xhr-loader\n  licenseXhrSetup: undefined, // used by eme-controller\n  // fetchSetup: undefined,\n  abrController: abr_controller,\n  bufferController: buffer_controller,\n  capLevelController: cap_level_controller,\n  fpsController: fps_controller,\n  stretchShortVideoTrack: false, // used by mp4-remuxer\n  maxAudioFramesDrift: 1, // used by mp4-remuxer\n  forceKeyFrameOnDiscontinuity: true, // used by ts-demuxer\n  abrEwmaFastLive: 3, // used by abr-controller\n  abrEwmaSlowLive: 9, // used by abr-controller\n  abrEwmaFastVoD: 3, // used by abr-controller\n  abrEwmaSlowVoD: 9, // used by abr-controller\n  abrEwmaDefaultEstimate: 5e5, // 500 kbps  // used by abr-controller\n  abrBandWidthFactor: 0.95, // used by abr-controller\n  abrBandWidthUpFactor: 0.7, // used by abr-controller\n  abrMaxWithRealBitrate: false, // used by abr-controller\n  maxStarvationDelay: 4, // used by abr-controller\n  maxLoadingDelay: 4, // used by abr-controller\n  minAutoBitrate: 0, // used by hls\n  emeEnabled: false, // used by eme-controller\n  widevineLicenseUrl: undefined, // used by eme-controller\n  requestMediaKeySystemAccessFunc: requestMediaKeySystemAccess // used by eme-controller\n};\n\nif (true) {\n  hlsDefaultConfig.subtitleStreamController = subtitle_stream_controller;\n  hlsDefaultConfig.subtitleTrackController = subtitle_track_controller;\n  hlsDefaultConfig.timelineController = timeline_controller;\n  hlsDefaultConfig.cueHandler = cues_namespaceObject; // used by timeline-controller\n  hlsDefaultConfig.enableCEA708Captions = true; // used by timeline-controller\n  hlsDefaultConfig.enableWebVTT = true; // used by timeline-controller\n  hlsDefaultConfig.captionsTextTrack1Label = 'English'; // used by timeline-controller\n  hlsDefaultConfig.captionsTextTrack1LanguageCode = 'en'; // used by timeline-controller\n  hlsDefaultConfig.captionsTextTrack2Label = 'Spanish'; // used by timeline-controller\n  hlsDefaultConfig.captionsTextTrack2LanguageCode = 'es'; // used by timeline-controller\n}\n\nif (true) {\n  hlsDefaultConfig.audioStreamController = audio_stream_controller;\n  hlsDefaultConfig.audioTrackController = audio_track_controller;\n}\n\nif (true) hlsDefaultConfig.emeController = eme_controller;\n// CONCATENATED MODULE: ./src/hls.js\nvar hls__createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction hls__classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// polyfill for IE11\n__webpack_require__(12);\n\n/**\n * @module Hls\n * @class\n * @constructor\n */\n\nvar hls_Hls = function () {\n\n  /**\n   * @type {boolean}\n   */\n  Hls.isSupported = function isSupported() {\n    return is_supported_isSupported();\n  };\n\n  /**\n   * @type {HlsEvents}\n   */\n\n\n  hls__createClass(Hls, null, [{\n    key: 'version',\n\n    /**\n     * @type {string}\n     */\n    get: function get() {\n      return \"0.9.1\";\n    }\n  }, {\n    key: 'Events',\n    get: function get() {\n      return events[\"a\" /* default */];\n    }\n\n    /**\n     * @type {HlsErrorTypes}\n     */\n\n  }, {\n    key: 'ErrorTypes',\n    get: function get() {\n      return errors[\"b\" /* ErrorTypes */];\n    }\n\n    /**\n     * @type {HlsErrorDetails}\n     */\n\n  }, {\n    key: 'ErrorDetails',\n    get: function get() {\n      return errors[\"a\" /* ErrorDetails */];\n    }\n\n    /**\n     * @type {HlsConfig}\n     */\n\n  }, {\n    key: 'DefaultConfig',\n    get: function get() {\n      if (!Hls.defaultConfig) return hlsDefaultConfig;\n\n      return Hls.defaultConfig;\n    }\n\n    /**\n     * @type {HlsConfig}\n     */\n    ,\n    set: function set(defaultConfig) {\n      Hls.defaultConfig = defaultConfig;\n    }\n\n    /**\n     * Creates an instance of an HLS client that can attach to exactly one `HTMLMediaElement`.\n     *\n     * @constructs Hls\n     * @param {HlsConfig} config\n     */\n\n  }]);\n\n  function Hls() {\n    var _this = this;\n\n    var config = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    hls__classCallCheck(this, Hls);\n\n    var defaultConfig = Hls.DefaultConfig;\n\n    if ((config.liveSyncDurationCount || config.liveMaxLatencyDurationCount) && (config.liveSyncDuration || config.liveMaxLatencyDuration)) throw new Error('Illegal hls.js config: don\\'t mix up liveSyncDurationCount/liveMaxLatencyDurationCount and liveSyncDuration/liveMaxLatencyDuration');\n\n    for (var prop in defaultConfig) {\n      if (prop in config) continue;\n      config[prop] = defaultConfig[prop];\n    }\n\n    if (config.liveMaxLatencyDurationCount !== undefined && config.liveMaxLatencyDurationCount <= config.liveSyncDurationCount) throw new Error('Illegal hls.js config: \"liveMaxLatencyDurationCount\" must be gt \"liveSyncDurationCount\"');\n\n    if (config.liveMaxLatencyDuration !== undefined && (config.liveMaxLatencyDuration <= config.liveSyncDuration || config.liveSyncDuration === undefined)) throw new Error('Illegal hls.js config: \"liveMaxLatencyDuration\" must be gt \"liveSyncDuration\"');\n\n    Object(logger[\"a\" /* enableLogs */])(config.debug);\n    this.config = config;\n    this._autoLevelCapping = -1;\n    // observer setup\n    var observer = this.observer = new events_default.a();\n    observer.trigger = function trigger(event) {\n      for (var _len = arguments.length, data = Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        data[_key - 1] = arguments[_key];\n      }\n\n      observer.emit.apply(observer, [event, event].concat(data));\n    };\n\n    observer.off = function off(event) {\n      for (var _len2 = arguments.length, data = Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n        data[_key2 - 1] = arguments[_key2];\n      }\n\n      observer.removeListener.apply(observer, [event].concat(data));\n    };\n    this.on = observer.on.bind(observer);\n    this.off = observer.off.bind(observer);\n    this.trigger = observer.trigger.bind(observer);\n\n    // core controllers and network loaders\n\n    /**\n     * @member {AbrController} abrController\n     */\n    var abrController = this.abrController = new config.abrController(this);\n\n    var bufferController = new config.bufferController(this);\n    var capLevelController = new config.capLevelController(this);\n    var fpsController = new config.fpsController(this);\n    var playListLoader = new playlist_loader(this);\n    var fragmentLoader = new fragment_loader(this);\n    var keyLoader = new key_loader(this);\n    var id3TrackController = new id3_track_controller(this);\n\n    // network controllers\n\n    /**\n     * @member {LevelController} levelController\n     */\n    var levelController = this.levelController = new level_controller(this);\n\n    // FIXME: FragmentTracker must be defined before StreamController because the order of event handling is important\n    var fragmentTracker = new fragment_tracker_FragmentTracker(this);\n\n    /**\n     * @member {StreamController} streamController\n     */\n    var streamController = this.streamController = new stream_controller(this, fragmentTracker);\n\n    var networkControllers = [levelController, streamController];\n\n    // optional audio stream controller\n    /**\n     * @var {ICoreComponent | Controller}\n     */\n    var Controller = config.audioStreamController;\n    if (Controller) networkControllers.push(new Controller(this, fragmentTracker));\n\n    /**\n     * @member {INetworkController[]} networkControllers\n     */\n    this.networkControllers = networkControllers;\n\n    /**\n     * @var {ICoreComponent[]}\n     */\n    var coreComponents = [playListLoader, fragmentLoader, keyLoader, abrController, bufferController, capLevelController, fpsController, id3TrackController, fragmentTracker];\n\n    // optional audio track and subtitle controller\n    Controller = config.audioTrackController;\n    if (Controller) {\n      var audioTrackController = new Controller(this);\n\n      /**\n       * @member {AudioTrackController} audioTrackController\n       */\n      this.audioTrackController = audioTrackController;\n      coreComponents.push(audioTrackController);\n    }\n\n    Controller = config.subtitleTrackController;\n    if (Controller) {\n      var subtitleTrackController = new Controller(this);\n\n      /**\n       * @member {SubtitleTrackController} subtitleTrackController\n       */\n      this.subtitleTrackController = subtitleTrackController;\n      coreComponents.push(subtitleTrackController);\n    }\n\n    Controller = config.emeController;\n    if (Controller) {\n      var emeController = new Controller(this);\n\n      /**\n       * @member {EMEController} emeController\n       */\n      this.emeController = emeController;\n      coreComponents.push(emeController);\n    }\n\n    // optional subtitle controller\n    [config.subtitleStreamController, config.timelineController].forEach(function (Controller) {\n      if (Controller) coreComponents.push(new Controller(_this));\n    });\n\n    /**\n     * @member {ICoreComponent[]}\n     */\n    this.coreComponents = coreComponents;\n  }\n\n  /**\n   * Dispose of the instance\n   */\n\n\n  Hls.prototype.destroy = function destroy() {\n    logger[\"b\" /* logger */].log('destroy');\n    this.trigger(events[\"a\" /* default */].DESTROYING);\n    this.detachMedia();\n    this.coreComponents.concat(this.networkControllers).forEach(function (component) {\n      component.destroy();\n    });\n    this.url = null;\n    this.observer.removeAllListeners();\n    this._autoLevelCapping = -1;\n  };\n\n  /**\n   * Attach a media element\n   * @param {HTMLMediaElement} media\n   */\n\n\n  Hls.prototype.attachMedia = function attachMedia(media) {\n    logger[\"b\" /* logger */].log('attachMedia');\n    this.media = media;\n    this.trigger(events[\"a\" /* default */].MEDIA_ATTACHING, { media: media });\n  };\n\n  /**\n   * Detach from the media\n   */\n\n\n  Hls.prototype.detachMedia = function detachMedia() {\n    logger[\"b\" /* logger */].log('detachMedia');\n    this.trigger(events[\"a\" /* default */].MEDIA_DETACHING);\n    this.media = null;\n  };\n\n  /**\n   * Set the source URL. Can be relative or absolute.\n   * @param {string} url\n   */\n\n\n  Hls.prototype.loadSource = function loadSource(url) {\n    url = url_toolkit_default.a.buildAbsoluteURL(window.location.href, url, { alwaysNormalize: true });\n    logger[\"b\" /* logger */].log('loadSource:' + url);\n    this.url = url;\n    // when attaching to a source URL, trigger a playlist load\n    this.trigger(events[\"a\" /* default */].MANIFEST_LOADING, { url: url });\n  };\n\n  /**\n   * Start loading data from the stream source.\n   * Depending on default config, client starts loading automatically when a source is set.\n   *\n   * @param {number} startPosition Set the start position to stream from\n   * @default -1 None (from earliest point)\n   */\n\n\n  Hls.prototype.startLoad = function startLoad() {\n    var startPosition = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : -1;\n\n    logger[\"b\" /* logger */].log('startLoad(' + startPosition + ')');\n    this.networkControllers.forEach(function (controller) {\n      controller.startLoad(startPosition);\n    });\n  };\n\n  /**\n   * Stop loading of any stream data.\n   */\n\n\n  Hls.prototype.stopLoad = function stopLoad() {\n    logger[\"b\" /* logger */].log('stopLoad');\n    this.networkControllers.forEach(function (controller) {\n      controller.stopLoad();\n    });\n  };\n\n  /**\n   * Swap through possible audio codecs in the stream (for example to switch from stereo to 5.1)\n   */\n\n\n  Hls.prototype.swapAudioCodec = function swapAudioCodec() {\n    logger[\"b\" /* logger */].log('swapAudioCodec');\n    this.streamController.swapAudioCodec();\n  };\n\n  /**\n   * When the media-element fails, this allows to detach and then re-attach it\n   * as one call (convenience method).\n   *\n   * Automatic recovery of media-errors by this process is configurable.\n   */\n\n\n  Hls.prototype.recoverMediaError = function recoverMediaError() {\n    logger[\"b\" /* logger */].log('recoverMediaError');\n    var media = this.media;\n    this.detachMedia();\n    this.attachMedia(media);\n  };\n\n  /**\n   * @type {QualityLevel[]}\n   */\n\n\n  hls__createClass(Hls, [{\n    key: 'levels',\n    get: function get() {\n      return this.levelController.levels;\n    }\n\n    /**\n     * Index of quality level currently played\n     * @type {number}\n     */\n\n  }, {\n    key: 'currentLevel',\n    get: function get() {\n      return this.streamController.currentLevel;\n    }\n\n    /**\n     * Set quality level index immediately .\n     * This will flush the current buffer to replace the quality asap.\n     * That means playback will interrupt at least shortly to re-buffer and re-sync eventually.\n     * @type {number} -1 for automatic level selection\n     */\n    ,\n    set: function set(newLevel) {\n      logger[\"b\" /* logger */].log('set currentLevel:' + newLevel);\n      this.loadLevel = newLevel;\n      this.streamController.immediateLevelSwitch();\n    }\n\n    /**\n     * Index of next quality level loaded as scheduled by stream controller.\n     * @type {number}\n     */\n\n  }, {\n    key: 'nextLevel',\n    get: function get() {\n      return this.streamController.nextLevel;\n    }\n\n    /**\n     * Set quality level index for next loaded data.\n     * This will switch the video quality asap, without interrupting playback.\n     * May abort current loading of data, and flush parts of buffer (outside currently played fragment region).\n     * @type {number} -1 for automatic level selection\n     */\n    ,\n    set: function set(newLevel) {\n      logger[\"b\" /* logger */].log('set nextLevel:' + newLevel);\n      this.levelController.manualLevel = newLevel;\n      this.streamController.nextLevelSwitch();\n    }\n\n    /**\n     * Return the quality level of the currently or last (of none is loaded currently) segment\n     * @type {number}\n     */\n\n  }, {\n    key: 'loadLevel',\n    get: function get() {\n      return this.levelController.level;\n    }\n\n    /**\n     * Set quality level index for next loaded data in a conservative way.\n     * This will switch the quality without flushing, but interrupt current loading.\n     * Thus the moment when the quality switch will appear in effect will only be after the already existing buffer.\n     * @type {number} newLevel -1 for automatic level selection\n     */\n    ,\n    set: function set(newLevel) {\n      logger[\"b\" /* logger */].log('set loadLevel:' + newLevel);\n      this.levelController.manualLevel = newLevel;\n    }\n\n    /**\n     * get next quality level loaded\n     * @type {number}\n     */\n\n  }, {\n    key: 'nextLoadLevel',\n    get: function get() {\n      return this.levelController.nextLoadLevel;\n    }\n\n    /**\n     * Set quality level of next loaded segment in a fully \"non-destructive\" way.\n     * Same as `loadLevel` but will wait for next switch (until current loading is done).\n     * @type {number} level\n     */\n    ,\n    set: function set(level) {\n      this.levelController.nextLoadLevel = level;\n    }\n\n    /**\n     * Return \"first level\": like a default level, if not set,\n     * falls back to index of first level referenced in manifest\n     * @type {number}\n     */\n\n  }, {\n    key: 'firstLevel',\n    get: function get() {\n      return Math.max(this.levelController.firstLevel, this.minAutoLevel);\n    }\n\n    /**\n     * Sets \"first-level\", see getter.\n     * @type {number}\n     */\n    ,\n    set: function set(newLevel) {\n      logger[\"b\" /* logger */].log('set firstLevel:' + newLevel);\n      this.levelController.firstLevel = newLevel;\n    }\n\n    /**\n     * Return start level (level of first fragment that will be played back)\n     * if not overrided by user, first level appearing in manifest will be used as start level\n     * if -1 : automatic start level selection, playback will start from level matching download bandwidth\n     * (determined from download of first segment)\n     * @type {number}\n     */\n\n  }, {\n    key: 'startLevel',\n    get: function get() {\n      return this.levelController.startLevel;\n    }\n\n    /**\n     * set  start level (level of first fragment that will be played back)\n     * if not overrided by user, first level appearing in manifest will be used as start level\n     * if -1 : automatic start level selection, playback will start from level matching download bandwidth\n     * (determined from download of first segment)\n     * @type {number} newLevel\n     */\n    ,\n    set: function set(newLevel) {\n      logger[\"b\" /* logger */].log('set startLevel:' + newLevel);\n      var hls = this;\n      // if not in automatic start level detection, ensure startLevel is greater than minAutoLevel\n      if (newLevel !== -1) newLevel = Math.max(newLevel, hls.minAutoLevel);\n\n      hls.levelController.startLevel = newLevel;\n    }\n\n    /**\n     * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\n     * @type {number}\n     */\n\n  }, {\n    key: 'autoLevelCapping',\n    get: function get() {\n      return this._autoLevelCapping;\n    }\n\n    /**\n     * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\n     * @type {number}\n     */\n    ,\n    set: function set(newLevel) {\n      logger[\"b\" /* logger */].log('set autoLevelCapping:' + newLevel);\n      this._autoLevelCapping = newLevel;\n    }\n\n    /**\n     * True when automatic level selection enabled\n     * @type {boolean}\n     */\n\n  }, {\n    key: 'autoLevelEnabled',\n    get: function get() {\n      return this.levelController.manualLevel === -1;\n    }\n\n    /**\n     * Level set manually (if any)\n     * @type {number}\n     */\n\n  }, {\n    key: 'manualLevel',\n    get: function get() {\n      return this.levelController.manualLevel;\n    }\n\n    /**\n     * min level selectable in auto mode according to config.minAutoBitrate\n     * @type {number}\n     */\n\n  }, {\n    key: 'minAutoLevel',\n    get: function get() {\n      var hls = this,\n          levels = hls.levels,\n          minAutoBitrate = hls.config.minAutoBitrate,\n          len = levels ? levels.length : 0;\n      for (var i = 0; i < len; i++) {\n        var levelNextBitrate = levels[i].realBitrate ? Math.max(levels[i].realBitrate, levels[i].bitrate) : levels[i].bitrate;\n        if (levelNextBitrate > minAutoBitrate) return i;\n      }\n      return 0;\n    }\n\n    /**\n     * max level selectable in auto mode according to autoLevelCapping\n     * @type {number}\n     */\n\n  }, {\n    key: 'maxAutoLevel',\n    get: function get() {\n      var hls = this;\n      var levels = hls.levels;\n      var autoLevelCapping = hls.autoLevelCapping;\n      var maxAutoLevel = void 0;\n      if (autoLevelCapping === -1 && levels && levels.length) maxAutoLevel = levels.length - 1;else maxAutoLevel = autoLevelCapping;\n\n      return maxAutoLevel;\n    }\n\n    /**\n     * next automatically selected quality level\n     * @type {number}\n     */\n\n  }, {\n    key: 'nextAutoLevel',\n    get: function get() {\n      var hls = this;\n      // ensure next auto level is between  min and max auto level\n      return Math.min(Math.max(hls.abrController.nextAutoLevel, hls.minAutoLevel), hls.maxAutoLevel);\n    }\n\n    /**\n     * this setter is used to force next auto level.\n     * this is useful to force a switch down in auto mode:\n     * in case of load error on level N, hls.js can set nextAutoLevel to N-1 for example)\n     * forced value is valid for one fragment. upon succesful frag loading at forced level,\n     * this value will be resetted to -1 by ABR controller.\n     * @type {number}\n     */\n    ,\n    set: function set(nextLevel) {\n      var hls = this;\n      hls.abrController.nextAutoLevel = Math.max(hls.minAutoLevel, nextLevel);\n    }\n\n    /**\n     * @type {AudioTrack[]}\n     */\n\n  }, {\n    key: 'audioTracks',\n    get: function get() {\n      var audioTrackController = this.audioTrackController;\n      return audioTrackController ? audioTrackController.audioTracks : [];\n    }\n\n    /**\n     * index of the selected audio track (index in audio track lists)\n     * @type {number}\n     */\n\n  }, {\n    key: 'audioTrack',\n    get: function get() {\n      var audioTrackController = this.audioTrackController;\n      return audioTrackController ? audioTrackController.audioTrack : -1;\n    }\n\n    /**\n     * selects an audio track, based on its index in audio track lists\n     * @type {number}\n     */\n    ,\n    set: function set(audioTrackId) {\n      var audioTrackController = this.audioTrackController;\n      if (audioTrackController) audioTrackController.audioTrack = audioTrackId;\n    }\n\n    /**\n     * @type {Seconds}\n     */\n\n  }, {\n    key: 'liveSyncPosition',\n    get: function get() {\n      return this.streamController.liveSyncPosition;\n    }\n\n    /**\n     * get alternate subtitle tracks list from playlist\n     * @type {SubtitleTrack[]}\n     */\n\n  }, {\n    key: 'subtitleTracks',\n    get: function get() {\n      var subtitleTrackController = this.subtitleTrackController;\n      return subtitleTrackController ? subtitleTrackController.subtitleTracks : [];\n    }\n\n    /**\n     * index of the selected subtitle track (index in subtitle track lists)\n     * @type {number}\n     */\n\n  }, {\n    key: 'subtitleTrack',\n    get: function get() {\n      var subtitleTrackController = this.subtitleTrackController;\n      return subtitleTrackController ? subtitleTrackController.subtitleTrack : -1;\n    }\n\n    /**\n     * select an subtitle track, based on its index in subtitle track lists\n     * @type{number}\n     */\n    ,\n    set: function set(subtitleTrackId) {\n      var subtitleTrackController = this.subtitleTrackController;\n      if (subtitleTrackController) subtitleTrackController.subtitleTrack = subtitleTrackId;\n    }\n\n    /**\n     * @type {booelan}\n     */\n\n  }, {\n    key: 'subtitleDisplay',\n    get: function get() {\n      var subtitleTrackController = this.subtitleTrackController;\n      return subtitleTrackController ? subtitleTrackController.subtitleDisplay : false;\n    }\n\n    /**\n     * Enable/disable subtitle display rendering\n     * @type {boolean}\n     */\n    ,\n    set: function set(value) {\n      var subtitleTrackController = this.subtitleTrackController;\n      if (subtitleTrackController) subtitleTrackController.subtitleDisplay = value;\n    }\n  }]);\n\n  return Hls;\n}();\n\n/* harmony default export */ var src_hls = __webpack_exports__[\"default\"] = (hls_Hls);\n\n/***/ }),\n/* 10 */\n/***/ (function(module, exports, __webpack_require__) {\n\nfunction webpackBootstrapFunc (modules) {\n/******/  // The module cache\n/******/  var installedModules = {};\n\n/******/  // The require function\n/******/  function __webpack_require__(moduleId) {\n\n/******/    // Check if module is in cache\n/******/    if(installedModules[moduleId])\n/******/      return installedModules[moduleId].exports;\n\n/******/    // Create a new module (and put it into the cache)\n/******/    var module = installedModules[moduleId] = {\n/******/      i: moduleId,\n/******/      l: false,\n/******/      exports: {}\n/******/    };\n\n/******/    // Execute the module function\n/******/    modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n/******/    // Flag the module as loaded\n/******/    module.l = true;\n\n/******/    // Return the exports of the module\n/******/    return module.exports;\n/******/  }\n\n/******/  // expose the modules object (__webpack_modules__)\n/******/  __webpack_require__.m = modules;\n\n/******/  // expose the module cache\n/******/  __webpack_require__.c = installedModules;\n\n/******/  // identity function for calling harmony imports with the correct context\n/******/  __webpack_require__.i = function(value) { return value; };\n\n/******/  // define getter function for harmony exports\n/******/  __webpack_require__.d = function(exports, name, getter) {\n/******/    if(!__webpack_require__.o(exports, name)) {\n/******/      Object.defineProperty(exports, name, {\n/******/        configurable: false,\n/******/        enumerable: true,\n/******/        get: getter\n/******/      });\n/******/    }\n/******/  };\n\n/******/  // define __esModule on exports\n/******/  __webpack_require__.r = function(exports) {\n/******/    Object.defineProperty(exports, '__esModule', { value: true });\n/******/  };\n\n/******/  // getDefaultExport function for compatibility with non-harmony modules\n/******/  __webpack_require__.n = function(module) {\n/******/    var getter = module && module.__esModule ?\n/******/      function getDefault() { return module['default']; } :\n/******/      function getModuleExports() { return module; };\n/******/    __webpack_require__.d(getter, 'a', getter);\n/******/    return getter;\n/******/  };\n\n/******/  // Object.prototype.hasOwnProperty.call\n/******/  __webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n/******/  // __webpack_public_path__\n/******/  __webpack_require__.p = \"/\";\n\n/******/  // on error function for async loading\n/******/  __webpack_require__.oe = function(err) { console.error(err); throw err; };\n\n  var f = __webpack_require__(__webpack_require__.s = ENTRY_MODULE)\n  return f.default || f // try to call default if defined to also support babel esmodule exports\n}\n\nvar moduleNameReqExp = '[\\\\.|\\\\-|\\\\+|\\\\w|\\/|@]+'\nvar dependencyRegExp = '\\\\((\\/\\\\*.*?\\\\*\\/)?\\s?.*?(' + moduleNameReqExp + ').*?\\\\)' // additional chars when output.pathinfo is true\n\n// http://stackoverflow.com/a/2593661/130442\nfunction quoteRegExp (str) {\n  return (str + '').replace(/[.?*+^$[\\]\\\\(){}|-]/g, '\\\\$&')\n}\n\nfunction getModuleDependencies (sources, module, queueName) {\n  var retval = {}\n  retval[queueName] = []\n\n  var fnString = module.toString()\n  var wrapperSignature = fnString.match(/^function\\s?\\(\\w+,\\s*\\w+,\\s*(\\w+)\\)/)\n  if (!wrapperSignature) return retval\n  var webpackRequireName = wrapperSignature[1]\n\n  // main bundle deps\n  var re = new RegExp('(\\\\\\\\n|\\\\W)' + quoteRegExp(webpackRequireName) + dependencyRegExp, 'g')\n  var match\n  while ((match = re.exec(fnString))) {\n    if (match[3] === 'dll-reference') continue\n    retval[queueName].push(match[3])\n  }\n\n  // dll deps\n  re = new RegExp('\\\\(' + quoteRegExp(webpackRequireName) + '\\\\(\"(dll-reference\\\\s(' + moduleNameReqExp + '))\"\\\\)\\\\)' + dependencyRegExp, 'g')\n  while ((match = re.exec(fnString))) {\n    if (!sources[match[2]]) {\n      retval[queueName].push(match[1])\n      sources[match[2]] = __webpack_require__(match[1]).m\n    }\n    retval[match[2]] = retval[match[2]] || []\n    retval[match[2]].push(match[4])\n  }\n\n  return retval\n}\n\nfunction hasValuesInQueues (queues) {\n  var keys = Object.keys(queues)\n  return keys.reduce(function (hasValues, key) {\n    return hasValues || queues[key].length > 0\n  }, false)\n}\n\nfunction getRequiredModules (sources, moduleId) {\n  var modulesQueue = {\n    main: [moduleId]\n  }\n  var requiredModules = {\n    main: []\n  }\n  var seenModules = {\n    main: {}\n  }\n\n  while (hasValuesInQueues(modulesQueue)) {\n    var queues = Object.keys(modulesQueue)\n    for (var i = 0; i < queues.length; i++) {\n      var queueName = queues[i]\n      var queue = modulesQueue[queueName]\n      var moduleToCheck = queue.pop()\n      seenModules[queueName] = seenModules[queueName] || {}\n      if (seenModules[queueName][moduleToCheck] || !sources[queueName][moduleToCheck]) continue\n      seenModules[queueName][moduleToCheck] = true\n      requiredModules[queueName] = requiredModules[queueName] || []\n      requiredModules[queueName].push(moduleToCheck)\n      var newModules = getModuleDependencies(sources, sources[queueName][moduleToCheck], queueName)\n      var newModulesKeys = Object.keys(newModules)\n      for (var j = 0; j < newModulesKeys.length; j++) {\n        modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]] || []\n        modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]].concat(newModules[newModulesKeys[j]])\n      }\n    }\n  }\n\n  return requiredModules\n}\n\nmodule.exports = function (moduleId, options) {\n  options = options || {}\n  var sources = {\n    main: __webpack_require__.m\n  }\n\n  var requiredModules = options.all ? { main: Object.keys(sources) } : getRequiredModules(sources, moduleId)\n\n  var src = ''\n\n  Object.keys(requiredModules).filter(function (m) { return m !== 'main' }).forEach(function (module) {\n    var entryModule = 0\n    while (requiredModules[module][entryModule]) {\n      entryModule++\n    }\n    requiredModules[module].push(entryModule)\n    sources[module][entryModule] = '(function(module, exports, __webpack_require__) { module.exports = __webpack_require__; })'\n    src = src + 'var ' + module + ' = (' + webpackBootstrapFunc.toString().replace('ENTRY_MODULE', JSON.stringify(entryModule)) + ')({' + requiredModules[module].map(function (id) { return '' + JSON.stringify(id) + ': ' + sources[module][id].toString() }).join(',') + '});\\n'\n  })\n\n  src = src + '(' + webpackBootstrapFunc.toString().replace('ENTRY_MODULE', JSON.stringify(moduleId)) + ')({' + requiredModules.main.map(function (id) { return '' + JSON.stringify(id) + ': ' + sources.main[id].toString() }).join(',') + '})(self);'\n\n  var blob = new window.Blob([src], { type: 'text/javascript' })\n  if (options.bare) { return blob }\n\n  var URL = window.URL || window.webkitURL || window.mozURL || window.msURL\n\n  var workerUrl = URL.createObjectURL(blob)\n  var worker = new window.Worker(workerUrl)\n  worker.objectURL = workerUrl\n\n  return worker\n}\n\n\n/***/ }),\n/* 11 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nObject.defineProperty(__webpack_exports__, \"__esModule\", { value: true });\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__demux_demuxer_inline__ = __webpack_require__(8);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1__events__ = __webpack_require__(1);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2__utils_logger__ = __webpack_require__(0);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_events__ = __webpack_require__(6);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_events___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_3_events__);\n/* demuxer web worker.\n *  - listen to worker message, and trigger DemuxerInline upon reception of Fragments.\n *  - provides MP4 Boxes back to main thread using [transferable objects](https://developers.google.com/web/updates/2011/12/Transferable-Objects-Lightning-Fast) in order to minimize message passing overhead.\n */\n\n\n\n\n\n\nvar DemuxerWorker = function DemuxerWorker(self) {\n  // observer setup\n  var observer = new __WEBPACK_IMPORTED_MODULE_3_events___default.a();\n  observer.trigger = function trigger(event) {\n    for (var _len = arguments.length, data = Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      data[_key - 1] = arguments[_key];\n    }\n\n    observer.emit.apply(observer, [event, event].concat(data));\n  };\n\n  observer.off = function off(event) {\n    for (var _len2 = arguments.length, data = Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n      data[_key2 - 1] = arguments[_key2];\n    }\n\n    observer.removeListener.apply(observer, [event].concat(data));\n  };\n\n  var forwardMessage = function forwardMessage(ev, data) {\n    self.postMessage({ event: ev, data: data });\n  };\n\n  self.addEventListener('message', function (ev) {\n    var data = ev.data;\n    // console.log('demuxer cmd:' + data.cmd);\n    switch (data.cmd) {\n      case 'init':\n        var config = JSON.parse(data.config);\n        self.demuxer = new __WEBPACK_IMPORTED_MODULE_0__demux_demuxer_inline__[\"a\" /* default */](observer, data.typeSupported, config, data.vendor);\n        try {\n          Object(__WEBPACK_IMPORTED_MODULE_2__utils_logger__[\"a\" /* enableLogs */])(config.debug === true);\n        } catch (err) {\n          console.warn('demuxerWorker: unable to enable logs');\n        }\n        // signal end of worker init\n        forwardMessage('init', null);\n        break;\n      case 'demux':\n        self.demuxer.push(data.data, data.decryptdata, data.initSegment, data.audioCodec, data.videoCodec, data.timeOffset, data.discontinuity, data.trackSwitch, data.contiguous, data.duration, data.accurateTimeOffset, data.defaultInitPTS);\n        break;\n      default:\n        break;\n    }\n  });\n\n  // forward events to main thread\n  observer.on(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].FRAG_DECRYPTED, forwardMessage);\n  observer.on(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].FRAG_PARSING_INIT_SEGMENT, forwardMessage);\n  observer.on(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].FRAG_PARSED, forwardMessage);\n  observer.on(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].ERROR, forwardMessage);\n  observer.on(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].FRAG_PARSING_METADATA, forwardMessage);\n  observer.on(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].FRAG_PARSING_USERDATA, forwardMessage);\n  observer.on(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].INIT_PTS_FOUND, forwardMessage);\n\n  // special case for FRAG_PARSING_DATA: pass data1/data2 as transferable object (no copy)\n  observer.on(__WEBPACK_IMPORTED_MODULE_1__events__[\"a\" /* default */].FRAG_PARSING_DATA, function (ev, data) {\n    var transferable = [];\n    var message = { event: ev, data: data };\n    if (data.data1) {\n      message.data1 = data.data1.buffer;\n      transferable.push(data.data1.buffer);\n      delete data.data1;\n    }\n    if (data.data2) {\n      message.data2 = data.data2.buffer;\n      transferable.push(data.data2.buffer);\n      delete data.data2;\n    }\n    self.postMessage(message, transferable);\n  });\n};\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (DemuxerWorker);\n\n/***/ }),\n/* 12 */\n/***/ (function(module, exports) {\n\n/*! http://mths.be/endswith v0.2.0 by @mathias */\nif (!String.prototype.endsWith) {\n\t(function() {\n\t\t'use strict'; // needed to support `apply`/`call` with `undefined`/`null`\n\t\tvar defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\ttry {\n\t\t\t\tvar object = {};\n\t\t\t\tvar $defineProperty = Object.defineProperty;\n\t\t\t\tvar result = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {}\n\t\t\treturn result;\n\t\t}());\n\t\tvar toString = {}.toString;\n\t\tvar endsWith = function(search) {\n\t\t\tif (this == null) {\n\t\t\t\tthrow TypeError();\n\t\t\t}\n\t\t\tvar string = String(this);\n\t\t\tif (search && toString.call(search) == '[object RegExp]') {\n\t\t\t\tthrow TypeError();\n\t\t\t}\n\t\t\tvar stringLength = string.length;\n\t\t\tvar searchString = String(search);\n\t\t\tvar searchLength = searchString.length;\n\t\t\tvar pos = stringLength;\n\t\t\tif (arguments.length > 1) {\n\t\t\t\tvar position = arguments[1];\n\t\t\t\tif (position !== undefined) {\n\t\t\t\t\t// `ToInteger`\n\t\t\t\t\tpos = position ? Number(position) : 0;\n\t\t\t\t\tif (pos != pos) { // better `isNaN`\n\t\t\t\t\t\tpos = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tvar end = Math.min(Math.max(pos, 0), stringLength);\n\t\t\tvar start = end - searchLength;\n\t\t\tif (start < 0) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tvar index = -1;\n\t\t\twhile (++index < searchLength) {\n\t\t\t\tif (string.charCodeAt(start + index) != searchString.charCodeAt(index)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String.prototype, 'endsWith', {\n\t\t\t\t'value': endsWith,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.prototype.endsWith = endsWith;\n\t\t}\n\t}());\n}\n\n\n/***/ })\n/******/ ])[\"default\"];\n});\n//# sourceMappingURL=hls.js.map\n\n//# sourceURL=webpack:///./node_modules/hls.js/dist/hls.js?");

/***/ }),

/***/ "./node_modules/node-libs-browser/mock/empty.js":
/*!******************************************************!*\
  !*** ./node_modules/node-libs-browser/mock/empty.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("\n\n//# sourceURL=webpack:///./node_modules/node-libs-browser/mock/empty.js?");

/***/ }),

/***/ "./node_modules/raw-loader/index.js!./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/raw-loader!./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js ***!
  \***************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = \"function SpringStreams(f){this.version=\\\"2.0.0\\\";var p=\\\"tns-gallup.dk\\\";var e=200;var m=2000;var P=\\\"default\\\";var G=new Array();this.namespace=\\\"com.kma.springstreams\\\";this.syncrate=20;this.pausesync=6;this.maxstates=50;var a=this;this.pageContext;var N;A(n());if(f){P=f}x();function n(){var Q={\\\"2cnt.net\\\":{syncrates:[3,7,10,10,10,10,10,60]}};return Q}function A(R){var S;if(R){for(var Q in R){if(Q==p){S=R[Q]}}if(S){C(S.syncrates)}}}function C(Q){if(Q){N=Q}}function H(){return N}this.getSyncRates=H;function t(T,R,Q){if(a.pageContext===undefined){a.pageContext=a.defaultPageContext}if(!T){return}var S=new w(this,T,R,Q);G.push(S);return S}this.track=t;function x(){setInterval(k,e);setInterval(r,m)}function b(){for(var Q=0;Q<G.length;++Q){try{G[Q].stop()}catch(R){D(R)}}}this.unload=b;function k(S){for(var Q=0;Q<G.length;++Q){try{G[Q].update(S)}catch(R){D(R)}}}this.doUpdate=k;function r(S){for(var Q=0;Q<G.length;++Q){try{G[Q].sync(S)}catch(R){D(R)}}}this.doSync=r;function D(Q){E(\\\"\\\",Q)}this.error=D;function u(R,Q){return v([[R,Q]])}function F(Q){if(Q&&Q.site!=undefined){return Q.site}return P}function y(Q){}this.debug=y;function l(){if(a.pageContext.getWindowLocationURL()===undefined){return\\\"http://\\\"}if(\\\"https\\\"==a.pageContext.getWindowLocationURL().slice(0,5)){return\\\"https://ssl-\\\"}else{return\\\"http://\\\"}}function J(){if(!this.nlso){try{var Q=\\\"\\\";Q=a.pageContext.getLocalStorageItem(\\\"i00\\\");if(Q){return\\\"&c=\\\"+Q}else{var R=\\\"0000\\\",T=R+Math.ceil((new Date()).getTime()/1000).toString(16)+(32768|Math.random()*65535).toString(16)+R;a.pageContext.setLocalStorageItem(\\\"i00\\\",T)}}catch(S){console.log(\\\"error\\\"+S)}}return\\\"\\\"}function E(S,R){var Q=l()+F(R)+\\\".\\\"+p+\\\"/j0=\\\"+u(S,R)+\\\"?lt=\\\"+(new Date()).getTime().toString(36)+J();a.pageContext.preloadImage(Q);this.debug(Q)}this.send=E;function v(U){var S;var V;var T;var R;var W=/[+&,;=~]/g;var X;var Q;switch(typeof U){case\\\"string\\\":return W.test(U)?escape(U).replace(W,function(Y){var Z=Q[Y];if(Z){return Z}return Y}):escape(U);case\\\"number\\\":return isFinite(U)?U.toString():\\\"null\\\";case\\\"boolean\\\":case\\\"null\\\":return U.toString();case\\\"object\\\":if(!U){return\\\"null\\\"}S=[];if(typeof U.length==\\\"number\\\"&&!(U.propertyIsEnumerable(\\\"length\\\"))){R=U.length;for(V=0;V<R;V+=1){S.push(v(U[V])||\\\"null\\\")}return\\\",\\\"+S.join(\\\"+\\\")+\\\";\\\"}for(T in U){if(typeof T==\\\"string\\\"){if(T!=\\\"site\\\"){X=v(U[T]);if(X){S.push(v(T)+\\\"=\\\"+X)}}}}return\\\",\\\"+S.join(\\\"+\\\")+\\\";\\\"}return\\\"\\\"}function w(am,aj,an,ai){var ag=Math.round((Math.random()*10000000000)).toString(36);var V=Math.round(new Date().getTime()/1000);var ac;var ao;var ae;var aa;var W=[0,0,V.toString(36)];var X=0;var ap=0;var Y=true;var S=false;var af;var U;var R;var Q;ac=am;ao=aj;if(ai){af=ai}else{af=ac.HTML5Adapter}aa=ah(an);ae=new Array();ae.push(W);Q=0;U=am.syncrate;R=am.getSyncRates();ad();function ah(at){var aq=new Object();for(var ar in at){aq[ar]=at[ar]}return aq}function al(aq){if(ae.length<ac.maxstates){ae.push(aq)}}function T(aq){W=[aq,aq,Math.round(new Date().getTime()/1000).toString(36)];al(W);Y=true;X=0}function ad(){if(R!=null){if(Q<R.length){U=R[Q++];ac.debug(\\\"switch syncrate to \\\"+U)}}}function Z(au){if(S){return}var aq=W[1];var ar=aq;try{ar=Math.round(af.getPosition(ao))}catch(av){}try{if(aq==ar){if(X>=0){X++;if(X==ac.pausesync){Y=true}}return}if(X>=ac.pausesync){T(ar)}else{if(aq<ar-1){T(ar)}else{if(aq>ar){T(ar)}else{W[1]=ar;if(W[1]-W[0]>=U){if(ar-ap>=U){Y=true;ad()}}X=0}}}}catch(at){D=true;ac.error(at)}}this.update=Z;function ak(){if(S){return}Y=true;S=true;ab(null)}this.stop=ak;function ab(at){if(Y){try{if(ao.width){aa.sx=ao.width}if(ao.videoWidth){aa.sx=ao.videoWidth}if(ao.height){aa.sy=ao.height}if(ao.videoHeight){aa.sy=ao.videoHeight}}catch(ar){}if(a.pageContext.getDeviceID!==undefined&&a.pageContext.getDeviceID()!==undefined){aa[a.pageContext.getDeviceID()[\\\"id_name\\\"]]=a.pageContext.getDeviceID()[\\\"id_value\\\"]}aa.uid=ag;aa.pst=ae;var aq;try{if(!aa.dur||aa.dur==0){aa.dur=af.getDuration(ao)}}catch(ar){}try{aq=af.getMeta(ao)}catch(ar){}aa.vt=(Math.round(new Date().getTime()/1000))-V;ac.send(aq,aa);ap=W[1]}Y=false}this.sync=ab}this.defaultPageContext={getLocalStorageItem:h,setLocalStorageItem:c,preloadImage:z,getWindowLocationURL:d,};this.HTML5Adapter={getMeta:B,getPosition:q,getDuration:o};this.DefaultAdapter={getMeta:j,getPosition:L,getDuration:M};this.WMStreamAdapter={getMeta:s,getPosition:i,getDuration:g};this.RVStreamAdapter={getMeta:O,getPosition:K,getDuration:I};function B(Q){return{pl:\\\"HTML 5 Video\\\",pv:\\\"HTML 5\\\",sx:screen.width,sy:screen.height}}function o(Q){return Math.round(Q.duration)}function q(Q){return Q.currentTime}function j(Q){return{pl:\\\"DEF\\\",pv:version,sx:screen.width,sy:screen.height}}function L(Q){return new Date().getTime()/1000}function M(Q){return 0}function s(Q){return{pl:\\\"MSWM\\\",plv:Q.versionInfo,sx:screen.width,sy:screen.height}}function i(Q){if(Q.CurrentPosition){return Q.CurrentPosition}if(Q.currentPosition){return Q.currentPosition}if(Q.controls){if(Q.controls.currentPosition){return Q.controls.currentPosition}}if(Q.Controls){if(Q.Controls.currentPosition){return Q.Controls.currentPosition}}return 0}function g(Q){if(Q.currentMedia){if(Q.currentMedia.Duration){return Q.currentMedia.Duration}if(Q.currentMedia.duration){return Q.currentMedia.duration}}else{if(Q.CurrentMedia){if(Q.CurrentMedia.duration){return Q.CurrentMedia.duration}if(Q.CurrentMedia.Duration){return Q.CurrentMedia.Duration}}}}function O(Q){return{pl:\\\"RV\\\",plv:Q.GetVersionInfo(),sx:screen.width,sy:screen.height}}function K(Q){return(Q.GetPosition()/1000)}function I(Q){return(Q.GetLength()/1000)}function c(Q,R){localStorage.setItem(Q,R)}function h(Q){return localStorage.getItem(Q)}function z(Q){(new Image()).src=Q}function d(){return document.location.href}}SpringStreams.prototype.setPageContext=function(a){this.pageContext=a};\"\n\n//# sourceURL=webpack:///./node_modules/@dr/drc-media-statistics/js/3rd_party/springstreams/2.0.0/springstreams.js?./node_modules/raw-loader");

/***/ }),

/***/ "./node_modules/scriptjs/dist/script.js":
/*!**********************************************!*\
  !*** ./node_modules/scriptjs/dist/script.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_RESULT__;/*!\n  * $script.js JS loader & dependency manager\n  * https://github.com/ded/script.js\n  * (c) Dustin Diaz 2014 | License MIT\n  */\n\n(function (name, definition) {\n  if (typeof module != 'undefined' && module.exports) module.exports = definition()\n  else if (true) !(__WEBPACK_AMD_DEFINE_FACTORY__ = (definition),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?\n\t\t\t\t(__WEBPACK_AMD_DEFINE_FACTORY__.call(exports, __webpack_require__, exports, module)) :\n\t\t\t\t__WEBPACK_AMD_DEFINE_FACTORY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__))\n  else {}\n})('$script', function () {\n  var doc = document\n    , head = doc.getElementsByTagName('head')[0]\n    , s = 'string'\n    , f = false\n    , push = 'push'\n    , readyState = 'readyState'\n    , onreadystatechange = 'onreadystatechange'\n    , list = {}\n    , ids = {}\n    , delay = {}\n    , scripts = {}\n    , scriptpath\n    , urlArgs\n\n  function every(ar, fn) {\n    for (var i = 0, j = ar.length; i < j; ++i) if (!fn(ar[i])) return f\n    return 1\n  }\n  function each(ar, fn) {\n    every(ar, function (el) {\n      return !fn(el)\n    })\n  }\n\n  function $script(paths, idOrDone, optDone) {\n    paths = paths[push] ? paths : [paths]\n    var idOrDoneIsDone = idOrDone && idOrDone.call\n      , done = idOrDoneIsDone ? idOrDone : optDone\n      , id = idOrDoneIsDone ? paths.join('') : idOrDone\n      , queue = paths.length\n    function loopFn(item) {\n      return item.call ? item() : list[item]\n    }\n    function callback() {\n      if (!--queue) {\n        list[id] = 1\n        done && done()\n        for (var dset in delay) {\n          every(dset.split('|'), loopFn) && !each(delay[dset], loopFn) && (delay[dset] = [])\n        }\n      }\n    }\n    setTimeout(function () {\n      each(paths, function loading(path, force) {\n        if (path === null) return callback()\n        path = !force && path.indexOf('.js') === -1 && !/^https?:\\/\\//.test(path) && scriptpath ? scriptpath + path + '.js' : path\n        if (scripts[path]) {\n          if (id) ids[id] = 1\n          return (scripts[path] == 2) ? callback() : setTimeout(function () { loading(path, true) }, 0)\n        }\n\n        scripts[path] = 1\n        if (id) ids[id] = 1\n        create(path, callback)\n      })\n    }, 0)\n    return $script\n  }\n\n  function create(path, fn) {\n    var el = doc.createElement('script'), loaded\n    el.onload = el.onerror = el[onreadystatechange] = function () {\n      if ((el[readyState] && !(/^c|loade/.test(el[readyState]))) || loaded) return;\n      el.onload = el[onreadystatechange] = null\n      loaded = 1\n      scripts[path] = 2\n      fn()\n    }\n    el.async = 1\n    el.src = urlArgs ? path + (path.indexOf('?') === -1 ? '?' : '&') + urlArgs : path;\n    head.insertBefore(el, head.lastChild)\n  }\n\n  $script.get = create\n\n  $script.order = function (scripts, id, done) {\n    (function callback(s) {\n      s = scripts.shift()\n      !scripts.length ? $script(s, id, done) : $script(s, callback)\n    }())\n  }\n\n  $script.path = function (p) {\n    scriptpath = p\n  }\n  $script.urlArgs = function (str) {\n    urlArgs = str;\n  }\n  $script.ready = function (deps, ready, req) {\n    deps = deps[push] ? deps : [deps]\n    var missing = [];\n    !each(deps, function (dep) {\n      list[dep] || missing[push](dep);\n    }) && every(deps, function (dep) {return list[dep]}) ?\n      ready() : !function (key) {\n      delay[key] = delay[key] || []\n      delay[key][push](ready)\n      req && req(missing)\n    }(deps.join('|'))\n    return $script\n  }\n\n  $script.done = function (idOrDone) {\n    $script([null], idOrDone)\n  }\n\n  return $script\n});\n\n\n//# sourceURL=webpack:///./node_modules/scriptjs/dist/script.js?");

/***/ }),

/***/ "./node_modules/setimmediate/setImmediate.js":
/*!***************************************************!*\
  !*** ./node_modules/setimmediate/setImmediate.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global, process) {(function (global, undefined) {\n    \"use strict\";\n\n    if (global.setImmediate) {\n        return;\n    }\n\n    var nextHandle = 1; // Spec says greater than zero\n    var tasksByHandle = {};\n    var currentlyRunningATask = false;\n    var doc = global.document;\n    var registerImmediate;\n\n    function setImmediate(callback) {\n      // Callback can either be a function or a string\n      if (typeof callback !== \"function\") {\n        callback = new Function(\"\" + callback);\n      }\n      // Copy function arguments\n      var args = new Array(arguments.length - 1);\n      for (var i = 0; i < args.length; i++) {\n          args[i] = arguments[i + 1];\n      }\n      // Store and register the task\n      var task = { callback: callback, args: args };\n      tasksByHandle[nextHandle] = task;\n      registerImmediate(nextHandle);\n      return nextHandle++;\n    }\n\n    function clearImmediate(handle) {\n        delete tasksByHandle[handle];\n    }\n\n    function run(task) {\n        var callback = task.callback;\n        var args = task.args;\n        switch (args.length) {\n        case 0:\n            callback();\n            break;\n        case 1:\n            callback(args[0]);\n            break;\n        case 2:\n            callback(args[0], args[1]);\n            break;\n        case 3:\n            callback(args[0], args[1], args[2]);\n            break;\n        default:\n            callback.apply(undefined, args);\n            break;\n        }\n    }\n\n    function runIfPresent(handle) {\n        // From the spec: \"Wait until any invocations of this algorithm started before this one have completed.\"\n        // So if we're currently running a task, we'll need to delay this invocation.\n        if (currentlyRunningATask) {\n            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a\n            // \"too much recursion\" error.\n            setTimeout(runIfPresent, 0, handle);\n        } else {\n            var task = tasksByHandle[handle];\n            if (task) {\n                currentlyRunningATask = true;\n                try {\n                    run(task);\n                } finally {\n                    clearImmediate(handle);\n                    currentlyRunningATask = false;\n                }\n            }\n        }\n    }\n\n    function installNextTickImplementation() {\n        registerImmediate = function(handle) {\n            process.nextTick(function () { runIfPresent(handle); });\n        };\n    }\n\n    function canUsePostMessage() {\n        // The test against `importScripts` prevents this implementation from being installed inside a web worker,\n        // where `global.postMessage` means something completely different and can't be used for this purpose.\n        if (global.postMessage && !global.importScripts) {\n            var postMessageIsAsynchronous = true;\n            var oldOnMessage = global.onmessage;\n            global.onmessage = function() {\n                postMessageIsAsynchronous = false;\n            };\n            global.postMessage(\"\", \"*\");\n            global.onmessage = oldOnMessage;\n            return postMessageIsAsynchronous;\n        }\n    }\n\n    function installPostMessageImplementation() {\n        // Installs an event handler on `global` for the `message` event: see\n        // * https://developer.mozilla.org/en/DOM/window.postMessage\n        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages\n\n        var messagePrefix = \"setImmediate$\" + Math.random() + \"$\";\n        var onGlobalMessage = function(event) {\n            if (event.source === global &&\n                typeof event.data === \"string\" &&\n                event.data.indexOf(messagePrefix) === 0) {\n                runIfPresent(+event.data.slice(messagePrefix.length));\n            }\n        };\n\n        if (global.addEventListener) {\n            global.addEventListener(\"message\", onGlobalMessage, false);\n        } else {\n            global.attachEvent(\"onmessage\", onGlobalMessage);\n        }\n\n        registerImmediate = function(handle) {\n            global.postMessage(messagePrefix + handle, \"*\");\n        };\n    }\n\n    function installMessageChannelImplementation() {\n        var channel = new MessageChannel();\n        channel.port1.onmessage = function(event) {\n            var handle = event.data;\n            runIfPresent(handle);\n        };\n\n        registerImmediate = function(handle) {\n            channel.port2.postMessage(handle);\n        };\n    }\n\n    function installReadyStateChangeImplementation() {\n        var html = doc.documentElement;\n        registerImmediate = function(handle) {\n            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n            var script = doc.createElement(\"script\");\n            script.onreadystatechange = function () {\n                runIfPresent(handle);\n                script.onreadystatechange = null;\n                html.removeChild(script);\n                script = null;\n            };\n            html.appendChild(script);\n        };\n    }\n\n    function installSetTimeoutImplementation() {\n        registerImmediate = function(handle) {\n            setTimeout(runIfPresent, 0, handle);\n        };\n    }\n\n    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.\n    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);\n    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;\n\n    // Don't get fooled by e.g. browserify environments.\n    if ({}.toString.call(global.process) === \"[object process]\") {\n        // For Node.js before 0.9\n        installNextTickImplementation();\n\n    } else if (canUsePostMessage()) {\n        // For non-IE10 modern browsers\n        installPostMessageImplementation();\n\n    } else if (global.MessageChannel) {\n        // For web workers, where supported\n        installMessageChannelImplementation();\n\n    } else if (doc && \"onreadystatechange\" in doc.createElement(\"script\")) {\n        // For IE 6–8\n        installReadyStateChangeImplementation();\n\n    } else {\n        // For older browsers\n        installSetTimeoutImplementation();\n    }\n\n    attachTo.setImmediate = setImmediate;\n    attachTo.clearImmediate = clearImmediate;\n}(typeof self === \"undefined\" ? typeof global === \"undefined\" ? this : global : self));\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/setimmediate/setImmediate.js?");

/***/ }),

/***/ "./node_modules/timers-browserify/main.js":
/*!************************************************!*\
  !*** ./node_modules/timers-browserify/main.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var apply = Function.prototype.apply;\n\n// DOM APIs, for completeness\n\nexports.setTimeout = function() {\n  return new Timeout(apply.call(setTimeout, window, arguments), clearTimeout);\n};\nexports.setInterval = function() {\n  return new Timeout(apply.call(setInterval, window, arguments), clearInterval);\n};\nexports.clearTimeout =\nexports.clearInterval = function(timeout) {\n  if (timeout) {\n    timeout.close();\n  }\n};\n\nfunction Timeout(id, clearFn) {\n  this._id = id;\n  this._clearFn = clearFn;\n}\nTimeout.prototype.unref = Timeout.prototype.ref = function() {};\nTimeout.prototype.close = function() {\n  this._clearFn.call(window, this._id);\n};\n\n// Does not start the time, just sets up the members needed.\nexports.enroll = function(item, msecs) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = msecs;\n};\n\nexports.unenroll = function(item) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = -1;\n};\n\nexports._unrefActive = exports.active = function(item) {\n  clearTimeout(item._idleTimeoutId);\n\n  var msecs = item._idleTimeout;\n  if (msecs >= 0) {\n    item._idleTimeoutId = setTimeout(function onTimeout() {\n      if (item._onTimeout)\n        item._onTimeout();\n    }, msecs);\n  }\n};\n\n// setimmediate attaches itself to the global object\n__webpack_require__(/*! setimmediate */ \"./node_modules/setimmediate/setImmediate.js\");\n// On some exotic environments, it's not clear which object `setimmeidate` was\n// able to install onto.  Search each possibility in the same order as the\n// `setimmediate` library.\nexports.setImmediate = (typeof self !== \"undefined\" && self.setImmediate) ||\n                       (typeof global !== \"undefined\" && global.setImmediate) ||\n                       (this && this.setImmediate);\nexports.clearImmediate = (typeof self !== \"undefined\" && self.clearImmediate) ||\n                         (typeof global !== \"undefined\" && global.clearImmediate) ||\n                         (this && this.clearImmediate);\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/timers-browserify/main.js?");

/***/ }),

/***/ "./node_modules/timezone-js/src/date.js":
/*!**********************************************!*\
  !*** ./node_modules/timezone-js/src/date.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_RESULT__;// -----\n// The `timezoneJS.Date` object gives you full-blown timezone support, independent from the timezone set on the end-user's machine running the browser. It uses the Olson zoneinfo files for its timezone data.\n//\n// The constructor function and setter methods use proxy JavaScript Date objects behind the scenes, so you can use strings like '10/22/2006' with the constructor. You also get the same sensible wraparound behavior with numeric parameters (like setting a value of 14 for the month wraps around to the next March).\n//\n// The other significant difference from the built-in JavaScript Date is that `timezoneJS.Date` also has named properties that store the values of year, month, date, etc., so it can be directly serialized to JSON and used for data transfer.\n\n/*\n * Copyright 2010 Matthew Eernisse (mde@fleegix.org)\n * and Open Source Applications Foundation\n *\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * Credits: Ideas included from incomplete JS implementation of Olson\n * parser, 'XMLDAte' by Philippe Goetz (philippe.goetz@wanadoo.fr)\n *\n * Contributions:\n * Jan Niehusmann\n * Ricky Romero\n * Preston Hunt (prestonhunt@gmail.com)\n * Dov. B Katz (dov.katz@morganstanley.com)\n * Peter Bergström (pbergstr@mac.com)\n * Long Ho\n */\n\n /*jshint laxcomma:true, laxbreak:true, expr:true*/\n(function () {\n  // Standard initialization stuff to make sure the library is\n  // usable on both client and server (node) side.\n  'use strict';\n  var root = this;\n\n  // Export the timezoneJS object for Node.js, with backwards-compatibility for the old `require()` API\n  var timezoneJS = {};\n  if (true) { // AMD\n    !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() {\n     return timezoneJS;\n    }).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n  } else {}\n\n  timezoneJS.VERSION = '0.4.13';\n\n  // Grab the ajax library from global context.\n  // This can be jQuery, Zepto or fleegix.\n  // You can also specify your own transport mechanism by declaring\n  // `timezoneJS.timezone.transport` to a `function`. More details will follow\n  var ajax_lib = root.$ || root.jQuery || root.Zepto\n    , fleegix = root.fleegix\n    // Declare constant list of days and months. Unfortunately this doesn't leave room for i18n due to the Olson data being in English itself\n    , DAYS = timezoneJS.Days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n    , MONTHS = timezoneJS.Months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n    , SHORT_MONTHS = {}\n    , SHORT_DAYS = {}\n    , EXACT_DATE_TIME = {};\n\n  //`{ 'Jan': 0, 'Feb': 1, 'Mar': 2, 'Apr': 3, 'May': 4, 'Jun': 5, 'Jul': 6, 'Aug': 7, 'Sep': 8, 'Oct': 9, 'Nov': 10, 'Dec': 11 }`\n  for (var i = 0; i < MONTHS.length; i++) {\n    SHORT_MONTHS[MONTHS[i].substr(0, 3)] = i;\n  }\n\n  //`{ 'Sun': 0, 'Mon': 1, 'Tue': 2, 'Wed': 3, 'Thu': 4, 'Fri': 5, 'Sat': 6 }`\n  for (i = 0; i < DAYS.length; i++) {\n    SHORT_DAYS[DAYS[i].substr(0, 3)] = i;\n  }\n\n\n  //Handle array indexOf in IE\n  //From https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Global_Objects/Array/indexOf\n  //Extending Array prototype causes IE to iterate thru extra element\n  var _arrIndexOf = Array.prototype.indexOf || function (el) {\n    if (this === null) {\n      throw new TypeError();\n    }\n    var t = Object(this);\n    var len = t.length >>> 0;\n    if (len === 0) {\n      return -1;\n    }\n    var n = 0;\n    if (arguments.length > 1) {\n      n = Number(arguments[1]);\n      if (n != n) { // shortcut for verifying if it's NaN\n        n = 0;\n      } else if (n !== 0 && n !== Infinity && n !== -Infinity) {\n        n = (n > 0 || -1) * Math.floor(Math.abs(n));\n      }\n    }\n    if (n >= len) {\n      return -1;\n    }\n    var k = n >= 0 ? n : Math.max(len - Math.abs(n), 0);\n    for (; k < len; k++) {\n      if (k in t && t[k] === el) {\n        return k;\n      }\n    }\n    return -1;\n  };\n\n  // Format a number to the length = digits. For ex:\n  //\n  // `_fixWidth(2, 2) = '02'`\n  //\n  // `_fixWidth(1998, 2) = '98'`  // year, shorten it to the 2 digit representation\n  //\n  // `_fixWidth(23, 1) = '23'`  // hour, even with 1 digit specified, do not trim\n  //\n  // This is used to pad numbers in converting date to string in ISO standard.\n  var _fixWidth = function (number, digits) {\n    if (typeof number !== 'number') { throw 'not a number: ' + number; }\n    var trim = (number > 1000);   // only trim 'year', as the others don't make sense why anyone would want that\n    var s = number.toString();\n    var s_len = s.length;\n    if (trim && s_len > digits) {\n      return s.substr(s_len - digits, s_len);\n    }\n    s = [s];\n    while (s_len < digits) {\n      s.unshift('0');\n      s_len++;\n    }\n    return s.join('');\n  };\n\n  // Abstraction layer for different transport layers, including fleegix/jQuery/Zepto/Node.js\n  //\n  // Object `opts` include\n  //\n  // - `url`: url to ajax query\n  //\n  // - `async`: true for asynchronous, false otherwise. If false, return value will be response from URL. This is true by default\n  //\n  // - `success`: success callback function\n  //\n  // - `error`: error callback function\n  // Returns response from URL if async is false, otherwise the AJAX request object itself\n  var _transport = function (opts) {\n    if (!opts) return;\n    if (!opts.url) throw new Error ('URL must be specified');\n    if (!('async' in opts)) opts.async = true;\n\n    // Server-side (node)\n    // if node, require the file system module\n    if (typeof window === 'undefined' && \"function\" === 'function') {\n      var nodefs = __webpack_require__(/*! fs */ \"./node_modules/node-libs-browser/mock/empty.js\");\n      if (opts.async) {\n        // No point if there's no success handler\n        if (typeof opts.success !== 'function') return;\n        opts.error = opts.error || console.error;\n        return nodefs.readFile(opts.url, 'utf8', function(err, data) {\n          return err ? opts.error(err) : opts.success(data);\n        });\n      }\n      return nodefs.readFileSync(opts.url, 'utf8');\n    }\n\n    // Client-side\n    if ((!fleegix || typeof fleegix.xhr === 'undefined') && (!ajax_lib || typeof ajax_lib.ajax === 'undefined')) {\n      throw new Error('Please use the Fleegix.js XHR module, jQuery ajax, Zepto ajax, or define your own transport mechanism for downloading zone files.');\n    }\n    if (!opts.async) {\n      return fleegix && fleegix.xhr\n      ? fleegix.xhr.doReq({ url: opts.url, async: false })\n      : ajax_lib.ajax({ url : opts.url, async : false, dataType: 'text' }).responseText;\n    }\n    return fleegix && fleegix.xhr\n    ? fleegix.xhr.send({\n      url : opts.url,\n      method : 'get',\n      handleSuccess : opts.success,\n      handleErr : opts.error\n    })\n    : ajax_lib.ajax({\n      url : opts.url,\n      dataType: 'text',\n      method : 'GET',\n      error : opts.error,\n      success : opts.success\n    });\n  };\n\n  // Constructor, which is similar to that of the native Date object itself\n  timezoneJS.Date = function () {\n    if(this === timezoneJS) {\n      throw 'timezoneJS.Date object must be constructed with \\'new\\'';\n    }\n    var args = Array.prototype.slice.apply(arguments)\n    , dt = null\n    , tz = null\n    , arr = []\n    , valid = false\n    ;\n\n\n    //We support several different constructors, including all the ones from `Date` object\n    // with a timezone string at the end.\n    //\n    //- `[tz]`: Returns object with time in `tz` specified.\n    //\n    // - `utcMillis`, `[tz]`: Return object with UTC time = `utcMillis`, in `tz`.\n    //\n    // - `Date`, `[tz]`: Returns object with UTC time = `Date.getTime()`, in `tz`.\n    //\n    // - `year, month, [date,] [hours,] [minutes,] [seconds,] [millis,] [tz]: Same as `Date` object\n    // with tz.\n    //\n    // - `Array`: Can be any combo of the above.\n    //\n    //If 1st argument is an array, we can use it as a list of arguments itself\n    if (Object.prototype.toString.call(args[0]) === '[object Array]') {\n      args = args[0];\n    }\n    // If the last string argument doesn't parse as a Date, treat it as tz\n    if (typeof args[args.length - 1] === 'string') {\n      valid = Date.parse(args[args.length - 1].replace(/GMT[\\+\\-]\\d+/, ''));\n      if (isNaN(valid) || valid === null) {  // Checking against null is required for compatability with Datejs\n        tz = args.pop();\n      }\n    }\n    var is_dt_local = false;\n    switch (args.length) {\n      case 0:\n        dt = new Date();\n        break;\n      case 1:\n        dt = new Date(args[0]);\n        // Date strings are local if they do not contain 'Z', 'T' or timezone offsets like '+0200'\n        //  - more info below\n        if (typeof args[0] == 'string' && args[0].search(/[+-][0-9]{4}/) == -1\n                && args[0].search(/Z/) == -1 && args[0].search(/T/) == -1) {\n            is_dt_local = true;\n        }\n        break;\n      case 2:\n        dt = new Date(args[0], args[1]);\n        is_dt_local = true;\n        break;\n      default:\n        for (var i = 0; i < 7; i++) {\n          arr[i] = args[i] || 0;\n        }\n        dt = new Date(arr[0], arr[1], arr[2], arr[3], arr[4], arr[5], arr[6]);\n        is_dt_local = true;\n        break;\n    }\n\n    this._useCache = false;\n    this._tzInfo = {};\n    this._day = 0;\n    this.year = 0;\n    this.month = 0;\n    this.date = 0;\n    this.hours = 0;\n    this.minutes = 0;\n    this.seconds = 0;\n    this.milliseconds = 0;\n    this.timezone = tz || null;\n    // Tricky part:\n    // The date is either given as unambiguous UTC date or otherwise the date is assumed\n    // to be a date in timezone `tz` or a locale date if `tz` is not provided. Thus, to\n    // determine how to use `dt` we distinguish between the following cases:\n    //  - UTC   (is_dt_local = false)\n    //    `timezoneJS.Date(millis, [tz])`\n    //    `timezoneJS.Date(Date, [tz])`\n    //    `timezoneJS.Date(dt_str_tz, [tz])`\n    //  - local/timezone `tz`   (is_dt_local = true)\n    //    `timezoneJS.Date(year, mon, day, [hour], [min], [second], [tz])`\n    //    `timezoneJS.Date(dt_str, [tz])`\n    //\n    // `dt_str_tz` is a date string containing timezone information, i.e. containing 'Z', 'T' or\n    // /[+-][0-9]{4}/ (e.g. '+0200'), while `dt_str` is a string which does not contain\n    // timezone information. See: http://dygraphs.com/date-formats.html\n    if (is_dt_local) {\n       this.setFromDateObjProxy(dt);\n    } else {\n       this.setFromTimeProxy(dt.getTime(), tz);\n    }\n  };\n\n  // Implements most of the native Date object\n  timezoneJS.Date.prototype = {\n    getDate: function () { return this.date; },\n    getDay: function () { return this._day; },\n    getFullYear: function () { return this.year; },\n    getMonth: function () { return this.month; },\n    getYear: function () { return this.year - 1900; },\n    getHours: function () { return this.hours; },\n    getMilliseconds: function () { return this.milliseconds; },\n    getMinutes: function () { return this.minutes; },\n    getSeconds: function () { return this.seconds; },\n    getUTCDate: function () { return this.getUTCDateProxy().getUTCDate(); },\n    getUTCDay: function () { return this.getUTCDateProxy().getUTCDay(); },\n    getUTCFullYear: function () { return this.getUTCDateProxy().getUTCFullYear(); },\n    getUTCHours: function () { return this.getUTCDateProxy().getUTCHours(); },\n    getUTCMilliseconds: function () { return this.getUTCDateProxy().getUTCMilliseconds(); },\n    getUTCMinutes: function () { return this.getUTCDateProxy().getUTCMinutes(); },\n    getUTCMonth: function () { return this.getUTCDateProxy().getUTCMonth(); },\n    getUTCSeconds: function () { return this.getUTCDateProxy().getUTCSeconds(); },\n    // Time adjusted to user-specified timezone\n    getTime: function () {\n      return this._timeProxy + (this.getTimezoneOffset() * 60 * 1000);\n    },\n    getTimezone: function () { return this.timezone; },\n    getTimezoneOffset: function () { return this.getTimezoneInfo().tzOffset; },\n    getTimezoneAbbreviation: function () { return this.getTimezoneInfo().tzAbbr; },\n    getTimezoneInfo: function () {\n      if (this._useCache) return this._tzInfo;\n      var res;\n      // If timezone is specified, get the correct timezone info based on the Date given\n      if (this.timezone) {\n        res = this.timezone === 'Etc/UTC' || this.timezone === 'Etc/GMT'\n          ? { tzOffset: 0, tzAbbr: 'UTC' }\n          : timezoneJS.timezone.getTzInfo(this._timeProxy, this.timezone);\n      }\n      // If no timezone was specified, use the local browser offset\n      else {\n        res = { tzOffset: this.getLocalOffset(), tzAbbr: null };\n      }\n      this._tzInfo = res;\n      this._useCache = true;\n      return res;\n    },\n    getUTCDateProxy: function () {\n      var dt = new Date(this._timeProxy);\n      dt.setUTCMinutes(dt.getUTCMinutes() + this.getTimezoneOffset());\n      return dt;\n    },\n    setDate: function (date) {\n      this.setAttribute('date', date);\n      return this.getTime();\n    },\n    setFullYear: function (year, month, date) {\n      if (date !== undefined) { this.setAttribute('date', 1); }\n      this.setAttribute('year', year);\n      if (month !== undefined) { this.setAttribute('month', month); }\n      if (date !== undefined) { this.setAttribute('date', date); }\n      return this.getTime();\n    },\n    setMonth: function (month, date) {\n      this.setAttribute('month', month);\n      if (date !== undefined) { this.setAttribute('date', date); }\n      return this.getTime();\n    },\n    setYear: function (year) {\n      year = Number(year);\n      if (0 <= year && year <= 99) { year += 1900; }\n      this.setUTCAttribute('year', year);\n      return this.getTime();\n    },\n    setHours: function (hours, minutes, seconds, milliseconds) {\n      this.setAttribute('hours', hours);\n      if (minutes !== undefined) { this.setAttribute('minutes', minutes); }\n      if (seconds !== undefined) { this.setAttribute('seconds', seconds); }\n      if (milliseconds !== undefined) { this.setAttribute('milliseconds', milliseconds); }\n      return this.getTime();\n    },\n    setMinutes: function (minutes, seconds, milliseconds) {\n      this.setAttribute('minutes', minutes);\n      if (seconds !== undefined) { this.setAttribute('seconds', seconds); }\n      if (milliseconds !== undefined) { this.setAttribute('milliseconds', milliseconds); }\n      return this.getTime();\n    },\n    setSeconds: function (seconds, milliseconds) {\n      this.setAttribute('seconds', seconds);\n      if (milliseconds !== undefined) { this.setAttribute('milliseconds', milliseconds); }\n      return this.getTime();\n    },\n    setMilliseconds: function (milliseconds) {\n      this.setAttribute('milliseconds', milliseconds);\n      return this.getTime();\n    },\n    setTime: function (n) {\n      if (isNaN(n)) { throw new Error('Units must be a number.'); }\n      this.setFromTimeProxy(n, this.timezone);\n      return this.getTime();\n    },\n    setUTCFullYear: function (year, month, date) {\n      if (date !== undefined) { this.setUTCAttribute('date', 1); }\n      this.setUTCAttribute('year', year);\n      if (month !== undefined) { this.setUTCAttribute('month', month); }\n      if (date !== undefined) { this.setUTCAttribute('date', date); }\n      return this.getTime();\n    },\n    setUTCMonth: function (month, date) {\n      this.setUTCAttribute('month', month);\n      if (date !== undefined) { this.setUTCAttribute('date', date); }\n      return this.getTime();\n    },\n    setUTCDate: function (date) {\n      this.setUTCAttribute('date', date);\n      return this.getTime();\n    },\n    setUTCHours: function (hours, minutes, seconds, milliseconds) {\n      this.setUTCAttribute('hours', hours);\n      if (minutes !== undefined) { this.setUTCAttribute('minutes', minutes); }\n      if (seconds !== undefined) { this.setUTCAttribute('seconds', seconds); }\n      if (milliseconds !== undefined) { this.setUTCAttribute('milliseconds', milliseconds); }\n      return this.getTime();\n    },\n    setUTCMinutes: function (minutes, seconds, milliseconds) {\n      this.setUTCAttribute('minutes', minutes);\n      if (seconds !== undefined) { this.setUTCAttribute('seconds', seconds); }\n      if (milliseconds !== undefined) { this.setUTCAttribute('milliseconds', milliseconds); }\n      return this.getTime();\n    },\n    setUTCSeconds: function (seconds, milliseconds) {\n      this.setUTCAttribute('seconds', seconds);\n      if (milliseconds !== undefined) { this.setUTCAttribute('milliseconds', milliseconds); }\n      return this.getTime();\n    },\n    setUTCMilliseconds: function (milliseconds) {\n      this.setUTCAttribute('milliseconds', milliseconds);\n      return this.getTime();\n    },\n    setFromDateObjProxy: function (dt) {\n      this.year = dt.getFullYear();\n      this.month = dt.getMonth();\n      this.date = dt.getDate();\n      this.hours = dt.getHours();\n      this.minutes = dt.getMinutes();\n      this.seconds = dt.getSeconds();\n      this.milliseconds = dt.getMilliseconds();\n      this._day = dt.getDay();\n      this._dateProxy = dt;\n      this._timeProxy = Date.UTC(this.year, this.month, this.date, this.hours, this.minutes, this.seconds, this.milliseconds);\n      this._useCache = false;\n    },\n    setFromTimeProxy: function (utcMillis, tz) {\n      var dt = new Date(utcMillis);\n      var tzOffset = tz ? timezoneJS.timezone.getTzInfo(utcMillis, tz, true).tzOffset : dt.getTimezoneOffset();\n      dt.setTime(utcMillis + (dt.getTimezoneOffset() - tzOffset) * 60000);\n      this.setFromDateObjProxy(dt);\n    },\n    setAttribute: function (unit, n) {\n      if (isNaN(n)) { throw new Error('Units must be a number.'); }\n      var dt = this._dateProxy;\n      var meth = unit === 'year' ? 'FullYear' : unit.substr(0, 1).toUpperCase() + unit.substr(1);\n      dt['set' + meth](n);\n      this.setFromDateObjProxy(dt);\n    },\n    setUTCAttribute: function (unit, n) {\n      if (isNaN(n)) { throw new Error('Units must be a number.'); }\n      var meth = unit === 'year' ? 'FullYear' : unit.substr(0, 1).toUpperCase() + unit.substr(1);\n      var dt = this.getUTCDateProxy();\n      dt['setUTC' + meth](n);\n      dt.setUTCMinutes(dt.getUTCMinutes() - this.getTimezoneOffset());\n      this.setFromTimeProxy(dt.getTime() + this.getTimezoneOffset() * 60000, this.timezone);\n    },\n    setTimezone: function (tz) {\n      var previousOffset = this.getTimezoneInfo().tzOffset;\n      this.timezone = tz;\n      this._useCache = false;\n      // Set UTC minutes offsets by the delta of the two timezones\n      this.setUTCMinutes(this.getUTCMinutes() - this.getTimezoneInfo().tzOffset + previousOffset);\n    },\n    removeTimezone: function () {\n      this.timezone = null;\n      this._useCache = false;\n    },\n    valueOf: function () { return this.getTime(); },\n    clone: function () {\n      return this.timezone ? new timezoneJS.Date(this.getTime(), this.timezone) : new timezoneJS.Date(this.getTime());\n    },\n    toGMTString: function () { return this.toString('EEE, dd MMM yyyy HH:mm:ss Z', 'Etc/GMT'); },\n    toLocaleString: function () {},\n    toLocaleDateString: function () {},\n    toLocaleTimeString: function () {},\n    toSource: function () {},\n    toISOString: function () { return this.toString('yyyy-MM-ddTHH:mm:ss.SSS', 'Etc/UTC') + 'Z'; },\n    toJSON: function () { return this.toISOString(); },\n    toDateString: function () { return this.toString('EEE MMM dd yyyy'); },\n    toTimeString: function () { return this.toString('H:mm k'); },\n    // Allows different format following ISO8601 format:\n    toString: function (format, tz) {\n      // Default format is the same as toISOString\n      if (!format) format = 'yyyy-MM-dd HH:mm:ss';\n      var result = format;\n      var tzInfo = tz ? timezoneJS.timezone.getTzInfo(this.getTime(), tz) : this.getTimezoneInfo();\n      var _this = this;\n      // If timezone is specified, get a clone of the current Date object and modify it\n      if (tz) {\n        _this = this.clone();\n        _this.setTimezone(tz);\n      }\n      var hours = _this.getHours();\n      return result\n      // fix the same characters in Month names\n      .replace(/a+/g, function () { return 'k'; })\n      // `y`: year\n      .replace(/y+/g, function (token) { return _fixWidth(_this.getFullYear(), token.length); })\n      // `d`: date\n      .replace(/d+/g, function (token) { return _fixWidth(_this.getDate(), token.length); })\n      // `m`: minute\n      .replace(/m+/g, function (token) { return _fixWidth(_this.getMinutes(), token.length); })\n      // `s`: second\n      .replace(/s+/g, function (token) { return _fixWidth(_this.getSeconds(), token.length); })\n      // `S`: millisecond\n      .replace(/S+/g, function (token) { return _fixWidth(_this.getMilliseconds(), token.length); })\n      // 'h': 12 hour format\n      .replace(/h+/g, function (token) { return _fixWidth( ((hours%12) === 0) ? 12 : (hours % 12), token.length); })\n      // `M`: month. Note: `MM` will be the numeric representation (e.g February is 02) but `MMM` will be text representation (e.g February is Feb)\n      .replace(/M+/g, function (token) {\n        var _month = _this.getMonth(),\n        _len = token.length;\n        if (_len > 3) {\n          return timezoneJS.Months[_month];\n        } else if (_len > 2) {\n          return timezoneJS.Months[_month].substring(0, _len);\n        }\n        return _fixWidth(_month + 1, _len);\n      })\n      // `k`: AM/PM\n      .replace(/k+/g, function () {\n        if (hours >= 12) {\n          if (hours > 12) {\n            hours -= 12;\n          }\n          return 'PM';\n        }\n        return 'AM';\n      })\n      // `H`: hour\n      .replace(/H+/g, function (token) { return _fixWidth(hours, token.length); })\n      // `E`: day\n      .replace(/E+/g, function (token) { return DAYS[_this.getDay()].substring(0, token.length); })\n      // `Z`: timezone abbreviation\n      .replace(/Z+/gi, function () { return tzInfo.tzAbbr; });\n    },\n    toUTCString: function () { return this.toGMTString(); },\n    civilToJulianDayNumber: function (y, m, d) {\n      var a;\n      // Adjust for zero-based JS-style array\n      m++;\n      if (m > 12) {\n        a = parseInt(m/12, 10);\n        m = m % 12;\n        y += a;\n      }\n      if (m <= 2) {\n        y -= 1;\n        m += 12;\n      }\n      a = Math.floor(y / 100);\n      var b = 2 - a + Math.floor(a / 4)\n        , jDt = Math.floor(365.25 * (y + 4716)) + Math.floor(30.6001 * (m + 1)) + d + b - 1524;\n      return jDt;\n    },\n    getLocalOffset: function () {\n      return this._dateProxy.getTimezoneOffset();\n    }\n  };\n\n\n  timezoneJS.timezone = new function () {\n    var _this = this\n      , regionMap = {'Etc':'etcetera','EST':'northamerica','MST':'northamerica','HST':'northamerica','EST5EDT':'northamerica','CST6CDT':'northamerica','MST7MDT':'northamerica','PST8PDT':'northamerica','America':['northamerica','southamerica'],'Pacific':'australasia','Atlantic':'europe','Africa':'africa','Indian':'africa','Antarctica':'antarctica','Asia':'asia','Australia':'australasia','Europe':'europe','WET':'europe','CET':'europe','MET':'europe','EET':'europe'}\n      , regionExceptions = {'Pacific/Honolulu':'northamerica','Atlantic/Bermuda':'northamerica','Atlantic/Cape_Verde':'africa','Atlantic/St_Helena':'africa','Indian/Kerguelen':'antarctica','Indian/Chagos':'asia','Indian/Maldives':'asia','Indian/Christmas':'australasia','Indian/Cocos':'australasia','America/Danmarkshavn':'europe','America/Scoresbysund':'europe','America/Godthab':'europe','America/Thule':'europe','Asia/Istanbul':'europe','Asia/Yekaterinburg':'europe','Asia/Omsk':'europe','Asia/Novosibirsk':'europe','Asia/Krasnoyarsk':'europe','Asia/Irkutsk':'europe','Asia/Yakutsk':'europe','Asia/Vladivostok':'europe','Asia/Sakhalin':'europe','Asia/Magadan':'europe','Asia/Kamchatka':'europe','Asia/Anadyr':'europe','Africa/Ceuta':'europe','GMT':'etcetera','Europe/Nicosia':'asia'};\n    function invalidTZError(t) { throw new Error('Timezone \\'' + t + '\\' is either incorrect, or not loaded in the timezone registry.'); }\n    function builtInLoadZoneFile(fileName, opts) {\n      var url = _this.zoneFileBasePath + '/' + fileName;\n      return !opts || !opts.async\n      ? _this.parseZones(_this.transport({ url : url, async : false }))\n      : _this.transport({\n        async: true,\n        url : url,\n        success : function (str) {\n          return _this.parseZones(str) && typeof opts.callback === 'function' && opts.callback();\n        },\n        error : function () {\n          throw new Error('Error retrieving \\'' + url + '\\' zoneinfo files');\n        }\n      });\n    }\n    function getRegionForTimezone(tz) {\n      var exc = regionExceptions[tz]\n        , reg\n        , ret;\n      if (exc) return exc;\n      reg = tz.split('/')[0];\n      ret = regionMap[reg];\n      // If there's nothing listed in the main regions for this TZ, check the 'backward' links\n      if (ret) return ret;\n      var link = _this.zones[tz];\n      if (typeof link === 'string') {\n        return getRegionForTimezone(link);\n      }\n      // Backward-compat file hasn't loaded yet, try looking in there\n      if (!_this.loadedZones.backward) {\n        // This is for obvious legacy zones (e.g., Iceland) that don't even have a prefix like 'America/' that look like normal zones\n        _this.loadZoneFile('backward');\n        return getRegionForTimezone(tz);\n      }\n      invalidTZError(tz);\n    }\n    //str has format hh:mm, can be negative\n    function parseTimeString(str) {\n      var pat = /(\\d+)(?::0*(\\d*))?(?::0*(\\d*))?([wsugz])?$/;\n      var hms = str.match(pat);\n      hms[1] = parseInt(hms[1], 10);\n      hms[2] = hms[2] ? parseInt(hms[2], 10) : 0;\n      hms[3] = hms[3] ? parseInt(hms[3], 10) : 0;\n      return hms.slice(1, 5);\n    }\n    //z is something like `[ '-3:44:40', '-', 'LMT', '1911', 'May', '15', '' ]` or `[ '-5:00', '-', 'EST', '1974', 'Apr', '28', '2:00' ]`\n    function processZone(z) {\n      if (!z[3]) { return; }\n      var yea = parseInt(z[3], 10)\n        , mon = 11\n        , dat = 31;\n      //If month is there\n      if (z[4]) {\n        mon = SHORT_MONTHS[z[4].substr(0, 3)];\n        dat = parseInt(z[5], 10) || 1;\n      }\n      var t = z[6] ? parseTimeString(z[6]) : [0, 0, 0];\n      return [yea, mon, dat, t[0], t[1], t[2]];\n    }\n    function getZone(dt, tz) {\n      var utcMillis = typeof dt === 'number' ? dt : new Date(dt).getTime();\n      var t = tz;\n      var zoneList = _this.zones[t];\n      // Follow links to get to an actual zone\n      while (typeof zoneList === 'string') {\n        t = zoneList;\n        zoneList = _this.zones[t];\n      }\n      if (!zoneList) {\n        // Backward-compat file hasn't loaded yet, try looking in there\n        if (!_this.loadedZones.backward) {\n          //This is for backward entries like 'America/Fort_Wayne' that\n          // getRegionForTimezone *thinks* it has a region file and zone\n          // for (e.g., America => 'northamerica'), but in reality it's a\n          // legacy zone we need the backward file for.\n          _this.loadZoneFile('backward');\n          return getZone(dt, tz);\n        }\n        invalidTZError(t);\n      }\n      if (zoneList.length === 0) {\n        throw new Error('No Zone found for \\'' + tz + '\\' on ' + dt);\n      }\n      //Do backwards lookup since most use cases deal with newer dates.\n      for (var i = zoneList.length - 1; i >= 0; i--) {\n        var z = zoneList[i];\n        if (z[3] && utcMillis > z[3]) break;\n      }\n      return zoneList[i+1];\n    }\n    function getBasicOffset(time) {\n      var off = parseTimeString(time)\n        , adj = time.charAt(0) === '-' ? -1 : 1;\n      off = adj * (((off[0] * 60 + off[1]) * 60 + off[2]) * 1000);\n      return off/60/1000;\n    }\n    function getAdjustedOffset(off, min) {\n      return -Math.ceil(min - off);\n    }\n\n    //if isUTC is true, date is given in UTC, otherwise it's given\n    // in local time (ie. date.getUTC*() returns local time components)\n    function getRule(dt, zone, isUTC) {\n      var date = typeof dt === 'number' ? new Date(dt) : dt;\n      var ruleset = zone[1];\n      var basicOffset = zone[0];\n\n      // If the zone has a DST rule like '1:00', create a rule and return it\n      // instead of looking it up in the parsed rules\n      var staticDstMatch = ruleset.match(/^([0-9]):([0-9][0-9])$/);\n      if (staticDstMatch) {\n        return [-1000000, 'max', '-', 'Jan', 1, [0, 0, 0], parseInt(staticDstMatch[1],10) * 60 + parseInt(staticDstMatch[2], 10), '-'];\n      }\n\n      //Convert a date to UTC. Depending on the 'type' parameter, the date\n      // parameter may be:\n      //\n      // - `u`, `g`, `z`: already UTC (no adjustment).\n      //\n      // - `s`: standard time (adjust for time zone offset but not for DST)\n      //\n      // - `w`: wall clock time (adjust for both time zone and DST offset).\n      //\n      // DST adjustment is done using the rule given as third argument.\n      var convertDateToUTC = function (date, type, rule) {\n        var offset = 0;\n\n        if (type === 'u' || type === 'g' || type === 'z') { // UTC\n          offset = 0;\n        } else if (type === 's') { // Standard Time\n          offset = basicOffset;\n        } else if (type === 'w' || !type) { // Wall Clock Time\n          offset = getAdjustedOffset(basicOffset, rule[6]);\n        } else {\n          throw new Error('unknown type ' + type);\n        }\n        offset *= 60 * 1000; // to millis\n\n        return new Date(date.getTime() + offset);\n      };\n\n      //Step 1:  Find applicable rules for this year.\n      //\n      //Step 2:  Sort the rules by effective date.\n      //\n      //Step 3:  Check requested date to see if a rule has yet taken effect this year.  If not,\n      //\n      //Step 4:  Get the rules for the previous year.  If there isn't an applicable rule for last year, then\n      // there probably is no current time offset since they seem to explicitly turn off the offset\n      // when someone stops observing DST.\n      //\n      // FIXME if this is not the case and we'll walk all the way back (ugh).\n      //\n      //Step 5:  Sort the rules by effective date.\n      //Step 6:  Apply the most recent rule before the current time.\n      var convertRuleToExactDateAndTime = function (yearAndRule, prevRule) {\n        var year = yearAndRule[0]\n          , rule = yearAndRule[1];\n          // Assume that the rule applies to the year of the given date.\n\n        var hms = rule[5];\n        var effectiveDate;\n\n        if (!EXACT_DATE_TIME[year])\n          EXACT_DATE_TIME[year] = {};\n\n        // Result for given parameters is already stored\n        if (EXACT_DATE_TIME[year][rule])\n          effectiveDate = EXACT_DATE_TIME[year][rule];\n        else {\n          //If we have a specific date, use that!\n          if (!isNaN(rule[4])) {\n            effectiveDate = new Date(Date.UTC(year, SHORT_MONTHS[rule[3]], rule[4], hms[0], hms[1], hms[2], 0));\n          }\n          //Let's hunt for the date.\n          else {\n            var targetDay\n              , operator;\n            //Example: `lastThu`\n            if (rule[4].substr(0, 4) === 'last') {\n              // Start at the last day of the month and work backward.\n              effectiveDate = new Date(Date.UTC(year, SHORT_MONTHS[rule[3]] + 1, 1, hms[0] - 24, hms[1], hms[2], 0));\n              targetDay = SHORT_DAYS[rule[4].substr(4, 3)];\n              operator = '<=';\n            }\n            //Example: `Sun>=15`\n            else {\n              //Start at the specified date.\n              effectiveDate = new Date(Date.UTC(year, SHORT_MONTHS[rule[3]], rule[4].substr(5), hms[0], hms[1], hms[2], 0));\n              targetDay = SHORT_DAYS[rule[4].substr(0, 3)];\n              operator = rule[4].substr(3, 2);\n            }\n            var ourDay = effectiveDate.getUTCDay();\n            //Go forwards.\n            if (operator === '>=') {\n              effectiveDate.setUTCDate(effectiveDate.getUTCDate() + (targetDay - ourDay + ((targetDay < ourDay) ? 7 : 0)));\n            }\n            //Go backwards.  Looking for the last of a certain day, or operator is '<=' (less likely).\n            else {\n              effectiveDate.setUTCDate(effectiveDate.getUTCDate() + (targetDay - ourDay - ((targetDay > ourDay) ? 7 : 0)));\n            }\n          }\n          EXACT_DATE_TIME[year][rule] = effectiveDate;\n        }\n\n\n        //If previous rule is given, correct for the fact that the starting time of the current\n        // rule may be specified in local time.\n        if (prevRule) {\n          effectiveDate = convertDateToUTC(effectiveDate, hms[3], prevRule);\n        }\n        return effectiveDate;\n      };\n\n      var findApplicableRules = function (year, ruleset) {\n        var applicableRules = [];\n        for (var i = 0; ruleset && i < ruleset.length; i++) {\n          //Exclude future rules.\n          if (ruleset[i][0] <= year &&\n              (\n                // Date is in a set range.\n                ruleset[i][1] >= year ||\n                // Date is in an 'only' year.\n                  (ruleset[i][0] === year && ruleset[i][1] === 'only') ||\n                //We're in a range from the start year to infinity.\n                    ruleset[i][1] === 'max'\n          )\n             ) {\n               //It's completely okay to have any number of matches here.\n               // Normally we should only see two, but that doesn't preclude other numbers of matches.\n               // These matches are applicable to this year.\n               applicableRules.push([year, ruleset[i]]);\n             }\n        }\n        return applicableRules;\n      };\n\n      var compareDates = function (a, b, prev) {\n        var year, rule;\n        if (!(a instanceof Date)) {\n          year = a[0];\n          rule = a[1];\n          a = (!prev && EXACT_DATE_TIME[year] && EXACT_DATE_TIME[year][rule])\n            ? EXACT_DATE_TIME[year][rule]\n            : convertRuleToExactDateAndTime(a, prev);\n        } else if (prev) {\n          a = convertDateToUTC(a, isUTC ? 'u' : 'w', prev);\n        }\n        if (!(b instanceof Date)) {\n          year = b[0];\n          rule = b[1];\n          b = (!prev && EXACT_DATE_TIME[year] && EXACT_DATE_TIME[year][rule]) ? EXACT_DATE_TIME[year][rule]\n            : convertRuleToExactDateAndTime(b, prev);\n        } else if (prev) {\n          b = convertDateToUTC(b, isUTC ? 'u' : 'w', prev);\n        }\n        a = Number(a);\n        b = Number(b);\n        return a - b;\n      };\n\n      var year = date.getUTCFullYear();\n      var applicableRules;\n\n      applicableRules = findApplicableRules(year, _this.rules[ruleset]);\n      applicableRules.push(date);\n      //While sorting, the time zone in which the rule starting time is specified\n      // is ignored. This is ok as long as the timespan between two DST changes is\n      // larger than the DST offset, which is probably always true.\n      // As the given date may indeed be close to a DST change, it may get sorted\n      // to a wrong position (off by one), which is corrected below.\n      applicableRules.sort(compareDates);\n\n      //If there are not enough past DST rules...\n      if (_arrIndexOf.call(applicableRules, date) < 2) {\n        applicableRules = applicableRules.concat(findApplicableRules(year-1, _this.rules[ruleset]));\n        applicableRules.sort(compareDates);\n      }\n      var pinpoint = _arrIndexOf.call(applicableRules, date);\n      if (pinpoint > 1 && compareDates(date, applicableRules[pinpoint-1], applicableRules[pinpoint-2][1]) < 0) {\n        //The previous rule does not really apply, take the one before that.\n        return applicableRules[pinpoint - 2][1];\n      } else if (pinpoint > 0 && pinpoint < applicableRules.length - 1 && compareDates(date, applicableRules[pinpoint+1], applicableRules[pinpoint-1][1]) > 0) {\n\n        //The next rule does already apply, take that one.\n        return applicableRules[pinpoint + 1][1];\n      } else if (pinpoint === 0) {\n        //No applicable rule found in this and in previous year.\n        return null;\n      }\n      return applicableRules[pinpoint - 1][1];\n    }\n    function getAbbreviation(zone, rule) {\n      var base = zone[2];\n      if (base.indexOf('%s') > -1) {\n        var repl;\n        if (rule) {\n          repl = rule[7] === '-' ? '' : rule[7];\n        }\n        //FIXME: Right now just falling back to Standard --\n        // apparently ought to use the last valid rule,\n        // although in practice that always ought to be Standard\n        else {\n          repl = 'S';\n        }\n        return base.replace('%s', repl);\n      } else if (base.indexOf('/') > -1) {\n        //Chose one of two alternative strings.\n        return base.split('/', 2)[rule ? (rule[6] ? 1 : 0) : 0];\n      }\n      return base;\n    }\n\n    this.zoneFileBasePath = null;\n    this.zoneFiles = ['africa', 'antarctica', 'asia', 'australasia', 'backward', 'etcetera', 'europe', 'northamerica', 'pacificnew', 'southamerica'];\n    this.loadingSchemes = {\n      PRELOAD_ALL: 'preloadAll',\n      LAZY_LOAD: 'lazyLoad',\n      MANUAL_LOAD: 'manualLoad'\n    };\n    this.getRegionForTimezone = getRegionForTimezone;\n    this.loadingScheme = this.loadingSchemes.LAZY_LOAD;\n    this.loadedZones = {};\n    this.zones = {};\n    this.rules = {};\n\n    this.init = function (o) {\n      var opts = { async: true }\n        , def = this.loadingScheme === this.loadingSchemes.PRELOAD_ALL\n          ? this.zoneFiles\n          : (this.defaultZoneFile || 'northamerica');\n      //Override default with any passed-in opts\n      for (var p in o) {\n        opts[p] = o[p];\n      }\n      return this.loadZoneFiles(def, opts);\n    };\n\n    //Get a single zone file, or all files in an array\n    this.loadZoneFiles = function(fileNames, opts) {\n      var callbackFn\n        , done = 0;\n      if (typeof fileNames === 'string') {\n        return this.loadZoneFile(fileNames, opts);\n      }\n      //Wraps callback function in another one that makes\n      // sure all files have been loaded.\n      opts = opts || {};\n      callbackFn = opts.callback;\n      opts.callback = function () {\n        done++;\n        (done === fileNames.length) && typeof callbackFn === 'function' && callbackFn();\n      };\n      for (var i = 0; i < fileNames.length; i++) {\n        this.loadZoneFile(fileNames[i], opts);\n      }\n    };\n    //Get the zone files via XHR -- if the sync flag\n    // is set to true, it's being called by the lazy-loading\n    // mechanism, so the result needs to be returned inline.\n    this.loadZoneFile = function (fileName, opts) {\n      if (typeof this.zoneFileBasePath === 'undefined') {\n        throw new Error('Please define a base path to your zone file directory -- timezoneJS.timezone.zoneFileBasePath.');\n      }\n      //Ignore already loaded zones.\n      if (this.loadedZones[fileName]) {\n        return;\n      }\n      this.loadedZones[fileName] = true;\n      return builtInLoadZoneFile(fileName, opts);\n    };\n    this.loadZoneJSONData = function (url, sync) {\n      var processData = function (data) {\n        data = eval('('+ data +')');\n        for (var z in data.zones) {\n          _this.zones[z] = data.zones[z];\n        }\n        for (var r in data.rules) {\n          _this.rules[r] = data.rules[r];\n        }\n      };\n      return sync\n      ? processData(_this.transport({ url : url, async : false }))\n      : _this.transport({ url : url, success : processData });\n    };\n    this.loadZoneDataFromObject = function (data) {\n      if (!data) { return; }\n      for (var z in data.zones) {\n        _this.zones[z] = data.zones[z];\n      }\n      for (var r in data.rules) {\n        _this.rules[r] = data.rules[r];\n      }\n    };\n    this.getAllZones = function () {\n      var arr = [];\n      for (var z in this.zones) { arr.push(z); }\n      return arr.sort();\n    };\n    this.parseZones = function (str) {\n\n      if (!str) {\n        return false;\n      }\n\n      var lines = str.split('\\n')\n        , arr = []\n        , chunk = ''\n        , l\n        , zone = null\n        , rule = null;\n      for (var i = 0; i < lines.length; i++) {\n        l = lines[i];\n        if (l.match(/^\\s/)) {\n          l = 'Zone ' + zone + l;\n        }\n        l = l.split('#')[0];\n        if (l.length > 3) {\n          arr = l.split(/\\s+/);\n          chunk = arr.shift();\n          //Ignore Leap.\n          switch (chunk) {\n            case 'Zone':\n              zone = arr.shift();\n              if (!_this.zones[zone]) {\n                _this.zones[zone] = [];\n              }\n              if (arr.length < 3) break;\n              //Process zone right here and replace 3rd element with the processed array.\n              arr.splice(3, arr.length, processZone(arr));\n              if (arr[3]) arr[3] = Date.UTC.apply(null, arr[3]);\n              arr[0] = -getBasicOffset(arr[0]);\n              _this.zones[zone].push(arr);\n              break;\n            case 'Rule':\n              rule = arr.shift();\n              if (!_this.rules[rule]) {\n                _this.rules[rule] = [];\n              }\n              //Parse int FROM year and TO year\n              arr[0] = parseInt(arr[0], 10);\n              arr[1] = parseInt(arr[1], 10) || arr[1];\n              //Parse time string AT\n              arr[5] = parseTimeString(arr[5]);\n              //Parse offset SAVE\n              arr[6] = getBasicOffset(arr[6]);\n              _this.rules[rule].push(arr);\n              break;\n            case 'Link':\n              //No zones for these should already exist.\n              if (_this.zones[arr[1]]) {\n                throw new Error('Error with Link ' + arr[1] + '. Cannot create link of a preexisted zone.');\n              }\n              //Create the link.\n              //Links are saved as strings that are the keys\n              //of their referenced values.\n              //Ex: \"US/Central\": \"America/Chicago\"\n              if (isNaN(arr[0])) {\n                _this.zones[arr[1]] = arr[0];\n              }\n              else {\n                _this.zones[arr[1]] = parseInt(arr[0], 10);\n              }\n              break;\n          }\n        }\n      }\n      return true;\n    };\n    //Expose transport mechanism and allow overwrite.\n    this.transport = _transport;\n    this.getTzInfo = function (dt, tz, isUTC) {\n      //Lazy-load any zones not yet loaded.\n      if (this.loadingScheme === this.loadingSchemes.LAZY_LOAD) {\n        //Get the correct region for the zone.\n        var zoneFile = getRegionForTimezone(tz);\n        if (!zoneFile) {\n          throw new Error('Not a valid timezone ID.');\n        }\n        //Get the file and parse it -- use synchronous XHR.\n        this.loadZoneFiles(zoneFile);\n      }\n      var z = getZone(dt, tz);\n      var off = +z[0];\n      //See if the offset needs adjustment.\n      var rule = getRule(dt, z, isUTC);\n      if (rule) {\n        off = getAdjustedOffset(off, rule[6]);\n      }\n      var abbr = getAbbreviation(z, rule);\n      return { tzOffset: off, tzAbbr: abbr };\n    };\n  }();\n}).call(typeof window !== \"undefined\" ? window : this);\n\n\n//# sourceURL=webpack:///./node_modules/timezone-js/src/date.js?");

/***/ })

}]);